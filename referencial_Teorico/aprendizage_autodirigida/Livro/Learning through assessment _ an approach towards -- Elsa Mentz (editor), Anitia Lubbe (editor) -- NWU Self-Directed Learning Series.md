<!-- image -->

/u0045/u0064/u0069.alt /u0074 /u0065 /u0064 /u0020 /u0062 /u0079 /u0045 /u006C /u0073 /u0061 /u0020 /u004D /u0065 /u006E /u0074 /u007A /u0020 /u0026 /u0020 /u0041 /u006E /u0069.alt /u0074 /u0069.alt /u0061 /u0020 /u004C /u0075 /u0062 /u0062 /u0065/u0020

NWU Self-Directed Learning Series Volume 7

## /u004C /u0065 /u0061 /u0072 /u006E /u0069.alt /u006E /u0067 /u0074 /u0068 /u0072 /u006F /u0075 /u0067 /u0068

/u0061 /u0073 /u0073 /u0065 /u0073 /u0073 /u006D /u0065 /u006E /u0074 /u0041/u006E/u0020/u0061/u0070/u0070/u0072/u006F/u0061/u0063/u0068/u0020/u0020 /u0053/u0065/u006C/u0066 /u002D/u0044/u0069.alt/u0072/u0065/u0063/u0074/u0065/u0064/u0020/u0020

/u0074/u006F/u0077/u0061/u0072/u0064/u0073 /u0020/u0020 /u004C/u0065/u0061/u0072/u006E/u0069.alt/u006E/u0067

<!-- image -->

Published by AOSIS Books, an imprint of AOSIS Publishing.

## AOSIS Publishing

15 Oxford Street, Durbanville 7550, Cape Town, South Africa Postnet Suite #110, Private Bag X19, Durbanville 7551, South Africa Tel: +27 21 975 2602

Website: https:/ /www.aosis.co.za

Copyright © Elsa Mentz and Anitia Lubbe (eds.). Licensee: AOSIS (Pty) Ltd The moral right of the author has been asserted.

Cover image: Original design created with the use of provided images. The images are https:/ /www.freepik.com/ free-photo/symbols-come-out-bulb-top-book\_985250.htm#page=1&amp;query=lightbulb%20book&amp;position=0 and https:/ /www.freepik.com/free-photo/closeup-person-filling-out-questionary-form\_1027065.htm#page=1&amp;query=as sessment&amp;position=14, released under Freepik License.

Published in 2021 Impression: 1

ISBN: 978-1-77634-161-0 (print) ISBN: 978-1-77634-162-7 (epub)

ISBN: 978-1-77634-163-4 (pdf)

DOI: https:/ /doi.org/10.4102/aosis.2021.BK280

How to cite this work: Mentz, E. &amp; Lubbe, A. (eds.), 2021, 'Learning through assessment: An approach towards Self-Directed Learning', in NWU Self-Directed Learning Series Volume 7, pp. i-286, AOSIS, Cape Town.

NWU Self-Directed Learning Series ISSN: 2707-1537 Series Editor: Elsa Mentz

Printed and bound in South Africa.

Listed in OAPEN (http:/ /www.oapen.org), DOAB (http:/ /www.doabooks.org/) and indexed by Google Scholar. Some rights reserved.

This is an open access publication. Except where otherwise noted, this work is distributed under the terms of Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International license (CC BY-NC-ND 4.0). A copy of which is available at https:/ /creativecommons.org/licenses/by-nc-nd/4.0/. Enquiries outside the terms of the Creative Commons licence should be sent to the Rights Department, AOSIS, at the above address or to publishing@aosis.co.za.

The publisher accepts no responsibility for any statement made or opinion expressed in this publication. Consequently, the publishers and copyright holder will not be liable for any loss or damage sustained by any reader as a result of his or her action upon any statement or opinion in this work. Links by third-party websites are provided by AOSIS in good faith and for information only. AOSIS disclaims any responsibility for the materials contained in any third-party website referenced in this work.

Every effort has been made to protect the interest of copyright holders. Should any infringement have occurred inadvertently, the publisher apologises and undertakes to amend the omission in the event of a reprint.

NWU Self-Directed Learning Series Volume 7

## /u004C /u0065 /u0061 /u0072 /u006E /u0069.alt /u006E /u0067 /u0074 /u0068 /u0072 /u006F /u0075 /u0067 /u0068 /u0061 /u0073 /u0073 /u0065 /u0073 /u0073 /u006D /u0065 /u006E /u0074

/u0041/u006E/u0020/u0061/u0070/u0070/u0072/u006F/u0061/u0063/u0068/u0020/u0020 /u0074/u006F/u0077/u0061/u0072/u0064/u0073 /u0020/u0020 /u0053/u0065/u006C/u0066 /u002D/u0044/u0069.alt/u0072/u0065/u0063/u0074/u0065/u0064/u0020/u0020 /u004C/u0065/u0061/u0072/u006E/u0069.alt/u006E/u0067

EDITORS Elsa Mentz Anitia Lubbe

<!-- image -->

## Social Sciences, Humanities, Education and Business Management Domain Editorial Board at AOSIS

## Commissioning Editor: Scholarly Books

Andries G. van Aarde, MA, DD, PhD, D Litt, South Africa

## Board Members

Jan Botha, Professor Centre for Research on Evaluation, Science and Technology, Stellenbosch University, Stellenbosch, South Africa

Joan Hambridge, Deputy Dean, Faculty of Humanities, University of Cape Town; Professor, School of Languages and Literatures, University of Cape Town, Cape Town, South Africa

Sakari Häkkinen, Dean, Diocese of Kuopio, Finland

Glenna Jackson, Associate Editor, Professor Chair, Department of Religion and Philosophy, Otterbein University, Westerville, OH, United States of America Gregory C. Jenkins, Dean-elect, St George's College, Jerusalem, Israel Reina-Marie Loader, Director and Filmmaker, CinémaHumain, Vienna, Austria

Babita Marthur-Helm, Senior Lecturer, Organisational Transformation &amp; Development; Managing Diversity Gender Empowerment, University of Stellenbosch Business School, Stellenbosch, South Africa

Christopher Mbazira, Professor of Law and Coordinator of the Public Interest Law Clinic, Makerere University, Kampala, Uganda

Piet Naudé, Professor Ethics Related to Politics, Economics and Business; Director, University of Stellenbosch Business School, Stellenbosch, South Africa

Charles Neill, Professor Department of Business Administration, The British

University in Egypt, El Sherouk, Cairo Governorate, Egypt

Cornelia Pop, Full Professor Department of Business, Faculty of Business, Babes-Bolyai University, Cluj-Napoca, Romania

Michael Schratz, Professor Institut für LehrerInnenbildung und Schulforschung, Dekan der School of Education, Leopold-Franzens-Universität Innsbruck, Innsbruck, Austria Johann Tempelhoff, Professor Research Niche for Cultural Dynamics of Water (CuDyWat), School of Basic Sciences, Vaal Triangle Campus of North-West University, Vanderbijlpark, South Africa

Anthony Turton, Professor Centre for Environmental Management; Director, TouchStone Resources, University of the Free State, Bloemfontein, South Africa Willie L. van der Merwe, Professor and Chair Philosophy of Religion, Apologetics and Encyclopaedia of Theology; Professor Extraordinary, Stellenbosch University, Stellenbosch, South Africa; Vrije Universiteit Amsterdam, Amsterdam, Netherlands Christi van der Westhuizen, Associate Professor Department of Sociology, Faculty of Humanities, University of Pretoria, Pretoria, South Africa

Joke van Saane, Professor Amsterdam Center for the Study of Lived Religion, Vrije Universiteit Amsterdam, Amsterdam, Netherlands

Paul van Tongeren, Professor Department of Philosophy, Radboud University Nijmegen, Nijmegen, Netherlands

Robert G. Varady Deputy Director and Research, Professor Environmental Policy, Udall Center for Studies in Public Policy, The University of Arizona, Tucson, AZ, United States of America

Xiao Yun Zheng, Professor and Assistant President Yunnan Academy of Social Sciences (YASS); Director, International Center for Ecological Culture Studies (ICECS-YASS), Yunnan Academy of Social Sciences, Kunming City, China

## Peer review declaration

The publisher (AOSIS) endorses the South African 'National Scholarly Book Publishers Forum Best Practice for Peer Review of Scholarly Books'. The manuscript was subjected to rigorous two-step peer review before publication, with the identities of the reviewers not revealed to the author(s). The reviewers were independent of the publisher and/or authors in question. The reviewers commented positively on the scholarly merits of the manuscript and recommended that the manuscript be published. Where the reviewers recommended revision and/or improvements to the manuscript, the authors responded adequately to such recommendations.

## Research Justification

This book aims to contribute to the discourse of learning through assessment within a self-directed learning (SDL) environment. It adds to the scholarship of assessment and SDL within a face-to-face and online learning environment.

As part of the NWU Self-Directed Learning Book Series, this book (vol. 7) is devoted to scholarship in the field of SDL, focusing on ongoing and envisaged assessment practices for SDL through which learning within the 21st century can take place. It is important to change the way we think about assessment, not only in higher education institutions but also in the school context, and for assessment practices to be aligned with SDL. This  book  acknowledges and emphasises the role of assessment as a pedagogical tool to foster SDL during face-to-face as well as online learning situations. The way in which higher education conceptualises teaching, learning and assessment has been inevitably changed because of the coronavirus disease 2019 (COVID-19) pandemic. Now more than ever, we need learners to be self-directed in their learning. Assessment plays a key role in learning and, therefore, we have to identify innovative ways in which learning can be assessed and which are likely to become the new norm even after the pandemic has been brought under control. The goal of this book, consisting of original research, is to assist with the paradigm shift regarding the purpose of assessment, as well as to provide new ideas on assessment strategies, methods and tools appropriate to foster SDL in all modes of delivery.

Although all the chapters focus on assessment within a SDL environment, different foci in each chapter contribute to the rich knowledge bank in this field. The 10 chapters, although  eclectic  in  approach  and  based  on  different  methodologies  (conceptual chapters and chapter using mixed-method or qualitative methodologies) - contribute to the broader knowledge base in the field of assessment and SDL.

The target audience of the book includes academics and researchers in the field of SDL in the education landscape.

After  a  call  for  contributions  to  this  book,  the  two  editors  undertook  a  screening process from submitted abstracts to select the chapters for this book. After submission of the final chapters, the editors were responsible for reviewing the content and then provided feedback to authors in order to make amendments where necessary before final  submission  to  the  publisher,  AOSIS.  Thereafter  an  independent  and  rigorous peer review process was administered by AOSIS and amendments were again made where applicable. We are confident that the chapters in this book will contribute to the academic scholarship in the field of SDL and assessment.

In  accordance  with  the  requirements  of  the  Department  of  Higher  Education  and Training, this book contains more than 50% of original research content not published before and no part of the book has been plagiarised.

Elsa Mentz, Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa.

Anitia Lubbe, Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa.

## Contents

| Abbreviations, Boxes, Figures and Tables Appearing in the                                                  |       |
|------------------------------------------------------------------------------------------------------------|-------|
| Text and Notes                                                                                             | xv    |
| List of Abbreviations                                                                                      | xv    |
| List of Boxes                                                                                              | xvii  |
| List of Figures                                                                                            | xvii  |
| List of Tables                                                                                             | xviii |
| Notes on Contributors                                                                                      | xix   |
| Foreword                                                                                                   | xxv   |
| Preface                                                                                                    | xxvii |
| Chapter 1: Self-directed learning-oriented assessment and assessment                                       |       |
| literacy: Essential for 21st century learning                                                              | 1     |
| Anitia Lubbe, Elsa Mentz                                                                                   |       |
| Abstract                                                                                                   | 1     |
| Introduction                                                                                               | 2     |
| Conceptualisation of assessment within a social constructivist learning  perspective                       | 3     |
| Learning-oriented assessment                                                                               | 5     |
| Formative assessment                                                                                       | 6     |
| Assessment for and as learning                                                                             | 7     |
| Self-directed learning-oriented assessment                                                                 | 9     |
| Self-directed learning                                                                                     | 11    |
| The role of metacognition, motivation and self-regulation  in self-directed learning-oriented assessment   | 13    |
| Feedback to support current and future learning within a  self-directed learning-oriented environment      | 14    |
| The important role of assessment literacy within a self-directed  learning-oriented assessment environment | 16    |
| Educators' assessment literacy                                                                             | 17    |
| Students' assessment literacy                                                                              | 19    |
| Self-directed learning-oriented assessment and assessment literacy:  Essential for 21st century learning   | 20    |
| Conclusion                                                                                                 | 24    |
| Acknowledgements                                                                                           | 25    |

| Chapter 2: Assessing axiologolects: Exploring the language of  situated self-directed learning-oriented assessment   | 27   |
|----------------------------------------------------------------------------------------------------------------------|------|
| Jako Olivier                                                                                                         |      |
| Abstract                                                                                                             | 27   |
| Introduction                                                                                                         | 28   |
| Situated self-directed learning-oriented assessment                                                                  | 30   |
| Self-directed learning                                                                                               | 30   |
| Situated learning                                                                                                    | 30   |
| Situated self-directed learning and assessment                                                                       | 31   |
| Axiologolects: A language of assessment                                                                              | 33   |
| Language and assessment                                                                                              | 33   |
| Comprehension                                                                                                        | 34   |
| Readability                                                                                                          | 34   |
| Research methodology                                                                                                 | 35   |
| Research design and orientation                                                                                      | 35   |
| Sampling                                                                                                             | 36   |
| Data collection                                                                                                      | 36   |
| Data analysis                                                                                                        | 37   |
| Inductive content analysis                                                                                           | 37   |
| Corpus linguistic analysis                                                                                           | 37   |
| Readability analysis                                                                                                 | 37   |
| Results                                                                                                              | 38   |
| Results of the inductive content analysis                                                                            | 38   |
| Situated learning                                                                                                    | 38   |
| Aspects fostering self-directed learning                                                                             | 39   |
| Self-directed multimodal learning elements                                                                           | 40   |
| Language issues                                                                                                      | 41   |
| Results of the corpus linguistic analysis                                                                            | 42   |
| Results of the readability tests                                                                                     | 43   |
| Findings and discussion                                                                                              | 45   |
| Recommendations                                                                                                      | 47   |
| Limitations                                                                                                          | 49   |
| Conclusion                                                                                                           | 49   |
| Chapter 3: Self-directed multimodal assessment: Towards assessing  in a more equitable and differentiated way        |      |
|                                                                                                                      | 51   |
| Jako Olivier                                                                                                         |      |
| Abstract                                                                                                             | 51   |
| Introduction                                                                                                         | 52   |
| Self-directed learning-oriented assessment and student agency                                                        | 54   |

| Self-directed learning and assessment                                                            | 54   |
|--------------------------------------------------------------------------------------------------|------|
| From student voice in assessment to student agency                                               | 56   |
| Monomodal and multimodal assessment                                                              | 57   |
| Multimodal learning                                                                              | 57   |
| From multimodal learning to multimodal assessment                                                | 58   |
| Equitable assessment                                                                             | 61   |
| Differentiation and assessment                                                                   | 62   |
| Self-directed multimodal assessment                                                              | 63   |
| From multimodality to self-directed multimodal assessment                                        | 63   |
| Combining modes                                                                                  | 64   |
| Training and preparing for self-directed multimodal assessment                                   | 65   |
| Literacy and self-directed multimodal assessment                                                 | 65   |
| Recommendations for equitable and differentiated self-directed  multimodal assessments           | 67   |
| Conclusion                                                                                       | 69   |
| Chapter 4: Aligning metaliteracy with self-directed learning to  expand assessment opportunities | 71   |
| Trudi E. Jacobson, Thomas P. Mackey, Jako Olivier                                                |      |
| Abstract                                                                                         | 72   |
| Introduction                                                                                     | 72   |
| The metaliteracy framework                                                                       | 73   |
| Introducing the framework                                                                        | 73   |
| The core components of metaliteracy                                                              | 75   |
| Learning domains                                                                                 | 75   |
| Learner roles                                                                                    | 77   |
| Characteristics                                                                                  | 79   |
| Goals and learning objectives                                                                    | 79   |
| Self-directed learning viewed through the lens of metaliteracy                                   | 80   |
| Defining self-directed learning                                                                  | 80   |
| Approaches to self-directed learning                                                             | 81   |
| Self-directed learning and the online environment                                                | 82   |
| Self-directed learning and assessment                                                            | 82   |
| Integrating self-directed learning and assessment with metaliteracy's  core components           | 83   |
| Affective learning domain                                                                        | 83   |
| Metacognitive learning domain                                                                    | 85   |
|                                                                                                  | 88   |
| Behavioural learning domain                                                                      |      |
| Metaliteracy, assessment and self-directed learning in action                                    | 88   |

| Adapting a self-directed digital badging challenge to  educational planning                                                | 89   |
|----------------------------------------------------------------------------------------------------------------------------|------|
| Developing metaliteracy and self-directed learning in a culture of  assessment in an information literacy course           | 92   |
| Course expectations and focus                                                                                              | 93   |
| Spotlight on self-directed learning and assessment                                                                         | 95   |
| Conclusion                                                                                                                 | 97   |
| Chapter 5: Leveraging student self-directed learning through online  tutoring and integrated ipsative assessment           | 99   |
| Iman C. Chahine ,  Saeid Belkasim                                                                                          |      |
| Abstract                                                                                                                   | 100  |
| Introduction                                                                                                               | 100  |
| Ipsative assessment in the context of self-directed learning                                                               | 102  |
| Peer and self-assessment                                                                                                   | 105  |
| Peer assessment                                                                                                            | 105  |
| Self-assessment                                                                                                            | 106  |
| Strategies for peer and self-assessment                                                                                    | 106  |
| Ipsative feedback                                                                                                          | 107  |
| Background: Role of technology in ipsative assessment                                                                      | 109  |
| Computer adaptive tests                                                                                                    | 110  |
| Online tutoring community                                                                                                  | 112  |
| Online collaboration and knowledge assessment                                                                              | 113  |
| Online tutoring system design                                                                                              | 114  |
| Ipsative assessment of students using the system                                                                           | 118  |
| Prototype system implementation and preliminary results                                                                    | 119  |
| Conclusion                                                                                                                 | 120  |
| Chapter 6: Assessment as an epistemological tool to facilitate  metacognitive awareness and promote self-directed learning | 123  |
| Divan Jagals                                                                                                               |      |
| Abstract                                                                                                                   | 123  |
| Introduction                                                                                                               | 124  |
| Setting of the context                                                                                                     | 125  |
| The ontology of assessment                                                                                                 | 126  |
| Conceptual framework                                                                                                       | 128  |
| Assessment and assessment literacy                                                                                         | 128  |
| The agenda of assessment                                                                                                   | 129  |
| Aspects of assessment literacy                                                                                             | 129  |
| Conceptualising assessment in terms of metacognition                                                                       | 130  |

| Facilitating metacognitive awareness                                                                                                | 130   |
|-------------------------------------------------------------------------------------------------------------------------------------|-------|
| Awareness of metacognitive knowledge                                                                                                | 131   |
| Awareness of metacognitive regulation                                                                                               | 132   |
| Self-directed learning in assessment                                                                                                | 133   |
| Theoretical orientation                                                                                                             | 134   |
| Awareness on an implicit level                                                                                                      | 135   |
| Awareness on a perceptual level                                                                                                     | 135   |
| Awareness as a metarepresentation                                                                                                   | 135   |
| Philosophical analysis                                                                                                              | 136   |
| The self in assessment                                                                                                              | 139   |
| The use of assessment as an epistemological tool                                                                                    | 140   |
| Conclusion                                                                                                                          | 141   |
| Chapter 7: Value of feedback during the implementation of the  group-individual-group cooperative learning method of assessment     | 143   |
| Elsa Mentz, Anitia Lubbe                                                                                                            |       |
| Abstract                                                                                                                            | 143   |
| Introduction                                                                                                                        | 144   |
| Problem statement                                                                                                                   | 144   |
| Theoretical and conceptual framework                                                                                                | 145   |
| Social constructivist perspective                                                                                                   | 146   |
| Sustainable assessment                                                                                                              | 146   |
| Assessment feedback within sustainable assessment                                                                                   | 147   |
| Cooperative learning environment conducive to  assessment feedback                                                                  | 149   |
| The group-individual-group cooperative method of assessment                                                                         | 150   |
| Effectiveness of the assessment feedback in the group-individual-group  cooperative learning method of assessment                   | 153   |
| Results                                                                                                                             | 154   |
| Evaluation of the group-individual-group cooperative  learning method of assessment according to sustainable  assessment principles | 154   |
| Results Related to Student and Teacher Perceptions of Feedback                                                                      | 157   |
| Increased learning and knowledge acquisition                                                                                        | 158   |
| Broadened horizons                                                                                                                  | 158   |
| Acknowledgement of multiple answers and perspectives                                                                                | 158   |
| Motivation for future learning                                                                                                      | 158   |
| Exposure to different learning strategies and study skills for  future learning                                                     | 159   |
| Improved understanding and clarification                                                                                            | 159   |
| Identification of own gaps                                                                                                          | 159   |

| Timely assistance                                                                                                                                           | 159   |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|
| Peer interaction                                                                                                                                            | 160   |
| Peer assistance                                                                                                                                             | 160   |
| Discussion                                                                                                                                                  | 160   |
| Conclusion                                                                                                                                                  | 163   |
| Acknowledgements                                                                                                                                            | 163   |
| Chapter 8: Assessment: The driving force behind self-directed                                                                                               |       |
| learning in English teacher training  Marike Annandale, Elizabeth M. Reyneke                                                                                | 165   |
| Abstract                                                                                                                                                    | 165   |
| Introduction                                                                                                                                                | 166   |
| English as the global lingua franca                                                                                                                         | 167   |
| The role of English in South Africa and its implications for  English teacher training                                                                      | 168   |
| English teacher training in the third year of the B.Ed. Senior and  Further Education and Training phase at a higher education  institution in South Africa | 171   |
| Outcomes of the English for Education third-year modules                                                                                                    | 171   |
| High-quality learning experiences promoting critical  engagement and self-directed learning                                                                 | 173   |
| Quality assessment that enhances critical engagement and  self-directed learning                                                                            | 176   |
| Feedback                                                                                                                                                    | 178   |
| A variety of innovative assessment tasks                                                                                                                    | 180   |
| Critical thinking and problem-solving                                                                                                                       | 181   |
| Integration of topics and their relevance                                                                                                                   | 183   |
| Conclusion                                                                                                                                                  | 184   |
| to enhance self-directed learning                                                                                                                           | 187   |
| Abstract                                                                                                                                                    | 187   |
| Introduction                                                                                                                                                | 188   |
| Problem statement                                                                                                                                           | 189   |
| Theoretical-conceptual framework                                                                                                                            | 190   |
| Self-directed learning                                                                                                                                      | 191   |
| Digital learning                                                                                                                                            | 193   |
| Online marking                                                                                                                                              | 195   |
| Formative assessment                                                                                                                                        | 197   |
| Feedback                                                                                                                                                    | 199   |

| Research methodology                                                                                                                                                           |   201 |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|
| Research approach                                                                                                                                                              |   201 |
| Population and sample                                                                                                                                                          |   201 |
| Quantitative methods and instruments                                                                                                                                           |   202 |
| Qualitative methods and instruments                                                                                                                                            |   202 |
| Findings                                                                                                                                                                       |   203 |
| Quantitative finding                                                                                                                                                           |   203 |
| Qualitative findings                                                                                                                                                           |   205 |
| The effect of electronic feedback on student's learning                                                                                                                        |   206 |
| A basis for being independent                                                                                                                                                  |   206 |
| Detailed feedback, self-assessment and self-reflection                                                                                                                         |   206 |
| Feedback to guide the improvement of learning                                                                                                                                  |   207 |
| Improved end product                                                                                                                                                           |   207 |
| Experiences of electronic marking and feedback                                                                                                                                 |   207 |
| Perceived quality of feedback                                                                                                                                                  |   207 |
| Speed of feedback                                                                                                                                                              |   208 |
| Future implementation of electronic marking                                                                                                                                    |   208 |
| Attitude towards electronic feedback                                                                                                                                           |   208 |
| Factors that influence the electronic marking and feedback  experience                                                                                                         |   209 |
| Emergency remote teaching and learning                                                                                                                                         |   209 |
| Minimal interaction for students                                                                                                                                               |   209 |
| Discussion                                                                                                                                                                     |   210 |
| Conclusion                                                                                                                                                                     |   214 |
| Chapter 10: The role of teachers' assessment beliefs in fostering  self-directed learning skills within the school learning context  and its implications for higher education |   217 |
| Abstract                                                                                                                                                                       |   218 |
| Introduction                                                                                                                                                                   |   218 |
| Conceptual and theoretical framework                                                                                                                                           |   219 |
| The link between assessment beliefs and actual assessment actions                                                                                                              |   221 |
| The link between attributions and learner behaviour                                                                                                                            |   222 |
| Research methods                                                                                                                                                               |   225 |
| Capturing teachers' assessment beliefs                                                                                                                                         |   225 |
| Capturing learners' self-directed learning behaviour                                                                                                                           |   226 |
| Procedures                                                                                                                                                                     |   226 |
| Research findings                                                                                                                                                              |   227 |
| Teachers' assessment beliefs                                                                                                                                                   |   227 |
| Assessment is for the improvement of learning                                                                                                                                  |   228 |

| Assessment is for the improvement of teaching                                                    |   228 |
|--------------------------------------------------------------------------------------------------|-------|
| Assessment is for certifying learners                                                            |   228 |
| Assessment serves as a way of certifying learning                                                |   229 |
| Assessment provides insight into teacher effectiveness                                           |   229 |
| Assessment has a negative impact on learners                                                     |   229 |
| Assessment has little impact on teaching and learning                                            |   230 |
| How do teachers' assessment beliefs influence the self-directed  learning behaviour of learners? |   231 |
| Social skills should be developed in the Natural Sciences classroom                              |   231 |
| Learning strategies that foster transmission mode                                                |   232 |
| Learning strategies that foster making sense of ideas                                            |   232 |
| Approach to studying is characterised by lack of motivation                                      |   233 |
| Goal setting is focused on aiming for good results                                               |   234 |
| Taking responsibility for learning                                                               |   234 |
| Learners could evaluate their own learning progress                                              |   235 |
| Learners have a strong dependency on teachers to evaluate  their work                            |   235 |
| Attribute success or failure to task difficulty                                                  |   236 |
| Attributes success or failure to effort taken towards a task                                     |   236 |
| The tendency of learners to become motivated                                                     |   236 |
| The influence of the belief that assessment holds learners  accountable                          |   237 |
| The influence of the belief that assessment holds teachers  accountable                          |   238 |
| The influence of the belief that assessment improves  teaching and learning                      |   240 |
| The influence of the belief that assessment is irrelevant to  teaching and learning              |   241 |
| Discussion                                                                                       |   242 |
| Emphasis by teachers was on preparing learners for examinations                                  |   245 |
| Emphasis by learners was on obtaining good grades                                                |   245 |
| Absence of assessment methods like self- and peer-assessment                                     |   246 |
| Dominance of teacher-centred approaches                                                          |   246 |
| Threatening learning environments                                                                |   247 |
| Contextual factors that hinder learning                                                          |   248 |
| Inadequate implementation of the assessment policy                                               |   248 |
| Implications for higher education and conclusion                                                 |   249 |
| Conclusion                                                                                       |   250 |
| References                                                                                       |   251 |
| Index                                                                                            |   285 |

## Abbreviations, Boxes, Figures and Tables Appearing in the Text and Notes

## List of Abbreviations

AaL

Assessment as Learning

AfL

Assessment for Learning

AI

Artificial Intelligence

AoL

Assessment of Learning

BICS

Basic Interpersonal Communication Skills

CAA

Computer Assisted Assessment

CALP

Cognitive Academic Language Proficiency

CALT

Computer Adaptive Language Testing

CAPS

Curriculum and Assessment Policy Statement

CAT

Computer Adaptive Test

CBT

Computer-Based Test

CDL

Center for Distance Learning

CEEA

Canadian Engineering Education Association

CHAT

Cultural-Historical Activity Theory

CL

Cooperative Learning

CLMoA

Cooperative Learning Method of Assessment

CRESST

Centre for Research on Evaluation, Standards, and Student Testing

CTT

Classic Test Theory

DBE

Department of Basic Education

EAL

English Additional Language

EASA

Education Association of South Africa

EFAL

English First Additional Language

EHL

English Home Language

EP

Evidence of Performance

EX

Examinations

FET

Further Education and Training

GA

General Assessments

GIG

Group-Individual-Group

HEI

Higher Education Institutions

ICEP

International Conference on Engaging Pedagogy

| ICLS   | International Conference of the Learning Sciences   |
|--------|-----------------------------------------------------|
| IL     | Information Literacy                                |
| IRT    | Item Response Theory                                |
| ITS    | Intelligent Tutoring Systems                        |
| LMS    | Learning Management System                          |
| LOA    | Learning-Oriented Assessment                        |
| LoLT   | Language of Learning and Teaching                   |
| MDCA   | Multimodal Digital Classroom Assessments            |
| MDT    | Measurement Decision Theory                         |
| ML     | Metaliteracy Learning                               |
| MOOC   | Massive Open Online Courses                         |
| NDA    | Non-Disposable or Renewable Assignments             |
| NILOA  | National Institute for Learning Outcomes Assessment |
| NRF    | National Research Foundation                        |
| NS     | Natural Sciences                                    |
| OER    | Open Educational Resources                          |
| PDF    | Portable Document Format                            |
| PLA    | Prior Learning Assessment                           |
| PRO    | Personal Responsibility Orientation                 |
| QFT    | Question Formulation Technique                      |
| RU     | Rubrics                                             |
| SDL    | Self-Directed Learning                              |
| SDLI   | Self-Directed Learning Instrument                   |
| SDLT   | Self-Directed Learning with Technology              |
| SDLTS  | Self-Directed Learning with Technology Scale        |
| SDMA   | Self-Directed Multimodal Assessment                 |
| SDML   | Self-Directed Multimodal Learning                   |
| SES    | Supplemental Educational Services                   |
| SLOA   | Self-Directed Learning-Oriented Assessment          |
| SRL    | Self-Regulated Learning                             |
| SRSSDL | Self-Rating Scale of Self-Directed Learning         |
| TALiP  | Teacher Assessment Literacy in Practice             |
| TE     | Tests                                               |
| TEFL   | Teaching English as a Foreign Language              |
| ZPD    | Zone of Proximal Development                        |

List of Boxes

| Box  1.1: Five key strategies of formative assessment.                                                                                  | 8   |
|-----------------------------------------------------------------------------------------------------------------------------------------|-----|
| Box  1.2: Self-directed learning skills and competencies.                                                                               | 12  |
| Box  1.3:   Four types of knowledge and skills relating to educators'  assessment literacy.                                             | 19  |
| List of Figures                                                                                                                         |     |
| Figure  1.1: Mind map of assessment nomenclature.                                                                                       | 4   |
| Figure  1.2:   Theoretical underpinnings of self-directed learning-oriented  assessment.                                                | 10  |
| Figure  1.3:   Summary of the importance of assessment literacy and its  influence on assessment and self-directed learning.            | 22  |
| Figure  5.1:   Depiction of ipsative longitudinal assessment process.                                                                   | 103 |
| Figure  5.2: Components of ipsative assessments.                                                                                        | 104 |
| Figure  5.3:   Depiction of the general architecture of the knowledge  evaluation system.                                               | 113 |
| Figure  5.4: Depiction of online tutoring system architecture and framework.                                                            | 115 |
| Figure  5.5:   Depiction of the ipsative assessment activity using  Bayesian Theorem.                                                   | 117 |
| Figure  5.6: Depiction of the structure of topics and related questions.                                                                | 118 |
| Figure  5.7:   Depiction of the iterative ipsative assessment of  student knowledge.                                                    | 119 |
| Figure  6.1: The self in self-directed learning.                                                                                        | 139 |
| Figure  7.1:   Graphical representation of the group-individual-group  cooperative learning method of assessment.                       | 152 |
| Figure  8.1: Processes of semantic change: Self-study (Example 1).                                                                      | 174 |
| Figure  8.2:   Pertinent questions: Speaking and writing (Romylos  et al. 2020a:18-19).                                                 | 174 |
| Figure  9.1: Number of student participants per year group.                                                                             | 203 |
| Figure  9.2: Number of student participants per subject area.                                                                           | 204 |
| Figure  9.3:   Number of participants in a specific category of self-directed  learning.                                                | 205 |
| Figure  10.1: An illustration of the connection between teachers'  assessment beliefs and learners' self-directed   learning behaviour. | 220 |

| Figure  10.2:   An example of an activity triangle used in the  cultural-historical activity theory framework.                              | 224   |
|---------------------------------------------------------------------------------------------------------------------------------------------|-------|
| Figure  10.3:   Cultural-historical activity theory as a research lens to  further analyse data.                                            | 244   |
| List of Tables                                                                                                                              |       |
| Table  1.1:   Principles for design and implementation of learning-oriented  assessment tasks.                                              | 6     |
| Table 2.1:  Summary of the assessment text dataset.                                                                                         | 36    |
| Table 2.2: Verb frequency based on the Revised Bloom's Taxonomy  Action Verbs.                                                              | 42    |
| Table 2.3:  Summary of the corpus and readability scores.                                                                                   | 44    |
| Table  4.1: I  nterconnections between metaliteracy, self-directed learning  and assessment.                                                | 95    |
| Table  5.1: Peer and self-assessment strategies and key benefits.                                                                           | 107   |
| Table  5.2:   Requirements for system maintenance as proposed by the  second author.                                                        | 118   |
| Table  6.1:   Conceptualisation of assessment practice.                                                                                     | 126   |
| Table  6.2:   Conditions of an epistemology of engagement in relation to  the levels of metacognitive awareness.                            | 137   |
| Table  7.1:   Group-individual-group cooperative learning method of  assessment measured against principles of sustainable   assessment.    | 155   |
| Table  7.2:   Group-individual-group cooperative learning method of  assessment measured against principles of successful feedback.         | 156   |
| Table  8.1:   Guidelines for employing the four characteristics of  quality assessment to enhance self-directed learning.                   | 177   |
| Table  9.1: Assessment OF, FOR and AS learning.                                                                                             | 199   |
| Table  9.2: Construct reliability for each section.                                                                                         | 205   |
| Table  9.3: Themes and categories.                                                                                                          | 206   |
| Table  10.1:   Brown's (2002:27) categories of teacher assessment  conceptions, which include Opre's (2015:229) implications  for practice. | 221   |
| Table  10.2: Summary of Natural Sciences teachers' assessment beliefs.                                                                      | 231   |

## Notes on Contributors

## Marike Annandale

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: 24116297@g.nwu.ac.za ORCID: https:/ /orcid.org/0000-0002-4421-0873

Marike Annandale is a lecturer and the programme leader for the Senior and FET phase  at  the  Faculty  of  Education  at  the  North-West  University  (NWU).  She teaches English for Education to the students who study via distance learning. Her research focus area is in self-directed learning with an emphasis on how this manifests  in  English  language  education  and  training  at  tertiary  education institutions. Mrs Annandale started her career as a junior lecturer at the NWU in 2018 and has been immersed in English distance learning teaching ever since.

## Saeid Belkasim

Department of Computer Science, Georgia State University, Atlanta, GA, United States of America Email: sbelkasim@gsu.edu

ORCID: https:/ /orcid.org/0000-0001-5704-6198

Saeid Belksim is an Associate Professor at the Department of Computer Science at Georgia State University. He is a well-known researcher in image processing, shape retrieval and pattern recognition. He has more than 80 publications in prestigious  journals  and  conference  proceedings.  Dr  Belkasim's  research publications have been cited in several books, theses and over 2000 refereed international journals and conference proceedings. The most cited publication is the comparative study of moment invariants for extracting shape features. This article won the prestigious most honourable mention award given by the international pattern recognition society. Dr Belkasim's research has been used as a benchmark by many researchers. He has pioneered many of the techniques in the state of the art of current research. Some of these techniques have been named by other researchers as Belkasim's method, a clear indication of the strong recognition he attained in the research community.

## Byron J. Bunt

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Vanderbijlpark, South Africa Email: byron.bunt@nwu.ac.za

ORCID: https:/ /orcid.org/0000-0002-2102-4381

Byron  J.  Bunt  is  a  lecturer  in  the  Faculty  of  Education  of  the  North-West University and is part of the research unit Self-Directed Learning. He has been

working  in  the  field  of  teacher  education  for  the  past  nine  years,  and  his research  niche  encompasses  cognitive  education,  with  a  specific  focus  on developing students' creative and critical thinking through the use of various teaching strategies and technology. He has published in the fields of history education and teacher education. He is the author of the chapter entitled Cognitive development strategies within the History classroom in the book Teaching and Learning History and Geography ,  published  by  Van  Schaik  in 2018.  He  has  begun  a  scholarship  of  teaching  and  learning  project  which involves the use of a self-developed trading card game called Dogs of War, which will be used within his History classroom with the aim of developing the self-directed learning abilities of his students. Before lecturing, he worked as a  teacher  at  General  Smuts  High  School  in  Vereeniging,  teaching  Social Science and Technology.

## Iman C. Chahine

Department of Curriculum &amp; Instruction,

College of Education, University of Massachusetts Lowell, Lowell, MA, United States of America; Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: iman\_Chahine@uml.edu ORCID: https:/ /orcid.org/0000-0001-7066-3625

Iman C. Chahine is an Extraordinary Professor in the Research Unit Self-Directed Learning  at  the  Faculty  of  Education,  North-West  University.  She  is  also  an Associate Professor  of  Mathematics  Education  at  the  University  of  Massachusetts Lowell in the US, a Fulbright US Scholar in South Africa and the Co-editor of the Journal of Mathematics and Culture. Her main research focus is on ethnomathematics and indigenous  mathematical  knowledge  systems  across cultural contexts. She has received several recognitions, including the National Science Foundation STaR Award and EERA (a branch of AERA) Director of Awards,  and  is  currently  involved  in  researching  the  ethnomathematical practices  in  the  workplace  and  the  role  of  immersion  in  enhancing  teacher performance. She serves as the treasurer for the International Study Group on Ethnomathematics (ISGEm). She has published at the national and international levels, and she also acts as a supervisor for postgraduate students .

## Josef de Beer

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: josef.debeer@nwu.ac.za ORCID: https:/ /orcid.org/0000-0002-2411-6599

Josef  de  Beer  is  a  Research  Professor  in  the  Research  Unit  Self-Directed Learning, in the Faculty of Education, North-West University. His main research focus is on the affordances of indigenous knowledge to enhance self-directed

learning  in  the  Natural  Sciences.  Accolades  include  the  National  Research Foundation's Excellence in Science Engagement' Award that Josef received in 2019,  and  the  Education  Association  of  South  Africa's  Medal  of  Honour  in 2020. Josef is the principal investigator in a Fuchs Foundation funded project, 'Teachers  without  Borders'.  He  has  published  at  national  and  international level, and acts as supervisor for postgraduate students.

## Trudi E. Jacobson

Information Literacy Department, University Libraries, University at Albany, State University of New York, Albany, NY, United States of America; Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: tjacobson@albany.edu ORCID: https:/ /orcid.org/0000-0001-8444-276X

Trudi E. Jacobson is  an Extraordinary Professor in the Research Unit Self-Directed Learning  at the Faculty of Education, North-West University, and the head of the Information Literacy Department and a distinguished librarian at the University at Albany, SUNY. She is also an Adjunct Professor in UAlbany's First Year Experience and MS Information Science programs. Her research focuses on metaliteracy, information  literacy  and  open  pedagogy.  She  co-chaired  the  Association  of College and Research Libraries' task force that developed the Framework for Information Literacy for Higher Education. She has co-authored and co-edited numerous books on metaliteracy, digital badging, instructional collaborations for information literacy and motivation in connection with information literacy. She has also written or co-written many articles and book chapters. Her newest book, Metaliterate Learner as Producer, written with Prof. Thomas P. Mackey, will be published in 2022 by Neal-Schuman/ALA Editions.

## Divan Jagals

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: divan.jagals@nwu.ac.za

ORCID: https:/ /orcid.org/0000-0001-5840-6298

Divan  Jagals  is  a  senior  lecturer  in  the  School  for  Professional  Studies  of Education at the Faculty of Education, North-West University. His research interests include the facilitation of metacognitive awareness through mediating tools  such  as  ontological,  epistemological  and  methodological  tools  to understand and promote self-directed learning. He has received a number of research grants and was selected as one of three research fellows under the UNESCO Chair for Personalised and Adaptive Distance Education at the Swiss Distance University of Applied Sciences, Brig, Switzerland. He has published at  the  national  and  international  levels,  and  also  acts  as  a  supervisor  for postgraduate students.

## Effiness M. Kamanga

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: efkamanga@yahoo.com ORCID: https:/ /orcid.org/0000-0001-6577-2747

Effiness Kamanga is a secondary school teacher at Tshukudu High School in the North-West province. Her area of expertise includes teaching Grade 8 and 9 Natural Sciences and Grade 11 and 12 Physical Sciences. She completed her MEd in Curriculum studies in the Research Unit Self-Directed Learning at the North-West University, Potchefstroom campus, cum laude. Her  dissertation entitled, 'The influence of Natural Sciences teachers' assessment beliefs on Grade  9  learners'  self-directed  learning  behaviour'  forms  the  basis  of  the research reported in this chapter. She is currently continuing her research on assessment in the Natural Sciences, for a PhD study.

## Anitia Lubbe

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: anitia.lubbe@nwu.ac.za ORCID: https:/ /orcid.org/0000-0001-5687-1030

Anitia Lubbe has been working in the field of teacher education since 2011, and her research niche encompasses assessment, assessment literacy, cooperative learning  and  self-directed  learning.  Her  PhD,  entitled  'Cooperative  learningoriented  assessment:  Implications  for  students'  assessment  literacy  and  selfdirectedness  in  learning',  is  an  amalgamation  of  her  research  interests  in cooperative learning, assessment and self-directed learning. She has published at national level, and acts as supervisor for postgraduate students. She is currently also part of two research projects with a specific focus on assessment for SDL.

## Thomas P. Mackey

School of Arts and Humanities, State University of New York (SUNY) Empire State College, Albany, NY, United States of America; Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: tom.mackey@esc.edu ORCID: https:/ /orcid.org/0000-0001-8148-9992

Thomas P. Mackey is an Extraordinary Professor in the Research Unit SelfDirected  Learning  at  the  Faculty  of  Education,  North-West  University  in South Africa and a Professor of Arts and Media in the School of Arts and Humanities  at  State  University  of  New  York  (SUNY)  Empire  State  College. His research into metaliteracy, a pedagogical framework he originated with Trudi E. Jacobson, emphasises the learner as producer in social information

environments. He has published books on this topic, as well as peer-reviewed articles  and  conference  proceedings,  and  has  been  invited  to  keynote internationally  on  his  metaliteracy  research.  Prior  to  his  current  faculty appointment, he served as Associate Dean and Dean of the Center for Distance Learning (CDL), and in senior management roles as Vice Provost for Academic Programs and Interim Provost. He teaches courses in History and Theory of New Media, Information Design, Digital Storytelling, and Ethics of Digital Art and  Design  and  has  developed  several  international  Massive  Open  Online Courses (MOOCs) about metaliteracy.

## Elsa Mentz

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: elsa.mentz@nwu.ac.za ORCID: https:/ /orcid.org/0000-0002-7267-080X

Elsa  Mentz  is  the  Research  Director  for  the  Research  Unit  Self-Directed Learning at the Faculty of Education of the North-West University. She is also a Professor in Computer Science Education and her main research focus is the promotion of Self-Directed Learning through the implementation of cooperative learning. She has acted for extended periods as Executive Dean of the Faculty of Education at the North-West University. She is a National Research Foundation (NRF) rated researcher and editor of book publications entitled 'Self-directed learning research: An imperative for transforming the educational  landscape'  and  'Self-directed  Learning  for  the  21st  Century: Implications  for  Higher  Education'.  She  received  several  research  awards, including the 2020 Malcom Knowles award for significant lifelong contributions to  the  field  of  self-directed  learning  and  the  2020  Research  medal  of  the Education Association of South Africa. She completed several funded research projects, has published at national and international level and acts as supervisor for postgraduate students.

## Jako Olivier

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Mahikeng, South Africa Email: jako.olivier@nwu.ac.za ORCID: https:/ /orcid.org/0000-0002-5860-6027

Jako Olivier is the holder of the UNESCO Chair in Multimodal Learning and Open Educational Resources and is a Professor of Multimodal Learning in the Faculty of Education at North-West University (NWU). His research, within the  NWU's  Research  Unit  Self-Directed  Learning,  focuses  on  self-directed multimodal  learning,  open  educational  resources,  multiliteracies,  blended and e-learning in language classrooms as well as multilingualism in education.

He currently holds a Y rating from the National Research Foundation (NRF) and was awarded the Education Association of South Africa (EASA) Emerging Researcher  Medal  in  2018.  In  addition  to  recently  editing  a  book  on  selfdirected multimodal learning, he has published numerous articles and book chapters at the national and international levels, and he also acts as a supervisor for postgraduate students.

## Elizabeth M. Reyneke

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa Email: maryna.reyneke@nwu.ac.za

ORCID: https:/ /orcid.org/0000-0001-9499-4306

Elizabeth  M.  Reyneke  is  the  Deputy  Dean  (Teaching  and  Learning)  at  the Faculty  of  Education  at  the  North-West  University  (NWU).  She  is  also  an Associate  Professor  in  the  Subject  Group  English  for  Education.  Her  main research focus is on Assessment, and English across the Curriculum to enhance self-directed learning. Professor Reyneke is currently leading a project that focuses on training academic staff across the different faculties and campuses of the NWU to implement Multilingual Pedagogies in teaching and assessment. She has been involved in teacher training for the past 17 years after working in Secondary  Education  for  17  years.  She  has  published  at  national  and international levels, and is experienced in postgraduate supervision.

## Gideon van Tonder

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Vanderbijlpark, South Africa Email: deon.vantonder@nwu.ac.za ORCID: https:/ /orcid.org/0000-0001-5486-1242

Gideon  (GP)  van  Tonder  holds  a  PhD  in  Education  Management.  He  has worked in the field of teacher education for the past 31 years. Since 2011, he has concentrated on the professional development of teachers, in particular on internships, induction, self-directed learning and various teaching strategies. He believes in inspiring individuals and, as Deputy Director of the School of Commerce and Social Studies,  he  has  established  and  led  a  school-based project: ' Establishing  the  merits  of  a  school-wide  community  of  practice project  utilising  teaching  strategies  for  the  development  of  self-directed learning'. Through  this  initiative,  he  improves  research  among  staff  and promotes self-directed learning skills of pre-service teachers through a variety of  teaching  strategies.  Dr  Van  Tonder  was  awarded  the  NWU  Teaching Excellence Award in 2019 and received the Distinguished Teaching Excellence Award in the same year.

## Foreword

## David Carless a,b

a Faculty of Education, University of Hong Kong, Pokfulam, Hong Kong b Honorary Research Fellow, Faculty of Education, North-West University, Potchefstroom, South Africa

An enduring educational challenge is to design assessment so that it functions both as a productive learning tool and a reliable measuring one. This edited collection by scholars at North-West University makes a useful contribution to contemporary debates by analysing and exemplifying the linkages between SDL and learning-oriented assessment approaches.

In SDL, students take ownership of their own learning with the guidance of the teacher. Learners formulate goals, choose appropriate learning strategies and self-evaluate progress towards learning outcomes. Self-directed learners often  work  in  teams  because  complex  learning  can  rarely  be  achieved  in isolation. Through SDL, students develop many of the capacities needed for lifelong learning.

Assessment  drives  the  content  and  approaches  of  student  learning.  If assessment tasks are not seen to encourage or promote SDL, then students may choose surface or passive approaches to learning. Self-directed learning implies a need for participative assessment practices which involve collaboration, peer feedback and student self-evaluation.

I  have  previously  suggested  that  learning-oriented  assessment  involves three  interlocking  components:  well-designed  assessment  tasks,  students' development of self-evaluative capacities, and active student involvement in feedback  processes  (Carless  2015a). This learning-oriented assessment framework coheres well with ideas on SDL because it highlights the importance of student self-assessment and a proactive role in feedback interactions.

A  key  teacher's  role  is  to  design  summative  assessment  tasks  which promote student learning behaviours resonating with SDL principles. Case studies  of  assessment  designs  by  expert  university  teachers  illustrated  a

How to cite: Carles, D., 2021, 'Foreword', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach  towards  Self-Directed  Learning (NWU  Self-Directed  Learning  Series  Volume  7),  pp.  xxv-xxvi, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.0f

number  of  key  features  of  such  approaches  (Carless  2015b).  Effective assessment designs are supported by the following 10 principles:

- 1. promotes deep rather than surface approaches to learning
- 2.  spreads student cognitive engagement consistently over the duration of a course
- 3.  mirrors authentic real-life applications of the discipline
- 4.  impedes malpractice, such as contract cheating or plagiarism
- 5.  develops  student  connoisseurship  by  appreciation  of  key  disciplinary concepts
- 6.  designs feedback processes for student involvement and uptake
- 7. involves some student flexibility or choice
- 8.  exploits digital possibilities for synthesis and interaction
- 9.  provides opportunities for peer feedback and student self-evaluation
- 10.  produces worthwhile learning outcomes, aligned with course objectives.

These  guidelines  for  effective  assessment  design  represent  an  ideal  to  be targeted  whilst  acknowledging  that  inevitable  compromises  arise  from disciplinary  and  contextual  features.  It  is  not  envisaged  that  any  course assessment design will meet all of the features but they can be used as a checklist for enhancement purposes.

The COVID-19 pandemic also brings to the fore new imperatives of how to organise assessment and feedback in a socially distanced world. Although there are obvious challenges, the pandemic also prompts us to question some of our conventional practices, such as closed book examinations in a large hall. These may now be replaced by richer, more authentic assessment tasks resonating with the 10 principles above.

The pandemic also encourages us to re-consider digital possibilities  for feedback processes. If less face-to-face oral feedback is feasible, we need to consider  options,  such  as  audio  and  video  feedback.  Digitally  enabled feedback  does,  however,  need  to  avoid  some  of  the  trappings  of  teacher transmission  pedagogy.  Self-directed  feedback  approaches  highlight  the value  of  student  peer  review,  for  example,  peer-to-peer  audio  or  video feedback. Within these approaches, the development of teacher and student feedback literacy are important elements (Carless &amp; Boud 2018).

This collection of papers also represents a tribute to the legacy of our dear colleague, the late Kobus Lombard. Kobus made pioneering contributions to assessment in support of SDL both in South Africa and further afield. The impressive achievements of the SDL research unit at North-West University are a fitting continuation of his work.

## Preface

## Elsa Mentz

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Anitia Lubbe

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

A central theme of this book is learning through assessment to enhance selfdirected learning (SDL). Chapter 1 sets the scene by providing a framework for SDL-oriented assessment and assessment literacy as essential components of  learning  in  the  21st  century.  This  chapter  explains  the  rationale  for  the emphasis on SDL when studying the role of assessment in learning.

Chapter 2 emphasises the importance of context for SDL when exploring situated SDL and the need to consider its social context. This chapter then indicates  how  language  should  be  used  in  order  to  support  situated  SDLoriented  assessment.  The  practices  regarding  the  language  of  assessment within selected university modules are explored and a progressively individualised  conceptual-theoretical  framework  to  understand  assessment as a tool for SDL is proposed.

In the light of the rapid move to online learning, the next three chapters position SDL and assessment within the online learning environment.

Chapter  3,  a  conceptual  chapter,  explores  the  scholarship  around  selfdirected multimodal assessment in order to provide recommendations which would make equitable and differentiated assessment possible. It suggests a framework  for  self-directed  multimodal  assessment  for  individual  modal needs of students for technological access and skills, also paying attention to students with special needs or disabilities.

In Chapter 4, the interconnections between metaliteracy as a holistic model that  prepares  individuals  to  participate  constructively  in  social  information environments and SDL were explored. Assessment methods within SDL most appropriate for determining progress towards metaliteracy were indicated. The chapter also provides two examples of how the intersection of metaliteracy, SDL and assessment might be addressed in practice.

How to cite: Mentz, E. &amp; Lubbe, A., 2021, 'Preface', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. xxvii-xxviii, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.0p

Chapter  5  advances  the  establishment  of  an  online  tutoring  system, integrating several state-of-the-art online education systems geared towards helping  students  to  be  more  self-directed,  maximising  their  learning  and raising their self-efficacy through integrated ipsative assessments.

Assessment as an epistemological tool to facilitate metacognitive awareness and to promote SDL is the focus of Chapter 6. The chapter offers a philosophical analysis of the conceptions of assessment and metacognitive awareness in light of the theory of an epistemology of engagement. A framework is offered that can serve as a model for exploring metacognition and SDL in assessment practices.

The  next  four  chapters  offer  empirical  investigations  into  assessment practices. Chapter 7 reports on a qualitative interpretivist investigation about the  value  of  assessment  feedback  during  the  implementation  of  a  specific cooperative learning method of assessment. The evaluation was done within a sustainable assessment perspective.

Chapter 8 critically explores the English for Education teaching, learning and assessment practices of a selected institution to establish how teaching, learning and the curriculum can be structured to enhance quality assessment and  SDL.  A  variety  of  assessment  tasks  and  assessment  that  encourages critical thinking and problem-solving is discussed as components that enhance quality assessment and SDL.

In Chapter 9, the consequences of online marking and feedback in a schoolwide  community  of  practice  project,  utilising  teaching  strategies  for  the development of SDL, are explored. With sufficient practice and support, the future looks promising for online feedback, as the responses from students indicate  positive  trends  with  regards  to  the  quality  of  the  feedback  they received. The authors argued that the paradigm shift towards online feedback is in the best interest of developing SDL.

Chapter 10 bridges the gap between schooling and higher education by reporting  on  qualitative  research,  utilising  cultural-historical  activity  theory (CHAT)  as  a  research  lens  and  aimed  at  understanding  the  influence  of teachers'  assessment  beliefs  on  learners'  SDL  behaviour.  As  a  result,  this chapter advocates for higher education to include more structured programmes for teachers that would support them in becoming cognisant of their  assessment  beliefs  and  changing  negative  belief  systems  that  work against appropriate learner developmental needs.

In  conclusion,  this  book  emphasises  the  key  role  of  assessment  within learning  to  support  and  enhance  SDL  and  how  it  should  be  implemented within  a  face-to-face  and  online  environment.  With  theoretical  as  well  as empirical methodologies applied in the different chapters, it covers a wide range of foci connected to assessment and SDL.

## Self-directed learningoriented assessment and assessment literacy: Essential for 21st century learning

## Anitia Lubbe

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Elsa Mentz

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Abstract

In  the  two  decades  since  the  year  2000,  because  of  the  mobilisation  of learners and learning, there has been a call for more self-directed learners (Hussey &amp; Smith 2010; Teo 2019). The ability to take responsibility for one's

How to cite: Lubbe, A. &amp; Mentz, E., 2021, 'Self-directed learning-oriented assessment and assessment literacy: Essential for 21st century learning', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 1-25, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.01

own  learning,  such  as  identifying  learning  needs,  setting  learning  goals, monitoring and evaluating the learning process and goal achievement are key characteristics  of  a  self-directed  learner  (Brockett  &amp;  Hiemstra  1991,  2012; Brookfield 2009; Kasworm 1983; Knowles 1975; Nepal &amp; Stewart 2010; Nicol 2009). The development of these self-directed learning (SDL) skills, like many complex skills, not only takes time but requires a paradigm shift away from other-directed teaching and learning. Self-monitoring and evaluation processes needed to determine goal achievement, according to Earl and Katz (2006), are not instinctive processes and need to be supported. One of the ways in which learners can be supported in such processes of becoming more self-directed  is  through  participative  assessment  practices  (Lubbe  2020; Sambell, McDowell &amp; Montgomery 2013). Despite the fact that a number of educational  assessment  features  have  been  identified  to  support  SDL, educational  assessments  that  foster  SDL  are  limited  (Coombs,  DeLuca  &amp; MacGregor 2020; Kvale 2007). This conceptual chapter sets the scene for this book on SDL assessment and involves a review of relevant literature on SDLoriented  assessment  and  assessment  literacy  and  is  informed  by  social constructivism. This chapter presents practical guidelines in terms  of requirements for assessments towards SDL, as well as the assessment literacies required for effective SDL through assessment.

## Introduction

In its broadest sense, assessment is the process of gathering information. The type  of  information  gathered  is  influenced  by  the  assessor's  intention. Therefore, the purpose of assessment influences the assessment strategies, tools and methods. One's approach to assessment is also influenced by lack of training or professional development (Shepard et al. 2005; Stiggins 1999; Tierney 2006), the presence of a testing or learning culture (Shepard 2000; Stobart  2008),  as  well  as  one's  'implicit  beliefs  about  learning'  (DeLuca, Coombs  &amp;  LaPointe-McEwan  2019:159).  Therefore,  one's  mindset  towards learning influences the way in which assessment is approached. In order to be a successful learner within the 21st century, possessing SDL skills is vital for not  only  learning  but  for unlearning and relearning as  well  (Toffler  1991; [ authors' added emphasis ]). Although a paradigm shift towards more social constructivist educational settings is noticeable, assessment practices are still predominantly driven from a behaviourist and cognitivist school of thought. Within a social constructivist driven educational environment, 'the construction of knowledge and not the reproduction of knowledge is paramount' (Pritchard 2014:35).  Therefore,  assessment  is  central  to  the  learning  process.  Using assessment to promote learning, instead of only testing knowledge, provides a  platform  for  more  participative  and  dialogic  assessment  practices.  Such practices will also likely enable students to learn 'many things that are not intended and/or not formally assessed' (Hay, Tinning &amp; Engstrom 2015:32).

Students learn from the pedagogical practice itself (Evans, Davies &amp; Penny 1999:10), and also learn aspects about themselves (Redelius &amp; Hay 2009:289). 'The reality  is  that  assessment  is  pedagogical  whether  or  not  pedagogy  is intended.  That  is,  the  way  assessment  is  conducted  has  consequences  for student engagement and learning' (Hay et al. 2015:41). The authors of this chapter believe that assessment is a fundamental constituent of the teaching and learning process. This chapter advocates a learning-oriented approach to assessment. Firstly, we will discuss the conceptualisation of assessment from a social constructivist perspective, after which we will indicate the importance of learning-oriented assessment (LOA). Finally, we will discuss the value of self-directed learning-oriented assessment (SLOA), which is the core of what this book is all about.

## Conceptualisation of assessment within a social constructivist learning perspective

The Latin  verb ad sedere or assidere ,  meaning  'to  sit  down  beside',  is  the origin of the term 'assess' and, according to Bachman and Palmer (2010), as well as Hodges, Eames and Coll (2014), involves feedback regarding students' learning processes. According to Lubbe (2020):

[ T ]he active role that students must play in the process of assessment is highlighted by the fact that assessment is rooted in a verb ('sit'), which implies students' active involvement during the assessment process. (p. 30)

Not surprising is the fact that assessment has a major influence on the lives of students  and  educators  alike  (Boud  &amp;  Falchikov  2007).  Consequently,  the design  and  development  of  assessment  should  be  focused  on  supporting students' learning processes (Gibbs &amp; Simpson  2004;  Quesada-Serra, Rodríguez-Gómez &amp; Ibarra-Sáiz 2016). The fact remains, however, that  the relationship  between  learning  and  assessment  is  often  still  perceived  by students as only a grade (McMorran, Ragupathi &amp; Luo 2017).

According to Shepard, Penuel and Pellegrino (2018), the contribution of social  interactions  to  what  students  can  know,  do  and  become,  is  not acknowledged  by  behaviourist  and  cognitive  learning  theories.  A  further limitation  of  the  behaviourist  and  cognitive  learning  theories  is  their inadequacy in clarifying the way in which students become more skillful at thinking  and  doing  (Shepard  et  al.  2018).  Social  constructivism  'offers  a powerful, integrative account of how motivational aspects of learning are completely entwined with cognitive development' (Shepard et al. 2018:23). Student  engagement  in  teaching,  learning  and  assessment  processes  are encouraged,  and  thus  peer-  and  self-assessment  methods  are  frequently used  (Baird  et  al.  2014).  Within  social  constructivist  theory,  students  are responsible for their own meaning-making and knowledge construction in collaboration  with  others,  through  being  involved  in  participative  and

engaging activities.  Per  implication,  the  role  of  the  student  is  active  and independent in  nature.  However,  as  soon  as  educators  rely  on  traditional assessment  regimes,  despite  the  implementation  of  participative  and engaging teaching-learning activities, students' intrinsic motivation decreases (Flint &amp; Johnson 2011:8). This decrease can be related to the loss of  learner  autonomy  and  control  over  the  learning  process  and  progress when assessments are rigid and rooted within a testing culture. According to Boud (2015:6),  '[a]cts  of  assessment  must  be  designed  to  leave  learners better equipped to learn further'.

Even though a detailed discussion of relevant assessment terminology is not within the scope of this chapter, a brief outline aimed at clarifying possible confusion with regards to conceptual knowledge of assessment types and forms  of  assessment  is  necessary.  Figure  1.1  contains  a  brief  outline  of assessment nomenclature; however, it is not exhaustive but rather informative as an introduction to this book.

Source : Authors' own compilation, based on Chapman and King (2013), Carless (2015a), Earl (2013), Falchikov (2005), Mok (2009), Reddy et al. (2015) and Wiliam (2011).

<!-- image -->

In the following discussion of LOA and SLOA, only assessment terms that pre-eminently apply to LOA and SLOA will be elaborated upon and, therefore, we will not pay attention to the clarification of all the different assessment terms in this chapter.

## Learning-oriented assessment

Because LOA refers to the notion that all assessment ought to support the enhancement of student learning (Carless 2015a), the key elements of LOA will be elaborated upon. According to Carless, Joughn and Mok (2006) and Carless (2014, 2015a, 2015b), the development of LOA came about after identifying  the  need  for  the  design  and  implementation  of  assessment practices  that  are  focused  on  the  learning  process,  because  summative assessment  was  heavily  weighted.  The  LOA  framework  conceptualises the  importance  of,  and  relationship  between,  LOA  tasks,  developing evaluative expertise, as well as student engagement with feedback (Carless 2015a:6). These three key drivers in LOA are conceptualised as a framework pyramid,  with  the  LOA  tasks  at  the  top  (Carless  2015a).  According  to Carless (2015a:7), 'the design of the assessment task or tasks impinges on potential  prospects  for  the  development  of  evaluative  expertise  and engagement with feedback'.

Learning-oriented  assessment  tasks  directly  influence  the  efforts  of students; therefore, it is placed at the apex of the LOA framework pyramid (Carless 2015a). Several principles for the design and implementation of LOA tasks are suggested by Carless (2015a:27) and are outlined in Table 1.1.

Although the principles and implications of LOA tasks in Table 1.1 are selfexplanatory, their influence when using them to guide assessment development is  noteworthy. Vanderlelie and Alexander (2016) made use of the LOA task framework to develop their assessment strategy by placing greater emphasis on  formative  assessment  and  online  learning  and  reported  a  significant improvement in student performance as a result. Similar results were reported by Van Staden (2016), who also used the LOA framework for the development of an LOA task in the form of an electronic portfolio.

Evaluative  expertise,  the  second  key  driver  of  LOA,  refers  to  students' ability to evaluate their own and their peers' work (Carless 2015a). According to Carless (2015a), students will develop evaluative expertise when they can generate, analyse and apply criteria. Examples of how students can develop evaluative  expertise  include  peer  dialogue,  self-assessment  of  work  in progress,  as  well  as  analysing  and  discussing  exemplars  of  quality  work (Carless  2015a;  Wiliam  2011).  Therefore,  it  is  evident  that  the  quality  of assessment tasks directly influences the development of students' evaluative expertise.

Self-directed learning-oriented assessment and assessment literacy

TABLE 1.1: Principles for design and implementation of learning-oriented assessment tasks.

| Principle                                                                                                            | Implications                                                                                                                                                                                                                                                                                                         |
|----------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Encouraging students' deep approaches to  learning and scaffolding the development  of suitable learning objectives. | Tasks that are well designed are likely to capture students'  study time and effort, as well as encourage students to spend  time studying outside class meetings and hence take a deep  approach to learning. Task design should be approached from  a programme-wide perspective.                                  |
| Balancing the formative and summative  facets to enable all assessments to be  learning-oriented.                    | Encouraging a variety of assessment tasks may encourage  student motivation. The use of portfolios provides the  possibility for the useful merging of formative and summative  assessment.                                                                                                                          |
| Spreading student effort and intellectual  engagement evenly through a module.                                       | Tasks should be designed so that student effort is evenly  distributed across the module (i.e. topics and weeks). The  inclusion of multiple tasks distributes intellectual engagement  evenly over a module.                                                                                                        |
| Supporting the development of ways of  understanding the nature of quality in the  discipline.                       | Student metacognition is developed by providing students  with the opportunity to engage with - and even developing -  criteria, standards and exemplars of quality work. Peer  dialogues can assist students in engaging with quality.                                                                              |
| Involving some personal student  investment or choice.                                                               | Choice can give students a greater sense of ownership, and  summative assessment should give space to individuality.                                                                                                                                                                                                 |
| Facilitating dialogic forms of feedback.                                                                             | Feedback should be timely, interactive and of good quality.  Constructive criticism can open up possibilities for students to  advance in their work. At the heart of good feedback, practice  is the development of students' self-evaluative capacities.  Feedback should be embedded within assessment practices. |

Source : Adapted from Carless (2015a:27).

Student engagement with useful feedback is the third key driver of LOA. According to Carless (2015a), students will not be able to use feedback unless they have some conception of what quality work looks like. If students are not engaged in the feedback process - giving and receiving feedback, as well as acting upon feedback - its influence on student learning will be limited (Carless 2015a). Feedback should be integrated with assessment activities, as opposed to being provided only as post-assessment (Carless 2015a).

Evident from the LOA framework is the fact that the purpose of LOA tasks is more formative than summative. Greater emphasis is placed on assessment for learning (AfL) and assessment as learning (AaL) approaches as opposed to assessment of learning (AoL).

## Formative assessment

Formative  assessments  differ  from  summative  assessments  based  on  the function  that  the  evidence  from  the  assessment  serves  (Wiliam  2011). According to Wiliam (2011):

An assessment functions formatively to the extent that evidence about student achievement is elicited, interpreted, and used by teachers, learners, or their peers to make decisions about the next steps in instruction that are likely to be better, or better founded, than the decisions they would have made in the absence of that evidence. (p. 43)

The aim of formative assessment is to improve teaching and learning as well as to diagnose any difficulties students might be encountering during their learning process (Dixon &amp; Worrell 2016). An important aspect of formative assessment is that it is an ongoing process (Box, Shoog &amp; Dabbs 2015) during which gathered data inform both pedagogy and student learning (Dixon &amp; Worrell  2016;  Falchikov  2005).  According  to  Van  der  Kleij  et  al.  (2015), formative assessment is implemented with the purpose of providing feedback to students and educators. Although the focus of formative assessments is not to improve academic performance, but rather student learning, QuesadaSerra et al. (2016) state that formative assessments have been identified to improve academic performance.

Wiliam (2011:51-158) identified five key strategies of formative assessment involving  the  educator,  the  student  and  the  peer.  These  key  strategies  are outlined in Box 1.1.

Summative assessment, as opposed to formative assessment, is defined as 'cumulative assessments […] that intent to capture what a student has learned, or the quality of the learning, and judge performance against some standards'  (National  Research  Council  2001:25).  Gardner  (2010)  opines that summative assessments are predominantly high-stakes assessments used  to  determine  how  much  learning  took  place.  Because  summative assessments  occur  at  the  end  of  a  learning  period,  such  as  a  unit  or semester,  such  assessments  are  almost  always  graded  (Dixon  &amp;  Worrell 2016). It is noteworthy, though, to point out that summative assessment tools  and  instruments  (tests)  can  also  be  used  for  formative  purposes. Their  success,  however,  is  nested  in  the  design  and  planning  of  the assessments.

## Assessment for and as learning

According  to  Earl  (2013:27),  AfL  'shifts  the  emphasis  from  summative assessment to formative assessment, from making judgements to creating descriptions that can be used in the service of the next stage of learning'. Therefore, AfL practices seek to close the gap between existing and anticipated learning (Clark 2012). The focus of AfL, as opposed to AoL, is on improving learning and occurs multiple times during the learning process (Earl 2013). Slavin  (2012)  states  that  the  core  aspects  of  AfL  are  informing  educators about the need for additional instruction, as well as informing students about the need for additional study.

Earl (2013) opines that AaL is an extension of AfL, with self-assessment, self-monitoring, self-regulation, as well as metacognition at the heart of AaL. The active participation of students in AaL practices is highlighted by Reddy et  al.  (2015),  and  therefore  peer  and  self-assessment  methods  are  a  vital

## BOX 1.1 : Five key strategies of formative assessment.

| Clarifying, sharing and understanding  learning intentions and success criteria                                      | Can be accomplished through the following: •  Have students look at samples of other students'  work - after students have identified the strengths  and weaknesses of the samples, they can engage in  a discussion. •  Provide students with rubrics - this could help the  students to develop a sense of quality. •  Co-construction of learning intentions - educators  can develop learning intentions or success criteria  with the students - this will enable students to  discuss and develop their own learning intentions  and success criteria. •  Samples of quality student work can also be used  to exemplify outstanding work in a concrete way  through engaging feedback. •  Have students design test items with a  memorandum about the work they have been  learning - this will enable students to clarify,  share and understand learning intentions, as well  as to be informed regarding their own level of   |
|----------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Engineering effective classroom  discussions and other learning tasks that  elicit evidence of student understanding | Refers to the importance of determining the students'  position in their learning trajectory. This can be  accomplished through: •  Student engagement through questioning. •  Waiting time after posing questions. •  Practicing evaluative and interpretive listening.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| Providing feedback that moves learners  forward.                                                                     | Highlights the fact that feedback has a formative  function only when the information which is fed back  to the students is used by the students to improve their  learning                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| Activating students as instructional  resources for one another.                                                     | When activating students as learning resources for  their peers, student learning is increased. Techniques  that can be implemented in the activation of students  as resources include: •  Peer evaluation of work. •  End-of-topic questions. •  Error classification. •  Group-based test preparation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| Activating students as the owners of their  own learning                                                             | Students learn better when they manage and crucially  reflect upon their own learning. Techniques that can be  implemented: •  Learning logs. •  Learning portfolios.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |

Source : Adapted from Wiliam (2011).

aspect of AaL practices/activities. According to Ferris and Hedgcock (2014), students within an AaL context not only (Lam 2015):

[ B ]ecome  more  self-directed  in  the  learning  process,  but  they  also  develop  a better understanding of learning goals, assessment criteria, and quantitative and qualitative feedback that assists them to plan for future learning. (p. 1906)

The  'role  of  the  student  as  the  critical  connector  between  assessment and their learning' is the focus of AaL (Earl 2013:28). It is important, however, not to interpret the role of the educator as being absent or uninvolved. Earl and Katz (2006:41) identify the following roles that educators should fulfil to promote the development of independent students during an AaL approach:

- · demonstrate and explain self-assessment skills
- · guide  students  in  goal  setting  and  to  monitor  their  progress  towards reaching them
- · make exemplars and models of good practice and quality work that reflect curriculum outcomes available
- · develop clear criteria of good practice in partnership with students
- · guide  students  in  the  process  of  developing  inner  feedback  or  selfassessment processes
- · provide  regular  and  challenging  opportunities  for  students  to  practice becoming self-assessors who are confident and competent
- · monitor the metacognitive processes and learning of students
- · provide feedback that are descriptive
- · create a safe and supportive learning environment.

Mok  (2013)  states  that  feedback  practices  which  contribute  to  students' metacognition are regarded as AaL. Self-directed learning-oriented assessment  has  been  conceptualised  and  described  by  Mok  (2013)  as assessment practices that are learning-oriented and therefore adhere to AaL criteria and are aimed at developing students' SDL. Because core aspects of AaL,  including  self-assessment,  self-monitoring,  metacognition  and  selfregulation, are key characteristics of a self-directed learner as well (Knowles 1975), SLOA will be discussed next.

## Self-directed learning-oriented assessment

According  to  Mok  (2009),  AoL,  AfL  and  AaL  are  the  three  integrated components  of  the  SLOA  framework.  Although  several  authors  (including Dixon &amp; Worrell 2016; Earl 2013; Reddy et al. 2012) connect the memorisation and recalling of a certain body of knowledge with AoL, the SLOA framework justifies its importance in terms of longer-term support for AaL (Mok 2009). According to Brandt (2020:9), 'self-directed learners having limited content

knowledge can implement cognitive strategies for gathering information, but they may lack the content expertise to effectively integrate new information with  existing  knowledge'.  Furthermore,  Mok  (2009)  opines  that  AoL  will support students' development of metacognitive skills, and hence AoL will aid and  support  AaL.  The  AfL  component  of  the  SLOA  framework  refers  to engaging  students  in  sharing  criteria  for  successful  learning,  which  will generate  feedback  conducive  to  learning.  The  AaL  component  refers  to students  taking  responsibility  for  their  own  learning  'through  reflecting  on evidence of learning generated from assessment activities' (Mok 2009:26).

Learning-oriented assessment, SDL, metacognition, motivation, as well as feedback are the theoretical underpinnings of SLOA (Mok 2009:7-11) and this is outlined in Figure 1.2. According to Mok (2009:5), the 'extension of LOA to SLOA concerns the self-directed component'.

This section aims to provide a brief overview of the theoretical underpinnings of SLOA.

<!-- image -->

Source : Adapted from Mok (2009:7-11).

LOA, learning-oriented assessment; SDL, self-directed learning.

## Self-directed learning

Guglielmino and Long (2011:1) describe SDL as 'a dynamic combination of attitudes and skills, essential for dealing with the complexity individuals face in  all  aspects  of  their  lives'.  Brandt  (2020:3)  opines  that  SDL  'represents  a process  of  learning  that  is  individual,  purposeful,  and  developmental'.  The SDL  definition,  which  is  most  well-known,  and  possibly  the  most  widely adopted, is that of Malcolm Shepard Knowles (1975) and he describes SDL as:

A process in which individuals take initiative, with or without the help of others, in diagnosing their learning needs, formulating learning goals, identifying human and material resources for learning, choosing and implementing appropriate learning strategies, and evaluating learning outcomes. (p. 18)

Knowles'  (1975)  definition  points  towards  a  self-directed  learner  being immersed in the following five processes: (1) learning needs diagnosis, (2) goal setting,  (3)  selection  of  relevant  learning  resources,  (4)  selection  and implementation  of  relevant  strategies  for  learning,  and  (5)  evaluation  of learning outcomes. Brandt (2020:5) states that this 'multifaceted definition illustrates its complexity, encompassing cognitive, intrapersonal, and interpersonal skills'. Guglielmino and Long (2011:2) also opine that SDL is 'our most  basic,  natural  response  to  newness,  problems,  or  challenges  in  our environment'. At the 34th International Self-Directed Learning Symposium in 2020, the following definition was adopted as the International Society for Self-Directed Learning 2020 definition: 'Self-directed learning is an intentional learning process that is created and evaluated by the learner' (ISSDL 2020).

Developing one's self-directedness in learning demands the development of certain specific skills and competencies. Such skills and competencies are well  researched  and  documented  (Dynan,  Cate  &amp;  Rhee  2008;  Guglielmino 1978; Knowles 1975; Lord et al. 2010; Roberts 2010; Warburton &amp; Volet 2012). Box 1.2 provides a brief outline of such skills and competencies.

It is quite clear from this lengthy list of characteristics that assessment of own learning plays a key role in the life of a self-directed learner.

According  to  Jossberger  et  al.  (2010)  and  Morris  (2019),  self-directed learners  are  most  capable  of  adapting  to  changing  social  and  contextual conditions. Self-directed adult learners are better prepared to acquire new skill  sets  (Barnes  2016),  stay  employed (Morrison &amp; Premkumar 2014) and, according to Seibert, Kramer and Crant (2001), nurture their long-term career success.

Often, the terms SDL  and  self-regulated learning (SRL) are used synonymously. According to Brandt (2020:5), this terminological confusion is referred to as the 'jingle-jangle' fallacies. The 'jingle fallacy' denotes the use of a single term ('self-directed learning') to describe quite a number of different things in various contexts. The 'jangle fallacy' surfaces where different terms

## BOX 1.2 : Self-directed learning skills and competencies.

## A self-directed learner can:

## Dynan et al. (2008):

- · apply basic concepts to authentic problems or scenarios
- · recognise and explain major fundamental assumptions
- · build simple models based on principles
- · compare the pros and cons of models

## Knowles (1975):

- · ollaboratively relate to peers identify peers as resources for diagnosing learning needs and for c planning learning
- · provide and accept assistance from peers realistically identify their own learning needs, with the help of others
- · ranslate their identified learning needs into learning goals t
- · dentify various resources i
- · select appropriate strategies for learning
- · gather and corroborate evidence of the achievement of learning goals

## Guglielmino (1978):

- · take initiative in their learning process
- · be independent and persistent in their learning
- · accept responsibility for their own learning
- · have a high degree of curiosity
- · exercise self-discipline
- · take joy in learning
- · evaluate their own progress
- · use basic study skills
- · manage their time effectively develop an action plan tolerate ambiguity
- · accept and use criticism
- · be goal-oriented and able to formulate learning goals
- · select and use many learning strategies
- · view problems as challenges and discover new approaches for dealing with problems

## Lord et al. (2010):

- · reflect and analyse
- · be flexible, independent and motivated

## Roberts (2010):

- · utilise a broad range of cognitive and metacognitive skills

## Warburton and Volet (2012):

- · sk guided questions for enquiry interrogate the assumptions underpinning newly encountered ideas a
- · identify suitable resources
- · use or modify selected resources to achieve learning goals

Source : Authors' own compilation, adapted from Lubbe (2020).

are used to describe the same construct. In order to clarify the relationship between SDL and SRL, a closer look at SRL, although not within the scope of this book, is necessary.

An earlier definition of SRL by Jossberger et al. (2010) is used by Saks and Leijen (2014) to clarify the difference between SDL and SRL:

A  self-directed  learner  decides  what  needs  to  be  learned  next,  diagnoses  his learning needs, formulates learning goals, finds suitable resources for learning, monitors  and  reflects  on  his  learning  activities.  The  first  step  in  learning  to self-direct one's learning is the skill to self-regulate learning activities and task performances  (Jossberger  et  al.  2010).  Self-regulated  learning  […]  concerns processes within task execution. Self-directed learning may include self-regulated learning  but  not  the  opposite  (Jossberger  et  al.  2010).  In  other  words,  a  selfdirected learner is supposed to self-regulate, but a self-regulated learner may not self-direct. (p. 192)

According to Brydges, Dubrowski and Regehr (2010), effective self-regulation skills are essential for an effective self-directed learner. Furthermore, Gandomkar and Sandars (2018) concur with Jossberger et al. (2010) that an effective  self-regulated  learner  is  more  often  than  not,  not  self-directed  in their learning.

Candy (1991:311) opines that '[the] term self-direction has misled many into elevating the individual above the collective - but the nature of knowledge and  learning  inherently  puts  learners  in  relationship  with  others'.  Students develop  SDL  skills  when  they  interact  with  others  during  interpersonal activities (Brandt 2020:8).

The competencies needed to self-assess one's own work as well as those of others are key competencies of a self-directed learner. We thus would like to agree with Mok (2009) that it is important to extend LOA to SLOA.

## The role of metacognition, motivation and selfregulation in self-directed learning-oriented assessment

John Flavell (1976) defines the term metacognition as follows:

In any kind of cognitive transaction with the human or nonhuman environment, a variety of information processing activities may go on. Metacognition refers, among other things, to the active monitoring and consequent regulation and orchestration of these processes in relation to the cognitive objects or data on which they bear, usually in the service of some concrete goal or objective. (p. 232)

Metacognition  is  characterised  by  two  distinctive  components,  namely metacognitive  knowledge  and  self-regulation  of  cognition.  Metacognitive knowledge includes factual (knowing what ), contextual (knowing when and why ), as well as procedural (knowing how ) knowledge (Flavell 1976). Wiliam

(2011) opines that metacognitive skills will be useful to students only if they are motivated to learn.

According  to  Mok  (2009),  sustaining  students'  motivation  is  equally important  as  raising  metacognitive  and  cognitive  awareness.  Therefore, according to Shraw, Crippen and Hartley (2006) as well as Duckworth et al. (2019),  motivation  is  an  essential  mediator  behind  students'  commitment, engagement and persistence in SDL. 'Motivation is a prerequisite to exercising both  autonomy  and  self-regulation  in  learning'  (Brandt  2020:17).  Current research  on  motivation  and  cognition  points  towards  the  importance  of activating students to take ownership of their own learning (Wiliam 2011).

Self-regulation of cognition refers to the students' ability to monitor and control  their  thought  processes  whilst  working  on  a  specific  task.  These thought processes include formulating learning goals, planning, monitoring progress, evaluating the selected learning strategies and re-selecting learning strategies,  if  necessary  (Mok  2009).  Such  self-regulatory  skills  are  vital  for students to evaluate the achievement of their set learning goals.

## Feedback to support current and future learning within a self-directed learning-oriented environment

Designing assessment tasks through which quality feedback can be generated is an important feature of the SLOA framework (Mok 2009). Feedback has a central role to play in the relationship between learning and assessment.

The type of feedback provided and the ways in which feedback is provided and received affect the power of feedback in the learning process (Hattie &amp; Temperley 2007). Feedback is defined as (Hattie &amp; Temperley 2007):

[ ]nformation provided by the agent (e.g. teacher, peer, book, parent,  self,  experience) I regarding aspects of one's performance or understanding. A teacher or parent can provide corrective information, a peer can provide an alternate strategy, a book can provide information to clarify ideas, a parent can provide encouragement, and a learner can look up the answer to evaluate the correctness of a response. (p. 81)

According to Hattie and Timperley (2007), the following three questions are addressed through effective feedback:

Where am I going ? How am I doing ? and Where to next ? The answers to these questions enhance learning when there is a discrepancy between what is understood and what is aimed to be understood. (p. 102)

Therefore, feedback can lead to the restructuring of students' understanding (Evans 2013).

Opportunities  for  students  to  engage  with  feedback,  instead  of  merely receiving  a  grade,  are  vital  to  bringing  about  any  noticeable  change  in

students' learning (Boud 2015). We concur with Winstone et al. (2017) that feedback without any action is just as unproductive as action without any feedback. Therefore, for feedback to contribute to students' learning gains, student participation should be at the core of feedback practices (Delva et al. 2013). According to Winstone et al. (2017), giving and receiving feedback is a two-way dialogic process to which the receiver responds after deciphering and interpreting the feedback. In instances where higher education students fail  to  implement  assessment  feedback  effectively,  low  levels  of  students' assessment literacy, as well as students' passive role in feedback processes can be to blame (Carless et al. 2011; Winstone et al. 2017). Because assessment literacy 'involves a combination of knowledge, skills and competencies' related to assessment (Price et al. 2012:10), it is not surprising when students with low levels of assessment literacy fail to act upon received feedback, as students will not be able to act on it if they do not understand it (Mulliner &amp; Tucker 2015; O'Donovan, Rust &amp; Price 2016). Moreover, feedback is not acted upon when  students  perceive  it  as  being  provided  either  too  late  (Beaumont, O'Doherty &amp; Shannon 2011) or badly timed and unhelpful (Urquhart, Rees &amp; Ker 2014). Consequently, it is vital to provide students with ample opportunities to  practise  how  to  identify,  appreciate,  interpret  (Blair  &amp;  McGinty  2013; Poulos &amp; Mahony 2008) and value feedback (Boud 2015).

Peer and self-assessment methods are useful feedback tools (Brandt 2020). According to Nicol and Macfarlane-Dick (2006), the implementation of peer assessment methods will provide students with opportunities to make objective judgements against specific standards and will also enable students to engage in the evaluation process when assessing the work of others. Therefore, peer assessment will support the development of reflective skills, as well as taking responsibility  for  students'  own  learning  (Nicol,  Thomson  &amp;  Breslin  2014). Harris and Brown (2013) define self-assessment methods as assessments that encompass monitoring and reflecting on one's own learning progress. Selfassessment methods may include descriptions, such as characteristics of one's work, and evaluation of how good one's work is (Brown, Andrade &amp; Chen 2015). According to Nicol and Macfarlane-Dick (2006) and Tee and Ahmed (2014), self-assessment involves and encourages reflection; however, not all reflection leads to self-assessment. The ability to self-assess, according to Sadler (2013), should be practised independently of peers and educators, whilst the role of the educator is to 'teach students how to judge quality and modify their own work during production' (Sadler 2013:55).

According to O'Donovan et al. (2016), the feedback dilemma can also be overcome by the development of students' and educators' assessment literacy. It seems that the relationship between feedback and assessment literacy is an intricate  one.  Price  et  al.  (2012)  state  that  a  student  will  become  more assessment literate when engaging with feedback. The conceptual clarification of assessment literacy (ALit) and a detailed discussion of its aspects follows.

## The important role of assessment literacy within a self-directed learning-oriented assessment environment

Assessment's potential to positively contribute towards students' learning is hindered by low levels of ALit. This is because of educators being involved in several assessment processes and related decision-making, without sufficient assessment-related training (Xu &amp; Brown 2016:2).

Within ALit, there is a lack of consistently used assessment terminology in the literature. Traditional and basic definitions of ALit are provided by scholars such as Stiggins (1991), Popham (2011) and Price et al. (2012), amongst others. Stiggins  (1991:535)  states  that  being  an  assessment  literate  person  implies that one has 'a basic understanding of the meaning of high- and low-quality assessment' and that one is 'able to apply that knowledge to various measures of  assessment'.  According  to  Popham  (2011:265),  '[a]ssessment  literacy consists  of  an  individual's  understanding  of  the  fundamental  assessment concepts and procedures deemed likely to influence educational decisions'. Price et al. (2012:10-11) believe that ALit involves the following:

- · an appreciation of assessment's relationship to learning
- · a conceptual understanding of assessment (i.e. understanding of the basic principles  of  valid assessment  and  feedback  practice,  including  the terminology used)
- · understanding of the nature, meaning and level of assessment criteria and standards
- · skills in self- and peer-assessment
- · familiarity  with  technical  approaches  to  assessment  (i.e.  familiarity  with pertinent assessment  and  feedback  skills,  techniques  and  methods, including their purpose and efficacy)
- · possession  of  the  intellectual  ability  to  select  and  apply  appropriate approaches and techniques to assessed tasks (not only does one have the requisite skills, but one is also able to judge which skill to use when, and for which task).

## According to Willis, Adie and Klenowski (2013):

ALit  is a  dynamic  context-dependent  social  practice  that  involves  teachers articulating and negotiating classroom and cultural knowledge with one another and  with  learners,  in  the  initiation,  development  and  practice  of  assessment  to achieve the learning goals of students. (p. 242)

Within the 21st century social constructivist context, however, a more complex and contemporary explanation of ALit is evolving (Deneen &amp; Brown 2016). Therefore,  more  recent  discussions  on  ALit  include  its  socially  negotiated structure  (DeLuca,  LaPointe-McEwan  &amp;  Luhanga  2016;  Looney  et  al.  2017; Lubbe 2020).

Assessment's centrality to the learning process, as well as the vital role that educators and students play in the assessment process, necessitates a deeper focus  on  ALit.  Therefore,  ALit  'is  a  core  professional  requirement  across educational systems' (DeLuca et al. 2016:251). Both students and educators need  to  become  more  assessment  literate  not  only  to  address  possible dissatisfaction with assessment but also for assessment to be more effective and efficient (Price et al. 2012; Smith et al. 2013). Furthermore, '[w]idespread assessment  literacy  would  inevitably  lead  to  more  holistic  viewpoints  and practice,  understanding  the  interconnectedness  of  assessment,  feedback, community,  standards,  and  self-regulation'  (Price  et  al.  2012:2).  A  brief discussion of educators' and students' assessment literacy follows.

## Educators' assessment literacy

According to Kahl, Hofman and Bryant (2012), a broad definition of educators' assessment  literacy  entails  educators  identifying,  selecting  or  creating assessments for various purposes, as well as analysing, evaluating and using the generated assessment evidence to improve students' learning. Edwards (2017)  is  of  the  opinion  that  educators  must  be  assessment  literate  for assessment  to  be  successfully  used  to  enhance  student  learning  and, according to Popham (2011), educators' assessment literacy will enable them to  evaluate  students  fittingly.  Not  surprisingly,  Gotch  and  French  (2014) identify  assessment  literacy  as  an  important  characteristic  of  effective educators.  Because  assessment  literate  educators  support  students  to become  'critical  consumers  of  feedback'  (Stiggins  1991:535),  educators' assessment literacy also affects students' motivation and achievement (Kahl et al. 2012).

Stiggins  (1991:535)  proposes  that  assessment  literate  educators  ask themselves the following important questions: ' What does this assessment tell students about the achievement outcomes we value? ' and ' What is likely to be the  effect  of  this  assessment  on  students? '  In  a  later  publication,  Stiggins (1995) posits that assessment literate educators:

- · recognise what to assess
- · recognise the reason they assess
- · recognise how to assess
- · can identify possible problems with assessment and know how to prevent such problems from reoccurring
- · are also aware of the possible negative consequences of incorrect/poor assessment.

Volante  and  Fazio  (2007)  are  of  the  opinion  that  assessment  literate educators recognise the different purposes of assessment and can use them accordingly.

In  2004, MacLellan did a study to establish the degree to which teacher candidates  were  ready  to  assess  study  learning;  the  results  revealed  that compartmentalisation  of assessment  knowledge  leads  to  low  levels of assessment literacy. Educators often 'believe that the assessment training that they received as undergrads did not prepare them to be comfortable with the decisions they are routinely charged to make' (Mertler 2009:101). According to DeLuca  and  Volante  (2016),  teacher  candidates  may  not  receive  enough exposure  to  assessment  pedagogy  because  of  relatively  short  educational programmes and sporadic work-integrated learning interruptions. The following four assessment principles, rooted in social constructivism are, according to Abell and Siegel (2011:212), at the heart of educators' assessment literacy and much needed to create an 'assessment-centred learning environment':

- · educators learn through the process of assessment
- · students learn through the process of assessment
- · for students to regulate their own learning, assessment ought to support students to be metacognitive about their knowledge and skills development
- · assessment tasks need to be unbiased towards all students.

Knowledge of the purpose of assessment, what should be assessed, various assessment strategies, as well as how to interpret assessment data and actiontaking  are  the  four  types  of  knowledge  and  skills  related  to  the  abovementioned principles (Abell &amp; Siegel 2011). These types of knowledge and skills are briefly outlined in Box 1.3.

After reviewing assessment literacy studies over the past three decades, Xu  and  Brown  (2016)  conceptualised  the  Teacher  Assessment  Literacy  in Practice (TALiP) framework. According to Xu and Brown (2016:27-28), TALiP consists of three levels of mastery, namely:

- · mastery of educational assessment knowledge - implying that educators should  possess  knowledge  of  the  following:  discipline  and  pedagogical content  ('what',  'why'  and  'how'  of  assessment);  assessment  purposes, content  and  methods;  grading;  feedback;  peer-  and  self-assessment; assessment  interpretation  and  communication;  as  well  as  assessment ethics
- · an internalised set of understanding and skills of the interconnectedness of assessment, teaching and learning
- · a self-directed awareness of assessment processes and one's own identity as an assessor.

ALit  is  not  just  based  on  assessment  knowledge  but  is  rather  a  'situated, dynamic, and evolving system' (Xu &amp; Brown 2016:27).

It is evident  that  pre-service  teacher  programmes  need  to  address assessment  literacy  as  a  prerequisite  for  creating  an  'assessment-centred

BOX 1.3 : Four types of knowledge and skills relating to educators' assessment literacy.

| Knowledge of the purpose of assessment                    | Such knowledge relates to the educator's purpose  with the assessment. According to Abell and Volkmann  (2006), the educator's view of learning and assessment  values is related to the type of assessment that the  educators choose to use                                                                                                    |
|-----------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Knowledge of what to assess                               | Such knowledge is not only related to the stipulated  aims in the curriculum, but to the belief of how learning  occurs as well. The knowledge of what to assess is  associated with the purpose of assessment and deep- rooted in the fundamental assessment values and  principles                                                             |
| Knowledge of assessment strategies                        | Such knowledge refers to the various ways in which  an educator assesses student learning, as well as to  the knowledge of content-specific assessments. There  is an obvious connection between the knowledge  of assessment strategies and the knowledge of  assessment purposes                                                               |
| Knowledge of assessment interpretation and  action-taking | Such knowledge refers to educators' intentions with  assessment data. It is believed that a key aspect of  assessment literacy is what educators know regarding  'interpreting and acting upon assessment data' (Abell &amp;  Siegel 2011:215), as well as what they know about using  assessment data to assist students in their learning  process |

Source : Author's own compilation, based on Abell and Siegel (2011).

learning  environment'  (Abell  &amp;  Siegel  2011:212).  In  order  to  change  the educator-driven  summative-focused  assessment  context,  the  status  quo needs to be challenged. Douglas and Morris (2014:21) found that the actions of  educators  are  largely  responsible  for  creating  an  environment  which promotes - or does not promote - students' SDL. This is because of the fact that teachers' ability to support students in becoming self-directed in their learning is tied to their own self-directedness (Kramarski &amp; Michalsky 2009). Du  Toit-Brits  (2019:8)  states  that  '[e]ducator  expectation  is  an  important factor in enhancing students' self-directedness'. The 21st-century educational landscape needs skillful, self-directed, assessment literate educators who will be able to utilise the power of assessment to reinforce students' learning in both face-to-face and online environments.

## Students' assessment literacy

According to Smith et al. (2013), research on students' assessment literacy is limited, despite the fact that numerous researchers emphasise its importance (Carless 2007; DeLuca et al. 2016; Edwards 2017; Smith et al. 2013).

Three dimensions of students' assessment literacy are identified by Smith et al. (2013). Students should:

- · understand assessment's purpose, as well as its connection to their learning trajectory
- · be conscious of assessment processes
- · be exposed to opportunities to develop self-assessment skills.

Price et al. (2012) suggest that the following can contribute towards students becoming assessment literate. Students need to appreciate the relationship between learning and assessment, understand assessment and its processes conceptually, and develop peer and self-assessment skills.

Lubbe (2020) found in a study of first-year Life Sciences students that there is a linear relationship between students' ALit and their SDL readiness. Students' increased understanding of the purpose of assessment to enhance and monitor their own learning also increases their SDL readiness. She found that  their  SDL  readiness  improved  with  an  increased  understanding  of assessment protocols and standards as well as the increased ability to judge their own and their peers' work. Lubbe (2020) also emphasised the influence of peer and self-assessment on students' SDL.

Several  studies  (Orsmond,  Merry  &amp;  Callaghan  2004;  Orsmond,  Merry  &amp; Reiling 2002; Price et al. 2012; Rust, Price &amp; O'Donovan 2003; Smith et al. 2013;) showed how peer assessment not only enabled students to construct a feedback  loop,  but  also  how  it  improved  students'  performance.  Students believed the timing, quality and the different approaches to a task were useful in their learning process. The ability to use assessments for learning and to make use of peer- and self-assessment methods is also part of a self-directed learner's repertoire and will be discussed in the 'Self-directed learning-oriented assessment and assessment literacy' section.

## Self-directed learning-oriented assessment and assessment literacy: Essential for 21st century learning

From the discussions in the previous sections, it is evident that the successful implementation  of  assessments  which  will  promote  student  learning  is influenced by the educator's and student's ALit.

Having  a  sound  knowledge  base  of  assessment,  as  well  as  the  interrelatedness of  teaching,  learning  and  assessment  processes  are  vital  aspects  of  an educator's ALit repertoire. Being an assessment literate educator will enable the planning and implementation of assessment practices which are conducive for  student  learning.  According  to  Tholin  (2008:10),  '[s]elf-assessment  is  a natural  element  of  self-directed  learning'.  Not  only  will  assessment  literate educators  design  assessments  with  students'  learning  trajectories  in  mind, but also with their SDL skills development in mind.

Within  the  21st  century  higher  education  context,  assessment  practices should not only engage students in the learning process and their progress but  also  support  the  development  of  SDL  skills.  Teaching,  learning  and assessment should comprise an inseparable collection of processes based on the social constructivist approach. The focus should rather be on the learning processes of students, as opposed to the assessment practices, and therefore assessment should be utilised as a pedagogical tool. According to Binkley et al.  (2012),  student  engagement,  persistence  in  learning,  metacognition,  as well as self-regulation should be promoted. Once students focus more on the learning  process  and  less  on  doing  well  in  an  assessment  task,  learning orientation will be promoted. Assessment will further student learning when assessments are planned to provide feedback and not for making comparative judgements (Earl 2013). Even though students are natural-born learners, Kvale (2007) identified the following aspects of assessment as potentially discouraging lifelong 21st-century learning:

- · making use of a grade point average as a learning objective
- · predominant use of multiple-choice tests
- · test anxiety
- · absence of feedback
- · lack of authentic assessment
- · the absence of peer and self-assessment methods.

Falchikov (2005) opines that the use of more traditional types of assessments will  cause  students  to  be  passive  consumers  as  they  will  have  little  or  no control over the assessment processes. Not surprisingly, Earl (2013) believes the  status  quo  of  assessment  should  be  challenged.  Boud  and  Falchikov (2007:4) state that 'studying in higher education is arguably for […] providing a foundation for a lifetime of learning and work in which there is little formal assessment or formal instruction'. Therefore, assessment practices within the 21st century should be rethought and redesigned in order to promote SDL and ALit.

Figure 1.3 is an illustration of the summary of the necessity of ALit and its influence  on  assessment  and  SDL  from  a  social  constructivist  teachinglearning philosophy. The influence of an educator's teaching-learning philosophy on the nature of assessment and its implementation (Ertmer &amp; Newby 2013; Reddy et al. 2015) cannot be ignored. Rooted within the social constructivist paradigm is the use of a variety of pedagogical approaches that are  collaborative  in  nature  (inquiry-,  problem-  and  project-based  learning) because of their ability to support socially mediated learning (Brandt 2020). Assessment from a social constructivist perspective will differ in design and implementation from those from a behaviourist and cognitivist perspective. Students will learn best when they are actively involved in the construction of their own understanding (Pritchard 2014; Slavin 2012). Per implication, social

ALit, assessment literacy; SDL, self-directed learning.

<!-- image -->

constructivist educators will make use of teaching-learning activities that are cooperative and collaborative in nature (Ben-Zvi Assaraf 2011).

An educator's level of ALit will determine to a large extent the types of assessment  practices  that  are  designed  and  implemented.  This  is  not surprising, as an assessment literate educator's repertoire includes the ability to comprehend the purpose of assessment, to understand that assessment is interconnected with the teaching-learning process and the ability to design and implement assessments that are learning-oriented (Popham 2011; Price et al. 2012).  An  assessment  literate  educator  within  a  social  constructivist paradigm  recognises  that  assessment  is  not  an  add-on.  Key  skills  of  an assessment literate educator (Abell &amp; Siegel 2011; DeLuca et al. 2016; Kahl et al. 2012; Looney et al. 2017; Popham 2011; Price et al. 2012; Stiggins 1991, 1995) are:

- · possessing sound knowledge of assessment nomenclature and functions
- · grasping  that  learning  takes  place  through  the  process  of  assessment, therefore, planning assessment with learning in mind
- · having a sound knowledge of various assessment instruments and tools
- · being skilled in supporting peer and self-assessment methods
- · understanding the importance of feedback to students' learning trajectory
- · possessing sound knowledge of assessment interpretation.

An assessment literate educator will be able to comprehend the importance of  peer  and  self-assessment  methods  to  support  students'  motivation  and metacognition. Being skillful in the design of LOA tasks, which will provide opportunities  for  students'  development  of  their  evaluative  expertise  and feedback  literacy  is  yet  another  characteristic  of  an  assessment  literate educator, as a result of their being knowledgeable in the purpose of assessment and assessment strategies (Abell &amp; Siegel 2011).

Because assessment literates will be able to realise the purpose and power of  assessment  to  improve  learning,  the  design  and  implementation  of assessments will  be  greatly  influenced.  The  power  of  socially  constructing knowledge  through  assessment  tasks  was  highlighted  by  Lubbe  (2020) through the implementation of cooperative learning-embedded assessment. Not  only  did  the  social  aspect  enable  students  to  learn  from  their  peers through  multiple  perspectives,  but  it  provided  a  platform  for  immediate feedback. Utilising peer and self-assessment methods will enable students to develop sufficient metacognitive insights into their own learning process and progress.  Whether  or  not  students  will  be  able  to  use  peer  and/or  selfassessment methods to accurately assess themselves for summative purposes is  not  necessarily  relevant  within  an  SDL-oriented  environment.  The  focus should rather be on the learning process, as well as on the development of vital SDL skills, as observed by Papert (1998):

So the model that says learn while you're at school, while you're young, the skills that you will apply during your lifetime are no longer tenable. The skills that you can learn when you're at school will not be applicable. They will be obsolete by the time you get into the workplace and need them, except for one skill. The one really competitive skill is the skill of being able to learn. It is the skill of being able not to give the right answer to questions about what you were taught in school, but to make the right response to situations that are outside the scope of what you were taught in school. We need to produce people who know how to act when they're faced with situations for which they were not specifically prepared. (p. 4)

Because educators are not able to predict what students will learn as a result of  a  certain  pedagogical  practice,  Wiliam  (2011:50)  states  that  conducting assessments  for  formative  purposes  'involves  getting  the  best  possible evidence about what students have learned and then using this information to decide what to do next'. Because assessment within a social constructivist environment relies on the shared involvement of educators and students, the dialogic interaction between students will enable students to consider, share and develop ideas (Pritchard 2014). According to Quesada-Serra et al. (2016), peer and self-assessment methods promote students' active learning, whilst Boud and Falchikov (2007) opine that their development into self-directed learners and assessors is also promoted. The ability to provide and receive feedback from peers, possibly because of seeing peers as resources, is a vital SDL skill (Guglielmino 1978; Knowles 1975). Recorded benefits of peer and

self-assessment include the improvement of negotiation and diplomacy skills (Lopez-Pastor &amp; Sicilia-Camacho 2017), the development of critical thinking skills (Hanrahan &amp; Isaacs 2011) and the ability to take responsibility for one's own learning (Ljungman &amp; Silén 2008). Students' ability to take initiative in their own learning process will be promoted through assessment practices which are influenced by the educator's ALit. If the educator is designing and implementing  assessments  that  are  not  learning-oriented,  and  for  which students have no participative and active role to play, students will less likely be motivated to take initiative in their own learning. As a result, students might also  not  develop  the  ability  to  diagnose  their  learning  needs.  If  traditional assessments are the norm, students will less likely be expected to collaborate or participate in the assessment process; therefore, students will not be able to give and receive feedback or to see their peers as resources. When students are immersed, via peer and self-assessment, in the process(es) of assessment, they  are  likely  to  develop  the  ability  to  not  only  evaluate  their  learning objectives but also to learn from their peers. Being able to identify resources for learning, not merely relying on the educator, is key to SDL (Knowles 1975). Within a social constructivist approach, dialogic assessment feedback moves beyond  being  passively  transmitted  towards  being  a  participative  process (Rust et al. 2005). Educators' ability to envision assessment as a 'productive locus of engagement' (Sambell, Brown &amp; Race 2019:46) will enable them to utilise  the  power  of  assessment  as  a  pedagogical  practice  through  which students will be supported to gain SDL skills.

## Conclusion

This chapter took a learning-oriented approach to assessment, illustrating the importance of assessment literate educators who will utilise assessment as pedagogy within social constructivism. For assessment to not only support students' learning but their SDL as well, educators need to realise that their own  teaching-learning philosophies will influence the nature of their assessment  practices.  Within  the  21st  century,  from  a  social  constructivist perspective,  assessment  theory  and  practice  should  move  beyond  simply being the 'glue' that holds the teaching and learning processes together, to being  the  conductor  through  which  teaching  and  learning  take  place. Assessment should conduct the flow of teaching and learning in more than one direction. When assessment is used as an agent for teaching and learning, underpinned by social constructivism, students will become co-constructors of knowledge and assessments. Consequently, teaching and learning will not be an individualistic endeavour any longer, but rather a dialogic process that is intertwined with assessment pedagogy. The importance of ALit within the social constructivist paradigm and its direct influence on assessment processes is a  vital  aspect  of  assessment  within  a  self-directed  learning-oriented

environment. The focus of such assessment processes will be on learning, and especially SDL.

## Acknowledgements

This work is based on a research project supported by the National Research Foundation (NRF) of South Africa (Grant Number 90387). The grant holder acknowledges that opinions, findings and conclusions or recommendations expressed in any publication generated by the NRF-supported research are those of the author(s) and that the NRF accepts no liability whatsoever in this regard.

## Chapter 2

## Assessing axiologolects: Exploring the language of situated self-directed learning-oriented assessment

Jako Olivier

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Mahikeng, South Africa

## Abstract

In this chapter, the use of language in assessments was researched regarding its role in supporting situated SDL. In this regard, the construct of language was  approached  as  one  of  the  material  resources  for  learning  in  terms  of SLOA. Situated learning emphasises the importance of context in the learning environment, and this ties in with the need to consider the social context for SDL. The problem investigated by this study is how language should be used in order to support situated SLOA. From existing research on situated selfdirected  multimodal  learning,  students  and  lecturers  regard  language  as  a

How  to  cite: Olivier,  J.,  2021,  'Assessing  axiologolects:  Exploring  the  language  of  situated  self-directed learning-oriented assessment', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 27-49, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.02

problematic issue in terms of situated learning. Consequently, it was necessary to determine the nature of the language used in assessments in order to gauge if and how situated SLOA was supported. Hence, the practices regarding the axiologolect or language of assessment within selected university modules were explored by means of an analysis of assessment artefacts as provided by lecturers.

## Introduction

The nature of axiologolects, or the language of assessment, is explored in this chapter regarding the manner in which the formulation of assessment texts can  relate  to  situated  SDL.  In  the  context  of  this  chapter,  the  concept 'assessment text' is used to specifically refer to any assessment artefact used within  a  higher  education  context,  including  amongst  others:  classroom quizzes, written and multimodal assessments, online and written tests, and examinations.  A  selection  of  collected  assessment  texts  from  the  teacher training context at a selected university were used to create a data set of texts used for the analysis of the language of assessment. Furthermore, the purpose of the exploration was to gauge the assessment texts' support of both situated learning (Catalano 2015; Donaldson, Barany &amp; Smith 2020; Lave &amp; Wenger 2008;  Priest,  Saucier  &amp;  Eiselein  2016;  Yeoman  &amp;  Wilson  2019)  and  SDL (Brockett  &amp;  Hiemstra  2019;  Gibbons  2002;  Kicken,  Brand-Gruwel  &amp;  Van Merriënboer 2008).

The need to explore axiologolects emanates from challenges experienced by learners in terms of the language used in assessment texts. In this regard, Sambell, McDowell and Montgomery (2012:142) contend that 'students often do not understand the language in which university assessment criteria are typically couched'. Furthermore, previous research on situated self-directed multimodal learning (SDML) at university level (Olivier 2020c) showed the importance of language as a variable. Hence, this chapter aims to contribute to the scholarship of language used in the assessment context.

In this chapter, the term axiologolect is  used to refer to the language of assessment.  This  term  is  derived  from  the  Greek  verb αξιολογώ [axiolog ṓ ] which means to 'assess', as well as the suffix '-lect' used in analogy with words such as 'dialect' to refer to a specific form of language. This suffix can, however, also  be  traced  back  to  its  Greek  roots  through διάλεκτος [diálektos]  and ultimately λέγω [légō], which means 'I speak'. Hence, the term proposed here is regarded as an umbrella term for any language related to the assessment process. In addition, the plural form of the term, axiologolects, is preferred in some instances. Depending on the context or part of the assessment process, many forms of this language are used for posing questions, providing context,

responding to assessments, as well as providing feedback. It is essential to note that 'language of assessment' is also used to refer to the metalanguage of assessment, as is used by McDonald (2007), but that is not the focus of this chapter.

Language associated with assessment has wider implications than just the assessment process itself. In this regard, Gipps (1999:382-383) remarks that '[t]he language of assessment and evaluation is one of the defining elements through  which  young  persons  form  their  identity,  for  school  purposes  at least'. The quality of questions has an impact on efficient learning supporting SDL  (Horsley,  O'Neill  &amp;  Campbell  2009;  Horsley  et  al.  2010).  In  addition, axiologolects also relate to questioning in class (cf. Cummings 2020); however, despite its relevance to SDL, this type of action and spoken text falls outside of the ambit of this chapter.

In the same manner that language is a social activity, Gipps (1999) regards assessment  within  a  sociocultural  perspective.  With  the  lens  of  situated learning  used  in  this  chapter,  the  social  aspects  are  even  more  relevant  in approaching assessment. Furthermore, this approach links up with the view expressed by Cowie, Moreland and Otrel-Cass (2013) that:

- [ A ]  sociocultural view allows us to look beyond the individual student and their teacher to consider more broadly how the classroom as a setting might enable (and constrain), opportunities for learning. (p. 6)

Hence,  the  need  to  investigate  axiologolects  is  located  within  a  view  of language and assessment as integrated and dynamic social activities.

Furthermore, the role of language and communication in terms of SDL is evident. In this regard, Cheng et al. (2010) identified 'interpersonal communication' as one of the domains explored in their self-directed learning instrument (SDLI). The inclusion of the statement 'I am able to communicate messages  effectively  in  writing'  in  the  SDLI  shows  the  prominence  of formulating capacity for SDL (Cheng et al. 2010:1157). However, the focus in this chapter is specifically on formulations in terms of assessment language. Despite the emphasis on teacher-generated assessment texts in this chapter, the need for learner input in this regard also ties in with the view of Cheng et al. (2010).

The research questions driving this chapter, situated in a teacher training context, are as follows:

- · What is the nature of axiologolects in selected assessment texts?
- · How do axiologolects realised in assessment texts support situated SDLoriented assessment?

## Situated self-directed learningoriented assessment

## Self-directed learning

Central to this chapter's view of assessment is how assessment relates and contributes  to  SDL.  Hence,  the  concept  of  SDL  needs  to  be  delineated. Brockett and Hiemstra (2019:55) define the concept SDL as being 'a process in which a learner assumes primary responsibility for planning, implementing, and evaluating the learning process'. This also relates to learner self-direction or SDL as a characteristic which relates to 'a learner's desire or preference for assuming responsibility for learning' (Brockett &amp; Hiemstra 2019:56).

Costa  and  Kallick  (2004)  emphasise  that  a  self-directed  person  can  be considered as being self-monitoring, self-managing as well as self-modifying. According  to  Kicken  et  al.  (2008:223),  '[g]iving  students  control  over  the selection of learning tasks they want to perform is an intuitive and appealing instructional method to address their individual differences'. In addition, the relevance of constructive SDL in order to foster SDL skills is emphasised by Beckers et al. (2019).

From the literature, it is clear that language choice, and therefore language abilities  of  learners,  can  have  an  influence  on  the  success  of  any  SDL intervention (Siriwongs 2015). Hence, the role of language in terms of SDL should not only be considered within the context of assessments, but also other aspects of learner activities.

A further aspect relevant to this chapter is the issue of situated learning.

## Situated learning

For Lave and Wenger (2008:29), 'situated learning', which is considered part of  the  legitimate  peripheral  participation  process,  implies  that  students 'participate in communities of practitioners and that the mastery of knowledge and  skill  requires  newcomers  to  move  toward  full  participation  in  the sociocultural practices of a community'. This aspect is realised in a form of apprenticeship as learning where this learning is not only situated in a context but is in fact part of 'generative social practice in the lived-in world' (Lave &amp; Wenger 2008:35).

The challenge would be to determine how assessments can be utilised in support  of  situated  learning.  If  the  process  is  regarded  as  a  move  from peripheral  participation  to  community  activity  and  ultimately  expertise (Donaldson  et  al.  2020),  assessments  can  also  be  scaffolded  in  a  similar fashion.  This  could  be  realised  through  using  carefully  planned  peripheral participation through teacher-led prompts moving to community activity by

means of assessments conducted in groups leading ultimately to expertise which could be assessed in groups or individually. Within the context of this chapter, such assessments should also progress from the general to the more profession-specific,  which  would  entail  focusing  on  the  practice  of  being a teacher.

Within situated learning, concern is expressed regarding generality and its abstracted  and  decontextualised  nature  (Lave  &amp;  Wenger  2008).  Hence, learning should be focused on a contextualised and relevant context.

The concept of situated  learning  also  resonates  with  a  drive  to  a  more authentic  type  of  assessment.  For  Sambell  et  al.  (2012:13),  this authentic assessment implies  'applying  learning  to,  or  learning  within,  real-world contexts or practices beyond the academy'. Within the context of this chapter, that implies linking assessment with the practice of being a teacher.

## Situated self-directed learning and assessment

The term 'SDL-oriented assessment' used in this chapter is derived from the work by Magdalena Mo Ching Mok. The SDL-oriented assessment framework is described by Mok (2009) as:

[ A ] coherent framework of assessment, deliberately designed to capitalise on the integrative impact of metacognition, feedback, motivation, contextual factors, and self-regulation on learning in the construction of assessment activities in order to cultivate self-directed learning capacities in students. (p. 11)

Hence, with the focus on SDL, this framework highlights the integration of a number of supportive aspects. According to this framework, assessment itself should advance learning and SDL and be used to inform the view of assessment in this chapter.

Automatic  computer-based  question  generation  from  texts  in  order  to support SDL has also been explored within the context of natural language generation (Lindberg 2013). Gibbons (2002:12) observes that 'assessment is an essential means of learning and learning how to learn: improvement flows from students' critical assessment of their own activities'. Consequently, when SDL and assessment are considered together, the emphasis is on formative assessment, and according to Cowie et al. (2013:3) '[f]ormative assessment involves feedback to students on their ideas and informs the differentiated teaching responses that are at the heart of effective teaching and learning'. The use of just-in-time feedback is also highlighted by Beckers et al. (2019) as the immediacy not only has a motivating effect on learners, but it can also benefit the learning process.

Within SDL it might be necessary to expand the concept of assessment to also  relate  to  'assessment  as  learning,  self-assessment,  and  peer-to-peer learning'  (Bull  2017:64).  Furthermore,  the  importance  of  self-assessment  is

noted in the literature (Costa &amp; Kallick 2004; Gibbons 2002). According to Costa and Kallick (2004):

Assessing student growth toward self-direction demands alternative and authentic forms of assessment. Students can become more self-directed when they know the intended learning outcomes and receive constructive feedback regarding their progress during the learning process. (p. 3)

Hence,  self-assessment  should  be  integral  to  any  concurrence  of  SDL  and assessment within the classroom context.

The  assessment  process  in  itself  should  be  supportive  for  SDL.  In  this regard, Costa and Kallick (2004) observe that:

[ T ]he intent of assessment should be to support learners in becoming self-directing and that what matters most in any assessment strategy is whether learners are becoming increasingly more able to self-evaluate. (p. 3)

Learner agency and active participation in the assessment process is essential for  SDL.  Importantly,  within  SDL,  'students  learn  to  assess  themselves  and report  on  their  own  achievement  because  it  is  an  essential  part  of  the self-directing process' (Gibbons 2002:21). Ultimately, this also implies that '[s] tudents  learn  to  assess  their  goals,  plans,  and  procedures  as  well  as  their results or products, and they learn to assess themselves as learners' (Gibbons 2002:21). Furthermore, the role of learners in contributing to the assessment process can be achieved by setting assessment criteria (cf. Lombard 2018), for example including them in other aspects such as setting assessments and drawing up assessment texts.

Situated assessment implies that assessments should be linked to some legitimate peripheral participation process and, by implication, an appropriate context.  Within  context-situated  learning,  learning  as  participation  (Lave  &amp; Wenger 2008) implies that the student is integrally connected to the whole assessment process and that student agency is also pertinent in this context. This situated approach to assessment supports the notion that neither learning nor assessment can be separated from students' contexts (Cowie et al. 2013).

Because Lave and Wenger (2008:51) believe that 'learning, thinking, and knowing are relations amongst people in activity in, with, and arising from the socially and  culturally  structured  world',  it  should  be  considered  how assessment  is  interpreted  in  this  social  and  cultural  context.  A  view  of assessment that relates to situated and SDL also resonates with the concept of 'assessment for learning' by Cowie et al. (2013) where it is defined as follows:

Assessment for learning encompasses those everyday classroom practices through which teachers, peers and learners seek/notice, recognise and respond to student learning, throughout the learning, in ways that aim to enhance student learning and student learning capacity and autonomy. (p. 9)

This  definition  emphasises  assessment  as  a  continuous  process  where  not only the teacher but also peers and students themselves are equally prominent,

there  is  two-way  communication,  and  the  focus  is  enhancing  learning  and ultimately autonomy and not just measuring aspects of learning.

As in this chapter, assessment is regarded as a process of communication, the  phenomenon  of  axiologolects  is  discussed  in  the  'Axiologolects:  A language of assessment' section.

## Axiologolects: A language of assessment Language and assessment

In  the  South  African  context,  where  not  only  the  wider  learner  population speak  a  variety  of  languages,  learners  themselves  are  highly  multilingual (Coetzee-Van Rooy 2016; Heugh &amp; Stroud 2019). However, with the hegemony of  English  within  all  levels  of  education  (Desai  2016),  any  discussion  on assessment would be a discussion on English-based assessment. Yet, from the literature, the need and the advantages of mother tongue education and, by implication,  also  assessment  in  more  than  one  language  is  recommended (Christiansen &amp; Aungamuthu 2012). In addition, the use of learners' mother tongue  for  assessment  which  is  different  from  the  language  of  learning and teaching (LoLT) shows success and benefits for learners (Martín-Chazeaud 2017).

Central to axiologolects is the ability to formulate questions. According to Rothstein and Santana (2011), '[t]he skill of being able to generate a wide range of questions and strategize about how to use them effectively is rarely, if ever, deliberately taught'. It is important to consider the manner in which questions are formulated in order to ensure comprehension as well as effective learning in the classroom. The need for learners to be able to formulate their own questions is also emphasised from what can be expected in their future profession.  Within  this  context,  Horsley  et  al.  (2009)  have  shown  the importance of the quality of question formulation for the medical profession.

Furthermore,  the  discussion  on  question  formulation  also  relates  to supporting student agency as the literature encourages teachers to not only pose questions themselves but also empower learners to be able to formulate their  own  questions  (Rothstein  &amp;  Santana  2011).  This  aspect  is  also  highly relevant in contexts where learners are involved in the creation of assessments. This process of students taking charge of their learning can also have a positive effect  on  the  quality  of  learners'  cognitive  learning  activities  (Kicken  et  al. 2008).

It is key that teachers regard themselves as the mediators or 'facilitators of meaning-making' (Costa &amp; Kallick 2004:79) so that students themselves are active  in  the  meaning-making  process.  In  this  regard,  the  language  of assessment is merely an extension of this teacher's role.

In  many  sources,  the  issue  of  language  or  formulation  and  assessment focus a lot on feedback (cf. Cowie et al. 2013). However, the data analysed in this chapter were limited to assessment instructions. Consequently, feedback language would warrant further exploration, especially within the context of the appraisal framework by Martin and White (2005).

Variance in the type of language used in assessment texts is essential. In this regard, Tomlinson and Moon (2013) express the possible needs of learners in the following way:

Some students might benefit from use of more complex language on the assessment because that  language  is  appropriately  challenging  for  their  advanced  stage  of learning. On the other hand, some students might benefit from a version of the assessment that is written in simpler language or in bulleted form because long chunks of prose are problematic for them. (p. 45)

Consequently, only through having sufficient knowledge of learners' language repertoires  (cf.  Coetzee-Van  Rooy  2020)  and  language  skills,  teachers  can adapt the axiologolects used in assessment texts to attend to the needs of students. Furthermore, teachers need to consider aspects of comprehension in creating assessment texts.

## Comprehension

In order for assessment to be effective, some form of comprehension is implied on the part of students. It was found in the literature that the kind of questions, the assessment tool, as well as the type of language influence comprehension (Shohamy 1984). In addition, the formulation itself, which may depend on the assessment literacy of the assessor, such as the choice of verbs, may influence the way questions are answered (Semin &amp; De Poot 1997). Importantly, Shohamy (1984) found in her study on reading comprehension of language tests that using different languages and tools such as multiple-choice and open-ended questions may have a difference in the way in which texts are understood.

Various  aspects  can  have  an  influence  on  the  comprehension  of  an assessment text and this includes students' inability to link units of information within such a text; ambiguity in terms of words and sentences having multiple possible meanings; or students having insufficient background knowledge in order to understand aspects of an assessment text (Bailin &amp; Grafstein 2016).

Related to the issue of comprehension is the readability of a text as this provides information of the difficulty level of a text.

## Readability

An important aspect of any axiologolect is whether it is understandable. In this regard, this chapter draws on the theoretical background and scholarship of readability. Importantly, readability is influenced by a number of variables

such as 'a variety of linguistic factors, including syntactic, semantic, morphological, and textual (discourse) properties' (Bailin &amp; Grafstein 2016:2).

In  this  chapter,  readability  formulas  will  also  be  employed  in  order  to determine the level of readability. More on the specific formulas relevant to this study is presented under the data analysis.

The very commonly used Flesch-Kincaid readability tests involve scores for  Flesch  reading  ease  and  the  Flesch-Kincaid  grade  level  (cf.  Bailin  &amp; Grafstein 2016). The Flesch reading ease scores vary between 0 and 10 for difficult professional texts up to 90-100, which would be easily understood by an 11-year-old learner or basically a learner in Grade 5 (Flesch 1979). In contrast, the Flesch-Kincaid grade level provides a grade level up to Grade 12 and then continuing with 'Grade 13' onwards for years of education after school. These formulas use, amongst other aspects, the total number of words, sentences and syllables.

The Gunning Fog Index also conveys information regarding readability and uses average sentence length in order to determine sentence complexity or consider  the  number  of  polysyllabic  words  to  gauge  vocabulary  difficulty (Bailin &amp; Grafstein 2016). This index is also expressed at a grade level similar to the Flesch-Kincaid grade level.

The SMOG Index created by G. Harry McLaughlin is derived from Edward Fry's  Readability  Graph  and  the  Gunning  Fog  Index  but  implies  some simplification (Bailin &amp; Grafstein 2016). In order to determine the SMOG Index, the number of sentences used as well as the number of words of three or more syllables are considered. Finally, the Coleman-Liau Index (cf. Coleman &amp; Liau 1975) created by Meri Coleman and Ta Lin Liau involves the number of letters counted per 100 words as well as the determined average number of sentences counted per 100 words. The Coleman-Liau Index also results in a grade level as with some of the other readability indices mentioned here.

The 'Research methodology' section deals with the research methodology employed in order to address the research question posed at the start of this chapter.

## Research methodology

## Research design and orientation

This  mixed-method  corpus-driven  research  involved  both  qualitative  data generated through an in-depth inductive content analysis as well as quantitative data obtained through corpus linguistic analysis of selected assessment texts in the compiled corpus.

This chapter forms part of research done in order to explore situated and culturally appropriate SDML within a selected university, specifically in terms

of lecturers and distance education students. The findings of the initial part of this study have already been published (Olivier 2020c), and from this part it was evident that language is a significant variable for situated and culturally appropriate SDML. Consequently, it was decided that the language aspect would be explored further with this group.

Despite the focus on documents in this chapter, because university lecturers were involved in providing the texts, this study underwent an ethics review and  obtained  gatekeeper's  permission  from  the  selected  university.  The identified participants provided written informed consent to take part in this study and to provide assessment documents. Furthermore, participation was totally  voluntary  and  participants  were  allowed  to  withdraw  themselves and their documents at any point. Confidentiality and privacy were ensured throughout  the  process  and  consequently,  the  reported  findings  here  are phrased as not to overtly expose the modules or lecturers involved. The data used in this chapter were consequently stored securely electronically and will be erased after a period of seven years.

## Sampling

For the purposes of this research, the lecturers who were part of the initial part  of  the  wider  research  project  noted  above  (Olivier  2020c)  were approached. Of the 10 university lecturers who took part in the first part of the project,  seven  consented  to  continue  to  take  part  in  the  research  and  to provide data for this project. Hence, the corpus used for this study involved convenience sampling and texts were included as they were supplied by the participants who opted to be part of this research.

## Data collection

Some assessment texts were sent directly by email whilst others were provided through access to the learning management system. But no student or studentcreated texts were involved in this research. Ultimately, a total of 98 documents were used to create the data set used in this analysis (Table 2.1).

These documents were analysed in their original portable document format (PDF) or Word format for the content analysis, whilst they were converted

TABLE 2.1: Summary of the assessment text dataset.

| Type                 |   General  assessments (GA) |   Rubrics (RU) |   Tests (TE) |   Examinations (EX) |   Total |
|----------------------|-----------------------------|----------------|--------------|---------------------|---------|
| Number of  documents |                          52 |              6 |           32 |                   8 |      98 |

Note : The abbreviations used to refer to the documents in the rest of the chapter are provided in brackets.

into  a  simple  text  format  for  the  corpus  and  readability  analyses.  In  some cases,  content  such  as  the  rubrics  had  to  be  removed  from  the  general assessment documents and placed in separate text files for the sake of the corpus and readability analyses. In addition, for the purposes of the latter two analyses, all Afrikaans content had to be removed from the texts.

## Data analysis

## Inductive content analysis

The first phase of the data analysis involved a qualitative approach through which  all  the  collected  assessment  texts  in  the  data  set  were  inductively analysed  (Merriam  2009).  In  this  regard,  no  theory  was  tested,  but  rather qualitative  codes  were  derived  from  the  analysis  after  which  overarching themes  were  determined  which  were  in  turn  interpreted  in  terms  of  the relevant literature. Furthermore, this process also took on the form of a content analysis (Merriam 2009) in order to determine trends and findings from the various assessment texts.

## Corpus linguistic analysis

The  corpus  analysis  involved  exploring  frequencies  and  confirming  some findings of the content analysis by means of the concordance tool. To this end, AntConc (Antony 2020) corpus linguistic software was used and is described as '[a] freeware corpus analysis toolkit for concordancing and text analysis'. In this chapter, version 3.5.8 of AntConc was used.

One part of the corpus linguistic analysis involved exploring verb frequency based  on  the  Revised  Bloom's  Taxonomy  Action  Verbs.  Bloom's  revised taxonomy has been used in previous research in relation to question generation in the context of SDL (Lindberg 2013). The choice of verb is also highly relevant as this determines the way a question is answered (Semin &amp; De Poot 1997). This was done by adding the verbs from the verbs list in separate text files and loading them as search terms and displaying them under the Concordance function. In this way, the concordance hit count could be determined and each of the items checked whether they were indeed used as action verbs. The final counts were then normalised to a count per 1000 words in order to allow for comparison.

## Readability analysis

Part of the data analysis involved readability of the collected texts, and for this purpose  the  software Libro (cf.  Cavalcanti  2017)  was  used.  According  to Cavalcanti (2017), this software can be described as follows and all the tests listed here were conducted:

Libro is a cross-platform text analysis program written in Python and Free Pascal/ Lazarus which scans a whole text file (in plain text, HTML, EPUB, or ODT formats) and ranks all used words according to frequency, performing a quantitative analysis of the text using Shannon-Weaver information statistic and Zipf power law function. It  counts  words,  chars,  spaces,  and  syllables.  Also  computes  readability  indexes (Gunning  Fog,  Coleman-Liau,  automated  readability  index  (ARI),  SMOG  grade, Flesch-Kincaid grade level and Flesch reading ease). (n.p.)

In  this  chapter,  in  addition  to  some  general  characteristics  of  the  texts  as derived from the software, the following scores are reported: Flesch reading ease, Flesch-Kincaid grade level, Gunning Fog Index, SMOG Index and the Coleman-Liau Index.

## Results

## Results of the inductive content analysis

The main trends of the inductive content analysis are presented below with references to the different assessment documents in brackets. The content is presented verbatim as it appeared in the source documents; however, where certain words could make the relevant module and consequently the lecturer identifiable, that was redacted.

## Situated learning

There  was  some  evidence  of  situating  the  learning  in  the  dataset.  In  this regard, some questions would require students to link their answer to a reallife situation or case. Examples of this include:

- · '[…] propose a model for your school, based on the DBE's [Department of Basic Education's] guidelines' (GA3)
- · 'Write an advertisement for the appointment of an educator […]' (GA6)
- · 'Read the following extract and then answer the questions with proof of your school's or departmental policies based on it' (GA6)
- · 'Summarise by providing a narrative story about the impact of the various […] study units on your own career and development.' (GA16)
- · 'Which  strategy  will  you  implement  to  ensure  that  […]  in  your  school?' (GA44)

There were at least some assessments focusing on content related to teachers' daily activities (GA3, GA6, GA12, GA16, GA39) or focusing on the individual students  in  their  own  experience  or  aspirations  through  the  creation  of  a 'career plan' (GA14) or application in terms of the Curriculum and Assessment Policy Statement (CAPS) (GA28, GA30) or lesson plans (GA32).

However, other assessments approached theoretical concepts generically without any reference to a cultural or even work-related context (GA5, GA12, TE2-TE12). Most of the questions posed in the assessment texts were to the

point  and  basically  contained  just  a  question.  For  example,  'What  is  the difference between  probability  and  non-probability  sampling?'  (GA37). However,  there  were  some  instances  where  questions  in  the  assessment documents were contextualised within a wider description (GA19, GA21, GA23, GA25, GA28), actual newspaper articles (GA36) or cases (GA28, GA29, GA30, GA31, GA33, GA34, EX2, EX3, EX4, EX5, TE21, TE22). Furthermore, the use of multiple-choice questions was quite common for general formative assessments (GA27), online and written tests and examinations (EX2, TE1TE32). Although open-ended questions lacked in terms of most of the online tests, such questions were observed in some (TE23).

Few  assessments  specifically  request  students  to  reflect.  Reflection  is, however, an essential part of the assessment process, and Beckers et al. (2019) underline the importance of reflection in fostering SDL. At least GA38 prompts students to reflect on a lesson plan created. Consequently, this is also linked with their ultimate practice as teachers. In contrast, in another assessment personal views are discouraged as students are requested to present their 'point of view', but it is stated clearly that 'The answers to the assignment should reflect proper LITERATURE RESEARCH and not based on emotional reasoning or personal opinion' (GA39). In this case, little room was left for students to take ownership of their own learning process.

## Aspects fostering self-directed learning

For  most  of  the  documents,  little  student  agency  was  overtly  evident.  No evidence  of student participation could be observed  in creating the assessments, assessment criteria or rubrics. On a very basic level, some form of student agency was identified through students being able to select a topic for an assignment amongst a list of relevant topics identified by the teacher (GA5, GA15, GA37), or through the selection of sources to use in completing the assessment (GA5, GA15).

It  is  clear from the analysis of the documents that efforts were made to promote collaboration through completing assignments in groups (GA1) or pairs (GA11, GA15, GA17). Such assessments, depending of course on how they are planned and managed, may contribute towards fostering SDL as is evident in the literature (Johnson &amp; Johnson 2009, 2019). Some documents provided in-depth  instructions  for  peers  or  groups  in  order  to  do  peer  assessment (GA15, GA17, GA19, GA21, GA23, GA25). The majority of the assessments were clearly  meant  to  be  assessed  by  the  teacher,  followed  by  some  assessed automatically through the learning management system and a few through peer assessment (GA15, GA17, GA19, GA21, GA23, GA25).

However,  the  majority  of  general  assignments  had  to  be  completed individually  (GA2,  GA3,  GA5,  GA6,  GA7,  GA8,  GA12,  GA13,  GA14).  One assignment goes as far as including the following statement: 'Assignments are

individual tasks and not group activities' (GA32). In some cases, assignments were aimed at individuals' views (such as GA14) and consequently completing this individually would be sensible. However, for most of the other assessments, more collaboration could have been possible.

Some questions  were  posed  to  prompt  students  to  consider  their  own views  in  answering  the  question.  To  an  extent,  this  would  be  supportive towards some form of student agency, at least in terms of the formulation of the answer. Examples of this kind of approach included:

- · '[…] add your own interpretation and/or critique of the texts and offer a creative solution to existing problems' (GA32)
- · 'Based on your understanding, do you think the […]? Support your answer.' (GA33)

Marking rubrics were included in some assignments but were either not used or supplied for most of them. Most of the rubrics (some embedded in general assessment  documents  marked  as  GA  and  some  separate  marked  as  RU) contained  very  basic  descriptions  with  no  detailed  criteria  explaining  how specific marks can be reached (GA2, GA29, GA34, GA35, GA39, GA40, GA43, GA50). However, there were rubrics such as one to be used by peers (GA4, GA10) or the teacher (RU1, RU4) that contained a lot of detail guiding groups of  students  assessing  other  groups'  assessments  on  a  literature  review  in this case.

## Self-directed multimodal learning elements

A common type of assessment is longer written assignments in the form of essays and reports with set topics and no freedom to decide on the way it is presented (GA3, GA5, GA6, GA7, GA12, GA15, GA16, GA17, GA19, GA21, GA23, GA25,  GA36,  GA39,  GA41,  GA44).  Similar  approaches  were  followed  in examinations  with  longer  essay-type  questions  (EX1,  EX5,  EX7,  EX8).  The advantages of essays as a means of assessment are shown in the literature (Siriwongs 2015).

The tests (TE1-TE32) - presented as online tests on the learning management system  -  involved  multiple-choice  questions  with  basically  no  multimodal content, despite the fact that the learning management system allows for the inclusion of graphical, audio, video and even other embedded online content.

A lot of the instructions provided in assessments pertain to the structuring and technical aspects regarding the way in which the assignments have to be completed (GA5, GA7, GA15, GA19, GA21, GA23, GA25, GA29, GA32, GA37, GA40) with some assignments providing no instructions (GA36). There were clear efforts of scaffolding and supporting assessments through the use of

checklists (GA1, GA11). In some cases, even templates are provided for use by students in completing tasks (GA18, GA20, GA22, GA24). Such a document can  be  useful  in  supporting  new  students;  however,  this  could  become  an unnecessary crutch which could impact students' self-direction in mastering different aspects of word processing software themselves - a skill which is considered essential for students (as is evidenced by this research), as well as teachers ultimately. Consequently, few choices were available to students in terms of the mode of communication or interactional multimodality (Olivier 2020a, 2020b) employed.

However, limited assessments did allow for greater variation in terms of interactional  multimodality.  This  included  questions  or  tasks  that  involved designing or creating the following:

- · Mind map (GA13)
- · Diagram (GA13, GA37, EX4)
- · An analytical rubric (GA28, GA30)
- · Web page (GA40)
- · Video (GA49, GA52).

Interestingly,  for  the  assignments  utilising  multimodal  content,  the  rubrics' criteria  were  confined  to  content  and  language  issues,  and  no  multimodal aspects were specifically assessed. However, such an approach could make the use of a variety of modes possible for the same assignment.

## Language issues

The content analysis also allowed for the identification of various spelling and language errors.  This  was  especially  true  for  the  limited  Afrikaans  content (GA7, GA17, GA25, GA27, GA31, GA49, EX4, EX5, EX6, TE1, TE2, TE4, TE5, TE19,  TE30),  but  was  also  included  in  some  English  texts  (GA7,  GA28, GA30, GA32).

Some  inconsistencies  came  to  the  fore  in  the  translation,  with  texts presented  parallel  with  English  and  Afrikaans  equivalent  questions.  For example, in GA51, the words 'transform' was translated as 'hervorm' ('reform' in  English),  and  'apply'  was  translated  as  'implementeer'  ('implement'  in English). In these two examples, the Afrikaans equivalents are closely related but  differ  enough  to  make  a  semantically  significant  difference  in  the understanding of what is being asked. Another translation issue was the fact that if an automatic true-false question was used, the options always displayed English  answers  despite  the  fact  that  the  question  might  be  in  Afrikaans. Hence the limitations regarding the learning management systems language capabilities is a cause for concern. As these issues do not directly relate to the aims of this research, these errors were not explored in-depth.

## Results of the corpus linguistic analysis

A corpus analysis was done in this chapter in order to explore the nature of axiologolects  in  selected  assessment  texts.  Selective  frequency  tests  were done  on  the  corpus.  In  this  regard,  the  interrogative  words  and  questionrelated terms were explored within the whole corpus. Therefore, the instances reported here were included both in instructions as well as in parts of questions. The frequencies determined by AntConc's Word List were adapted based on the concordance list as some of the interrogative and question-related words might also serve other purposes, and only when they fulfilled the described function, they would be counted. Where possible different forms of words were all considered together and wrongly spelled words also counted. These frequencies were not normalised and are presented in terms of the full corpus (cf. Table 2.2).

It  was  found  that  the  word  'what'  was  the  most  common  interrogative word, occurring 173 times in the corpus. Of such constructions, the majority of the collocates were 'what are […]' (53 times), 'what is […]' (9 times) and 'what does […]' constructions followed by 'what can […]' and 'what will […]'. Nearly all these constructions involved basic knowledge probing questions such as 'What is a sample and a population?' (GA37).

Other  common  interrogative  words  included:  'which'  (116  times),  'how' (115 times), 'when' (43 times), 'why' (27), 'who' (7 times) and 'where' (6 times). In addition, other typical question-related words were also used numerously in the frequency list. The words with more than six instances included: 'explain' (42 times), 'design' (38 times), 'answer' (36 times), 'choose' (33 times), 'write' (32 times), 'complete' (29 times), 'determine' (19 times), 'discuss' (18 times), 'make'  (17  times),  'describe'  (16  times),  'identify'  (16  times),  'formulate' (15 times), 'compare' (11 times), 'analyse' (8 times) and 'define' (7 times).

The frequency of all the relevant terms from the Revised Bloom's Taxonomy Action Verbs was also determined and is summarised in Table 2.2.

However, SDL cannot be definitely fostered through specific phrasing of questions and assessment texts, but there are words that could have been

TABLE 2.2: Verb frequency based on the Revised Bloom's Taxonomy Action Verbs.

| Level         |   Total number of words (normalised to 1000) |   Number of words  1st years (normalised to 1000) |   Number of words  4th years (normalised to 1000) |
|---------------|----------------------------------------------|---------------------------------------------------|---------------------------------------------------|
| Remembering   |                                         13   |                                              13   |                                              11.6 |
| Understanding |                                          1.5 |                                               2.2 |                                               1.2 |
| Applying      |                                          2.7 |                                               3.4 |                                               2.9 |
| Analysing     |                                          1.8 |                                               0.2 |                                               1.7 |
| Evaluating    |                                          4.9 |                                               3.4 |                                               5.3 |
| Creating      |                                          7.1 |                                              13.2 |                                               9.3 |

expected in this corpus. Some of the words identified in the content analysis were explored through the corpus linguistic software by means of concordance searches. There were, for example, six instances prompting self-assessment and three for self-evaluation. Of all the 38 instances of the word 'plan', only 2 referred to it acting as a verb relating to an action to be completed by the student. From the eight instances of the word 'reflect', only three prompted students to reflect on something or on an assignment.

As  student  responsibility  and  resource  selection  is  key  to  SDL,  so  the patterns  of  selection  verbs  (such  as  'pick',  'select'  and  'choose')  were  also explored. For the word 'choose', out of 33 only 4 related to students being able to choose a topic. The rest of the instances were either used in general contexts or, similarly to all the five instances of 'select' used in multiple-choice questions to prompt a student to select an answer. Other words, such as 'pick', were either not used at all or were used in a general sense - as was the case with 'decide'.

An area for further exploration would, hence, be to compile a corpus of questions that are considered to be contributing to the fostering of SDL, and then, after linguistic analysis, guidelines could be provided in terms of question formulation.

## Results of the readability tests

Readability was also investigated in this chapter in order to determine the nature of axiologolects in selected assessment texts. The open source software Libro was used to determine a summary of the language features of the corpus and  to  explore  the  readability  of  the  texts.  This  summary  is  presented  in Table 2.3.

In terms of Flesch reading ease (cf. Bailin &amp; Grafstein 2016), nearly all the values  fall  between  50  and  60,  which  is  regarded  as  being  'fairly  difficult' (Flesch 1979) to read and is regarded at a Grade 10 to Grade 12 1  level. The only exception  would  be  the  rubrics  where  the  average  for  all  the  rubrics  is considered 'difficult to read' and regarded as being at university level (Flesch 1979), whilst the extracted rubrics for the first-year students is 'very difficult to read' and is at university graduate level. However, it should be noted that only one first-year rubric text was included in the corpus. Furthermore, the fourth-year rubric text with a value between 60 and 70 places it in a 'plain English' category which is at Grade 8 or Grade 9 level (Flesch 1979).

Furthermore, the Flesch-Kincaid readability tests also include the FleschKincaid grade level (cf. Bailin &amp; Grafstein 2016), which in the corpus ranges

## Assessing axiologolects

TABLE 2.3: Summary of the corpus and readability scores.

| Variables                                | General assignments   | General assignments   | General assignments   | Tests and examinations   | Tests and examinations   | Tests and examinations   | Rubrics   | Rubrics      | Rubrics       | Total   |
|------------------------------------------|-----------------------|-----------------------|-----------------------|--------------------------|--------------------------|--------------------------|-----------|--------------|---------------|---------|
| Variables                                | Total                 | First  years          | Fourth  years         | Total                    | First  years             | Fourth  years            | Total     | First  years | Fourth  years | Total   |
| Number of  characters                    | 203 015               | 5143                  | 28 879                | 151 325                  | 22 264                   | 28 879                   | 12 117    | 427          | 5027          | 366 457 |
| Number of  words                         | 29 470                | 809                   | 4395                  | 23 699                   | 3264                     | 4395                     | 1625      | 57           | 672           | 54 794  |
| Different  words                         | 3616                  | 363                   | 1139                  | 3501                     | 819                      | 1139                     | 428       | 46           | 166           | 5626    |
| % of  different  words                   | 12.27                 | 44.87                 | 25.92                 | 14.77                    | 25.09                    | 25.92                    | 26.34     | 80.7         | 24.7          | 10.27   |
| Number of  syllables                     | 50 986                | 1277                  | 7464                  | 39 802                   | 5716                     | 7464                     | 3088      | 118          | 1073          | 93 876  |
| Number of  sentences                     | 7971                  | 55                    | 342                   | 3514                     | 391                      | 342                      | 129       | 3            | 68            | 11 614  |
| Average  number of  characters  per word | 5.80                  | 5.33                  | 5.44                  | 5.56                     | 5.93                     | 5.44                     | 5.98      | 6.68         | 5.05          | 5.70    |
| Average  number of  syllables per  word  | 1.73                  | 1.58                  | 1.70                  | 1.68                     | 1.75                     | 1.70                     | 1.90      | 2.07         | 1.60          | 1.71    |
| Average  number of  words per  sentence  | 3.70                  | 14.71                 | 12.85                 | 6.74                     | 8.35                     | 12.85                    | 12.60     | 19           | 9.88          | 4.72    |
| Flesch  reading  ease                    | 56.72                 | 58.36                 | 50.12                 | 57.91                    | 50.21                    | 50.12                    | 33.28     | 12.41        | 61.72         | 57.11   |
| Flesch- Kincaid  grade level             | 6.27                  | 8.77                  | 9.46                  | 6.86                     | 8.33                     | 9.46                     | 11.75     | 16.24        | 7.11          | 6.47    |
| Gunning  Fog Index                       | 5.41                  | 7.37                  | 9.17                  | 7.25                     | 7.29                     | 9.17                     | 16.79     | 16.37        | 5.59          | 6.32    |
| SMOG Index                               | 5.31                  | 5.80                  | 7.24                  | 6.30                     | 6.41                     | 7.24                     | 10.08     | 10.50        | 5.43          | 5.74    |
| Coleman- Liau Index                      | 10.38                 | 13.60                 | 13.96                 | 12.57                    | 15.61                    | 13.96                    | 17.10     | 22.02        | 10.94         | 11.53   |

between Grade 6 and 'Grade 16' (which implies four years after school). For assignments, the overall grade was just over Grade 6, whilst the first-year and fourth-year assignments were just below and just above Grade 9 level. The tests and examinations were overall just under a Grade 7 level, with the first years  and  fourth  years  at  just  over  Grade  8  and  Grade  9,  respectively. The rubrics were overall at just under Grade 12 level, with the first years at Grade 16 (or Grade 12 plus 4 years) and the fourth years at a Grade 7 level. Once again, the first-year rubric text may skew the results as it is only one text and the nature of words may have an influence as well.

For  this  data  set,  the  Gunning  Fog  Index  corresponds  with  the  FleschKincaid grade level in most cases. The overall grade for assignments and that of the first years is slightly lower for the Gunning Fog Index. The same applies for tests and examinations for the first-years and rubrics for the fourth-years. There is quite a significant difference between the overall grade for rubrics across all years. But generally (except for the overall and first-year grades for the rubrics), the Gunning Fog Index is between Grade 5 and Grade 9.

As the Coleman-Liau Index also provides a grade level as the latter three readability  tests  discussed,  it  is  interesting  that  this  index  measures  quite higher than the others. Here the overall grade is between Grade 11 and Grade 12 whilst the rest of the values are between Grade 10 and Grade 13. The exception was first-year tests and examinations being at over Grade 15, the overall rubrics at Grade 17, and the already highlighted first-year rubric at Grade 22.

No consistent trend was identifiable from the readability scores. However, regardless of the first-year rubric as an outlier, the readability of rubrics seems to be less favourable, followed by the tests and the examinations, and finally, general  assessments  that  seem  to  be  the  most  accessible.  These  findings show  that  attention should be  paid to ensuring that rubrics are as understandable  as  general  assignments  and  that  tests  and  examinations should also not be written at a higher level than students are used to with other formative assessments. However, there seems to be some progression with fourth-year assessment texts being less readable than first-year texts, and that is to be expected.

## Findings and discussion

The  dataset  showed  clear  evidence  of  axiologolects having  elements supporting situated learning as assignments were often aimed at the practice of being a teacher. A general trend observed through the content analysis was the lack of student agency and participation in creating the assessments and the  assessment  criteria  and  rubrics.  Such  information  is  provided,  and  no evidence  of  inputs  by  students  was  found.  Hence,  it  is  assumed  that  the documents are exclusively teacher-generated. However, this is an issue that would require further empirical investigation.

In terms of SDL, some assessment texts showed evidence of supporting collaboration  through  peer  and  group  assessments.  The  manner  in  which questions  were  posed  also  prompted  student  views  and  engagement. However, overall, SDL was not openly promoted through assessment activities.

With regard to SDML, most of the assessments in the dataset related to long written assignments. Guidance in terms of structuring varied, but there was a trend towards provided a lot of detail in terms of layout and format.

Very few multimodal assessments were employed, but there were attempts to include more traditional multimodal genres such as mind maps, diagrams and rubrics as well as highly relevant genres such as websites and videos. However, the inclusion of more multimodal assessments as well as choices in this regard seems to be an area for future development.

In terms of general language issues, some spelling and language errors as well as translation inconsistencies were observed.

From the corpus linguistic analysis, the most prominent interrogative words employed were 'what', 'which' and 'how'. But from this analysis, little could be gleaned regarding SDL, SDML or even situated learning. However, when verb frequencies were explored regarding the Revised Bloom's Taxonomy Action Verbs, the overemphasis on remembering followed by creating was evident. There also seem to be very few questions relating to applying and analysing. An overreliance on remembering type questions may  have negative consequences in promoting an SDL approach for assessment.

From the readability tests, it was evident that there is quite a lot of variation between the texts. In order of readability, the general assignments seemed to be the simplest, followed by tests and the examinations and then rubrics as being the most complex. In addition, when first-year and fourth-year texts were compared, overall there seemed to be a logical progression in complexity.

An important requirement towards situated SDL-oriented assessment is addressing the role in and agency of students in terms of assessment. More than  20  years  ago,  Gipps  (1999:387)  already  highlighted  this  issue  and made the following recommendation: 'We need to bring out into the open the nature of the power relationship in teaching and assessment and point out the possibility  of  reconstructing  this  relationship'.  In  addition,  Gipps  (1999) proposes the following cause of action:

[ W ]e need to encourage teachers to bring pupils into the process of assessment, in order to recognize their social and cultural background, and into self-assessment, in order to develop their evaluative and metacognitive skills. (p. 387)

Teachers' knowledge of appropriate and adaptable axiologolects is essential. Being able to adequately employ linguistic resources should be regarded as part of teachers' assessment repertoires (cf. Cowie et al. 2013).

From  the  literature,  the  importance  of  feedback  within  the  assessment process was evident. Because this aspect of the axiologolects was not covered in  this  research,  it  is  a  possible  important  avenue  for  future  research  as feedback  language  would  also  need  to  be  researched  in  order  to  explain current  assessment  practices.  Here,  the  various  dialogues  (cf.  Cowie  et  al. 2013)  could  provide  very  rich  data  for  linguistic  and  assessment-related inquiry.

## Recommendations

Lecturers should consider the readability of texts and specifically ensure that tests and examinations as well as rubrics are not more complex linguistically than other assessments  utilised throughout  a  semester.  Consequently, readability tests - which are freely available online - can be used by teachers to gauge readability and assessment texts can then be adapted. In addition, assessment  texts  themselves  and  even  the  process  of  involving  students should  not  lead  to  cognitive  overload  or  some  form  of  burden  of  choice (Kicken et al. 2008) on the side of learners, and consequently, texts need to be structured effectively and processes are supported by clear structures.

The fact that no differentiation in language use was found for students with different  linguistic  needs  amplifies  the  need  for  greater  personalisation  of learning. In this regard, this chapter is in support of the plea made by Elana Shohamy (1984):

[ D ]ecision makers should be sensitive to the levels of proficiency of the test taker, since testing method, language and text, make more of a difference for low-level students than for advanced students. (p. 159)

Therefore, any assessment that is sensitive towards students' axiologolectal needs will have to be adaptable and informed by linguistic and comprehension data  that  could  be  derived  from  learning  analytics  and  other  diagnostic assessments that can be imbedded within the regular learning and assessment process.  According  to  Tomlinson  and  Moon  (2013:17),  'assessment  in  an effectively differentiated classroom is the foundation of successful instructional planning'.

The  most  important  recommendation  towards  situated  SDL-oriented assessment would be to include learners in the process of planning, structuring and not just the execution of assessments. As learners are expected to take charge of their learning, outcomes, resources and the whole process - on their way  towards  SDL  -  so  should  they  also  take  responsibility  for  aspects  of assessment and hence also have insight into axiologolects.

It  is  essential  that  learner  agency  is  recognised  through  letting  learners formulate questions - whether for the purposes of classroom engagement or for  more  formal  assessments.  This  aspect  of  learners  taking  charge  of  the assessment process would be beneficial to their SDL, as learner control in terms of task selection contributes to SDL according to the literature (Kicken et al. 2008). The Question Formulation Technique (QFT™) by Rothstein and Santana (2011) could be useful. Cummings (2020) summarises this technique as follows:

[ T ]he  teacher  presents  a  question  focus,  students  generate  questions  following a simple set of rules, students identify different types of questions and learn how

to transform them, students prioritize questions, teacher and students discuss the next steps, and students reflect on the process. (p. 38)

Cummings (2020) also emphasises the importance of convergent thinking that occurs because of the prioritisation, as well as how the reflection process as metacognitive element is essential for engagement. However, as Cummings (2020) found, mere inclusion of questioning by learners does not necessarily imply engagement and active participation and sharing of learners' thought processes are recommended. Moreover, Clark (2017) found that the QFT could also be used to successfully impact learners' curiosity which can be supportive of deep learning.

Any promotion of learner agency and greater responsibility in terms of learning need support and scaffolding on the part of the teacher (Beckers et al.  2019;  Kicken  et  al.  2008).  Consequently,  when  it  comes  to  supporting learners in contributing to the assessment process, teacher support is also essential and this can involve not only support in terms of content and subjectspecific skills but also axiologolectal skills. This prompts the need for further in-depth research in order to identify all the necessary relevant axiologolectal skills.

Promoting situated SDL-oriented assessment requires that such assessments be embedded in appropriate pedagogy. In this regard, Lombard (2018) observed that assessment approaches rely on the following:

[ C ]ompetent pedagogy which is embedded in attitudes and beliefs that subscribe to  the  idea  that  assessment  is  unequivocally  connected  to  quality  learning,  and knowledge and skills to successfully perform assessment with this perspective in mind. (p. 12)

The  affordances  that  technology  can  provide  in  terms  of  formulating  and evaluating  the  wording  of  assessments  need  to  be  explored.  As  Lindberg (2013) has shown, through the use of existing templates and technologies, questions  can  be  formulated  to  be  accurate,  effective  and  pitched  at  a sufficient level of cognitive complexity. The challenge is to inform such systems with sufficient corpora of questions relevant to the SDL context. The ability to attend to the adaptive needs of learners, as noted by Lindberg (2013), could also contribute to fostering learners' SDL.

Assessments, and by implication the axiologolects used in the pertinent assessment texts, should be supportive of situated learning. In this regard, both  process  and  language  should  promote  authentic  and  collaborative learning environments (Donaldson et al. 2020). It is hoped that in a similar fashion as Donaldson et al. (2020) found regarding student teachers being honed  as  designers  within  a  situated  learning  approach,  so  can  student teachers also be supported to approach assessments and axiologolects in an authentic manner that could encourage learner agency and foster SDL.

## Limitations

This study was limited in terms of the research population involved. Not only were they only from one institution, but the modules identified were specifically intended for distance learning students. In addition, only assessment texts voluntarily  supplied  or  made  available  through  the  learning  management system were included in the corpus. Consequently, the findings of this research are not generalisable and could be explored further with bigger corpora and more diverse contexts.

The study was mainly confined to English assessment texts, despite having access to some limited Afrikaans texts. For some of the tests, such as the readability  and  frequency  determination  in  terms  of  the  Revised  Bloom's Taxonomy Action Verbs, only the English texts were used.

A further issue is that the findings of this research are restricted to what can be gleaned from the corpus and it might be an option to compare such findings  with  the  intentions  and  views  of  lecturers  as  well  as  actual understanding and perceptions of students.

## Conclusion

This chapter started by stating that the nature of axiologolects in selected assessment texts, as well as the way in which axiologolects were realised in assessment  texts,  support  situated  SDL-oriented  assessment  would  be explored. It was found that this is done only in a limited way because from the dataset, it was evident that most of the assessment process is teacher-driven.

It is hoped that SDL-oriented assessment can ultimately become an 'organic and  persistent interactive loop' (Tomlinson  &amp;  Moon  2013:18)  involving teachers  and  learners,  and  through  which  axiologolectal  disciplinary  and student  needs  are  accommodated  through  dynamic  and  collaborative assessment text development.

In conclusion, it is evident from the analysis of the assessment texts that situated  learning  is  supported  through  situating  assessments  within  the practice of being a teacher. However, when it comes to SDL, little student agency  was  present,  and  in  terms  of  content,  the  assessments  did  not necessarily overtly prompt activities or actions that could act in support of fostering SDL. Despite this lack of clear linking with SDL-supporting processes, the openness of some questions had the potential of SDL being fostered in a more  covert  fashion.  Within  the  context  of  SDML,  the  lack  of  multimodal content  and  use  of  multimodal  assessments  were  clear.  Consequently,  the analysed assessment texts were heavily text-based.

## Chapter 3

## Self-directed multimodal assessment: Towards assessing in a more equitable and differentiated way

Jako Olivier

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Mahikeng, South Africa

## Abstract

An increase in the use of technology in education has led to changes in the way learning takes place and content is represented. However, despite this trend and preferences for digital modes of communication and challenges encountered by students, the assessment practices in higher education have remained largely monomodal and text-based. This conceptual chapter deals with the scholarship around self-directed multimodal assessment in order to provide  recommendations  which  would  make  equitable  and  differentiated

How to cite: Olivier, J., 2021, 'Self-directed multimodal assessment: Towards assessing in a more equitable and differentiated way', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 51-69, AOSIS, Cape Town. https:/ / doi.org/10.4102/aosis.2021.BK280.03

assessment  possible.  The  concept  of  multimodal  assessment  has  been extensively  researched  in  the  language  teaching  context,  especially  the theoretical  foundations  of  multimodality.  When  learning  is  regarded  as communication, the semiotic resources used in the broader learning context should  also  be  considered  for  assessment.  In  this  chapter,  assessment  is approached  as  SDL-oriented  assessment  with  the  emphasis  on  formative assessment that fosters self-directed learning. Therefore, assessment processes  should  accommodate  individual  multimodality  whilst  providing sufficient  opportunity  for  resource  selection  in  the  Knowlesian  sense.  This chapter is concluded by suggesting a framework for self-directed multimodal assessment  that  unpacks  the  relevant  variables  as  well  as  the  relevant processes and requirements. In this regard, a self-directed multimodal view of assessment would not only address individual modal needs of students for technological access and skills but also attend to the requirements of students with special needs or disabilities.

## Introduction

This  chapter  focuses  on  self-directed  multimodal  assessment  (SDMA)  and addresses the issue of the lack of multimodal assessments with an increasing need for a move away from monomodality in education. Multimodal meaningmaking (Bezemer &amp; Kress 2008, 2016) is a reality in education at all levels (Jones  et  al.  2020),  and  within  this  process,  assessment  involves  various aspects of meaning-extraction  and  meaning-making.  Furthermore,  this chapter  intends  to  gauge  how  SDMA  can  contribute  to  assessing  in  more equitable and differentiated ways.

Because of a proliferation of the integration of technology in education, learning and teaching have become a lot more multimodal (Nouri 2019; Ross, Curwood  &amp;  Bell  2020;  Smith  et  al.  2019;  Tan  et  al.  2020).  The  need  for self-directedness is also progressively important because of the pace at which knowledge  is  created  and  the  fact  that  educational  institutions  cannot adequately  prepare  students  for  a  dynamically  changing  world  of  work (Mok 2009). In this chapter, multimodal assessment is approached in terms of SDL, as student preferences and capabilities must be considered in order to support student agency  in learning. Consequently, various modes  of assessment are also implied.

Emphasising multimodal learning is highly relevant in the digital age as, according to Bell, Curwood and Ross (2018:1713), '[l]earning in a digital age involves the creation and assessment of multiple, multimodal, and multifaceted textual representations'. However, assessment practices have not necessarily adapted  accordingly.  In  support  of  this  statement,  Tan  et  al.  (2020:101) identify 'tension between conventional assessment practices and the contemporary  presence  of  digital  technologies'.  Moreover,  in  this  broader

context,  multimodal  assessment  relates  to  the  concept  of digitally  based classroom  assessment (Russell  2019)  but  can  also  be  relevant  outside classroom contexts.

When it comes to assessment, there still seems to be a preference for textbased assessing despite calls in literature (Bell et al. 2018; Cartner &amp; Hallas 2020; Fjørtoft 2020; Tran 2019) for the need to use a variety of modes for assessment. In this regard, Ross et al. (2020) summarise the current state in higher education as follows:

Within higher education, student learning in many disciplines has traditionally been assessed through written compositions and oral presentations, often in high-stakes exam environments. For students, this can lead to disengagement or difficulty in their ability to share, critique and generate knowledge in university settings. For teachers, this presents challenges to their pedagogy, including how they formatively and summatively assess student learning. (p. 292)

The  challenge,  therefore,  remains  for  teachers  to  consider  other  types  of assessments than written ones as and when they are appropriate. Furthermore, any  discussion  on  SDMA  should  also  contemplate  assessment  equity  and differentiation of assessments for students.

In  addition, whilst multimodality (Bezemer &amp; Kress 2008, 2016) is considered in formative assessments, there seems to be a reluctance to include digital media in  summative  or  high-stakes  external  assessment  opportunities  (Hafner  &amp;  Ho 2020; Ross et al.  2020).  Importantly,  within  a  broader  view  of  multimodal assessment, this phenomenon does not only relate to technology but can also refer to paper-based multimodal content (Tran 2019). The need for approaches to assessment where both multimodality and self-directedness are considered is  especially acute in contexts with 'strong examination cultures' (Mok 2009:61).

In this chapter, assessment is viewed from a sociocultural perspective. If approached  from  this  perspective,  'assessment  should  be  closely  coupled with  learning  and  enacted  as  dynamic  and  meaningful  in  relation  to  how students  come  to  see  themselves  as  learners'  (Silseth  &amp;  Gilje  2019:27).  In addition, this is part of a broader view of learning being mediated by culture and situated in real-life and authentic contexts (Olivier 2020c; Silseth &amp; Gilje 2019). Social semiotics serves as a theoretical foundation for SDMA. Social semiotics is an approach that focuses on how a community creates meaning through representations within the context of the communication landscape (Fjørtoft 2020). In the same way, a semiotic mode can be considered being a system of choices (Jones et al. 2020), so, too, could the mode of assessment be interpreted as a similar system.

In the context of this chapter, the emphasis is also on assessment as part of a social or communal process. To this end, SDMA could be interpreted within the context  of  the  Japanese  concept  of kankei, which  relates  to an interrelationship  (Arimoto  &amp;  Clark  2018),  or  the  South  African  concept  of

Ubuntu as  derived  from  the  Nguni  languages  and Botho from  the  Sotho languages.  For  Le  Grange  (2019:217), Ubuntu involves  humanness  and 'becoming more fully human through deeper relationships with other human beings'.  Le  Grange  also  interprets Ubuntu as  having  a  similar  meaning  as ukama , a Shona word emphasising 'relatedness'. Therefore, it is proposed that SDMA is considered within a broader Ubuntu-currere (Hlatshwayo &amp; Shawa 2020;  Le  Grange  2019)  approach  where  the  emphasis  is  shifted  from  the individual (the teacher) to 'an assemblage of human-human-nature' (Le Grange 2019:222). Hence, this humanness, as not only a South African phenomenon, but  rather  a  more  global  communal  approach,  should  be  prominent  for learning and ultimately assessment.

Assessment is regarded in this chapter within the context of SDML , which relates  to  an  approach  to  education  aimed  at  promoting  self-directedness (cf.  Brockett  &amp;  Hiemstra  2019;  Knowles  1975;  Mok  2009)  through  utilising individual  modal  preferences  of  students,  learning-related  communication through various modalities in addition to blending of learning, teaching and delivery  through  different  modes  (Olivier  2020a,  2020b).  The  emphasis  of this chapter is mainly on the higher education context, but most of the issues are also related to school-based education. Consequently, the terms teachers and students are  used  in  the  generic  sense  regardless  of  the  level  of educational delivery.

This conceptual chapter aims to explore through a critical review of relevant literature how SDMA can be used towards assessing in a more equitable and differentiated way. To this end, this chapter considers SDL-oriented assessment and student agency, the move from monomodal and multimodal assessment, and  issues  of  equitable  assessment  and  differentiation.  Finally,  practical recommendations for SDMA are suggested.

## Self-directed learning-oriented assessment and student agency

## Self-directed learning and assessment

The role and nature of assessment in SDL have been explored extensively in the literature (cf. Lubbe 2020; Lubbe &amp; Mentz 2019; Mok 2009; Zeng et al. 2018), and this chapter joins this broader discourse. In this chapter's context, the concept of SLOA is also relevant.

In this context of this chapter, SDL (cf. Brockett &amp; Hiemstra 2019; Knowles 1975)  is  considered  an  individually  driven  creative  and  resourceful  process towards student agency which involves making use of learning resources as well as people to set goals, selected means and strategies to reach set outcomes

and ultimately evaluate and reflect on the process. Assessment is a part of this process and can be approached in a manner as suggested in terms of the SLOA framework.

The SLOA framework by Mok (2009) emphasises that assessment should enhance and serve learning, and that SDL is essential. The framework entails the following (Mok 2009):

[ A ] coherent framework of assessment, deliberately designed to capitalise on the integrative impact of metacognition, feedback, motivation, contextual factors, and self-regulation on learning in the construction of assessment activities in order to cultivate self-directed learning capacities in students. (p. 11)

For  Mok  (2009),  the  concepts  of metacognition and self-regulation are fundamental to SLOA. These imply, for example, timely feedback, activities to raise students' metacognitive awareness and expanding students' self-regulation skills (Mok 2009). The SLOA can also be interpreted within the context of three integrated components: 'assessment of learning, assessment for learning,  and  assessment as learning'  (Mok  2009:11;  [ emphasis  in  the original ]). Hence, these components should also underly SDMA.

It is essential that assessment is not regarded as being separate from the learning taking place. Evidently, choices of assessment methods can prepare students for lifelong learning and also be supportive to AfL (Garside et al. 2009). Furthermore, Lubbe and Mentz (2019:362) concur that 'assessment should  not  be  separated  from  the  learning  process,  and  that  assessment practices should be embedded within social constructivism, with the learning process  at  its  core'.  Similarly, as  regards  multimodal  composition  and assessment, Silseth and Gilje (2019) found that:

[ S ]tudents, when dealing with assignments that involve multimodal composition, can be sceptical about investing time and effort in producing these types of texts if they are not integrated thoroughly into the assessment practice. (p. 38)

Consequently, the proposed SDMA would also need to be integrated into the broader multimodal learning process.

The implication is,  therefore,  not  only  embedding  assessment  in  and  as part of the learning process but also approaching it as a social phenomenon as was stated in the introduction. This approach also relates to the idea of viewing learning as communication (cf. Olivier 2020b), which, in the context of this chapter, refers to multimodal  communication  and,  specifically, interactional multimodality (Olivier 2020a, 2020b). Moreover, by focusing on multimodal  assessments,  the  divide  between  students'  creative  and  social experiences online (cf. Ross et al. 2020) can be crossed through exploiting students' knowledge and background within the classroom setting by moving from the personal to the more public educational sphere. In this context, the role and voice of the student become crucial.

## From student voice in assessment to student agency

The  issue  of  student  voice  and,  ultimately,  student  agency  in  assessment should be considered within a broader context where students - often outside of the classroom - are already active producers of knowledge through different modes  within  digital  environments  (Nouri  2019).  In  the  SLOA  context, Mok (2009) also emphasises that  students  should  be  activated  as  learner partners  and  resources.  In  this  chapter, student  agency refers  to  students being  able  to  make  their  own  choices  in  a  self-directed  manner  within  an educational context.

There is a need for student agency within the broader discourse and praxis of assessment. From the literature, a trend towards collaboration with students in the assessment process and even developing assessment criteria is evident (Hafner &amp; Ho 2020; Tan et al. 2020). In this regard, Bell et al. (2018:1714) note that  'teachers  within  higher  education  need  to  consider  how  to  create  a dialogue with students around assessments'. Wylie and Lyon (2019) also agree that teachers should ensure that students play an active role in the assessment process. The challenge is therefore to build on existing good practices where dialogue  has  been  established  with  students  as  regards  assessments  or establishing it where it has been overlooked. After which, dialogues can be transformed into active participation in the planning, structuring, monitoring and execution of assessment processes.

Moreover, the following statement by Hafner and Ho (2020) highlights the importance of student agency in multimodal assessment. They (Hafner &amp; Ho 2020) recommend that:

[ T ]eachers and students work collaboratively throughout the different stages of the design process so that students receive an appropriate amount of scaffolding to  develop  multimodal  communicative competence and digital skills required in their 21st century social lives. (p. 12)

Hence, engaging with students about assessment might not be sufficient, as they need to be empowered to make informed inputs and contributions. As stated above, this process also requires the development of skills extending beyond  communication  skills  but  also  touching  on  assessment  literacy (cf. Lubbe 2020).

Student agency is also associated with so-called critical assessment . This view, which  also  relates  to  equitable  assessment,  involves  challenging assessment  practices  with  a  critical  lens.  According  to  Montenegro  and Jankowski  (2020:9),  critical  assessment  requires  '[i]ncluding  the  voices  of students, especially those who belong to minoritized populations or those whose voices can often be left unheard, throughout the assessment process'. However, critical literacy also involves acknowledging that all assessment is

inherently  subjective,  assessment  types  should  be  varied  and  that  equity should be advanced (Montenegro &amp; Jankowski 2020). It can be the case, as was found by Olivier (2020c) in a South African context, that assessments are not adjusted to be sensitive or attuned to the different cultural values present in classrooms,  hence  the  need  for  a  critical  approach  to  the  overall assessment process.

The  use  of  multimodal  assessments,  as  a  way  of  giving  students  more choices, may also contribute to student agency. The use of multimodal (or specifically digital) tools can contribute to fostering student agency through supporting self- and peer-assessment (Wylie &amp; Lyon 2019). Tran (2019) makes the following observations about her research on using multimodal assessments with postgraduate students:

The choice gives all students an opportunity to have creative control over the mode of submission. The teacher is able to show students another level of respect, trust, and an openness to experimenting with assessment methods. (p. 169)

As the choice of resource is integral to SDL (cf. Knowles 1975), so does there also seem to be a social justice element to having multiple modes of submission available in order to address challenges regarding the digital divide and digital literacy levels.

Despite the literature promoting the notion of involving students throughout the learning and assessment process, it is clear that often this does not happen (cf. Olivier 2020c). In a study on culturally appropriate and situated multimodal learning  at  a  South  African  university,  Olivier  (2020c:260)  found  that 'according to students, on a broader level, they do not have any choice as to what learning content is included in their curricula'. Hence, in many contexts, a key requirement towards effective SDMA would be to create circumstances that are conducive to student agency and fostering SDL in assessments. These issues are approached in this chapter through multimodality, and so the move from monomodal to multimodal assessment is relevant.

## Monomodal and multimodal assessment Multimodal learning

The need for multimodal expression is not new and has been part of human communication through the incorporation of various modes of communication for ages (McGrail &amp; Behizadeh 2017). However, in education, there has been a hegemony of text-based resources and especially assessments. This phenomenon stands in  contrast  to  the  realities  of  students,  as  '[s]tudents have  different  ways  to  demonstrate  their  knowledge  and  we  need  to  use assessment metrics that appropriately elicit demonstrations of what students know' (Montenegro &amp; Jankowski 2017:15).

The term multimodal in this chapter also relates to the description of this term by Cartner and Hallas (2020:132) as 'a wide range of applications that enable users to share, comment, create, and discuss digital contents via text, visual, audio, tactile, gestural, and spatial representations'. Multimodal learning , according  to  Fadel  and  Lemke  (2012:2378),  entails  '[using]  multisensory approaches  to  learning,  combined  with  higher-order  experiences  such  as interactivity'.  This  definition  ties  in  with  the  broader  view  of  multimodal learning  concerning  the  different  levels  of  multimodality  (Olivier  2020a, 2020b).

Any extension of multimodal learning and, ultimately, multimodal assessment  can  merely  build  on  existing  multimodal  practices  amongst students. From research by Nouri (2019:695), it was concluded that 'students' construction and consumption of learning material is to a large extent taking place in a multimodal way'. Therefore, teachers and education institutions also need to reflect  this  broader  societal  change  and  make  use  of  students  as experts of multimodality who can work symbiotically with teachers as learning experts whilst building on their collaborative knowledge expertise.

In this chapter, the focus extends beyond general multimodal learning and concentrates on multimodal assessment.

## From multimodal learning to multimodal assessment

The importance of multimodal assessment has been explored in research on literacy, language learning and composition specifically. This includes research on  assessment  of  digital  composition  and  language-related  multimodal assessment (Baldwin 2016; Curwood 2012; Grapin &amp; Llosa 2020; Hafner &amp; Ho 2020;  McGrail  &amp;  Behizadeh  2017;  Silseth  &amp;  Gilje  2019;  Tan  et  al.  2020). Multimodal  assessment  has  also  been  explored  in  other  subjects  such  as science education (Jones et al. 2020; Smith et al. 2019). However, this approach has relevance for all subjects.

Unfortunately, teachers do not always regard multimodal assessment as important or relevant. Hafner and Ho (2020) ascribe this to a lack of teacher digital skills and confidence as well as the fact that multimodal assessments are not necessarily included in external or high-stakes assessments. The issue of validity is a further counterargument to the use of alternative methods of assessment (Garside et al. 2009).

Multimodal assessment also relates to addressing the demands of students. From the literature, it is clear that using and creating multimodal texts meet students' needs (Hafner &amp; Ho 2020) and that students have different modal

preferences (Nouri 2019; Silseth &amp; Gilje 2019). In this regard, Olivier (2019a:384) notes that '[i]ncreasingly, the context and practices of students require the use of multimodal media in classrooms'. Apart from individual learning and communicative  preferences  on  the  part  of  students,  teachers  should  also acknowledge the role dynamic digital environments play in making even more multimodal assessment practices possible. This pertains, for example, to the inclusion of different non-verbal elements such as pictograms, various icons, graphics, videos, animations, simulations and even virtual reality environments.

Multimodal learning and assessment have numerous advantages. The use of  multimodal  texts  can  improve  comprehension  and  student  engagement (Schmeck et al. 2014). Students also learn better in multimodal environments as Fadel and Lemke (2012:2379) maintain that '[s]tudents using well-designed combinations of visuals and text, accompanied by interactivity, learn more than  students  who  only  use  text'.  Therefore,  a  multimodal  approach  is preferred in order to support effective learning and engagement.

Multimodal  assessment  is  also  relevant to student  engagement  as, according  to  Tran  (2019:163),  'students  who  incorporate  multimodal  forms and approaches to their learning are better engaged with the content than those who employ traditional approaches, thereby enhancing their thinking and learning process'. Such engagement is crucial for student success, but the following observation by Russell (2019) is essential to understand the role of technology in engagement in multimodal contexts:

Finally,  the  development  of  technology-enhanced  items  and  more  interactive assessment environments can help increase student engagement with assessment. But while engagement is important for quality assessment, a more critical issue is the collection of evidence that is aligned with the decisions an educator aims to make. (p. 240)

Such evidence could be derived from technology involved in the assessment process using data analytics, for example. Furthermore, Smith et al. (2019:13) confirm  that  an  advantage  of  a  multimodal  approach  as  'multimodal assessment may be a valuable approach to utilizing the new generation of formative assessment approaches designed to evaluate students' responses formulated  in  multiple  modalities'.  In  addition,  in  regard  to  alternative assessment,  O'Brien,  Chlochasaigh  and  Ó'Ceallaigh  (2019:7)  found  that 'students  demonstrate  a  high  degree  of  self-expression,  self-reflection  on preferred  assessment  modes  for  learning  and  self-awareness  of  individual strengths'.  These  aspects  can  also  be  conducive  to  aspects  related  to metacognition and potentially act in support of fostering SDL.

Fjørtoft  (2020:2)  proposes  the  use  of  multimodal  digital  classroom assessments (MDCAs),  which  entail 'any teacher-designed assessment practices requiring students to combine two or more representational modes

using digital technology'. Furthermore, Fjørtoft (2020:3) associates MDCAs with performance assessments, as they both 'focus on the similarity between the  performance  that  is  observed  and  the  type  of  performance  that  is  of interest'.  Yet,  an  advantage  of  multimodal  assessments  might  also  be  that they could be used outside of the classroom.

Including  multimodal  feedback  is  a  further  extension  of  multimodal assessment, Tran (2019:167) calls this approach 'like for like feedback'. However, Tran (2019) describes the negative side of such an approach as follows:

[ ]f  like  for  like  feedback  is  chosen  to  be  part  of  the  feedback  and  assessment I process for a larger course, the issue of staff resourcing would need to be considered due to the amount of time needed to produce feedback using certain technologyenhanced learning tools. (p. 167)

However, the use of multimodal assessment feedback, although not like for like,  might  already  give  advantages  of  ease  and  speed  through  the  use  of audio- or video-recorded feedback. However, more in-depth research would be  necessary  to  probe  which  medium  of  feedback  would  be  the  most appropriate and whether a more differentiated approach would perhaps not be more suitable for a diverse student population. Yet, practical considerations on the part of the teacher should also inform such decisions as a myriad of ways of providing feedback might not be feasible.

Another  example  of  multimodal  assessment  artefact  type  is  videos.  As mobile technologies allow for easier video recording and even editing, these mediums show great promise even in low-resource contexts. The affordances of videos for multimodal learning are clear (Olivier 2019a; Yeh 2018). In this regard, Nouri (2019) observed that:

[ S ]tudents use of video for knowledge acquisition or knowledge representation, which  allow  for  learning  at  their  own  pace  (pause,  repeat),  flexible/mobile learning on the go, and broadening of perspectives (access to many alternative perspectives). (p. 696)

Importantly, when it comes to video as a medium of learning and assessment, students should be informed of the grammar of the medium where different shots,  cuts,  the  mise-en-scène,  sound  and  visual  elements  and  semiotics, amongst  many  other  facets,  carry  meaning.  As  such,  such  genre-specific elements  cannot  merely  be  ignored  or  reduced  to  'technical  aspects'  in assessment criteria.  To  this  end,  both  students  and  teachers  need  to  have sufficient assessment literacy in terms of multimodality in order to create and assess  such  artefacts.  Similarly,  the  nature  of  other  multimodal  genres  will have to be explored in terms of their unique characteristics.

In light of the above discussion on self-directedness, student agency and multimodality, equitable assessment is also explored.

## Equitable assessment

Little has been written about assessment and equity in the past (Montenegro &amp; Jankowski 2017). Importantly, Montenegro and Jankowski (2017) make the following statement:

Assessment, if not done with equity in mind, privileges and validates certain types of learning and evidence of learning over others, can hinder the validation of multiple means of demonstration, and can reinforce within students the false notion that they do not belong in higher education. (p. 5)

This issue also relates to a move towards socially just assessment (Montenegro &amp;  Jankowski  2020),  which  involves  considering  certain  biases  and  power relations and cogitating on the cultures in which assessments take place. As students  and  their  worlds  and  dispositions  differ,  so  should  learning  and assessment accommodate and support them in a multipronged approach.

Equitable assessment implies longitudinal and reliable AoL. In this regard, Fjørtoft (2020) contends that 'standardized tests and other types of singleday examinations rarely provide opportunities to represent student learning across longer time spans', and:

[ ]f the proposed intent of the assessment is to provide a picture of student growth I across time or to represent the breadth and depth of learning, high-stakes and snapshot types of assessment practices could be insufficient. (p. 9)

Conversely,  Fjørtoft  (2020)  describes  how  a  longitudinal  approach  with multimodal assessments, specifically MDCAs, can provide rich data on student skill and understanding.

The assessment criteria and rubrics for multimodal assessments do not necessarily always focus sufficiently on the nature of the different modes involved in artefacts. Bell et al. (2018:1713) note how assessment rubrics have not been adapted to multimodal contexts and that 'technical and compositional assessment criteria do not always address the richness and complexity of multimodal work'. Ross et al. (2020:291) also concur with this view and stress that 'technical and compositional assessment criteria do not always address the richness and complexity of multimodal work'. Hence, the development  of  multimodally  relevant  assessment  criteria  should  be  an ongoing process.

Equitable  assessment  involves  accommodating  the  diverse  needs  of students. In this regard, Montenegro and Jankowski (2017) believe that:

[ C ]hoosing  appropriate  assessment  tools  or  approaches  that  offer  the  greatest chance for various types of students to demonstrate their learning so that assessment results may benefit students from all backgrounds advances our collective interest in student success. (p. 5)

Consequently, it is essential to explore how SDMA can be used in the higher education context where students from different contexts and with different needs can be supported equitably.

A  further  aspect  of  equitable  assessment  is  the  issue  of  language (Driver  2019;  Gandhi-Lee  2018).  This  aspect  is  not  limited  to  the  use  of languages other than English, which is highly relevant to the South African context,  but  even  the  use  of  different  varieties  of  a  language  such  as  the English language. The latter suggestion, however, applies to any language of learning and teaching. The issue of language and dialectal diversity is also highly relevant in multimodal literacies or multiliteracies (cf. Olivier 2019b). The  role  of  language  in  making  equitable  assessment  possible  has  been explored, for example, in chemistry (Gandhi-Lee 2018). However, these issues require further subject- and language-specific interrogation in order to ensure that  assessments  are  comprehensible  to  students  from  different  language communities and with different language capabilities.

Specific needs of students with disabilities and special needs also relate to equitable assessment. In this context, assessment should be responsive to the needs  of  students  with  cognitive  or  learning  disabilities,  emotional  or behavioural disorders, or any other disposition that may require a differentiated approach (Driver 2019). It is clear that assessment policies and practices can marginalise students with disabilities (Driver 2019). The affordances of SDMA for assessment equity for students with disabilities require further in-depth investigation, especially in the South African context.

Within  the  South  African  milieu,  the  issue  of  equitable  assessment  especially in relation to SDMA - also relates to teachers' and students' access to  technology  and  skills.  According  to  Russell  (2019),  access  to  digital technology is a challenge in many contexts.

The  closely  related  concept  of  differentiation  is  also  pertinent  to  this chapter.

## Differentiation and assessment

In this chapter, differentiation entails an approach where different needs and capabilities of students are addressed in the classroom.

Differentiation  in  implementing  SDMA  should  be  considered  as  follows: 'while there may be multiple approaches and methods used across a program or institution for assessing student learning, at each instance of demonstration a single approach is employed' (Montenegro &amp; Jankowski 2017:6). Therefore, multimodality does not involve only a single assessment opportunity but also an assessment per student. Hence, differentiation also implies some form of individualisation,  which  ties  in  with  a  student-focused  view  of  learning  as advocated by SDL.

In  order  to  achieve  differentiation  in  terms  of  assessment,  assessments should  be  culturally  responsive.  This  implies  the  following  (Montenegro  &amp; Jankowski 2017):

Culturally responsive assessment is thus thought of as assessment that is mindful of the student populations the institution serves, using language that is appropriate for  all  students  when  developing  learning  outcomes,  acknowledging  students' differences in the planning phases of an assessment effort, developing and/or using assessment tools that are appropriate for different students, and being intentional in using assessment results to improve learning for all students. (p. 10)

To this end, teachers need to consider how specific modes employed in the assessment process or as assessment artefacts could be supportive in being culturally  responsive  and  appropriate  for  all  students.  This  also  implies teachers  being  aware  of  student  needs  and  profiles,  as  well  as  increased student involvement in all the processes related to assessment.

True differentiation would rely on having sufficient data on students and their needs. Consequently, some form of diagnostic or exploratory assessment at  the  start  of  an  academic  year  or  even  at  unit  level  could  be  essential. Differentiation can only be supported through obtaining sufficient data. This process  could  involve  using  data  analytics  -  that  is,  'the  measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimising learning and the environments in which it occurs' (Siemens &amp; Long 2011:34). Consequently, to inform effective SDMA, data analytics should be planned as being part of the learning and assessment process.

The concept of SDMA is explored next to address the issues of equitability and  differentiation.  A  broad  framework  for  SDMA  is  proposed,  focusing specifically on  multimodality,  the combination  of  modes,  training  and preparation, and literacy.

## Self-directed multimodal assessment

## From multimodality to self-directed multimodal assessment

In  the  literature  on  multimodality,  this  concept  relates  to  representation, communication and interaction through different semiotic resources (Fjørtoft 2020).  This  concept  has  been  extended  by  Olivier  (2020a,  2020b)  as multimodal  learning  to  be  realised  at  four  levels:  individual,  interactional, instructional and institutional multimodality. In this chapter, however, the focus on  multimodal  learning  is  confined  to  individual  multimodality,  specifically multimodal assessment artefact preferences; interactional multimodality with regard to how assessments are realised as multimodal communicative acts; and  finally, the  different  technologies  and  learning  modes  involved  as instructional multimodality.

As  stated  at  the  beginning  of  this  chapter,  the  prevalence  of  digital technologies in education  has resulted in increased opportunities for multimodal assessments. In this regard, Smith et al. (2019) state that:

[ G ]iven  the  growing  breadth  of  activities  enabled  by  digital  science  inquiry environments,  it  is  important  to  develop  assessment  tools  that  can  conduct integrated assessments of student work across multiple activities and modalities. (p. 3)

Silseth  and  Gilje  (2019)  also  express  the  need  for  appropriate  tools  for assessment of multimodal artefacts. The fact that higher education needs to adapt to the multimodal needs that students may have in regard to learning and assessment is also supported in the scholarship (Nouri 2019).

It  is  apposite  to  consider  how  different  modes  of  communication  and artefacts are interpreted within the theoretical frame of multimodality. This implies refocusing from multimodal learning to SDMA and involves combining different modes.

## Combining modes

An important aspect of any approach relating to multimodality is modes and the combination of different modes. According to Olivier (2020a), an essential element  of  instructional  multimodality,  which  is  also  of  importance  in  this chapter, is resource selection. Resource selection entails 'the use of different modes in the learning and teaching context, and in terms of self-direction, this relates  to  the  resources  that  are  relevant'  (Olivier  2020a:122).  The  use  of different  modes  also  implies  combining  them  for  effective  communication and, by implication, learning.

Moreover, the use of different modes emphasises the importance of not only approaching each mode individually but also considering the 'multimodal orchestration'  (Hafner  &amp;  Ho  2020)  or  the  way  multimodal  resources  are combined.  In  addition,  Smith  et  al.  (2019:14)  note  that  it  is  'important  to identify the families of modalities that offer the greatest potential synergistic benefits', as they foresee 'some combinations of modalities may have overlap in their diagnostic power, while others will exhibit great complementarity'.

Using SDMAs can contribute to assessment relevance. Within this context, Fjørtoft  (2020:9)  found,  in  using  MDCAs,  'teachers  can  tailor  assessment practices in the classroom and select the modes of representation most likely to provide relevant evidence of student learning, increase student engagement, and stimulate creativity'.

Both  students  and  teachers  should  be  prepared  and  empowered  to implement SDMA. This implies training teachers and supporting specific skills of students.

## Training and preparing for self-directed multimodal assessment

It is particularly important that teachers are sufficiently trained and supported in using multimodal assessments. This view is expressed in the literature, as teachers  must  be  informed  and  prepared  to  use  multimodal  assessments (Tran  2019).  In  this  regard,  Fjørtoft  (2020:3)  suggests  that  'although  the introduction  of  multimodal  and  digital  approaches  offers  possibilities  for expanding teachers' and students' repertoires, reconceptualizing teachers as designers of multimodal assessment practices remains a challenge'. Similarly, Mok (2009) underscores the importance of teacher capacity building within the context of SLOA.

In a study by Tran (2019), it is noticeable that, although students in this group were positive towards multimodal assessments, only five of 34 students opted  to  submit  a  reflection  in  a  mode  other  than  a  traditional  written document.  Tran  (2019)  ascribed  this  phenomenon  to  a  lack  of  skills,  a preference  for  a  mode  that  students  feel  comfortable  with,  as  well  as  not being  assessed  similarly.  Similarly,  O'Brien  et  al.  (2019)  note  that  students need support to choose different modes of assessment, otherwise they would opt for more traditional modes. However, giving options provide opportunities for  students  to  take  charge  of  not  only  their  learning  and  specifically assessment but also the vehicle through which they can take place.

The above-mentioned skills for SDMA also rely on specific literacies that must be developed in students.

## Literacy and self-directed multimodal assessment

Different literacies  are  also  highly  relevant  for  SDMA.  Effective  assessment does  not  only  imply  the  fostering  of  assessment  literacy  (cf.  Lubbe  2020; Montenegro &amp; Jankowski 2020; O'Brien et al. 2019), multimodal environments and the aim of promoting self-directedness can also imply supporting a range of  literacies  or  multiliteracies  (Olivier  2019b).  From  the  literature,  it  is  also clear that assessment literacy can play a role in contributing towards students using various modes of assessment (O'Brien et al. 2019).

Multimodal  literacy  is  a  prerequisite  for  multimodal  assessment  literacy. This  approach  to  literacy  is  also  prominent  because  of  the  increasing importance of different digital technologies. Multimodal literacy is also closely related  to  the  concept  of multiliteracies, and  these  are  sometimes  used interchangeably (Tan et al. 2020). The importance of multiliteracies for SDL has also been unpacked by Olivier (2019b), and this emphasises the relevance of SDMA as well. Furthermore, Ross et al. (2020) highlight the importance of multimodal literacy for the sake of multimodal assessments, and they also make a case for multimodal assessment literacy.

This statement implies teacher and student knowledge of semiotics and the different semiotic resources involved. In addition, both parties should have in-depth  knowledge  of  the  nature  and  affordances  of  different  modes  of communication and how they function within a specific discipline. The key is ultimately  also  optimum  comprehension  and  communication  and,  as  such, that the communicative potential of a mode should inform the choice of use or not. Consequently, there should be an active attempt in the classroom to develop  and  support  multimodal  assessment  literacy  towards  creating  a context conducive to the effective use of multimodal assessment.

Furthermore,  Ross  et  al. (2020)  propose  a  multimodal  assessment framework that teachers can use to determine their multimodal assessment criteria. The identified dimensions of the framework by Ross et al. (2020) are as follows:

- · 'Form, as well as content, is a vitally important site of criticality in multimodal work.'
- · 'Fostering students' creative dispositions and agency is a key benefit of introducing multimodal assignments, but these must be carefully designed to support such development.'
- · 'The intra-action of form and content must be recognised in the assessment process, and teachers must seek ways to look holistically at multimodal assignments and to explore with students what this means in practice.'
- · '[T]eachers have to consider what they are asking students to do, and how to value it appropriately.' (p. 299; [emphasis in the original])

In  this  regard,  it  is  essential  that  all  elements  of  a  multimodal  assessment artefact are critically evaluated and that not only the text-based elements but also all other modes are included. In addition, the mentioned criticality also pertains  to  the  composition  of  and  interplay  between  different  modes (Ross et al. 2020). The inclusion of creative dispositions and agency highlights the importance of creativity in and as a knowledge creation process. In line with the earlier reference to agency, once again, the assessment itself can and should be a vehicle towards fostering student agency. The above-mentioned framework  also  highlights  the  importance  of  having  a  holistic  view  of  a multimodal artefact - in this regard, encouraging students to not narrow the focus on only the different elements to be assessed but also the overall work (Ross et al. 2020). This aspect also involves what Ross et al. (2020:301) call a 'holistic evaluation', which should be fostered in students. The final dimension of  valuing  multimodal  assessments  involves  such  assessments  not  merely being something of less importance in comparison to other assessments.

A further important affordance for SDMA - drawn from the literature on multimodal literacy - is that the process of assessment should be considered and  flexible criteria should be employed.  Tan et al. (2020)  support

'acknowledgement and value of process, not just of the artefact, and flexible assessment  criteria  that  develop  learners'  meta-semiotic  awareness  and metalanguage  of  multimodal  texts'.  From  this  quote,  the  importance  of metalanguage in general is evident and consequently, the need for collaborative - teachers and students - development of a metalanguage for SDMA is essential.

In light of the foregoing discussion of the broader SDMA framework, some practical recommendations are made in the 'Recommendations for equitable and differentiated self-directed multimodal assessments' section.

## Recommendations for equitable and differentiated self-directed multimodal assessments

The following practical recommendations are made for using equitable and differentiated SDMA:

- · Teachers who consider using SDMAs should - as is suggested for MDCAs (Fjørtoft 2020) - ensure that the specific type of assessment is appropriate for the specific assessment and context.
- · The implementation of SDMAs can be done cooperatively and in line with Lubbe's (2020) approach to cooperative learning-embedded assessment and especially with the aid of various multimodal technologies which make cooperative learning possible asynchronously and over distance. Similarly, it has  been  determined  that  participative  assessment  practices  can contribute to developing SDL skills (Lubbe &amp; Mentz 2019).
- · In order to successfully use SDMAs, specific assessment literacies (cf. Lubbe 2020; Olivier 2019b) must be developed in students. Fjørtoft (2020) also highlights the importance of technology-specific literacies.
- · There is a need for the creation and/or standardisation of the metalanguage around SDMA in order for both students and teachers to be able to describe and adequately discuss such types of assessments.
- · In setting criteria for SDMAs, teachers should consider criticality, creativity, holism as well as assigning appropriate value to the assessments as per the framework by Ross et al. (2020).
- · Teachers can also consider that students be part of the process of setting up rubrics for SDMAs (cf. Ross et al. 2020; Tan et al. 2020), as this would not only allow for teachers to draw on students' knowledge of different digital modes but can also be a learning opportunity in itself.
- · Self-directed multimodal assessments should be informed by appropriate and detailed data aggregation (cf. Montenegro &amp; Jankowski 2020) to not only support equitable assessment but also gauge preferences and skills for the mode of assessment.

- · Multimedia design principles should be considered when setting up SDMAs. These design principles include the multimedia, temporal contiguity, spatial contiguity, coherence, redundancy, modality, individual differences, as well as direct manipulation principles (Fadel &amp; Lemke 2012).
- · As  with  SLOA  (Mok  2009),  SDMAs  also  require  commitment  from management  and the whole institution to embrace and promote self-directedness and multimodality in assessments and related policies.
- · Self-directed  multimodal  assessment  implies  authentic  tasks,  and  in  a multimodal environment, this can be done effectively through the use of digital technologies (cf. Russell 2019).

Furthermore,  SDMA  implies  rethinking  the  criteria  for  assessing  student assessment  artefacts. In this regard, in their research on multimodal compositions, Hafner and Ho (2020) list the following aspects that must be considered  and  could  also  be  of  value  for  other  types  of  multimodal assessments:

- · creativity and originality
- · organisation
- · language
- · delivery, modal interaction
- · variety
- · genre.

Self-directed multimodal assessment can also draw from the requirements for SLOA. Therefore, there should be external feedback by both teachers and peers and also internal feedback through self-monitoring and self-assessment by students themselves (Mok 2009). Such processes can easily be handled multimodally  through  sound-  or  video  recordings  or  even  other  modes  of delivery and especially through multimodal environments where online and digital learning spaces can be structured to prompt  reflections and assessments. In addition to the focus on awareness around metacognition as well as cognitive learning strategies, Mok (2009) highlights the importance of motivation in self-efficacy, self-regulation and ultimately self-direction. Once again, as with feedback, not only can student evaluation and reflection in this regard take place multimodally, but data can also be generated in multimodal environments on levels and the nature of motivation, self-efficacy, self-regulation and even self-direction. This, in turn, can inform the structure of activities in learning  management  systems  as  well  as  the  broader learning process.

Self-directed multimodal assessment also implies effective use of digital technologies  to  inform  the  learning  and  assessment  process.  To  this  end, teachers  must  consider  the  advantages  of  student  response  systems  and quizzing apps to obtain student input and feedback (Russell 2019). In support of  open education (cf. Olivier 2019a, 2020b), SDMAs can be shared online with appropriate licensing such as Creative Commons (Ehlers 2013).

Self-directed multimodal assessment may also involve both technologyenabled and technology-enhanced assessment items. In this regard, technology-enabled items are multimodal  by  nature, as they 'contain media,  such  as  video,  sound,  animations,  and  simulations  that  cannot  be presented on paper', whereas technology-enhanced items emphasise student agency  in  the  creation  of  multimodal  artefacts,  as  the  items  'require  testtakers  to  demonstrate  knowledge,  skills,  and  abilities  using  methods  for producing  a  response  that  differs  from  selecting  from  a  set  of  options  or entering alphanumeric content' (Russell 2019:228).

As with any innovation with assessment, implementing SDMA would require support from management and embedding the approach in the institutional culture (cf. Montenegro &amp; Jankowski 2020).

## Conclusion

In  conclusion,  in  implementing  SDMA,  students  should  not  be  made  to (Montenegro &amp; Jankowski 2017):

[ C ]onform  to  the  ways  of  higher  education,  thus  reinforcing  inequities  and expectations based on ideologies the students may not ascribe to, but to empower students  for  success  through  intentional  efforts  to  address  inequality  within our  structures,  create  clear  transparent  pathways,  and  ensure  that  credits  and credentials are awarded by demonstration of learning, in whatever form that may take. (p. 16)

Hence, SDMA implies a more nuanced and diverse approach to the modes of communication involved in assessment. It further implies a democratisation of the assessment process through greater involvement of students as they are the potential experts of the digital multimodal sphere. Furthermore, student agency is central to SDMA as they should take charge and be integral to the whole assessment process.

In this chapter, the concept of SDMA was explored as a phenomenon that should  be  considered  in  a  digital  and  increasingly  multimodal  educational context. As regards learning as communication, the lens of multimodality can also be used to approach assessment. Furthermore, SDL was underlined as an integral  facet  of  the  assessment  process.  The  author  therefore  highlighted SDL-oriented assessment and student agency as central to any implementation of SDMA.  The  shift  from  monomodal  to  multimodal  assessments  was interrogated  in  light  of  the  broader  discourse  on  multimodal  learning  and ultimately the relevance of multimodality and different modes of assessments. In addition, aspects of equitable and differentiated assessment were briefly discussed.  Finally,  an  overall  framework  for  SDMA  was  presented,  and recommendations were made for equitable and differentiated implementation of SDMA.

## Aligning metaliteracy with self-directed learning to expand assessment opportunities

## Trudi E. Jacobson a,b

a Information Literacy Department, University Libraries, University at Albany, State University of New York, Albany, NY, United States of America b Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Thomas P. Mackey a,b

a School of Arts and Humanities, State University of New York (SUNY) Empire State College, Albany, NY, United States of America b Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Jako Olivier

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Mahikeng, South Africa

How to cite: Jacobson, T.E., Mackey, T.P. &amp; Olivier, J., 2021, 'Aligning metaliteracy with self-directed learning to expand assessment opportunities', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 71-97, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.04

## Abstract

Metaliteracy is a holistic model that emphasises information-related knowledge attainment  whilst  challenging  individuals  to  take  charge  of  their  learning strategies and goals. It prepares learners to become informed consumers and responsible  producers  of  information.  Metacognition  is  a  core  concept  in metaliteracy, just as it is in SDL and in methods of assessment appropriate to SDL, such as AaL and AfL. This congruence provides clear avenues for using metaliteracy's  framework  in  ways  that  support  SDL.  The  first  part  of  the chapter explores metaliteracy and its connections with SDL and assessment. The remainder of the chapter provides two examples of how the intersection of metaliteracy, SDL and assessment might be addressed in practice. These case studies provide additional and practical connections that might suggest applications  in  other  settings.  The  first  section  explores  a  comprehensive metaliteracy digital badging system that is designed to advance SDL, with a focus on how the self-directed unit from this system was adapted for use in an open textbook. The final section of the chapter provides an example of how an online undergraduate course intertwines metaliteracy, information literacy and  editing  on  Wikipedia,  exemplifying  principles  of  SDL  and  providing examples of AaL and AfL.

## Introduction

Metaliteracy  is  a  pedagogical  framework  that  prepares  individuals  to  be empowered and self-directed  learners  to  actively  create  meaningful  content and participate constructively in social information environments (Jacobson &amp; Mackey 2013; Mackey &amp; Jacobson 2011). Metaliteracy's emphasis on the four learning  domains  -  affective,  behavioural,  cognitive,  and  metacognitive  provides strong links with SDL, AfL and the related AaL. The metaliteracy goals and  their  associated  learning  objectives,  roles  and  characteristics  provide additional connections. Whilst focused synergies will be examined in this chapter, it  is  worth  noting that if an individual strives to be metaliterate, they are per definition a self-directed learner who takes responsibility for their own learning.

There  is  no  academic  major,  no  certificate  programme,  no  continuing education  course  that  employs  instructors  to  teach  individuals  to  be metaliterate and certify them as such when the programme has ended. Nor is the goal of being a metaliterate learner an activity with a finite end. Rather, becoming metaliterate is a lifelong quest that requires commitment in the face of changing modes of participation, and frequent transformations in the opportunities and platforms for information creation, sharing and collaborative engagement. Becoming metaliterate is a lifelong practice of SDL, reinforced by the metaliteracy framework and a wide range of open educational resources (OERs). A central figure to SDL is Malcolm S. Knowles (1975), who provides the following classical definition of the concept:

SDL is 'a process in which individuals take the initiative, with or without the help of others, in diagnosing their learning needs, formulating learning goals, identifying human and material resources for learning, choosing and implementing appropriate learning strategies and evaluating learning outcomes'. (p. 18)

Hence, this process is student-centred and the teacher acts in a facilitator's role. In this regard, there is a distinct move from teachers being facilitators rather  than  transmitters  of  learning  (Loeng  2020;  Robinson  &amp;  Persky 2020).

This chapter will explore and make explicit the interconnections between metaliteracy and SDL, and identify the assessment methods most appropriate for  determining  one's  progress  towards  metaliteracy.  Finally,  this  chapter concludes with two examples from the United States of America describing how the intersection of metaliteracy, SDL and assessment might be addressed in practice.

## The metaliteracy framework

Metaliteracy prepares learners to become active and informed consumers and ethical producers of information (Jacobson &amp; Mackey 2013; Mackey &amp; Jacobson 2011). Metaliterate learners mindfully reflect on their learning and define the direction  of  their  ongoing  intellectual  development  (Mackey  &amp;  Jacobson 2014). They assess what and how they learn to advance SDL that is reinforced by the metaliteracy model.

As originally conceived (Mackey &amp; Jacobson 2011):

Metaliteracy promotes critical thinking and collaboration in a digital age, providing a comprehensive framework to effectively participate in social media and online communities. It is a unified construct that supports the acquisition, production, and sharing of knowledge in collaborative online communities. (p. 62)

## Introducing the framework

Through this  framework,  individuals  hone  their  abilities  to  think  critically and  adapt  to  social settings that are often mediated  by  emerging technologies. As part of this dynamic  process, individuals learn to continuously  evaluate  all  forms  of  information  through  evolving  media formats, whilst also understanding that they are empowered to produce and share knowledge in a multitude of collaborative and connected spaces. In these social settings that rely on contributions from participants (Mackey &amp; Jacobson 2014):

[ M ]etaliteracy expands the scope of how to use these spaces as individuals and requires a critical perspective that reflects on the networked environment itself and how knowledge is produced and shared. (p. 4)

The meta prefix  in  metaliteracy  signals  the  key  themes  that  define  this pedagogical  framework  (Mackey  &amp;  Jacobson  2014).  Metaliteracy  is  closely aligned with metacognition as introduced by Flavell, who argues for a reflective process  that  generates  insights  for  individuals  about  their  thinking  whilst allowing them to self-regulate or control their learning (Flavell 1979). As Flavell (1979) argues, metacognition:

[ C ]ould someday be parlayed into a method of teaching children (and adults) to make wise and thoughtful life decisions as well as to comprehend and learn better in formal educational settings. (p. 910)

This vision for metacognition indicates how reflection supports individuals in generating  new  insights  about  their  thinking  and  preparing  them  to  take charge of their learning. As Flavell argues, metacognitive reflection supports improved learning in formal instructional environments whilst also becoming a part of one's lifelong journey. As a key part of the metaliteracy framework, metacognition  is  empowering  because  it  shifts  the  emphasis  'beyond rudimentary  skills  development  and  prepares  students  to  dig  deeper  and assess their own learning' (Mackey &amp; Jacobson 2014:13).

The meta prefix in metaliteracy suggests part of the Greek meaning of the word,  that  of after or beyond (Lexico  2020).  Whilst  literacy  is  generally associated with reading and writing, and traditional definitions of information literacy  emphasise  search,  retrieval  and  evaluation,  metaliteracy  scaffolds learning by building upon these abilities to advance active participation and the production of new knowledge. The meta prefix  also  suggests  a  higher level of  abstraction,  such  as  a metalanguage (Lexico  2020),  denoting metaliteracy as a comprehensive framework rather than a linear or hierarchical skill set. In many ways, metaliteracy is a model that is about literacy and that encourages learners 'to understand their existing literacy strengths and areas for improvement and make decisions about their learning' (Mackey &amp; Jacobson 2014:2).  In  this  context,  individuals  strive  towards  higher-level  awareness about their learning through a nonlinear and decentred model rather than a formulaic  set of skills or outcomes  (Mackey  &amp;  Jacobson  2014:91-92). Metaliterate learners who develop 'his or her own metacognitive perspective will find that the flexibility so often found in real-world situations fits easily within this framework' (Mackey &amp; Jacobson 2014:92).

Metaliteracy  reinforces  SDL  with  an  emphasis  on  student  agency  and continual  reflection  and  growth.  Metaliterate  learners  are  encouraged  to 'critically self-assess different competencies' through metacognitive reflection (Mackey &amp; Jacobson 2014:2). Gaining a self-awareness of one's own literacy through  self-reflection  is  essential  to  metaliteracy  because  metaliterate learners 'critically evaluate and understand their knowledge as individuals and participants in social learning environments' (Mackey &amp; Jacobson 2014:14). In doing  so,  the  self-assessment  process  varies  depending  on  an  individual's

existing knowledge and learning goals and does not always follow the same prescribed pathway. The flexibility of this approach means that individuals who 'apply principles of the metaliteracy model in practice will find that the objectives can be met in a variety of different ways, depending on the learning context'  (Mackey  &amp;  Jacobson  2014:92).  This  variation  mirrors  Gibbons' (2002:111) observation on the SDL sequence of activities more generally, '[t]he criteria of success, just like the tasks that they are pursuing, vary from student to student'.

## The core components of metaliteracy

Metaliteracy is a holistic model that emphasises information-related knowledge attainment  whilst  challenging  individuals  to  take  charge  of  their  learning strategies  and  goals  (Mackey  &amp;  Jacobson  2014).  In  order  to  achieve  this comprehensive  approach,  the  metaliteracy  model  integrates  four  core components that include the learning domains, learner roles, characteristics and the related goals and learning objectives (Mackey, Jacobson &amp; O'Brien 2020).

## Learning domains

The learning domains are central to the metaliterate learner and recognise that individuals embody multiple spheres of learning and knowing (Jacobson, Mackey  &amp;  O'Brien  2018;  Mackey  &amp;  Jacobson  2014).  Bloom's  Taxonomy originally included three specific learning areas, including 'the cognitive, the affective, and the psychomotor domains' (Bloom 1956:7). The metacognitive dimension  was  added  to  Bloom's  classification  system  for  the  design  of learning objectives in a later revision (Krathwohl 2002:214). As a pedagogical framework, metaliteracy builds a foundation for SDL through all four domains that  include  the  affective  (feelings  and  attitudes),  behavioural  (skills  and actions), cognitive (thinking and knowing) and metacognitive (reflective and self-regulating). The affective domain addresses a person's emotions and attitudes that deepen comprehension about how they may perceive an information situation or context. Being aware of the affective domain prepares learners to investigate feelings and beliefs to analyse the impact of this domain on  their  thinking  and  actions.  The  behavioural  domain  emphasises  the competencies  that  learners  acquire  through  learning  activities.  Traditional definitions of information literacy tend to emphasise primarily skills development  as  reinforced  through  learning  outcomes  (American  Library Association 2000). From a metaliteracy perspective, the behavioural domain is  understood within the context of all four domains so that learners build upon skills  and  gain  new  ones  through  reflection,  thinking  and  action  in  a connected world of information.

The cognitive domain focuses on an individual's thinking and knowing. Similar  to  the  behavioural  domain,  the  cognitive  area  often  involves learning outcomes that advance skills and actions. Metaliteracy reinforces these important intersections but also considers a learning dynamic that encompasses  all  four  areas.  Pivotal  to  this  model  is  the  metacognitive domain that sparks reflective insights about one's thinking, feelings and actions  whilst  supporting  individuals  in  taking  charge  of  their  learning. According  to  John  H.  Flavell,  metacognition  provides  'opportunities  for thoughts and feelings about your own thinking to arise and, in many cases, call for the kind of quality control that metacognitive experiences can help supply' (Flavell 1979:908). This is an empowering concept for self-directed learners because reflection increases understanding about the cognitive and  affective  aspects  of  learning  whilst  also  supporting  the  ability  to analyse and discern quality in thought and action. Through this approach 'metaliterate  students  will  be  prepared  to  fill  the  gaps  in  learning  and develop  strategies  for  understanding  more  than  what  we,  as  teachers, present or discuss' (Mackey &amp; Jacobson 2014:13). The ongoing assessment of individual goals and progress that is gained through reflection provides learners with the capacity to self-regulate their learning.

By  framing  the  learning  process  through  four  interrelated  domains, metaliteracy encourages individuals to see how they learn and grow in these different areas. This unified approach to teaching and learning demonstrates how  the  four  domains  are  both  interrelated  and  integrated.  For  instance, learners  may  not  necessarily  be  encouraged  to  explore  their  emotional response to information, but these affective insights are valuable. For example, to avoid confirmation bias , which is 'seeking out and interpreting data in a way that strengthens our preestablished opinions' (Sharot 2017:22), it is critical to investigate one's feelings and attitudes about information and related issues. This requires metacognitive reflection and the cognitive ability to be objective in research and to seek out multiple perspectives as part of this process. This approach to critical inquiry values the ability to identify and think outside of one's own perspective or viewpoints. In addition, a person's affective response to a particular topic or concern may be a motivating factor to conduct an objective research inquiry to inform action. Imagine the individual who feels so strongly about climate change, for instance, that this emotional connection to the topic is a motivating factor to embark upon critical inquiry. As Flavell (1979:906) suggests, metacognition also provides awareness about the beliefs that  learners  have  regarding  their  learning.  Metaliteracy  supports  SDL  by foregrounding the relationships amongst the four domains so that learners assess  their  educational  needs  and  achievements  from  these  associated perspectives.

## Learner roles

The metaliterate learner roles  are  central  to  this  framework  because  these responsibilities  provide  a  real-world  context  for  SDL.  The  learner  roles  are defined as a way to unify the different components of the metaliteracy model because 'the domains are fluid, representing a comprehensive and interrelated set of goals and learning objectives that lead to empowering roles' (Mackey &amp; Jacobson 2014:91). Paulo Freire's central critique of what he describes as the banking model of education makes clear that learners are not empty vessels to  be  filled  with  deposits  of  knowledge  by  teachers  (Freire  2000:72).  He argues that '[w]hereas banking education anesthetizes and inhibits creative power,  problem-posing  education  involves  a  constant  unveiling  of  reality' (Freire 2000:81). As active participants in social settings, metaliterate learners do not simply gain skills by achieving outcomes alone, and instead envision themselves in real-world roles and scenarios. Each of these responsibilities relates in one way or another to the evaluation, production and sharing of information (Mackey &amp; Jacobson 2014).

Metaliteracy provides a context for the development of SDL and OERs that  supports  the  reflection  upon  the  roles  that  individuals  may  already play as well as those responsibilities that are new to them (Jacobson et al. 2018).  Metaliterate  learners  engage  with  these  ideas  and  resources  to improve  upon  the  roles  they  identify  with  whilst  striving  towards  new responsibilities as well. These roles are applicable to teaching and learning scenarios that promote active metaliterate learning. In one example, for instance, Professor Sally Friedman of the Political Science Department at the University at Albany developed a reading assignment for learners to reflect on the active roles they play (Jacobson &amp; Friedman 2019). In another example, a set of questions have been designed to apply the learner roles in a variety of educational settings (Jacobson et al. 2018). The learner roles have been applied in three different Massive Open Online Courses (MOOCs), including  a  connectivist  MOOC  and  two  xMOOCs  to  support  student agency in these environments (O'Brien et al. 2017). The metaliterate learner roles  are  central  in  the  Coursera  MOOC Empowering Yourself in a PostTruth World that reinforces the learner as producer role in particular for a culminating project that requires the creation of a digital artefact (Mackey 2020).

The  central  metaliterate  learner  role  is  producer,  because  it  signals  the crucial shift from consumer to creator of information. Robert Scholes (1985) argued that the academic boundaries between consumer and producer need to be better understood because reading itself is 'not simply as consumption but as a productive activity' when learners make meaning through this process and refer back to 'prior texts' as a continuous and critical learning activity

(Scholes  1985:8).  As  text  evolved  to  hypertext,  George  P.  Landow  (1992) envisioned a collaborative space that shifts the consumer to be a producer because individuals make decisions about which pathways to pursue through linked  documents  as  'newly  empowered,  self-directed  students'  (Landow 1992:120).  In  his  original  design  for  the  Web,  Tim  Berners-Lee  (2000) emphasised the importance of a hypertext editor because he envisioned 'an intimate collaborative medium' although he realised that it initially became more of a means for the publication of documents (Berners-Lee &amp; Fischetti 2000:57).

The  metaliteracy  framework  empowers  learners  to  responsibly  produce and share content in participatory environments (Mackey &amp; Jacobson 2011, 2014).  The  learner  as  producer  role  takes  into  account  the  interconnected aspect of collaborative media and prepares learners to adapt to these social technologies.  This  pivotal  responsibility  supports  related  roles  such  as  the researcher who engages in a process of critical inquiry to assess and create information and the communicator who effectively conveys ideas and engages with others in social settings. The communicator role is closely aligned with the participant who understands social contexts and contributes to communities  in  a  meaningful  way.  This  responsibility  benefits  from  an awareness of the collaborator role so that learners conscientiously work with others in these connected spaces. Metaliterate learners are translators who adapt ideas from one artistic form to another or who create media across different  platforms.  Through  this  process,  individuals  are  authors  who  not only write text documents but also gain the ability to author digital projects by combining text, image, sound and video elements.

As a producer of dynamic information, learners also need to understand the  contexts  and  responsibilities  associated  with  publishing  content. Through the publisher role, learners actively write, edit, produce and remix information for external audiences. This process necessitates an awareness of how to share content through a publishing medium such as a blog, wiki, social media  platform or independent  website. It also requires an understanding of how to properly identify and attribute digital materials that are openly licensed through a global community such as the Creative Commons. Additionally, publishers make decisions regarding how to license their own work. As part of this shared process in producing and publishing information in participatory settings, 'the learner is also a teacher and each individual is a collaborative partner in the learning experience' (Mackey &amp; Jacobson 2014:13). This is an especially empowering insight for self-directed learners  who  assess  and  regulate  their  learning  with  the  purpose  of expanding  their  knowledge  whilst  sharing  it  with  others  in  connected social settings.

## Characteristics

As metaliterate learners expand their roles through the lens of the four learning domains,  they  strive  towards  specific  metaliteracy  characteristics  (Mackey 2019). These attributes align closely with the learner roles and define specific qualities  to  aspire  to  as  part  of  the  learning  process.  The productive characteristic  is  gained  through  the  active  creation  of  dynamic  content  in collaborative communities. Individuals learn to be reflective about what and how they create information whilst being ethical and responsible in doing so. These  qualities  require  the collaborative characteristic  to  support  the  cocreation of knowledge as a purposeful social activity. Being participatory is a related attribute that learners aspire to as they understand the environments within which they engage and the attendant issues or concerns when doing so. In social media environments, for example, individuals need to be aware that misinformation and disinformation easily circulate without authoritative editorial mechanisms.  Considering  the  ongoing  changes  in  technology, learners  must  be  critically adaptive to  new  systems  whilst  asking  good questions about the influence of proprietary platforms and bad actors within these  spaces.  Additional  characteristics  include  being informed about  the authenticity and reliability of information and open to new ideas and different perspectives. In today's divided information environment, metaliterate learners need  to  gain  the civic-minded characteristic  to  reinforce  an  individual's responsibility to their community (Mackey 2019).

## Goals and learning objectives

The  metaliteracy  goals  and  learning  objectives  constitute  the  fourth  core component  of  this  comprehensive  framework.  The  four  goals  include  the following (Jacobson et al. 2018):

- 1. actively evaluate content whilst also evaluating one's own biases
- 2.  engage with all intellectual property ethically and responsibly
- 3.  produce and share information in collaborative and participatory environments
- 4.  develop  learning  strategies  to  meet  lifelong  personal  and  professional goals.

The  four  overarching  goals  are  reinforced  by  several  related  learning objectives that are identified with the most salient learning domains (affective, behavioural, cognitive and metacognitive). For instance, the first goal about evaluating  bias  is  supported  by  an  affective  and  cognitive  objective  to validate the  expertise  of  information  and  related  sources  whilst  also recognising  that  experts  actually  do  exist  in  society.  The  second  goal,  to advance responsible engagement with intellectual property, is supported by

a metacognitive objective to reflect on how to ethically incorporate someone else's  intellectual  property  into  your  own  work.  The  third  goal,  related  to producing  and  sharing  information,  is  reinforced  by  the  affective  and metacognitive objective to envision oneself as both a consumer and producer of  information.  Lastly,  the  fourth  goal,  about  developing  strategies  for meeting lifelong learning goals, is reinforced by a metacognitive objective to value this approach as part of one's lifetime practice. Additional objectives are  tagged  with  either  one  or  combinations  of  the  learning  domains  to advance metaliterate learning. This open resource is scalable to a multitude of educational settings and has been translated into a number of languages, including  Afrikaans,  French,  German,  Italian,  Portuguese,  Setswana  and Spanish (Metaliteracy.org 2019).

Through  the  core  components  of  metaliteracy,  individuals  develop  the capacity  to  better  understand  their  active  roles  for  engaging  with  and producing reliable and responsible information. They gain a new perspective on how they approach learning situations and develop self-directed strategies whilst striving towards the characteristics of the metaliterate learner.

## Self-directed learning viewed through the lens of metaliteracy

The concept of SDL is not new and has been integral to learning in diverse contexts  and  is  consequently  also  relevant  for  metaliteracy.  The  scholarly engagement with this concept harks back to the work of Lindeman (1926), Houle (1961) and Tough (1968) and a number of works on andragogy or adult education  and  self-education  (Brockett  &amp;  Hiemstra  2019;  Garrison  1997; Gibbons 2002; Loeng 2020; Zhu, Bonk &amp; Doo 2020).

## Defining self-directed learning

Epistemologically,  Loeng  (2020:5)  situates  SDL  in  what  this  author  calls romantic humanism as it 'emphasizes to a great extent that the human being has the power for personal development'. Whilst Van der Walt (2016) describes SDL as a pragmatic theory with roots in self-determination theory.

A definition for SDL by Malcolm S. Knowles was provided at the beginning of this chapter, but another perspective is provided by Gibbons (2002), who defines SDL as follows:

SDL is any increase in knowledge, skill, accomplishment, or personal development that  an  individual  selects  and  brings  about  by  his  or  her  own  efforts  using  any method in any circumstances at any time. (p. 2)

In addition to these definitions emphasising the process aspect of SDL, it has also  been  described  as  a  learner  characteristic  that  is  not  dichotomous  in

nature but rather occurs dynamically on a continuum (Brockett &amp; Hiemstra 2019;  Garrison  1992).  Candy  (1991)  distinguishes  between  two  processes, learner-controlled  instruction  and  autodidaxy,  as  well  as  two  personal attributes, self-management and personal autonomy, emphasising the relevance of SDL for both informal and formal learning contexts.

Despite  SDL's  focus  on  the  individual,  it  by  no  means  implies  student isolation or total independence (Candy 2004). In this regard, Brockett and Hiemstra (2019) emphasise that students should take responsibility for their own learning, but that the learning itself can take place within a group. In an SDL context, both teacher as facilitator and peers can play important roles through  established  learning  partnerships  (Brockett  &amp;  Hiemstra  2019).  In addition,  implementing cooperative learning strategies has been proven to have a positive effect on perceived SDL readiness (Mentz &amp; Van Zyl 2018). Hence, as with metaliteracy, SDL is also closely associated with collaboration in the learning process.

Within the context of this chapter on metaliteracy, the following requirements  identified  by  Loeng  (2020:10),  in  addition  to  controlling  the learning  situation,  show  the  intersections  between  SDL  and  metaliteracy: 'willingness  to  reflect,  critical judgement,  and  necessary  knowledge  of alternatives'.

## Approaches to self-directed learning

Various authors have provided models and schemes to describe SDL. Firstly, Knowles  (1975)  provides  six  steps  to  developing  a  learning  contract  as  a means to facilitate SDL in contexts where there are external requirements and where there is a need to align or link these up with students' own needs. In a similar  fashion,  Gibbons  (2002)  refers  to  student  learning  agreements. Consequently,  within  the  context  of  metaliteracy,  the  requirements  of  this concept can also potentially be reconciled with students' own goals by means of an embedded learning contract or agreement.

Bosch, Mentz and Goede (2019) provide an overview of key models of SDL,  including  Long's  instructional  model  for  SDL,  Candy's  SDL  model, Brockett  and  Hiemstra's  personal  responsibility  orientation  (PRO)  model, Garrison's  model  and  Oswalt's  model.  Brockett  and  Hiemstra  (2019:57) proposed the PRO model to 'recognize both the differences and similarities between  SDL  as  an  instructional  method  and  learner  self-direction  as  a personality characteristic'. This model also emphasises personal responsibility and both the learning  process  and  self-direction  of  the  learner  as  well  as wider factors within the social context.

The importance of the online context was evident in the first part of this chapter and consequently SDL also needs to be considered within this milieu.

## Self-directed learning and the online environment

The affordances of online environments for SDL are clear. Zhu et al. (2020) note the importance of SDL for successful learning online and specifically in MOOCs. In this regard, Candy (2004) also makes the following observation:

[ A ]t least some forms of self-directed learning are particularly suited to the online environment, and indeed many recent technological advances are precisely targeted at supporting independent learning and use, there is clearly merit in exploring the linkages at a practical as well as a conceptual level. (p. 4)

Online  platforms  provide  opportunities  for  collaboration  which  can  be supportive  for  SDL  (Candy  2004).  Such  opportunities  are  also  highly relevant as SDL is considered a 'collaborative process between teacher and learner' within a context where '[w]e live interdependently and knowledge is socially determined' (Garrison 1992:141). Again, this potential for collaboration  ties  in  with  the  requirements  of  some  learner  roles  within metaliteracy.

An important requirement for SDL, identified by Loeng (2020) is phrased as follows: 'As a self-directed learner, you must have minimum control over the time, pace, and place for learning'. Such flexibility is especially true for online environments  where  learning  can  be  synchronous  or  asynchronous,  selfpaced and accessed from wherever metaliterate learners want to access the relevant learning platform.

Furthermore, as the focus of this chapter is also specifically on the role of assessment, within the intersections of metaliteracy and SDL, the concept is also explored further.

## Self-directed learning and assessment

Central to learning is assessment and the same applies to SDL. In this regard, Gibbons (2002) highlights the relevance of student self-assessment as an essential skill for SDL. Mok (2009:11) approaches assessment in terms of SDL through the concept of 'SLOA'. Furthermore, Lubbe and Mentz (2019) have found that participative assessment practices can contribute to developing SDL  skills.  Hence,  both  in  terms  of  metacognition  and  a  participative approach, clear links can be identified between both SDL and metaliteracy. In  addition,  Costa  and  Kallick  (2004)  advocate  for  assessment  to  be  in support of SDL and that assessment strategies increasingly contribute to student agency. Ideally, within an SDL context, students should take charge when it comes to what and how assessment takes place. The importance of assessment  throughout  the  whole  SDL  process  is  explained  by  Gibbons (2002) as follows:

[ S ]tudents should be learning to think about and assess the whole learning sequence: what they have chosen to learn, the process they are following to complete the

tasks they have chosen, the success with which they are applying their energies to the tasks, and the quality of the results they achieved. (p. 111)

From this statement, the metacognitive role of assessment and the centrality of student agency in terms of assessment is evident. The remainder of the chapter explores the ways in which SDL and assessment can be integrated with metaliteracy's core components.

## Integrating self-directed learning and assessment with metaliteracy's core components

This section focuses on  the connections  between  metaliteracy's core components  (particularly  the  four  learning  domains  and  select  associated learning objectives), SDL and assessment, with an emphasis on AaL. Pertinent to this exploration is the notion of SDL as both a process and as a learner characteristic  (Brockett  &amp;  Hiemstra  2019;  Garrison  1992).  Metaliteracy  is  a pedagogical framework that advances several characteristics that reinforce SDL.  The  flexibility  of  the  learning  domains  and  roles  provide  real-world context for self-directed learners to actively engage.

## Affective learning domain

Metaliterate learners are prompted to recognise the presence and impact of the affective domain. The affective learning domain addresses how one feels when learning,  and  how  that  feeling  influences  learning.  Pekrun  and  LinnenbrinkGarcia (2014:1) note, with an emphasis on learner self-direction, that '[e]motions are  both experienced in  the  educational  setting  as  well  as instrumental for academic achievement and personal growth'. Learning may be hindered when negative feelings that might be overcome are not even noted.

The affective domain also contributes to motivation, such as when learners celebrate strides they have made. In fostering SDL, it is essential to promote enthusiasm  and  positivity  towards  students  being  actively  involved  in the  learning  process  (Gibbons  2002).  Garrison  (1997)  emphasises  the importance of the motivational dimension in his model of SDL. It is important to recognise that '[m]otivation plays a very significant role in the initiation and maintenance of effort toward learning and the achievement of cognitive goals' (Garrison 1997:26). In this context, both entering motivation which relates to students wanting to start and task motivation which pertains to staying on task  and  continuing  (Garrison  1997)  are  pertinent.  Zhu  et  al.  (2020:2087) emphasise the importance of motivation for SDL in an age of increased online learning  and  they  state  that  'the  learner  must  have  sufficient  motivation, whether intrinsic and extrinsic or some combination thereof, to find, explore, and use the learning platforms made available to them'.

A further relevant aspect in terms of motivation is SRL. The relationship between SDL and SRL is clear from the literature (Garrison 1997); however, they  are  distinct  concepts  (Robinson  &amp;  Persky  2020).  In  this  regard,  the scholarship on SRL provides insights in terms of how motivation plays a role in learning, specifically also in terms of self-efficacy and relates to a focus on affective,  cognitive  and  behavioural  processes  (Robinson  &amp;  Persky  2020). Motivation  contributes  to  SRL  and  exists  in  a  dynamic  relationship,  and furthermore, SRL  is positively related to self-efficacy (Pintrich 1999). Importantly, metacognitive experiences can also have an effect on motivation within the SRL context (Efklides, Schwartz &amp; Brown 2018). All these aspects also have an influence on assessment for and as learning as part of the SDL process.  With  regard  to  online  classes,  Darby  focuses  on  Brockett  and Hiemstra's (2019) interpretation of SDL. Darby writes, 'we have a powerful tool  to  fight  for  online  student  attention,  engagement,  and  persistence: emotions' (2020). Similarly, Zhu et al. (2020) have indicated the importance of SDL within the context of MOOCs.

It  should  be  considered  that  '[p]ositive  emotions,  such  as  enjoyment  of learning and pride, have been linked to intrinsic motivation and interest in students across all ages, including college' (Oades-Sese et al. 2014:247).

In terms of motivation within the learning context, teachers as facilitators also  have  a  role  to  play.  Gibbons  (2002)  makes  the  following  observation regarding the teacher's roles regarding motivation:

[ T ]he teacher must motivate students to take on the task of managing their own activities and must then teach them to motivate themselves as an essential aspect of continuing self-direction. (p. 93)

It is clear that students have different levels of SDL and motivation at the start and throughout the learning process. Consequently, support or even interventions might be relevant on the side of teachers. One way that this might be done is by teaching and modelling metaliteracy. Learners who are aware of their feelings about and whilst learning are able to recognise when those  feelings  are  hindering  motivation,  hampering  SRL.  The  metaliteracy goals  and  learning  objectives  include  pertinent  items.  Given  the  varying impacts of affect, some of these learning objectives are written neutrally. Two learning objectives address the need to 'develop learning strategies to meet lifelong personal and professional goals' (goal 4). These two objectives, which are both affective and behavioural, implicitly acknowledge the effort of staying current as a part of SDL (Jacobson et al. 2018):

- · Adapt  to  new  learning  situations  whilst  being  flexible  about  the  varied approaches to learning.
- · Adapt to and understand new technologies and the impact they have on learning.

Assessment as learning has an important role to play in striving towards the learning  objectives.  Earl  (2013:28)  describes  it  as  follows:  'Assessment as learning  is  a  subset  of  assessment for learning  that  emphasizes  using assessment  as  a  process  of  developing  and  supporting  metacognition  for students,'  which  will  be  considered  in  the  Metacognitive  Learning  Domain section. However, it should be noted that this assessment may be swift when working towards these two learning objectives, as they are behavioural as well as affective. Not fully succeeding may bring forth frustration (affective) and also the realisation that one has not mastered the adaptations as put forth (behavioural).

A positive climate can be considered nurturing towards student productivity and ultimately also SDL (Gibbons 2002). This aligns with an objective from goal two, 'engage with all intellectual property ethically and responsibly'. This objective,  which  is  metacognitive  as  well  as  affective,  exhorts  metaliterate learners to 'challenge yourself to formulate ethical and novel approaches to build upon the ideas of others that you find exciting and engaging' (Jacobson et al. 2018). Addressed in the positive climate Gibbons describes, it has the potential to inspire creative productivity, which in turn may lead to enhanced motivation.

Another  objective, which  is affective, behavioural and  cognitive, is 'recognize that learners are also teachers and teach what you know or learn in collaborative settings' (goal 3). This objective foregrounds a role, Teacher, and accompanying opportunity that is within reach through SDL. This aspect also ties in with the view by Knowles (1975) that others can act as human resources in the SDL process and that peers can play an important role in the learning process (Brockett &amp; Hiemstra 2019). One can aspire to expertise in a particular area  whilst  continuing  to  learn  in  others.  This  recognition  of  motivation  in directing one's own learning can lead to a pride of mastery.

## Metacognitive learning domain

The idea of the learner as teacher epitomises the empowering and SDL aspects of  metaliteracy.  As  a  learning  objective,  individuals  are  encouraged  to recognise their roles as teachers when sharing their knowledge in collaborative environments. This objective supports an overarching goal to produce and share  information  collaboratively,  which  is  another  core  concept  of  the metaliteracy framework.

Metaliteracy  encompasses  roles  beyond  simply  that  of  the  teacher  and requires  mastery  of  additional  learning  objectives.  Determining  when  one might be ready to teach others requires engagement with learning domains beyond the affective. An individual must reflect on what they do or do not

know (metacognitive learning domain), develop a plan to fill gaps (cognitive) and then take the steps necessary to fill those gaps (behavioural).

The  AaL  that  individuals  undergo  as  preparation  to  teach  others  may emanate from formal or informal SDL initiatives, or from learner self-direction. However, learners must recognise the value of such assessment and engage in it  for  themselves as needed. In the case of the learner as teacher, the assessment may produce feedback swiftly.  Is  the  person  being  taught  understanding? Grasping the content? The individual who is serving as teacher may reflect on the experience, in the moment or subsequently, and recognise gaps to address or be further motivated by successes. Or both. Peer review is also appropriate at times when learners are serving as teachers. In the process of assessing each other's work, students also take on the role traditionally associated with teachers.

Apart  from  the  prominence  of  metacognition  for  metaliteracy,  metacognition is  also  essential  for  SDL.  The  commonly  cited  definition  of  metacognition comes  from  Flavell  (1976:232),  where  it  is  regarded  as  'one's  knowledge concerning one's own cognitive processes and products or anything related to them'. This definition ties in well with the metaliteracy idea of student as producer and hence students in this context should be aware of the processes and products involved.

It  is  clear  that metacognitive strategies can have a positive influence on students' self-direction (Breed &amp; Bailey 2018; Evans 2018; Mariano &amp; Batchelor 2018).  Different  strategies  have  been  proven  to  support  metacognition including cooperative, process-oriented and problem-based learning (Breed &amp; Bailey 2018; Mariano &amp; Batchelor 2018). When it comes to assessment, the affordances for SDL in embedding metacognitive strategies within assignments are evident (Kincannon, Gleber &amp; Kim 1999). In this context, Evans (2018:4) also advocates for 'appropriate learning experiences and environments that support  open-ended  learning  so  as  to  balance  autonomy,  ambiguity,  and student motivation'.

This chapter has discussed the learning objective 'See oneself as a producer as well as consumer of information' in support of goal three to 'produce and share information in collaborative and participatory environments' in connection to the learner roles (Jacobson et al. 2018). This objective involves both the metacognitive and the affective learning domains. Gibbons (2002) recognised  the  importance  of  assessment  during  the  full  SDL  process.  In connection with the learner as producer role and learning objective, a learner's reflective assessment of an information product will provide feedback on the quality of the result and, in the realm of the affective domain as well as the metacognitive, the success of their engagement in the learning process.

When a learner  is  producing  non-disposable  or  renewable  assignments (NDA), those that have a life beyond assessment by the instructor, they are often more engaged and excited. Seraphin et al. (2019:86) review the literature on  NDAs,  which  provide  evidence  that  they  'build  intrinsic  motivation  and consistently promote self-directed productivity'. Seraphin et al. (2019) add:

[ C ]ultivating intrinsic drives […] through the production of work that is perceived to be meaningful and valuable may yield greater classroom achievement and learning productivity as well as enhanced well-being, among other self-reflective evaluations […]. (p. 186)

Metacognition is a core concept in metaliteracy, just as it is in SDL and AaL. This congruence provides clear avenues for using metaliteracy's framework in ways that support SDL.

## Cognitive learning domain

The  cognitive  learning  domain  lends  itself  to  AfL  over  time,  particularly because  striving  to  be  metaliterate  is  a  continuing  process.  Importantly, '[a]ssessment for learning shifts the emphasis from summative to formative assessment, from making judgments to creating descriptions that can be used in the service of the next stage of learning' (Earl 2013:27). Hawe and Dixon (2017:1182) differentiate between AfL and formative assessment through the emphasis  in  AfL  on  learning  and  the  role  of  the  learner.  This  check-in  on learning might be done in a course setting (Costa &amp; Kallick 2004):

Constructivist teachers realize that cognitive growth occurs when individuals revisit and reformulate a current perspective. Therefore, teachers provide data, present realities,  and  pose  questions  for  the  purpose  of  engendering  contradictions  to students' initial hypotheses, challenging present conceptions, illuminating another perspective, and breaching crystallized thinking. (p. 81)

Students  may  also  initiate  exploration.  Examples  of  cognitive  metaliteracy learning objectives that have the potential to encourage learners to actively consider,  analyse  and  evaluate  emanate  from  several  goals.  The  following objectives reflect both the cognitive and the behavioural domains (Jacobson et al. 2018):

- · Learning objective 8 from goal 1: Evaluate user-generated information in social media environments and differentiate between opinion and fact.
- · Learning objective 5 from goal 3: Translate information presented in one manner to another in order to best meet the needs of a particular audience.
- · Learning objective 7 from goal 4: Effectively communicate and collaborate in shared spaces to learn from multiple perspectives.

These learning objectives exemplify the constructive process of knowledge production that Costa and Kallick (2004) describes:

Knowledge is a constructive process rather than a finding. It is not the content stored in memory but the activity of constructing it that gets stored. Humans don't get ideas; they make ideas. Meaning making is not just an individual operation. The individual  interacts  with  others  to  construct  shared  knowledge.  There  is  a  cycle of internalization of what is socially constructed as shared meaning, which is then externalized to affect the learner's social participation. (p. 118)

As the dual-domain nature of these three learning objectives indicates, the behavioural learning domain is often inextricably connected with the cognitive. In order to show that learning has taken place, often an action needs to be performed, one that might be assessed. Therefore, it is appropriate to transition to this last of the four learning domains.

## Behavioural learning domain

The behavioural domain might usefully address both teacher behaviour and student behaviour. Beginning with the behavioural learning domain's connection with SDL in regard to the former, Gibbons (2002) emphasises the role of teachers modelling SDL behaviour themselves in order to contribute to the motivation of students. This scaffolding, whilst contributing to behavioural efficacy, also has the potential to address the affective component of learning. Learners who are hesitant about how to proceed now have an example to follow. This modelling should include examples of how to resolve difficulties, so that through their actions students can 'be proud of their ability to identify and resolve the difficulties they confront' (Gibbons 2002:101). It should also show students how to (Gibbons 2002):

[ T ]hink about and assess the whole learning sequence: what they have chosen to learn, the process they are following to complete the tasks they have chosen, the success with which they are applying their energies to the task, and the quality of the results they achieved. (p. 111)

Once students have learned how to follow a path of SDL, they will incorporate behaviours that enhance their goal of being a metaliterate learner, such as addressing those learning objectives listed in the cognitive domain section above.  Strengthening  individual  characteristics will involve a range  of assessment methods, often ones that include peer as well as self-review.

## Metaliteracy, assessment and self-directed learning in action

The remainder of the chapter provides two examples of how the intersection of metaliteracy, SDL and assessment might be addressed in practice. These case studies provide additional and practical connections that might suggest applications  in  other  settings.  The  first  section  explores  a  comprehensive metaliteracy digital badging system that is designed to advance SDL. Particular

attention is focused on the self-directed challenge from this system and how it was adapted for use in an open textbook. The final section of the chapter provides an example of how a credit-bearing online undergraduate course intertwines  metaliteracy,  information  literacy  and  editing  on  Wikipedia, exemplifying principles of SDL and providing examples of AaL and AfL.

## Adapting a self-directed digital badging challenge to educational planning

The metaliteracy digital badging system is an interactive competency-based resource that is organised around a constellation of metaliteracy concepts. Learners pursue quests, challenges and content badges in a scaffolding of activities  that  ultimately  lead  to  four  master  badges:  Master  evaluator, producer and collaborator, digital  citizen,  and  empowered  learner  (Metaliteracy. org  2014).  This  interactive  environment  engages  learners  with  the  content and leads to the completion of this work through specific writing assessments or short media projects. These activities are completed individually or through the guidance of an instructor or librarian associated with a disciplinary course at the University at Albany, SUNY (O'Brien 2018). The content for this system has been developed by a number of authors, including faculty and students, and is available as an OER that is available to everyone through a Google Sites website (Metaliteracy.org 2014).

The self-directed challenge discussed in this section was adapted from the  original badging  content  for  a  Lumen  Learning  open  textbook developed by Dr Susan Oaks, who is a Professor at SUNY Empire State College (Lumen Learning n.d.a). This repurposing of the challenge for the open textbook supports a required course at the college in Educational Planning that all students take to design their unique degree concentrations. This  is  an  ideal  application  of  this  badging  challenge  because  degree planning  at  SUNY  Empire  State  College  is  a  reflective  process  in  which self-directed  learners  work  individually  with  a  mentor  to  design  their program  of  study  (Herman  &amp;  Mandell  2004).  This  requires  students  to assess their transcript credit, determine if their life experience should be evaluated for college credit through prior learning assessment (PLA) and then combine these elements with new studies to develop a unique degree programme. As Herman and Mandell argue, 'Educational planning, including PLA, not only opens the academy to non-traditional students; it opens the academy  to  non-traditional  learning'  (Herman  &amp;  Mandell  2004:110).  In the  context  of  the  Educational  Planning  course  and  open  textbook,  the competency-based digital badging challenge supports students in fostering  self-direction  as  they  engage  in  the  degree  planning  process (Lumen Learning n.d.b).

As  seen  through  this  descriptive  analysis,  the  self-directed  challenge  is adaptable as a single unit, which allows it to be developed as a learning activity for  the  open  textbook.  It  is  also  organised  as  part  of  the  original  badging system and open website that includes four high-level badges, including a top-level  metaliteracy  badge  that  requires  achieving  all  of  the  others. According  to  Information  Literacy  Librarian  Kelsey  O'Brien  (2018),  who designs and manages this system and site:

Metaliteracy  places  the  emphasis  on  the  learner  by  fostering  learner  agency, ownership  and  identity.  Likewise,  the  Metaliteracy  Badging  System  is  oriented around the metaliterate learner. Both in content and structure, the system guides students  as  they  explore  their  roles  as  empowered  learners  and  contributors, reflecting  on  their  own  thinking  and  learning  processes  and  recognizing  their achievements as the fruition of both their successes and failures. (p. 186)

In  this  context,  the  pursuit  of  digital  badges  enacts  metaliteracy  through creative and inventive learning activities that are powered by the metaliteracy goals  and  learning  objectives.  Central  to  this  process  is  metacognitive reflection that allows for meditative thinking and awareness about one's own knowledge  discoveries  and  individualised  learning  through  the  badging journey. By cultivating learner agency, metaliteracy reinforces a key dimension of  SDL  that  plays  out  as  participants  achieve  competencies  through  the quests, challenges and content badges.

The badging content is built on a foundation provided by metaliteracy's core  components  especially  related  to  metacognition  and  the  learner  as producer role. The influence of metaliteracy plays out in the design of the interrelated materials as well, including the embedded quests and challenges. The self-directed challenge is part of the metacognitive reflection quest and leads to the Empowered Learner badge. The badge activity reinforces the importance of reflective thinking and illustrates how learners may struggle along the way whilst ultimately learning from the experience. According to O'Brien, this foregrounding of the learning process in the badging exercises, including  potential  difficulties  along  the  way,  will  'cultivate  an  underlying mindset that helps students develop resilience as researchers and learners' (O'Brien 2018:192). In this environment, learners continually reflect on a series of question prompts and written responses, whilst gaining insights about their own thinking and learning.

The  self-directed  challenge  explores  how  individuals  learn  through activities  that  take  place  in  academic  and  lifelong  learning  settings.  It reinforces  the  idea  that  metaliterate  learners  teach  themselves  and  also teach others in collaborative learning spaces. The challenge presents these ideas by providing a description of multiple learning scenarios and references the  definition  of  SDL  by  the  renowned  scholar  in  adult  learning  theory, Malcolm  S.  Knowles  (1975).  Through  this  introduction  to  SDL,  individuals gain new insights about their own learning needs and goals in both formal

and  informal  settings  and  are  asked  to  consider  this  perspective  in  their response.  The  culminating  activity  for  this  challenge  asks  participants  to reflect on their own learning, with questions based on the process outlined by Knowles that encourage them to consider specific scenarios from their own life.

The first set of questions in Part 1: Individual Reflection asks learners why they took the initiative as a self-directed learner, how they determined their own learning need, how they designed their own goals for learning, what kind of information was required for this process, how the strategy was implemented and how they evaluated it. In Part 2: Peer Reflection , the questions shift the emphasis from individual to peer reflection so that learners contemplate their own self-directed experiences and then reflect on the insights gained from a conversation they initiate with a friend, colleague or teacher. They are asked to write about the outcome from this interview and to think about how this other  person's  experience  with  self-direction  might  influence  their  own individualised learning approaches moving forward.

The  Educational  Planning  version  of  the  self-directed  challenge  builds upon this initial exercise with an in-depth learning activity that asks them to identify, analyse and reflect upon a time when they failed to learn something. This  activity  is prompted  by  several  related  questions  that  encourage individuals to contemplate what they learned by failing rather than succeeding. This in-depth activity engages learners in the idea that people gain knowledge through  an  ongoing  process  of  trial  and  error  rather  than  achieving  every predefined goal or objective. Overall, this self-directed challenge promotes meditative  thinking  that  is  practiced  through  writing  assignments  that incorporate both self-reflection and peer reflection. Learners engage with the ideas of a noted scholar, Malcolm S. Knowles, whilst reflecting on their own assessments in relation to insights offered by their peers.

Looking at this badging challenge through the lens of metaliteracy shows how it advances several of the culminating characteristics of the metaliterate learner.  Individuals  who  complete  the  learning  activity  are reflective by assessing  their  experience  and  that  of  peers.  This  learning  activity  is  built around  the  Knowles  quote  which  defines  SDL  authoritatively,  whilst  also placing the learner's experience at the centre. Multiple scenarios are presented that spur metacognitive reflection about this theme. In this context, learners are informed because in addition to the Knowles reference, learners are asked to study additional resources related to an example of SDL about playing the guitar.  Through  this  example,  learners  review  an  online  WikiHow  page,  a YouTube  video  from  a  guitar  expert  and  a  Coursera  MOOC  site  from  the Berklee College of Music that shows a wide range of openly available content about  music  education  from  a  well-respected  academic  institution.  Within this  context,  they  are open to  different  modes  and adaptable to  digital resources that extend beyond text.

Through  their  engagement  with  this  badging  challenge,  learners  are authors , communicators and collaborators. They assess and write about their own experience and then document and share these individual reflections by also  analysing  responses  from  peers.  The  exercise  promotes  a  reflective writing process that requires the analysis of scholarly and popular materials and integrates primary sources based on the learner's insights in relation to interviews with peers. Exposure to different formats in one activity supports the assessment of professionally produced academic resources in relation to online  materials.  Although  learners  gain  the productive characteristic  by writing up their analysis, they are not necessarily encouraged to produce a multimedia  response.  Dynamic  media  options  are  supported  by  the  larger badging  environment  with  outcomes  that  extend  beyond  the  written assignment in this challenge.

Although  one  learning  activity  is  not  expected  to  address  all  of  the metaliteracy characteristics, several are supported through this activity. The participatory characteristic  is  not  fully  developed  because  learners  submit their  individual  writing  assignments  to  the  instructor,  although  the  overall badging environment is interactive. In addition, the civic-minded characteristic is not a primary focus of this activity either. At the same time, however, the collaborative nature of the required interview with peers does support SDL as an individualised and collaborative process that benefits from shared ideas. The  larger  context  provided  by  the  Educational  Planning  course  includes opportunities for social engagement in the online community.

## Developing metaliteracy and self-directed learning in a culture of assessment in an information literacy course

A one-credit  information  literacy  course  at  the  University  at  Albany,  State University  of  New  York  was  designed  to  teach  both  metaliteracy  and information  literacy  using  open  pedagogy.  The  course,  which  is  taught asynchronously  online,  also  promotes  SDL  and  uses  both  AaL  and  AfL  to enhance student mastery and confidence. The course is a mere six weeks long, and thus the moving parts must all be carefully selected and aligned.

Information Literacy for the Humanities and Fine Arts meets the University at Albany's upper-level information literacy general education requirement for students  majoring  in  philosophy,  East  Asian  Studies  and  Korean  Studies, although students in other majors take it as well. Most students who enrol are seniors  and  have  a  solid  background  in  traditional  library  research-related abilities, a more traditional understanding of information literacy. This course asks students to move beyond their comfort zone by conducting research and sharing their results for an entirely different purpose than writing a scholarly

essay for their professor. They select a topic connected to their major field of study to research for the purpose of adding content to Wikipedia, through participation  in  the  Wiki  Education  programme  (WikiEdu  n.d.).  This  NDA provides benefits for readers around the world whilst also asking learners to engage with elements of metaliteracy and to take part in shaping their own learning.

## Course expectations and focus

The  course  syllabus  provides  a  brief  introduction  to  the  importance  of metaliteracy  in  the  course,  including  the  role  of  information  creator  in  a collaborative,  open  and  online  environment,  and  also  the  importance  of metacognition. The syllabus also highlights personal attributes that the course hopes students will enhance, attributes that encourage SDL, such as cultivating a growth mindset, accepting challenges and making space for opportunities that promote creativity and exploration, and allow connections and personalisation.

Metaliteracy  is  both  a  subject  of  study  within  the  course  as  well  as scaffolding as the students assume roles in a setting unfamiliar to them. After an introduction to metaliteracy, they focus on the learning domains and the roles.  At  the  same  time,  they  are  learning  about  information  literacy  as presented in the ACRL Framework for Information Literacy in Higher Education (Association of College &amp; Research Libraries 2015). This Framework is clustered around six  frames  essential  for  a  conceptual  understanding  of  information literacy:

- · authority is constructed and contextual
- · information creation as a process
- · information has value
- · research as inquiry
- · scholarship as conversation
- · searching as strategic exploration.

Students read all of the frames but engage with four in particular. Information has value is the first frame they grapple with, selected because the upcoming course project provides an entrée into the topic: Wikipedia primarily reflects topics selected and articles written by white males. There is a need for broader representation amongst Wikipedia editors (as writers are called) and subjects. Our explorations  of  the  value  that  information  can  have  range  far  beyond Wikipedia, but this situation informs students as they select their topics. Both the affective and the cognitive learning domains are involved, as students are motivated by the forum discussion and associated class reading.

Searching  as  strategic  exploration is  the  theme  of  the  following  week, which asks students to acknowledge that '[s]earching for information is often

nonlinear and iterative, requiring the evaluation of information sources and the  mental  flexibility  to  pursue  alternative  avenues  as  new  understanding develops' (Association of College &amp; Research Libraries 2015). The following week's theme is a metaliteracy learning goal, Engage with intellectual property ethically and responsibly, which encompasses Wikipedia's rules on plagiarism, but also highlights the students' role as information producers. This goal is supported by several objectives that encompass all of the learning domains in support of the ethical production of information.

Information creation as a process ,  the  next  frame  to  be  analysed,  helps students think about the different expectations of this project compared with the  writing  they  traditionally  engage  in.  Their  newfound  appreciation  of examining how they feel is of particular importance with this frame, as they are decidedly outside their comfort zone learning how to write for Wikipedia. This  frame  also  helps  to  prepare  them  for  appropriate  self-  and  peerassessment, as they are moving beyond the confines of scholarly writing, but need  to  acknowledge  that.  It  also  aligns  closely  with  the  emphasis  of information production that is woven throughout metaliteracy.

Produce and share information in collaborative &amp; participatory environments , another metaliteracy goal, is the theme of the last class of the semester. It reminds students of their obligations as they share their completed content in Wikipedia articles. A fourth frame, Scholarship as conversation , is not a weekly theme but does play a role during the second half of the course when students engage in discussion with other Wikipedians and with student peer reviewers. By sharing their knowledge in this way, learners become teachers as they fulfil this  key  metaliteracy  objective  in  support  of  producing  information  in  the collaborative environment of Wikipedia.

The open pedagogical approach of this course overlaps with elements of SDL.  Gibbons  describes  seven  principles  that  help  to  move  classes  from traditional teacher-directed learning towards student-directed learning (Gibbons 2002:43-45):

- · teach  students  the  skills  they  need  to  take  control  over  their  learning activities
- · shift the emphasis of the program from content to productivity
- · introduce new practices in gradual gradients of complexity
- · make new ideas familiar with connecting them to students' lives
- · develop in students the attitudes necessary for success
- · change from telling to asking, from lecturing to interaction
- · launch the student on a hero's journey of discovery.

Table  4.1  puts  each  theme  in  the  context  of  information  literacy  (IL),  the associated metaliteracy learning (ML) domains and roles, highlights elements of SDL per Gibbons and notes assessment that occurs in connection with that theme.

TABLE 4.1: Interconnections between metaliteracy, self-directed learning and assessment.

| Weekly IL frame or  ML goals                                                      | ML domains                                    | Roles                                              | SDL (per Gibbons  2002)                                                  | Assessment                                                                                                                                                                                                 |
|-----------------------------------------------------------------------------------|-----------------------------------------------|----------------------------------------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Introduction to ML  and IL                                                        | Cognitive Metacognitive                       | Participant  (class forum)                         | Introduction to new  attitudes                                           | Self-reflection  on ML                                                                                                                                                                                     |
| Information has value                                                             | Affective Cognitive Metacognitive             | Communicator Researcher Participant (class  forum) | Exploration of  theme based on  their experiences,  interests            | Peer responses to  posts in the class  forum                                                                                                                                                               |
| Searching as strategic  exploration                                               | Behavioural Cognitive                         | Researcher                                         | Gradients of  complexity based  on Wikipedia  requirements               | Instructor feedback  on submitted  sources                                                                                                                                                                 |
| Engage with  intellectual property  ethically and  responsibly                    | Behavioural Cognitive                         | Producer                                           | Gradients of  complexity                                                 | -                                                                                                                                                                                                          |
| Information creation  as a process                                                | Cognitive Metacognitive                       | Author Translator                                  | Shift from content  to productivity                                      | -                                                                                                                                                                                                          |
| Produce and  share information  in collaborative  and participatory  environments | Behavioural Cognitive                         | Producer Participant Communicator Author           | Shift to productivity  and interaction Launch on a journey  of discovery | Possible evaluative  response from  Wikipedia  community Metacognitive  reflection on ML's  roles of author and  participant Self-assessment  using course rubric Metacognitive  response to  metaliteracy |
| Scholarship as  conversation (carries  over several weeks)                        | Affective Behavioural Cognitive Metacognitive | Communicator Collaborator                          | Attitude  development                                                    | Peer review within  and outside the  class Possible Wikipedia  community review                                                                                                                            |

SDL, self-directed learning; IL, information literacy; ML, metaliteracy learning.

<!-- image -->

## Spotlight on self-directed learning and assessment

This course contains major components of SDL but is hampered by the brief time span available to develop the full environment associated with this form of  learning.  Per  the  first  principle  proposed  by  Gibbons  (2002),  teaching students the skills needed to take control of their own learning, students are throughout  the  course  working  through  tutorials  provided  by  the  Wiki Education programme. These tutorials have accountability attached to them: the course dashboard tracks their completion of each tutorial and prompts the  instructor  to  determine  whether  reminders  should  be  sent  to  students

who have not yet completed any tasks that are overdue. There are no grades associated  with  completion.  However,  students  will  struggle  in  the  live Wikipedia environment if they have not learned what they contain. There is the potential that students will recognise the importance of the tutorials, and therefore develop an appreciation for resources that will help them to succeed when they are engaged in SDL.

Regarding  Gibbons'  second  and  third  bullets,  student  production  of contributions to Wikipedia advance in complexity, from adding a citation to an  existing  article,  to  leaving  comments  on  a  fellow  editor's  talk  page,  to creating content that will be incorporated into an existing article (or creating a  new  one).  The Scholarship  as  conversation frame  overlaps  with  this production. Students interact with other community members as a way of becoming situated  in  the  environment,  but  these  members  also  provide  a source of assessment. This occurs in a neutral manner when students ask a question in a platform space for novices midway through the course but can become more personal as students grapple with peer feedback and possible negative  feedback  from  Wikipedia  community  members.  Should  negative feedback occur, it calls into play all four learning domains, as students feel rejected, work through their reactions and make decisions about actions to take.

Students engage in AaL as their draft contributions to a Wikipedia article near completion, as a classmate provides detailed feedback on their work. In addition, students in another university course that are honing  their peer assessment abilities also review the article draft, and despite the fact that they are first-year students, they have provided feedback that has proved to be particularly helpful to the seniors.

A newly implemented method of AaL has added to potential learning in the  course  -  students  review  their  contributions  using  the  assignment's assessment rubric, offering them an opportunity to make decisions about potential  changes  prior  to  summative  grading.  Because  they  have  made self-directed  choices  about  what  content  was  needed  to  enhance  the existing  article,  they  do  not  necessarily  see  strong  connections  between what they have accomplished compared to what another classmate might have  done.  This  flexible  rubric  provides  assurance  and  emphasises  the flexible  nature  of  the  assignment  based  on  each  student's  assessment  of what is needed.

Final reflective essays indicate that students understand how the course components  interconnect.  One  student's  comments  -  for  which  ethical clearance as part of a bigger project and written informed consent for use was obtained - encapsulates themes found in this chapter:

For the most part, I have only learned a fraction of what my major entails so I am not a true expert. I would say I am more of an acolyte, but even then, this

process has given me insight and the confidence to recognize that I know enough about a subject to at least start a Wiki page about it and generate interest from the larger community […]. [ T ]he coordination between Metaliteracy and Wikipedia has encouraged constant reflection on each word that I write and whether or not what I am writing is what I think and if it is the best way of thinking, engaging the  metacognitive  faculties  within  the  metaliteracy  framework.  (Undergraduate student, Philosophy major, 24 September 2020)

A six-week course provides challenges for integrating metaliteracy, IL and a mechanism for allowing students to put their newfound learning into practice, further developing it as they do. Whilst ideally there would be additional time to focus on SDL, the students do have the opportunity to continue with their 'journey of discovery' (Gibbons 2002:45).

## Conclusion

This chapter sought to explore and make explicit the interconnections between metaliteracy and SDL. An additional goal of the authors was to identify the assessment  methods  most  appropriate  for  determining  one's  progress towards metaliteracy and make connections between this assessment and the forms particularly pertinent in SDL, AaL and AfL.

The  chapter  started  with  an  overview  of  metaliteracy  and  its  core components, followed by a section that considered SDL as viewed through the lens of metaliteracy. It then delved into a close examination of selected components from metaliteracy, relating them to SDL and assessment. Two descriptive case studies close the chapter. This exploration on both the macro and the micro level provides solid evidence of the interrelationships amongst metaliteracy,  SDL,  AaL  and  AfL.  The  authors  propose  that  future  research studies into these topics expand their scope and their import by considering these connections.

## Chapter 5

## Leveraging student self-directed learning through online tutoring and integrated ipsative assessment

## Iman C. Chahine a,b

a Department of Curriculum &amp; Instruction, College of Education, University of Massachusetts Lowell, Lowell, MA, United States of America b Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Saeid Belkasim

Department of Computer Science, Georgia State University, Atlanta, GA, United States of America

How to cite: Chahine,  I.C.  &amp;  Belkasim,  S.,  2021,  'Leveraging  student  self-directed  learning  through  online tutoring and integrated ipsative assessment', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 99-121, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.05

## Abstract

In the wake of the coronavirus disease 2019 (COVID-19) pandemic early in 2020, drastic precautionary measures were put in place to slow down the expansive spread of the virus. Social distancing is one of the heightened mitigation efforts that countries adopted to dodge the explosive spread of the virus and to obviate its transmission. To ensure that student learning is not  compromised  as  a  result  of  such  an  aggressive  outbreak,  schools around the world resorted to online teaching and learning. Hastily, online tutoring  became  the  most  attractive  option  that  could  offer  online education  for  hundreds  of  millions  of  learners  whilst  preserving  the traditional  in-class  teacher-student  interaction.  Making  use  of  current research in databases and online learning tools was paramount to improve learning outcomes and to enhance student learning whilst saving effort, time and resources.

This chapter advances the establishment of an online tutoring system integrating several state-of-the-art online education systems geared towards helping students be more self-directed, maximising their learning and raising their self-efficacy through integrated ipsative assessments. The main  motivation  behind  the  online  tutoring  community  is  to  engage students  in  SDL  beyond  the  regular  class  periods.  The  novelty  of  this approach is that the system can reward students for their active participation by  giving  bonus  credits  measured  relative  to  their  contributions  to  the system.

The online system we are proposing is interactive and is designed to grow with  the  needs  of  the  participating  students.  The  students  not  only  pose questions for the system but can also create and add their own questions to challenge other students. This feature enables the system database to grow with the needs of the students from very simple and easy questions to very complex  ones  as  the  database  becomes  larger.  With  integrated  ipsative feedback,  students  can  monitor  their  own  learning  and  enhance  their metacognition.

## Introduction

Traditional tutorial sessions in many remediation programs in K-16 classrooms proved to be a successful approach to addressing gaps in student achievement (Ogina &amp; Mampane 2013). However, holding supplementary tutorial sessions is not always possible and may not be the ideal solution to support meaningful student AoL. Online tutoring is a very attractive option that would offer many features available in traditional tutorial sessions that are complemented by a computerised online learning system.

It  has  been  widely  established  that  one  of  the  attractive  aspects  of  an online tutoring community is immersing students in self-directed environments affording myriad opportunities for interactions with peers and teachers in real time and beyond the regular class periods (Luo 2015). The novelty of this selfregulated  environment  is  that  students  engage  in  reciprocal  teaching approaches  (Oczkus  2018),  orchestrating  interactive  dialogues  with  their peers  and  teachers,  and  are  rewarded  for  their  motivation  and  active participation by earning bonus credits measured relative to their contributions to the system. The proposed system is interactive and is designed to grow with  the  needs  of  the  participating  students.  The  students  not  only  pose questions for the system but can also create and add their own questions to challenge other students. Once a question receives an approval rating from both the teacher and the rest of the students, it will be permanently added to the database, accompanied by a proper answer to be used for the rest of the current term as well as future offerings of the same class. This feature enables the system database to grow with the needs of the students from very simple and easy questions to very complex ones as the database becomes larger.

The basic theme of this chapter is capitalising on the positive aspects of online  education  whilst  preserving  the  traditional  in-class  teacher-student interaction. We argue that making use of current research in databases and online learning tools can improve AoL outcomes and enhance student-teacher interaction whilst saving resources. Several studies suggest that systems that promote student interactions are more successful in online education (Banna et  al.  2015;  Rogers  et  al.  2003;  Salmon  2003).  The  proposed  knowledgebuilding feature of the online environment is used to self-direct students who lack knowledge in a certain topic to train themselves, overcome their weaknesses and  build  their  confidence.  The  online  tutoring  environment  uses  relational database  logic  to  pinpoint  specific  deficiencies  and  suggests  particular resource  locations  that  contain  the  needed  knowledge.  Furthermore,  it combines education as well as evaluation tools to assess initial knowledge level of students and to help them monitor their progress throughout their activities.

The  proposed  environment  is  principled  by  self-directed  learning  with technology  (SDLT),  in  which  the  learner  sets  their  own  learning  goals  to acquire  new  competencies  and  build  new  knowledge  (Long  1994).  The literature on the use of online environments as facilitators of SDL has confirmed that  engaging  in  collaborative  interactions  via  technology  could  in  fact improve student capacity to become self-directed learners (Lee et al. 2014; Teo  et  al.  2010).  Conversely,  Kirk  (2012)  asserts  that  the  extent  to  which learners are self-directed can predict their level of engagement in using online technologies as tools for learning. Furthermore, Alotaibi (2015) contends that the level of student academic success could be linked to the degree of their SDL readiness.

This chapter seeks to make a connection between SDLT and online tutoring environments with built-in assessment components. We argue that an efficient assessment of the gained knowledge at every stage of the learning process would  guide  both  the  teacher  and  the  student  to  put  more  emphasis  on particular subjects that in turn could save time and effort. As such, we propose the development of online tutoring systems that are geared towards helping students maximise their knowledge, improve their learning and monitor their progress using ipsative approaches to assessment. Hughes (2011) describes ipsative approaches to assessment as being self-referential, shifting the focus away from achieving external standards and onto individual learner's progress and learning gains. The database system could be interactive and dynamic and the majority of queries can be automatically answered by the proposed system. Computerised student assessments and evaluations have provided innovative tools that allow significant improvements in the way we teach and assess  student  learning.  Building  on  the  motivational  power  of  ipsative assessments,  this  chapter  argues  that  self-directed  online  tutoring,  an application of SDLT, could help learners become assessment literate, setting goals for learning, manoeuvring and managing academic resources enabling them to succeed in school subjects and beyond.

## Ipsative assessment in the context of self-directed learning

The  knowledge  assessment  component  of  the  proposed  online  tutoring environment  is  based  on  ipsative  assessment  approaches,  which  is  most critical to the design. Hughes (2011:353) defines ipsative assessment as 'the process  of  comparing  a  student's  performance  against  his/her  previous performance'. Unlike other approaches to externally referenced assessments, such  as  criterion  and  norm-referenced  that  rely  on  comparing  student performance to external criteria or to his peers, ipsative assessments are selfreferential  as  they  compare  students'  performance  to  their  own  previous performance mitigating the stress of competition between peers and focusing on  the  learners'  personal  progression  towards  achieving  desired  learning outcomes  (see  Figure  5.1).  By  encouraging  students  to  act  on  immediate feedback,  ipsative  assessment  champions  a  growth  mindset  attributing success in learning to effort and boosting self-esteem by rewarding self-paced personal progress.

Savage  and  Fautley  (2016:212)  described  ipsative  assessment  as  'an assessment the student makes against their own prior performance, so that they  are  measuring  their  personal  progression  against  their  own  previous work'. As such, the process of ipsative assessment is inextricably associated with  learning  as  students  actively  and  continuously  self-assess  in  order  to achieve learning outcomes (Partti, Westerlund &amp; Lebler 2015). Reflecting on

FIGURE 5.1: Depiction of ipsative longitudinal assessment process.

<!-- image -->

current and prior understandings of concepts and skills is key to a successful and productive ipsative assessment process.

Generally  speaking,  ipsative  assessments  consist  of  four  basic  elements underpinned by the belief that every learner can improve and an awareness of the importance of the learner's high self-esteem (see Figure 5.2).

Therefore,  the  learner  is  involved  throughout  the  process  as  an  active participant rather than a receptor, with the role of the teacher moving from controller  to  facilitator.  When  lessons  are  punctuated  by  self-  and  peerassessment, learners are actively engaged in thinking and articulating that thinking (Seifert &amp; Felix 2019). Even when engaged in independent tasks, they could be encouraged to stop at regular intervals and check their work against success criteria they benchmarked or look for places where they can improve.

As  opportunities  for  learning,  ipsative  assessments  can  offer  students occasions  to  discuss  and  work  cooperatively.  By  giving  specific  feedback about  specific  aspects  of  their  understanding,  offering  suggestions  for discussion, exploration or improvement, focusing on how students are learning as a means to help them better consolidate that learning without the stress of fierce competition. Through extensive exposure and self-directed appraisal, students eventually could independently close the gap between what they know and what they need to know and be able to achieve a specific standard(s) (Hughes, Wood &amp; Kitagwa 2014). To close the gap, Nicol and Macfarlane-Dick (2006) aver  that  students  need  to:  (1)  possess  a  concept  of  the  standard being aimed for, (2) compare the actual (or current) level of performance with that standard, and (3) engage in appropriate action, which leads to becoming self-regulated  learners.  In  an  environment  where  ipsative  assessment  is

FIGURE 5.2: Components of ipsative assessments.

<!-- image -->

employed, learning goals rather than performance goals dominate, and effort rather than ability is emphasised.

However,  the  literature  highlights  several  misconceptions  regarding  the effectiveness of ipsative assessments, mainly target setting and minimalising achievement. There is a misconception that any assessment might lead to learning. However, what is important is that ipsative assessment focuses on deepening and furthering learning rather than just measuring it (Broadfoot 1996). Finding out what students need to pass the tests, setting targets, and then finding out later whether they have been met or not does not align with the expectations of ipsative assessment. As with SDL, ipsative assessments relate to personal gains in learning as well as 'progression towards individual targets and possibly self-directed goals that matter, not only reaching external standards' (ed. Hughes 2017:2). Therefore, minimalising ipsative assessment is where the learned learning objectives can be 'ticked off'. This is true for closed skills (e.g. to be able to make a list, to state times tables in math, etc.) but with open skills such as problem-solving and proving a hypothesis, ticking off the criteria or the learning objective is meaningless. Students need to have models of  quality  and  be  encouraged  to  decide  where  success  has  been  met  and where they need to improve.

Although ipsative assessment draws from the characteristics of formative assessments, however, unlike the latter, student performance is compared to  her  best  previous  attempt  within  the  same  curricular  concepts.  In  this context,  assessment  is  considered  a  'profiling'  type  of  test.  A  reported advantage of ipsative assessments is the facility by which students can track their  progress  with  their  existing  'personal  best'  over  time  but  within  the same curricular content. Such a unique feature promotes ipsative assessment as a type of self-appraisal and reflection conducted by the student to monitor academic  progress  setting  realistic  goals  and  steps  for  achieving  those goals. Hughes (2014) declares that this type of self-competition supports student self-determination as they become more aware of their own progress,

self-diagnosing and self-regulate based  on successive feedback and establishing personalised plans to attain personal and curricular expectations. Furthermore, Hughes (2017) highlights key attributes of ipsative assessments that closely align with SDL approaches where the learner is allowed to set personal learning goals and to plan personal learning gains. Building on the guidelines proposed in Chapter 1 (this volume) regarding the effective use of assessment approaches to support meaningful learning, we argue that there is  a  mutual  overlap  between  the  goals  of  SDL  and  ipsative  assessment approaches in relation to enhancing students' skills to become autonomous and  self-directed  learner,  managing  and  controlling  their  learning  gains. These include peer and self-assessments and ipsative feedback as a modality of social learning.

## Peer and self-assessment

The involvement of students in the self-appraisal of their performance and the constructive criticism of their own work and the work of their peers is a key aspect of SDL (Youngeun &amp; Anderson 2016). In this context, peer and self-assessment emerge as equalising agents to ensure that students have a fair share of contributing to assessing their own learning gains and regulating their  self-performance  accordingly.  Students,  when  trained,  are  able  to identify their success against the success criteria of a task and then are able to identify others' and their own learning successes. Therefore, it is highly encouraged that across disciplines, students would be introduced to 'models of excellence' (Stewart 2012) and be allowed to make their own improvements, suggest  improvements  to  their  peers  and  identify  where  and  when  they require teacher support (not the answer). This frees the teacher from being the main source of knowledge and information and encourages students to become autonomous and self-reliant learners.

## Peer assessment

Double,  McGrane  and  Hopfenbeck  (2020)  confirmed  the  effectiveness  of peer assessment as a formative practice and encouraged its implementation in the classroom. Generally speaking, peer assessment or peer review engages students in using specified assessment benchmarks to review and assess their peers' written work, which in turn promotes student competence to provide feedback to their peers (Chin 2016). Through peer assessment, we argue that some  ownership  of  the  assessment  process  is  transferred  to  the  learners, which eventually leads to being more self-directed learners, with an enhanced sense  of  motivation  and  engagement  and  a  drive  to  learn  more  deeply, building up their understanding of new knowledge and skills. Furthermore, peer assessment affords students the opportunity to reflect deeply on how they  assess  a  task  compared  to  their  peers.  As  such,  peer  assessment

represents a major focus of self-directed assessment to inform learning and not  simply  a  means  to  monitor  grades.  As  a  result,  students  acquire  the necessary competencies to judge the reasonableness of ideas, to critique and justify, and to become more self-aware of their own learning (Reinholz 2016).

## Self-assessment

It has been widely established that making judgements about the progress of one's  own  learning  is  integral  to  the  learning  process.  Whilst  there  are numerous definitions in the literature describing self-assessment, the simplest characterisation is that it builds on a natural tendency of students to check out  the  progress  of  their  own  learning.  Andrade  (2010)  argues  that  selfassessment capitalises on the role of feedback as a catalyst for deep learning and improved performance. In describing the purposes of self-assessment, Andrade (2019) explains:

[ S ]elf-assessment is to generate feedback that promotes learning and improvements in performance. This learning-oriented purpose of self-assessment implies that it should be formative: if there is no opportunity for adjustment and correction, selfassessment is almost pointless. (p. 2)

Boud  (1995:11)  explains  that  self-assessment  with  its  emphasis  on  student responsibility and making judgements is 'a necessary skill for lifelong learning'. Additionally, the self-assessment process can help 'prepare students not just to solve the problems we already know the answer to, but to solve problems we cannot at the moment even conceive' (Brew 1995:57). Therefore, engaging students in the formulation of criteria for self-assessment tasks is essential to deepen their understanding of what constitutes quality learning outcomes across disciplines.

## Strategies for peer and self-assessment

Having assessed the work of others, students will find it easier to identify weaknesses in their own work and to see how they can make improvements (Boud &amp; Falchikov 2007). Therefore, it is recommended that students learn how  to  peer  assess  before  engaging  in  self-assessment.  Hughes  (2014) argues  that  it  is  essential  that  students  be  given  the  opportunity  to contemplate  and  meticulously  appraise  their learning progression by correlating their current performance with past effort and monitoring their advancement towards personal goal attainment. In this context, Spiller (2012) proposes  several  strategies  that  can  be  incorporated  in  the  classroom  to strengthen students' peer and self-assessment skills. We list 10 strategies in Table 5.1 that provide recommendations for enhancing students' peer and self-assessment practices.

TABLE 5.1: Peer and self-assessment strategies and key benefits.

| Peer and self-assessment strategies                                                                                                                               | Key benefits                                                                                                                                  |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| 1. Emphasise the need to focus on being attentive  to questions posed in class and to request  explanations if ideas presented are not clear (Barr  et al. 2002). | • Students use questioning as a means to inform  understanding.                                                                               |
| 1. Emphasise the need to focus on being attentive  to questions posed in class and to request  explanations if ideas presented are not clear (Barr  et al. 2002). | • Students reflect on each other's work to build  meaningful knowledge.                                                                       |
| 1. Emphasise the need to focus on being attentive  to questions posed in class and to request  explanations if ideas presented are not clear (Barr  et al. 2002). | • Students collaboratively build new knowledge.                                                                                               |
| 1. Emphasise the need to focus on being attentive  to questions posed in class and to request  explanations if ideas presented are not clear (Barr  et al. 2002). | • Students have ownership of their learning and support  the learning of their peers (Earl &amp; Katz 2006).                                      |
| 2. Peers share their work to negotiate  understanding and find better ways to build new  skills and knowledge.                                                    | • Students support each other in identifying criteria  for success based on their own learning trajectory  (Boud 1995).                       |
| 2. Peers share their work to negotiate  understanding and find better ways to build new  skills and knowledge.                                                    | • Students are informed of how others assess their  performance and thus develop the skill of self- directed assessment (Boud 1995).          |
| 3. Encourage students to accept constructive  criticism and acknowledge their strengths and  areas that need improvement.                                         | • Students become autonomous learners having control  over their learning (Price 2012).                                                       |
| 3. Encourage students to accept constructive  criticism and acknowledge their strengths and  areas that need improvement.                                         | • Students will trust each other and make informed  judgements about the quality of their performance.                                        |
| 4. Engage students in critically assessing each  other's work providing clear directions on how  their peers can improve performance.                             | • Support students to become independent researchers  seeking new knowledge to support their lifelong  learning.                              |
| 4. Engage students in critically assessing each  other's work providing clear directions on how  their peers can improve performance.                             | • Students build communities in their classrooms to  support each other (Nulty 2012).                                                         |
| 5. Train students to pose good and relevant  questions to each other and to set criteria for  successful performance (Boud 1995).                                 | • Students gain an understanding of key concepts as  they develop questions and answers.                                                      |
| 5. Train students to pose good and relevant  questions to each other and to set criteria for  successful performance (Boud 1995).                                 | • Students feel less stressed and become empowered to  engage in posing questions and assessing responses.                                    |
| 6. Make self- and peer-assessments as  opportunities for developing new knowledge and  skills.                                                                    | • Students become skilled in reflecting on their own  performance and monitor their learning progress and  that of their peers independently. |
| 6. Make self- and peer-assessments as  opportunities for developing new knowledge and  skills.                                                                    | • Students use assessment as a learning aid to facilitate  a deeper understanding of concepts (Race 2001).                                    |

<!-- image -->

## Ipsative feedback

Broadly speaking,  feedback  can  support  students  to  become  independent learners and equip them with the necessary skills to confidently conduct peerand self-assessment and make subsequent improvements to their ongoing work (Spiller 2012). Boud and Molloy (2013) define feedback as:

[ A ]  process  whereby  learners  obtain  information  about  their  work  in  order  to appreciate the similarities and differences between the appropriate standards for any given work and the qualities of the work itself, in order to generate improved work. (p. 6)

Hughes (2014) argues that ipsative feedback is one common form of ipsative assessment that enables dialogues with students, helping them reflect upon

their  experiences  and  contributing  to  their  satisfaction  and  interest  in learning. Furthermore, Hattie and Timperley (2007) explore developmental feedback, or feed forward , as a mechanism for predicting future learning gains. Nonetheless,  Hughes  (2017)  caution  against  the  term  ipsative feedback that is transmitted to students without their systematic engagement in  the  follow-up  process.  Hence,  the  focus  on  students  as  self-directed learners managing and controlling available resources in their environment to support meaningful learning and goal setting. Whether feedback is just there to be grasped or is provided by another person, effective feedback is dialogical  and  goal-referenced  (Hughes  2017);  tangible  and  transparent (Spiller  2012);  actionable;  specific  and  personalised;  timely;  ongoing  and consistent.

On  the  other hand, explicit ipsative feedback  can  become  quite challenging particularly that not only the baseline of the learner should be known  but  also  previous  levels  too.  In  this  case,  Hughes,  Hawkes  and Neumann (2017)  recommend  digital  record-keeping  through  an  adaptive virtual  learning  environment  that  stores  the  feedback  history  of  students during the academic year. As such, cumulative ipsative feedback collected over time is most useful to ensure seamless progression in learning and to support personalised gains.

There are numerous practical implications of ipsative feedback principles. Cited  mostly  is  closing  the  gap  in  student  knowledge  and  understanding (Goold  2016;  Hughes  2014,  2017).  Because  immediate  feedback  is  key  to influencing learning gains,  it  is  necessary  that  ipsative  feedback  be  incorporated into daily lesson plans. For example, questioning strategies provide one-toone  feedback  from  teacher  to  student  and  paired  discussions  provide individual feedback to students from their partner about their thinking or their written work. Mid-lesson learning stops as well as cooperative marking enable students  to  actively  improve  their  work  by  seeing  excellent  examples  and discussing possible improvements.

Similarly,  Hughes,  Smith  and  Creese  (2015)  highlight  the  role  of  virtual learning environments in capturing and recording ipsative feedback to ensure access  to  the  rich  information  on  student  learning  gains  in  the  process  of conducting ipsative assessments. These digital tools can help make progress visible to the students and teachers, generating history feedback profiles for individual  learners.  However,  some  challenges  are  cited  in  the  literature regarding  the  accessibility  and  tracing  of  digitised  ipsative  assessments pulling  together  information  on  student  progress  from  multiple  resources (Rennie &amp; Morrison 2013). Therefore, there is a need and demand to design virtual environments that facilitate ipsative assessment approaches compiling and storing feedback profiles of individual students to document and digitally preserve trajectories of learning gains over time.

## Background: Role of technology in ipsative assessment

In the past two decades, there has been a considerable increase in the use of computer  assisted  assessment  (CAA)  applications  in  educational  sciences. Particularly at the tertiary level and as number of students in the classrooms grew larger and larger, teachers were forced to digitise student assessment reports, using standard exams almost exclusively (Conole &amp; Warburton 2005). The problem with standard exams is that, in order to be able to discriminate between all the different knowledge levels, teachers had to include questions at  all  ranges  of  complexity.  As  a  result,  tests  became  longer  and  included questions that are either too difficult for some students with lower knowledge level or too easy for others with higher knowledge levels. Currently, the use of computer technology in student assessment has become a common practice across many educational disciplines. Rezaie and Golshan (2015) note numerous technology-based tools geared towards AoL, such as CBT (Computer-Based Test),  CAA,  CAT  (Computer  Aided/Assisted  or  Computer  Adaptive  Test) (Weiss &amp; Kingsbury 1984) and CALT (Computer Adaptive Language Testing).

Broadly,  CBT  employs  computer  tools  and  platforms  in  the  assessment process. Some of the early research in computer-based assessment is about the effect of using computers in student assessment compared to paper-andpencil (Brosnan 1999). Way and Robin (2016) trace back the origin of CBT to the work of psychologist Albert Binet. However, the attractiveness of CBT is captured by Bunderson, Inouye and Olsen (1988) when they declared:

The changes brought about by the wide availability and low cost of new technological delivery system alternatives are moving testing from its delivery through paper andpencil and printed booklets to delivery through online computer work-stations. (p. 402)

Thelwall (2000) describes earlier computer assessment tests as text-based, comprising basically of objective, factual questions eliciting specific answers and  restricting  marking  only  to  predefined  answer  keys  minimising  any subjective judgements on the part of the marker. Arguably, much of the earlier objective testing carried out was based on Classic Test Theory (CTT) principles (Bichi 2016; Bull &amp; McKenna 2000). Classic Test Theory comprises a set of psychometric procedures and measures the internal consistency of the items in the entire test. Magno (2009) avers that CTT procedures are developed on the  assumption  that  each  student  taking  the  test  has  a  true  score,  an unobservable quantity representing the hypothetical perfect score value of a student's ability, assuming no error because of assessment instruments. He further asserts that because measuring instruments can be biased, a student's score on a test does not necessarily reflect their true ability. The difference between the true score and the obtained score is attributed to an error in measurement.

## Computer adaptive tests

The term computer adaptive test (CAT) is a type of CBT that is user-tailored and describes a software application employing item response theory (IRT) principles  to  estimate  a  student's  ability  (Kimura  2017).  Noijons  (1994) describes CAT as:

[ A ]n integrated procedure in which language performance is elicited and assessed with the help of a computer, consisting of three integrated procedures including: generating the test, interaction with candidate, and evaluation of response. (p. 38)

The basis of most CATs is derived from a psychometric theory known as IRT. It was proposed by Birnbaum (1968) and was initially known as Latent Trait Theory. In IRT context, testing is based on item analysis approaches taking into consideration the student's ability (Magno 2009). Conejo et al. (2004) explain:

In IRT, it is assumed that the knowledge level of the student is measured with a single variable that is called the trait. Using as input data a set of responses of the students to a set of questions, the level of knowledge of the student is estimated (with some statistical method). Then, this estimation is used to determine the most informative item to ask next. These steps are repeated until some stopping criterion is met. (p. 2)

As such, different IRT models have been developed that direct the selection of questions based on various statistical techniques.

In general, Wainer and Mislevy (2000) argued that CAT is commonly used within IRT approaches; however, adaptive testing is not dependent on the IRT.

De Boeck and Wilson (2004) asserted that using explanatory item response theory  (explanatory  IRT)  will  enable  an  examination  of  how  background variables  can  influence  the  detection  of  initial  knowledge  levels  especially when the student first enters the virtual learning environment. Wauters et al. (2010) cautioned that a less precise initial assessment of ability may lead to inaccurate  readings  of  entry  knowledge  level  hereby  resulting  in  a  higher number of questions to determine students' accurate knowledge baseline. To address this issue, Park, Joo and Cornillie (2019) proposed using explanatory IRT modelling to assess students' knowledge levels taking into consideration their background information and previous learning trajectories. By simulating different  student  profiles  under  various  conditions,  the  authors  found  that using  explanatory  IRT  modelling  significantly  reduced  baseline  knowledge estimation errors.

Computer adaptive testing is one of the types of CAA software applications (Thompson 2011). In its simplest form, CAT is a multiple-choice test battery administered  by  a  computer,  where  questions  are  automatically  selected based on an examinee profile dynamically generated from the responses to prior  questions.  Concomitantly,  student  profiles  are  created  and  updated during the interaction with the online environment. Ipsative assessments are

supported  by  using  CAT  to  discern  personalised  learning  gains,  thereby reducing  the  stress  of  competition  and  easing  the  load  of  assessment anxieties (Bull &amp; McKenna 2004).

There are numerous advantages of using CAT tests. For example, Rezaie and Golshan (2015) cite a number of benefits for using CAT, including provision of innovative self-assessments, saving time and providing immediate feedback with a more efficient appraisal of student knowledge level compared to paperand-pencil  tests.  Computer  adaptive  testing  scoring  identifies  the  items correctly  answered  by  students  and  counts  the  overall  number  of  correct responses (Reckase 1989). For example, students answering difficult questions score higher than correctly answering an easier set of questions. Additionally, as the pool of items increases, the effectiveness and efficiency of the CAT system item selection algorithm increases.

Furthermore,  numerous  derivatives  of  CAT  were  developed  over  time. Trentin (1997) developed a hierarchical representation system where content tested is presented in a calibrated level of complexity. The system automatically adjusts  the  difficulty  levels  of  items  when  the  responses  that  the  student provide  fall  below  a  designated  value.  The  strength  of  Trentin's  proposed model lies in mapping student knowledge level with appropriate items on a test so that overachieving students receive high-level questions. By the same token,  Rudner  (2001)  employed  measurement  decision  theory  (MDT)  to design CAT that classifies student knowledge levels into either pass or fail. Additionally, Lütticke (2004) describes adaptive test questions where student responses are automatically analysed by the system. If an incorrect response is  provided, the system will prompt a tutoring assistance, presenting some feedback, and then the question is re-administered. This process is repeated until the student provides a correct response. Canfield (2001) referred to such systems  as  intelligent  tutoring  systems  (ITS)  where  the  systems  provide insight into students' knowledge level and adjust assessment accordingly. By supporting  immediate  and  precise  feedback  when  incorrect  answers  are submitted and introducing new concepts based on student readiness, Canfield (2001) confirms that these features qualify ITSs to be part of a new breed of instructional computer programs.

To increase measurement precision, it has been suggested that the CAT development system includes a large calibrated pool of questions or items, with a wide range of difficulty to accommodate a spectrum of different ability levels. There is some debate regarding the size of items that should be included in  a  CAT  system.  For  example,  Wainer  and  Eignor  (2000)  recommended populating thousands of question items, whereas McBride (2001) suggested that the pool should contain five times more items than what is administered to students. Stocking (1994), on the other hand, concluded that an item pool about 12 times the length of a CAT was acceptable to cover a variety of content domains and test formats.

The virtual environment is capable of accurately estimating the student's knowledge level at every stage of the assessment process using several builtin algorithms and  statistical methods.  Furthermore, the computerised assessment system can predict the questions to be administered next based on the student's record of accumulated previous answers, which fits a specific statistical  model  such  as  Bayes  model.  This  functionality  involves  sifting through  the  calibrated  item  pool  in  order  to  identify  a  non-administered question that best fits specific selection criteria (Dodd, De Ayala &amp; Koch 1995). Additionally, the literature cites a number of approaches that can be used to set a termination end-point, or 'stopping rules' of a particular test to ensure that students are tested on a unified standard (Stafford, Runyon &amp; Casabianca 2019). For example, a termination signal can be issued based on reaching a maximum number of questions, exceeding a predefined time limit, or achieving a desired knowledge level.

Oppl,  Reisinger  and  Eckmaier  (2017)  describe  a  multi-step  approach involved in the execution of CAT process. Starting with item 1 selection from a pool of questions, the item is then administered, eliciting responses from the student. If a correct answer is given, then the complexity level of the following question  will  be  increased.  Matteucci  and  Veldkamp  (2013)  further  explain that the CAT procedure continues in successive iterations and ends only when a specified criterion is met. Some of these criteria can be the test length, level of precision, or time span (Segall 2004).

## Online tutoring community

The pilot online tutoring community we propose in this chapter is developed by  the  second  author  and  is  a  system  that  brings  together  students  and teachers, teaching assistants and any other volunteers such as retired teachers or  senior  students.  The  system  is  managed  and  controlled  by  the  teacher, whose permission is required for anyone who wishes to become a member of the online tutoring community. The system is designed such that a particular topic is broken down into smaller segments, each assigned a low, medium or high  level  of  difficulty.  The  level  of  difficulty  of  each  question  can  be automatically determined by the system and approved by the teacher. Artificial intelligence (AI) tools and algorithms can be combined with pattern recognition tools to assess students' knowledge and highlight their weaknesses. The AI assessment tools can be used to tailor specific content for each individual student  and  provide  reading  material  and  adaptive  tests  to  assess  their progress towards achieving learning gains.

The basic component of the online tutoring environment is the development of  test  bank  questions  to  assess  the  level  of  participating  students  and  to evaluate their progress whilst utilising the system. The test bank can be as simple as multiple-choice questions that vary in difficulty to very complex

essay-type questions. The state of the art of the research in this topic is quite advanced, and there are several widely used ipsative assessment strategies that can be automated. For basic sciences, multiple-choice questions tests are widely used techniques to assess students' comprehension level. These tests, when administered by computers, cost less in terms of time and resources. Different  approaches  can  be  introduced  to  accurately  assess  the  level  of knowledge of each participating student and to provide ipsative feedback in the process.

## Online collaboration and knowledge assessment

The online tutoring environment is basically comprised of two components: a knowledge  evaluation  component  and  a  collaboration  component.  The knowledge evaluation component is based on using the CAT technology to design efficient tests to evaluate and monitor the progress of each participating student.  Each  student  can  request  an  evaluation  test  at  any  stage  during studying for a particular subject or topic. The test outcome can be used to guide students through the process of learning new knowledge and skills and provide feedback on the prerequisite background needed to fully comprehend concepts and processes (see Figure 5.3).

The  collaboration  component,  on  the  other  hand,  links  participating students  with  other  users  of  the  system  including  teachers,  teaching assistants and other volunteers to help in understanding certain topics or answer some difficult  questions.  The  collaboration  component  has  all  the necessary tools to support discussion boards, search engines, and editing functionality. The system provides immediate reinforcement for successful performance by rewarding bonus credits for students who actively engage

FIGURE 5.3: Depiction of the general architecture of the knowledge evaluation system.

<!-- image -->

in either answering or posing questions. In addition to extra credits that can be  counted  as  part  of  student  ongoing  formative  assessment  in  a  given discipline, other reinforcements can include activities or privileges such as playing  computer games or having extra time in the gym. We argue that positively rewarding students' participation in the virtual tutoring environment enhances their interest in becoming self-directed learners who are actively engaged in setting goals for success, which boosts their self-esteem.

## Online tutoring system design

The literature cites numerous studies that provide evidence of the effectiveness of online tutoring in improving student learning globally and across disciplines. For example, Huang (2013) showed that online tutoring significantly impacted student  performance  in  Mathematics.  Other  studies  also  suggested  that interactive  online  Mathematics  tutoring  could  result  in  improved  student success  rates  (Chappell  et  al.  2011).  Furthermore,  Chappell  et  al.  (2015) examined the impact of online Mathematics tutoring on student academic performance  and  perceptions.  Chappell  et  al.  also  deduced  that  tutoring resulted in a statistically significant increase in student assessment scores as well as positive attitudes towards the online experience.

Generally speaking, online tutoring is a web-based tool that supports the ipsative  assessment  of  student  performance  across  school  subjects.  The system would generate question items from an existing database dynamically based  on  students'  profile,  hereby  determining  students'  baseline  level  in terms  of  acquired  prerequisite  concepts.  The  second  author,  a  computer scientist, designed this system so that teachers can develop several assessment tools  to  measure  student  learning  and  monitor  their  progression  towards acquiring new knowledge and necessary skills. The main components of the proposed system are shown in Figure 5.4 and include three major modules: Knowledge organization, discussion board controls and testing management.

Question/knowledge management: This module manages all questions either posted by the students or designed by the teacher. It is the core module in the system.  The  communication  between  the  teacher  and  the  students  is conducted through postings to the discussion board and involves the following interaction:

- · The student posts some questions on the discussion board.
- · The teacher can view the students' level automatically through the system.
- · The teacher can use the system to evaluate the students' knowledge level.

Discussion board management: This module manages all posted threads and messages. It is the place where students can communicate with each other or

FIGURE 5.4: Depiction of online tutoring system architecture and framework.

<!-- image -->

communicate with the teacher by posting some questions and replying to the posted question. It works as follows:

- · A student posts a question in the discussion forum, which will become a new thread.
- · Other students post their reply under that thread, which becomes a series of messages linked to each other.
- · The teacher can 'close' the thread if some conclusions are reached, such as the answer/solution is found, or the question is trivial in that it does not need  any  further  discussion.  The  teacher  can  decide  whether  to  add  a question to the test database.

Testing management: This module manages all potential tests/quizzes and operates as follows:

- · The  teacher  specifies  a  set  of  questions  to  test  the  student's  level  on selected topics.
- · When a student posts a question, if the level of the student is unknown, the system will ask the student to do a level evaluation test. The result of the test will be used to determine the initial level of the student.
- · The student or the teacher can monitor the changes in knowledge level by requesting another evaluation test. The system can generate a new test with different questions one level of difficulty higher than his current level.

The system is designed to support and include the adaptive test evaluation component as well as the tutoring component. The evaluation component is used for both determining the current level of the participant and producing reports that can be analysed by the tutoring component to suggest a study plan for each participant.

## The basic system requirements consist of:

- · Question  database: The  question  database  is  a  dynamic  database populated with questions as the system evolves. Initially, the teachers may populate the database with sample questions. As the system evolves, it can extract new questions from the participating users. These questions can be used to enrich the system question database upon receiving approval from the teacher.
- · Question editor: This module will provide the teacher with an interface to add  questions  to  the  question  database.  A  user  can  define  different parameters of questions and any related answer options. An analysis tool is added to search all existing similar questions to enable the teacher or the student avoid duplicate questions.
- · Student  model: The  student  model  is  tailored  to  each  student  specific needs. Basically, the student model would assess the knowledge level of a particular student and store the level information in addition to statistical information  such  as  how  many  questions  were  answered  correctly  and display a study guide for the ones answered incorrectly. This model can also  be  used  later  to  monitor  the  progress  of  the  student  and  create statistical reports for the teacher.
- · Test  generator: This  is  the  main  module  in  the  knowledge  assessment process. It is responsible for dynamically selecting questions based upon specifications extracted from the student profile. The Prototype of ipsative assessment is shown in Figure 5.5.

Specifically, the activity starts by establishing the learner's initial knowledge level. This level represents the baseline and benchmark against which ipsative assessment and feedback are provided. The next step proceeds with selecting then administering a question item. Ipsative assessment follows evaluating responses  based  on  the  learner's  baseline  knowledge.  By  employing  the Bayesian Theorem, an estimation of new knowledge is possible, building on the baseline knowledge level obtained earlier. Consequently, a new question item is selected that is compatible with the hypothesised new knowledge. The cycle repeats until all questions are answered by the learner and the activity terminates at this point.

The basic requirements needed to maintain the functionality of the system are listed in Table 5.2.

The database design incorporates several elements including topics, suite of potential content-related question items, answer options, user profiles and system functionalities. In each test, a subject is divided into several different topics  depending  upon  their  importance.  The  questions  and  topics  are structured as shown in Figure 5.6.

FIGURE 5.5: Depiction of the ipsative assessment activity using Bayesian Theorem.

<!-- image -->

TABLE 5.2: Requirements for system maintenance as proposed by the second author.

| Maintenance  requirement         | Justification                                                                                                                                                                                                                                                                                                                          |
|----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Security                         | System security is an important functionality to keep each users' private records  and information protected from being accessed by any other user.                                                                                                                                                                                    |
| Reliability                      | The reliability of the system is key to keep confidence in the system high and plays  an important factor in keeping student participation high.                                                                                                                                                                                       |
| Maintainability                  | The system administrator in the initial stage is a graduate student who normally  uses the data resulting from the system to conduct educational research.                                                                                                                                                                             |
| Resource utilisation             | The effective use of all available resources to educate the students is an important  ingredient to the effectiveness of the system. External resources such as online  libraries can be linked to the system to add more inputs into some topics.                                                                                     |
| Administer item                  | This functionality is used to access an item in the database and pass it to users.                                                                                                                                                                                                                                                     |
| Evaluate response                | This stage is responsible for the actual evaluation process. It will take the user  response and then compare it with the correct answer in the database to find its  correctness.                                                                                                                                                     |
| Knowledge level  estimation      | The selection of the algorithm for knowledge estimation is implemented at this  stage. Two main approaches have been used for the algorithm.                                                                                                                                                                                           |
| Terminating a test               | To specify the criteria responsible for terminating a test, we use three approaches.  One approach terminates a test when a specified knowledge level has reached;  the second terminates the test when a certain number of questions have been  asked; and the third one terminates a test when a specified time period has  elapsed. |
| Save questions data in  database | This use case is used to handle the storage of question data into the database.  These data are then becoming available for all users of the system.                                                                                                                                                                                   |

<!-- image -->

FIGURE 5.6: Depiction of the structure of topics and related questions.

<!-- image -->

## Ipsative assessment of students using the system

The system is designed to encourage students to participate in the discussion board,  posting  questions  or  answers.  Each  participant  is  automatically evaluated by the system with a predefined set of points that can be used to determine the level of participation and later on can be used by the teacher towards giving extra credits in the course. Factors affecting the participation

level of a student might be the number of posted messages or the teacher assigned  bonuses,  for  example,  a  bonus  for  a  very  informative  posted message.

The evaluation of the student knowledge level is achieved through several testing components embedded in the software. Figure 5.7 outlines the main components of the process of evaluating the knowledge level of students or system users, which is divided into the following functionalities:

- 1. A student requests a level evaluation.
- 2.  The system identifies the current level and generates questions of a higher level.
- 3.  The student takes the test.
- 4.  The system checks whether the level can be incremented or not.

## Prototype system implementation and preliminary results

A  prototype  of  this  online  tutoring  with  integrated  ipsative  assessment environment has been successfully piloted and tested by the second author on one introductory computer science class at his institution. Around 80% of students  participated  in  the  pilot  using  the  environment  to  conduct  selfassessments and monitoring of performance. Furthermore, the second author conducted pre-post perception survey at the beginning and the end of the semester  to  record  student  feedback  related  to  the  effectiveness  of  this virtual environment. Results showed that 83% of the students who used the online system reported some improvement in their study skills. Furthermore, discussions between instructors in the same department revealed that faculty enthusiasm for the virtual environment is fairly high and that overall, students' impression  of  effectiveness  was  positive.  These  preliminary  results  are

FIGURE 5.7: Depiction of the iterative ipsative assessment of student knowledge.

<!-- image -->

encouraging considering that the system is fairly new and the fact that this intervention was the second author's first trial experimentation with such a system.

A number  of periodical evaluations were planned throughout the implementation stages. The testing and evaluation component of the software is  very  useful  to  extract  statistical  information  about  the  effectiveness  of the software in improving the knowledge level of the students in general or some segments of students in particular. The statistical reporting component is very useful in this regard. Surveys were also employed as useful means to collect overall student impressions and to reflect on this feedback by making adjustments to improve the virtual environment and to make it more efficient and user-friendly for the users.

## Conclusion

The proposed virtual system is a unique interactive and adaptive system that combines the advantages of online collaboration with that of a traditional classroom environment. A potential benefit of the pilot is supporting ipsative assessment and feedback by compiling and preserving student submissions across multiple modules, making it easy for students and teachers to track past performance and to monitor learning gains. Furthermore, teachers can employ the data nestled within this virtual environment as a pedagogical tool to direct further learning and monitor progress at different time points.

There  are  numerous  salient  features  of  this  virtual  ipsative  assessment system that supports self-directed approaches to knowledge-building. Firstly, the system complements classroom instruction by providing an interactive forum for students to pose questions, get answers from teachers and fellow classmates,  as  well  as  look  up  previous  discussions  on  course  topics  in  a convenient manner. The system includes intelligent algorithms to search the question bank for similar items given one or more keywords, thus providing a suite of smart searching capabilities. Based on keyword search, the system is  capable  of  retrieving  several  related  questions,  thereby  reducing  the repetition of questions posed in the forum. In this way, students are afforded opportunities to self-regulate their learning by managing access to knowledge from multiple resources.

Secondly, the system facilitates ipsative assessment approaches delineating trajectories of acquired knowledge levels over repeated assessment activities. At the beginning of a course, each student takes a short diagnostic assessment, which defines their baseline knowledge level. This baseline level determines the  level  of  complexity  of  successive  assessments  that  students  need  and delineate  the  depth  and  breadth  of  ipsative  feedback  required  during  the process.  By  taking  personalised  and  adaptive  assessment  modules  several

times during the duration of the course, students and their teachers can get a good  estimate  of  the  learning  that  is  taking  place  on  an  individual  basis. Results  from  these  ipsative  assessments  can  be  correlated  with  students' formative assessment in the course and support a plan to either enrich or remediate based on students' emerging needs.

Thirdly, the virtual environment facilitates student-content interaction by using an incentive-based system rewarding student engagement in SDL and giving  a  range  of  reinforcements,  including  extra  credit.  For  example,  the teacher can configure the system to migrate questions to the test bank and aggregate bonus points for individual students who use and contribute to the system over the duration of the course. The entire student group benefits from increased usage of the system. The question banks get enriched with the increased use of the system when new questions are posed by students and answers are populated. Ultimately, the enhanced knowledge base and skill acquisition  that  students  experience  by  independently  using  the  virtual environment  will  support  an  extended  interest  in  using  more  self-directed approaches to learning.

We envision that the virtual pilot environment will have several fundamental benefits.  Firstly,  there  is  unlimited  accessibility  as  students  can  create  and complete the assessments anytime and anywhere where Internet access is available.  Secondly,  another  benefit  relates  to  identifying  and  supporting struggling students by scaffolding instruction and establishing step-by-step remediation plans to close their knowledge gap and track their learning gains. Thirdly, we argue that the virtual tutoring pilot has the potential of stimulating dialogue between students, peers and teachers, allowing for more interactive context for making  decisions about  future learning building on past performance.  More  importantly,  and  as  Nicol  and  Macfalane-Dick  (2006) noted, enabling students to be self-directed learners delineating their own learning  progression  in  a  self-regulated  manner,  which  is  key  to  ensuring successful lifelong learning beyond school settings.

## Chapter 6

## Assessment as an epistemological tool to facilitate metacognitive awareness and promote self-directed learning

Divan Jagals

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Abstract

Assessment practices are largely seen as mediating ways to enhance students' learning.  As  the  COVID-19  pandemic,  with  set  lockdown  periods,  posed  a threat  to  education  practices  on  a  worldwide  scale,  opportunities  for  a stronger  and  more  rapid  movement  towards  online,  remote  and  distance modes of education are afoot. Internationally, the focus of higher education institutions  has  shifted  to  developing  and  supporting  innovative  education practices. This also involves practices of assessment, in particular assessment

How to cite: Jagals, D., 2021, 'Assessment as an epistemological tool to facilitate metacognitive awareness and promote self-directed learning', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 123-142, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.06

practices  that  provide  and  require  opportunities  and  approaches  for  SDL. Alternative  measures  have  been  put  in  place  with  the  after-effects  of  the pandemic  for  the  purpose  of  sustainable  education,  which  necessitates exploring  how  assessment  can  serve  as  a  tool  to  enhance  the  learning experience.  This  debate  has  provided  a  range  of  possible  propositions  of understanding SDL across various educational settings (e.g. teaching, learning and  research  initiatives).  To  this  end,  the  chapter  provides  a  proposition concerning the facilitation of metacognitive awareness and promotion of SDL capacities  needed  in  the  21st  century.  It  is  argued  that  higher  education institutions prepare and continue teaching and learning initiatives, especially in  terms  of  establishing  assessment  practices  that  will  promote  SDL.  This proposition is presented based on a philosophical analysis of the conceptions of  assessment  and  metacognitive  awareness  considering  the  theory  of  an epistemology of engagement. In closing, a framework is offered that can serve as  a  model  for  exploring  metacognition  and  SDL  in  assessment  practices, where assessment serves as an epistemological tool.

## Introduction

Several new practices of innovative applications of assessment have recently emerged,  including  the  use  of  videoconferencing  and  the  availability  of classroom websites. In addition, lecturers and students, in many cases, rely (perhaps now more than ever) on their own resourcefulness and materials to support and enhance learning experiences. With the hope of returning soon to what some call the 'new normal', the after-effects of rethinking assessment towards a sustainable form of education remain. However, amidst this need, an  online  Google  Scholar  search  for  available  publications  on  assessment practices  in  higher  education  produced  only  55  available  references  when limited  to  the  keywords  'problem-based  learning',  'self-directed  learning', 'metacognitive  awareness',  'higher  education'  and  'teacher  preparation' (Google  Scholar  2020a).  When  this  search  was  further  refined  to  recent publications of the past five years (between 2015 and 2020), the research results listed only 32 citations (Google Scholar 2020b). These results indicate the  limited  access  to  and  scarce  availability  of  innovative  applications  of assessment  practices  to  promote  SDL  towards  a  pedagogy  of  hope  for sustainable education.

Access for lecturers and students who are in search of literature reporting on the conditions and conduct of assessment practices that focus specifically on the facilitation of metacognitive awareness and the promotion of SDL is therefore limited. In this chapter, the author aims to narrow this gap in the literature by proposing a framework that could position assessment on an epistemological level, theoretically argued, in terms of the various conditions that  an  assessment  task  should  meet  in  order  to  facilitate  metacognitive

awareness and promote SDL. In this  way,  assessment  can  be  seen  as  an epistemological  tool  that  serves  as  a  knowledge  level  developed  by  the increase  of personal  engagement  with  reality,  which  occurs  through reflection  on  ideas  that  emerge  as  a  result  of  the  engagement  with  the assessment task.

Although there are many online access and source materials that can be used  to  conduct  assessment  (e.g.  see  Roberts  2019),  the  literature  search shows a scarcity in the field, as there are only a few publications with a focus on  SDL,  which  is  regarded  as  an  international  education  imperative.  This scarcity highlights the need for a framework and discussion that can assist educators  in  determining  important  aspects  of  assessment  and  learning, including a need for explanations on how to facilitate metacognitive awareness, which  emphasises  skills  such  as  planning,  monitoring  and  evaluation.  In essence, a framework is needed to offer guidance in terms of how students and lecturers should engage with the assessment process. This also requires a discussion  on  the  promotion  of  SDL  for  assessment  as  considered  from Knowles' (1975) important guiding principles for SDL. This chapter therefore holds the proposition that assessment opportunities must abide by a series of epistemological conditions. In the discussions that follow, three arguments are aligned to serve as epistemological tiers that structure the proposition. Firstly, in the conceptual framework, an overview of connections between the metacognition and SDL literature, both historical and practical, is provided. Secondly, in the theoretical framework, a discussion is offered on Brinck and Liljenfors (2013) theoretical tiers of metacognitive awareness. These conditions, in theory, explain the set conditions of when and how the student and the lecturer should engage with the assessment processes in such a way that the assessment can serve as a tool to facilitate metacognitive awareness towards  promoting  SDL.  Lastly,  in  the  philosophical  analysis  through  an 'epistemology  of  engagement'  and  its  implications  for  the  psychology  of metacognition, particularly in terms of the levels of metacognitive awareness, the argument is made to support the meta-theory that metacognition needs to be facilitated to promote student self-direction.

## Setting of the context

In  higher  education,  the  assumption  is  that  students  do  and  will  take responsibility for their learning. In a study by Chatzipanteli, Grammatikopoulos and Gregoriadis (2014), for instance, research indicated that it was necessary to enhance students' metacognitive awareness of the meta-level skills needed to  deepen  the  learning  experience.  As  a  consequence,  knowledge  transfer and critical thinking skills can then accumulate when students who exhibit metacognitive awareness by planning, monitoring and evaluating their work are enabled to improve their academic performance (Chekwa et al. 2015).

Internationally, the undertaking to move away from outmoded transmissivetype  teaching  approaches  towards  a  holistic  education  approach  (Miller 2000) promotes the idea that students learn how to learn and, in doing so, they  develop  self-reflective  problem-solving  skills  which  encourage  their pliability  and  adaptability.  Also,  teachers  encourage  such  thinking  about thinking practices in the classroom by modelling this behaviour, directing the self  in  learning  (Du  Toit-Brits  &amp;  Van  Zyl  2017).  In  contrast,  Roberts  (2019) reports that teaching styles in South Africa are outdated and do not sufficiently equip students for the future. Regarding the unpredicted worldwide pandemic in 2020, Egenti and Okoli (2020) point out that most teachers are now being forced to unlearn the ways they have always used for teaching and assessing, and this challenges much of the rooted beliefs held in their education.

## The ontology of assessment

Questioning can serve as a type of ontology-based assessment technique (as shown in Table 6.1). Ontologies describe the main concepts or content on which the assessment task is based and can be used in assessment tasks (Gavrilova  2003).  An  ontology-based  assessment  approach,  therefore, provides  a  way  to  deal  with  students'  evaluations  of  their  learning  and proposes  that  students  show  their  understanding,  knowledge  and  skills whilst constructing individual ontologies (or beliefs about learning). Such a method  of  assessment  gives  preferences  over  conventional,  traditional assessment  methods,  when  compared  to  techniques  such  as  tests  and quizzes  (Leshcheva,  Gorovaya  &amp;  Leshchev  2010).  According  to  Gavrilova (2003), ontology can be defined as a hierarchy of organised experiences or qualities that describe a domain, environment or context. Terms associated with the context of learning are often found in problem-based assessments (e.g.  word  problems,  project-based  learning  activities  or  problem-centred approaches)  which  provide  details  concerning  the  physical,  personal  and

TABLE 6.1: Conceptualisation of assessment practice.

| Assessment components as elements of the proposition                | Assessment components as elements of the proposition                            |
|---------------------------------------------------------------------|---------------------------------------------------------------------------------|
| Conception of assessment                                            | Purpose and functions of assessment                                             |
| What are lecturers' perceptions of the curriculum?                  | How does assessment serve as a tool to improve  teaching?                       |
| What are lecturers' beliefs about teaching and  learning processes? | How does assessment serve as a tool to improve  learning?                       |
| What are lecturers' beliefs about students?                         | How is assessment driven by the school or faculty for  accountability purposes? |
| What are lecturers' beliefs about professional  self-efficacy?      | How is assessment driven by the student for  accountability purposes?           |
|                                                                     | How is assessment driven by the lecturer for  accountability purposes?          |

Source : Inspired by Wang's (2019) framework of conceptions of assessment.

cognitive  space.  One  example  of  such  spaces  is  the  use  of  indigenous knowledge  in  the  classroom,  where  the  indigenous  practice  or  artefacts (e.g.  indigenous  board  games)  or  virtual  realities  such  as  laboratories  or cultural and heritage museums serve as ontological tools to mimic or (re) create the space, environment or context for learning which represents the particular  ontology.  Ontologies  can  therefore  serve  as  useful  structuring tools that draw upon the imaginative faculty of the lecturer and student to visualise and mentally create a model of the ontology of the task - a sort of hyper-space or domain of knowledge (also called a 'locale'). Ontology design is therefore also regarded as useful and may be considered a condition of the assessment  task.  Reflecting  on,  thinking  about  and  mentally  visiting  this locale requires higher-order meta-level thinking on a meta-level, which Jagals (2015) refers to as the 'metacognitive locale'.

In order to draw assessment, metacognitive awareness and SDL together -advocating  the use of assessment  to enhance  SDL  and metacognition, the association between epistemology and assessment needs to be clarified. First, epistemology can be defined as a philosophical theory of what knowledge is (Gavrilova 2003). Pedagogy may, in part, be seen as a form  or  type  of  educational  epistemology,  or  the  science  of  imparting knowledge to students. However, this relationship between epistemological concepts such as pedagogy and assessment is a topic seldom of educational debate (Leshcheva et al. 2010). The chapter therefore sets out to reason that assessment can serve as an epistemological tool that facilitates metacognitive awareness and promotes SDL. The remainder of this chapter is structured as follows to develop this framework of thinking and to motivate and support the proposition following this methodology:

- 1. An examination of the concepts of assessment, metacognition and SDL to anchor the entire proposition and form the basis on which a conceptualtheoretical framework can be built to support and explain the proposition (see Figure 6.1).
- 2.  Key components of the three concepts are explored, in particular as ways by which they can emerge in research as codes or themes (or elements of the proposition) (see Table 6.1).
- 3.  A review of related literature is offered to determine how scholars addressed these key components and to identify any underlying assumptions.
- 4.  A list of key concepts as constructs and variables relevant to the proposition have been arranged across the sections that follow, specifically to illustrate the different components of the concepts of assessment, metacognitive awareness and SDL.
- 5.  The  relevant  theory  concerning  the  tiers  of  metacognitive  awareness provides  an  understanding  of  the  implicit,  perceptual  and  metarepresentational levels of metacognitive awareness.

- 6.  The assumptions are then discussed in the philosophical analysis section of  this  chapter  following  Heyns'  (2006)  theory  of  an  epistemology  of engagement,  from  which  a  set  of  beliefs  is  formed  about  the  task  of assessment. Ultimately, such beliefs evolve into an implicit, perceptual and metarepresentational  metacognitive  awareness.  This  awareness,  in  turn, shapes  the  personal  epistemology,  which  is  discussed  next.  Thereby, facilitating metacognitive awareness and the SDL capacities needed in the 21st  century,  future  learning  and  lifelong  learning  towards  sustainable education could be enabled.

## Conceptual framework

There  is  a  perceived  role  that  students  are  accountable  for  the  learning process, and that assessment should take priority in this regard. The relationship between assessment and metacognition is, however, scarcely reported on in the literature on education because the initial search results (Google Scholar 2000a; Google Scholar 2000b) show few attempts in addressing this in higher education contexts. The work by Wang (2019) highlights assessment literacy as a guiding factor in determining the conception of assessment. Wang reports a  framework  of  conceptions  of  assessment,  which  will  contextualise  the discussion that follows. Furthermore,  the literature review suggests  a noteworthy  relationship  between  metacognitive  awareness  and  student academic achievement (e.g. Erlin, Rahmat &amp; Rejeki 2020).

## Assessment and assessment literacy

Assessment is usually depicted as a cyclical model that involves (1) a gathering of  information  about  students'  learning,  (2)  an  analysis  of  this  collected information,  (3)  interpreting  the  analysed  information,  (4)  recording  the interpreted information, (5) reporting on the recorded information, and (6) using the interpretations to enhance future learning. This process typically involves  a  number  of  infiltrating  principles  that  guide  the  degree  of  the assessment practice and include principles such as reliability, validity, fairness, meaningfulness, transparency, balance, bias, cognitive complexity, generalisation, feasibility and accountability. However, Wang's (2019) framework of the conceptions of assessment presents two major components of  assessment  as  (1)  conceptions  of  assessment  and  (2)  the  purpose  and functions of assessment, relating to these conceptions.

In essence, assessment purposes and functions define assessment in terms of  the  tools  it  offers  to  improve  teaching  and  learning  (Lam  2020).  As assessment  is  driven  by  the  faculty  for  accountability  purposes,  it  is  also driven  by  the  students,  and  so,  lecturers  also  hold  accountability  to  the different stakeholders in the assessment process (Wang 2019). The conceptions

that are held regarding these purposes and functions relate to the lecturers' perception of the curriculum being implemented and their epistemological beliefs concerning  teaching  and  learning  (Wang  2019).  Based  on  the conceptualisation of assessment in this section, the following list of questions, as inspired by Wang's (2019:157) framework, can serve as codes or themes (of underlying propositions) for exploring assessment practice.

## The agenda of assessment

Two decades ago, there was a notion that true assessment transformation in policy and practice could only occur when the curriculum reformed in the same direction (Lam 2020). First, a closer look at how assessment can be conceptualised. Today's education system can be regarded as the result of the industrial revolution (Pillay 2020), which organises students' developing skills and forthcoming careers that require much more unified ways of thinking. However,  education  takes  place  when  new  knowledge  emerges  through encounters  with  challenges  in  everyday  life  (Wheeler,  Waite  &amp;  Bromfield 2002). The curriculum should therefore emphasise the teaching of skills that develop a personal epistemology, one that holds education and its assessment as a cultivating practice.

## Aspects of assessment literacy

Numerous studies have reported on the various principles of planning and conducting assessment (see for instance Price et al. 2012). Recent literature by Khani (2020), however, suggests that teachers' cognition and practices of assessment are not congruent with the principles of assessment. Some studies (e.g. Lian &amp; Yew 2020) have reported on the various psychometric properties of assessment literacy to be at the heart of this problem. Assessment literacy refers to an individual's (either a student or lecturer's) understanding of the essential concepts or the procedures and approaches of assessment (InbarLourie &amp; Levi 2020). This includes the assessor's competency in selecting an appropriate  assessment  method.  Lian  and  Yew  (2020)  indicate  in  their framework  the  characteristics  of  assessment  literacy:  (1)  unistructural,  (2) multistructural, and (3) relational levels of the task.

Lian and Yew (2020) explain the levels as follows: the unistructural level requires the response to the assessment task to directly refer to a piece of concrete  information  or  factual  knowledge  in  the  task.  This  involves  the understanding of the envisioned educational or learning outcome. After such engagement,  in  response  to  the  task,  concrete,  abstract  and  relevant information  provided  in  and  by  the  task  can  be  focused  on  to  identify  a learning outcome. On the multistructural level , the task requires this specified information to be applied in a specific order. That is, the student needs to

determine the outcomes and categorise the learning needs where the task information  can  be  applied.  However,  on  the relational  level, the  task necessitates an amalgamation of all given information to make a decision. The assessor has to consider all the information provided to determine the most appropriate assessment method. It is also possible that the three levels can be combined in a single task; however, this then requires different levels of its application.

## Conceptualising assessment in terms of metacognition

Awareness of one's thinking and knowledge of the cognitive processes (or metacognitive knowledge) seem to play a vital role in the conception of assessment indicated in Wang's (2019) framework. It appears from studies such as those by Siegesmund (2017) that the understanding of metacognition for learning involves an understanding of assessment and relates  to  assessment  literacy  levels  identified  by  Lian  and  Yew  (2020). Examples of assessment practices that employ metacognitive awareness include guided participation as a form of apprenticeship teaching towards autonomy, self-assessment practices and authentic assessment practices that  utilise  real-life  situations  and  typically  involve  problem-based  or project-based learning initiatives - all of which align with productive and frequent feedback. Wang (2019) also mentions feedback that can serve as a metacognitive tool when being indorsed by self-assessment scripts and rubrics along with modelling.

## Facilitating metacognitive awareness

Flavell (1979) posits that metacognition is simply described as the process of the awareness of thinking. Reflecting on text for comprehension and scrutiny aimed at the purpose of academic achievement seem to be at the heart of the assessment process (Lam 2020); yet, the assessor's (as teacher or lecturer) beliefs  and  own  cognition  can  either  advance  or  impede  students'  beliefs about  themselves  and  their  cognitive  development  in  the  assessment  and awareness of the task at hand (Siegesmund 2017).

Metacognitive processes function on the meta-level of cognition. Whereas cognition refers to the object level, metacognition refers to the reflected and accumulated  knowledge  (or  awareness)  on  the  meta-level  (Jagals  2015). Metacognition is often associated with the dimensions on the meta-level, as illustrated by Flavell (1979) regarding metacognitive knowledge in addition to  metacognitive  experiences,  and  Brown's  (1987)  study  concerning  the dimension  of  metacognitive  regulation  or  self-regulation.  The  knowledge one develops and constructs based on the reflection of the metacognitive

knowledge, experiences and regulation processes is generally referred to as 'metacognitive awareness' (Efklides 2011).

## Awareness of metacognitive knowledge

Reflection on one's metacognitive knowledge occurs before, during and after cognitive  strategies  have  been  employed  (Jagals  2018).  This  process  of awareness occurs consciously and deliberately when the teaching-learning content  and  the  knowledge  about  the  thinking  processes  involved  in  that process  coincide.  This  refers  to  the  person,  task  and  strategy  knowledge represented in the unseen intangible thoughts about one's own capacities. The  act  of  reflecting  on  this  knowledge  ignites  the  interaction  between metacognitive  knowledge  and  the  regulation  of  this  knowledge,  such  that meta-level  awareness  oversees  the  understanding  and  application  of  the teaching-learning  content  (Jagals  2018).  Based  on  this  understanding,  it seems that deciding on an appropriate assessment strategy, the lecturer must think about similar tasks, reflect on the task and strategies and anticipate the development of this awareness.

As  indicated  by  Dunlosky  and  Kane  (2007),  metacognitive  awareness assists  in  the  learning  process  as  a  beneficial  motivation  in  the  learning experience. This form of mindfulness supports the learning process situated between one's capacities to be aware of own qualities and shortcomings and the feelings and emotions that accompany the learning experience.

Declarative knowledge responds to what information with respect to one's own understanding one becomes aware of (Jagals 2015). At the point when students  self-reflect on  their comprehension  of  a  specific task, they additionally become aware of the specific parts of the task that they discover to be simpler or more difficult to comprehend (Jagals 2018). The student at this point develops this contingent form of knowledge by focusing on either familiar and useful information (or information of oneself), task information or the system/processes  information  required  (Setlhodi 2019). Where metacognitive awareness creates opportunities to contemplate (Jagals 2018), students often either underestimate or overestimate their understanding and application of their knowledge and skills. Likewise, his misconception of selfknowledge appears to have an impact on the quality of the measures taken to assess metacognitive learning. This is regularly found in quantitative results whereby  self-reports  on  a  Likert-type  scale  are  meant  to  report  on  own metacognitive awareness, which forms, in turn, their own epistemology of learning (e.g. Siegesmund 2017).

Procedural knowledge refers to how one sees the assignment or task and thinks about the procedures underlying the task's content (Jagals 2015). This could be, for example, what length of time will be spent on completing the

task, what sort of appraisal openings ought to follow and what procedures or strategies  would  be  suitable  for  this  particular  assignment.  Furthermore, understanding the underlying systems, for example, different procedures and philosophies  associated  with  the  assessment  task  can  be  evaluated  to determine  what  specific  difficulties  are  to  be  expected  (Ramanarayanan, Evanini &amp; Tsuprun 2019).

Conditional knowledge alludes to the specific conditions where one's very own usefulness for utilising metacognitive systems can be applied. Students who are aware of the approaches they follow to solve a task are empowered to  reflect  on  these  strategies.  They  then  become  aware  of  the  conditions under which particular strategies or approaches to the task work in a way that is better than others. Efklides (2011) alludes to this awareness as the cycle of memory checking and self-guideline.

## Awareness of metacognitive regulation

Metacognitive  regulation  involves  the  actions  that  arise  from  the  intentional thinking  of  metacognitive  knowledge  and  serves  as  an  informed  and  goaldirected process to control one's thinking (Flavell 1979). Lecturers who are aware of their students' thinking are able to predict suitable assessment strategies that will promote the students' SDL (Pillay 2020). Metacognitive regulation comprises the monitoring and controlling of students' cognition (Erlin et al. 2020). Three distinctive metacognitive processes of self-regulation are present during assessment, namely planning, monitoring and evaluation. Metacognitive regulation raises awareness of the underlying practices to plan, predict, monitor and evaluate this thinking (Siegesmund 2017).

Siegesmund (2017) presents a model of metacognitive regulation of the self and  argues that self-questioning brings about metacognitive awareness. Siegesmund's (2017) model illustrates that the process of self-regulation requires the student to (first) self-assess by asking self-questions (e.g. What should I do differently next time? ), followed by a focus on task-assessment (e.g. What about this task do I already know? ).  This  process of self-assessment and task-assessment raises  the  awareness  of  metacognitive  knowledge.  Wang  (2019)  also  acknowledges this as the metacognitive component of cognitive knowledge in the assessment framework.  According  to  Siegesmund's  model,  the  next  two  steps  require planning and monitoring. The student plans (e.g. What steps will I take to solve this problem? ) and monitors ( What strategies that I have used are assisting me to complete the task? ) his or her thinking.

Planning embraces the setting and formulation of learning objectives. This requires,  in  turn,  a  reflective  process  to  bring  to  mind  an  awareness  of declarative,  conditional  and  procedural  metacognitive  knowledge.  When monitoring this process and their understanding thereof, students can make

changes  to  the  strategies  they  employ  for  learning,  as  well  as  revisit  the knowledge they have. This is followed by the student's self-evaluation (or selfassessment) concerning the effectiveness of the learning strategy. The student evaluates, that is, asks questions such as the following: What is required from me? or What knowledge or skills can I use to complete this task?

Interestingly, Flavell (1979) introduced the term 'metacognition' to the field of educational and cognitive psychology during the same decade that Knowles (1975) published his work on SDL. Even so, the theories involving these two concepts have developed alongside each other, often in different strands of teaching and learning philosophy.

## Self-directed learning in assessment

In  this  section,  SDL  refers  to  the  vital  features  of  a  critical,  rather  than mechanical or technical interpretation of the extent of learning and includes: (1)  self-direction  as  a  constant  deliberate  and  continuous  process  to  take personal control over learning decisions and (2) self-direction as the capacity to identify and access appropriate resources (Brookfield 2020).

Pillay (2020) raises the concern that South African school curricula do not  encourage  the  necessary  teaching  and  learning  activities  that  allow students  to  develop  much-needed  SDL  skills.  Once  these  students  have completed their secondary school studies and enrol at universities, they are not familiar with SDL activities in tertiary education. Du Toit-Brits and Van Zyl  (2017)  further  explain  a  discrepancy  between  the  students'  and  the lecturer's views on SDL. Often, the lecturer sees SDL as a holistic learning process, whilst the students hold a different mindset that pertains to SRL instead  of  reflective  learning  practices,  which  pertain  to  metacognitive awareness and SDL. There is, however, value in pacing SDL (Setlhodi 2019). In Pillay's study, for instance, a lack of critical reflective skills indicates an absence of self-directedness.

Lam (2020) shows that schools that focus on a product-type education, where knowledge production is seen as an end result of schooling, emphasise writing  processes  for  self-reflection.  Also,  Lam  (2020)  suggests  that  selfreflection is essential in empowering students to become less dependent on feedback  obtained  from  the  lecturer,  as  assessment  opportunities  that promote  SDL  offer  less  lecturer-driven  feedback  and  require  more  selfreflection.

Educationists,  teachers  and  researchers  often  experience  doubt  with regard to assessment, and not all lecturers and students are necessarily aware of the variety of accessible assessment approaches, particularly those that promote  SDL.  Those  who  are  aware  of  it  have  difficulty  in  selecting  an appropriate assessment approach (Roberts 2019). Van Hout-Wolters (2000)

distinguishes  between  four  types  of  goals  to  keep  in  mind  when  planning assessment practices: (1) diagnostic evaluation, (2) formative evaluation, (3) summative evaluation, and (4) non-evaluative assessment.

These  types  of  evaluation  should  not  be  interpreted  as  metacognitive evaluation, which is why these types of evaluations have been edited to refer directly to the particular assessment types:

- 1. Diagnostic  assessment refers  to  the  obtaining  of  information  about the  strong  and  weak  points  of  the  student's  learning  skills  (to  gather knowledge about the person) before the learning activity. The assessor can here determine what students' identified learning needs are, for instance, and in so doing kindle the process of SDL. This could lead to a discussion or self-developed and negotiated (between lecturer and student) framework towards  reaching  the  set  objectives.  Through  this  diagnostic  process, individual  students  can  benefit  from  personal  and  adaptive  learning environments for an individual, school or class level.
- 2. Formative assessment refers to the testing of progress made and involves a  process  where  the  goal  is  to  occasionally  collect  evidence during the lesson and then give feedback to the students, with some guidance on how the process can be personalised or adapted. In this assessment type, SDL can be promoted by monitoring the development of the learning process through self-reflection, self-report, reflective writing in cooperative learning settings or peer assessment.
- 3. Summative assessment occurs at the end of the learning experience or task to determine to what extent the identified objectives have been reached as a form of final testing. In the author's opinion, this is where most traditional approaches to assessment in higher education are focused - assessing for marks, and seems as if it is anticipated and expected by students (e.g. Lam 2020; Roberts 2019).
- 4. Non-evaluative assessment occurs without conclusion or judgement and serves to assess learning skills only for the purpose of recording it as a form of non-evaluative assessment. As this type of assessment does not count towards final grading in terms of test points or marks, students often underestimate its value for promoting SDL. The focus is on gaining insight into distinct learning skills and can take place before, during or after the learning activity.

## Theoretical orientation

Joksimovic  et  al.  (2019)  show  that  metacognitive  awareness  can  promote reflective  states  of  consciousness.  Their  study  builds  on  the  assumption concerning  how  metacognitive  knowledge  shapes  this  awareness  of  own cognitive processes and how one understands, manages or regulates these processes in  order  to  enhance  learning.  The  work  by  Brinck  and  Liljenfors

(2013) offers a theoretical perspective on metacognition. The authors explain that metacognitive awareness develops across three stages or metacognitive tiers, including (1) implicit experimental awareness, (2) perceptual awareness, and (3 metarepresentational awareness.

## Awareness on an implicit level

Approaches to an assessment task require skills such as arranging outcomes and information, observing the needed strategies to implement and assessing the application thereof (Flavell 1979). When a student becomes aware of these skills,  this  new  information  becomes  self-related  (Efklides  2009).  Efklides (2011)  proposes  that  learning  environments  help  with  creating  different sources  of  inspiration,  and  these  encounters  can  intuitively  influence  the awareness of other related thoughts, for example, expectations, convictions and perspectives (Pratt &amp; Collins 2000). Through involvement in such selfreflection,  awareness  is  encouraged  with  respect  to  the  expectations  for educating and learning, for example, what system, strategies or knowledge will best suit the assessment of task A, and what perspectives with respect to a specific theme will be constructed based on this approach or assessment method.

## Awareness on a perceptual level

The level of perceptual awareness includes the support of the metacognitive faculty of metacognitive awareness of feeling and thinking (Efklides 2011). In such  cases,  students  may  wonder  what  the  reason  is  for  completing  a particular task. Or they may wonder what the reason is for utilising a specific assessment technique, or whether it is relevant. Perceptual awareness can, for  instance,  serve  as  an  exceptional  and  personal  reflection  on  the  deep commitment between the student as future teacher and his or her realisation of the calling as a teacher (Proust 2013). On this level of awareness, educating and  learning  experiences  are  scrutinised  through  a  personal  search  for meaning.

## Awareness as a metarepresentation

Proust  (2013)  sees  metarepresentational  awareness  as  any  representation or  expression  that  alludes  to  both  the  substance  of  educating  (e.g.  the subject  or  educational  programme)  and  a  pertinent  assessment  method. Metarepresentational awareness can be viewed as a third or elevated type of awareness,  as  it  overarches  the  influences  of  cognition  and  metacognitive knowledge  and  regulation.  Together,  the  three  levels  of  metacognitive awareness can create a profound and individual incentive to the instructing and learning encounters and educate the advancement regarding a

hypothetical direction towards  understanding  the  estimation  of workincorporated  learning  for  proficient  educator  improvement  programmes  in open separation learning.

## Philosophical analysis

Self-directed students have a sense of personal agency about their learning (Siegesmund  2017).  Initially, in the conceptual  framework,  assessment practices were conceptualised according to the framework of conceptions of assessment (Wang 2019) and SDL, and then aligned with Brinck and Liljenfors' (2013) levels of metacognitive awareness as theoretical lens. Understanding metacognition  from  this  review,  along  with  its  knowledge  and  regulatory processes, offers an understanding of assessment across multiple conceptions. The work by South African authors, including that of Setlhodi (2019) and Du Toit-Brits  and  Van  Zyl  (2017),  seems  to  support  the  claims  made  that assessment and metacognitive awareness can promote SDL.

At  this  point,  the  author  wants  to  direct  the  reader's  attention  to  the philosophical underpinnings involving metacognitive awareness for SDL, with particular reference to the self in learning. This is because both metacognition and SDL have their roots in the underlying approaches to the ontology and epistemology  of  assessment  practices  (Proust  2013).  In  particular,  such  a philosophy provides the methodological principles by which assessment can be understood and by which it can serve as a component of engagement.

The  proposition  made  in  this  chapter  is  oriented  by  the  theory  of engagement (Heyns 2006) that serves as a metatheoretical lens to interpret and  understand  assessment  as  an  epistemological  tool.  This  involves  an understanding  of  the  application  of  assessment  practices  and  theory,  in other words, assessment literacy (e.g. what practices are suitable to conduct assessment)  and  includes  the  understanding  of  emerging  thoughts  in terms of affective experiences, the intentions, beliefs and attitudes towards assessment  practice  that  shape  the  perspective  and  reflections  on  this practice that inform a change in regulation (i.e. planning, monitoring and evaluation). After this orientation, the conceptual overlaps amongst assessment,  metacognitive  awareness  and  SDL  have  been  explored  by means of the theoretical framework, which then serves as the conceptualtheoretical framework that contextualises the underlying argument of the proposition.

Representational epistemology (Heyns 2006) refers to the process whereby a foundational idea (e.g. the content of a task) can be reflected upon to attain in  the  mind  an  exact  representation  of  that  idea.  In  this  sense,  the  act  of reflecting serves as the engagement with a task that generates a personal epistemology  of  how  both  the  content  of  the  task  and  the  task  itself  will

be  assessed.  An  argument  put  forward  by  Heyns  (2006)  concerning  such reflection  refers  to  the  theory  of  an  epistemology  of  engagement.  Heyns (2006) explains that engagement takes place in a series of eight conditions, summarised  in  Table  6.2  and  is  aligned  with  the  levels  of  metacognitive awareness as identified by Brinck and Liljenfors (2013).

Heyns (2006:75) explains the first condition as the gathering of 'foundational precepts or ideas about things and then build a representation from these building blocks'. When students engage with a task, they do so by reflecting on the instructions provided by the lecturer, as well as their own ideas about the  requirements  of  the  task.  Through  such  engagement,  they  build  a representation in that they become aware of their knowledge about the task, person and strategy. This epistemological engagement, it seems, facilitates implicit experiential awareness of metacognitive knowledge and metacognitive regulation  skills  because  of  the  conditions  of  the  task  that  serves  as  an epistemological tool.

Through such reflective engagement, a second condition is set in that the task itself must become a focal point in the learning process. In this sense, the  student  plans,  monitors  and  evaluates  the  ideas  on  the  task  and,  at the same time, becomes aware of the affective experience in learning, in that the  task  may  be  enjoyable  or  frustrating.  An  example  that  Strawderman (2009)  draws  on  to  explain  this  is  the  student's  awareness  of  his  or  her confidence (or lack thereof) to complete a task.

TABLE 6.2: Conditions of an epistemology of engagement in relation to the levels of metacognitive awareness.

| Conditions of an epistemology of engagement                                                                                                                                                                                  | Level of metacognitive awareness                                                                                    |
|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|
| 1. 'All knowledge is a perspective determined by our interest, aims  and beliefs'. (p. 79) 2. 'The aim of knowing is to engage with the multitude of aspects of  reality that are knowable and are thus engageable'. (p. 81) | Implicit experiential awareness to  facilitate awareness of metacognitive  knowledge and metacognitive  regulation. |
| 3. 'Representations and perspectives fundamentally or in principle  are in contact with reality'. (p. 84) 4. 'Knowing or finding truth about reality is important because we                                                 | Perceptual awareness to promote                                                                                     |
| are embedded in a reality that crucially influences our functioning  in it'. (p. 87) 5. 'The fundamental embeddedness of the self in the world  assumes a structure for human abilities and reality that enables and         | self-directed learning.                                                                                             |
| necessitates engagement'. (p. 88)                                                                                                                                                                                            |                                                                                                                     |
| 6. 'Knowledge comes into being in the act of engagement between  knower and known'. (p. 91) 7. 'Interaction between my abilities to engage with reality and the                                                              | Metarepresentational awareness to  transcend learning from the task to a  personal epistemology of self.            |

Source : Author's alteration from Heyns (2006) and Brinck and Liljenfors (2013).

The  third  condition  set  by  Heyns  (2006)  employs  the  notion  that  the student  has  reflectively  engaged  with  the  task,  and  his  or  her  implicit awareness, to the point where mental representations or ideas of the task are being  perceived  as  related  to  other  perceptions  or  ideas.  Strawderman's (2009) model shows that students associate their affective and meta-affective experiences to the origins of the idea. For instance, they will typically recall a family member or friend helping them with a similar task or point out their own success at attempts with related tasks in the past. This, as the fourth condition  implies,  affects  future  engagement  with  the  task,  as  affective experience with the task facilitates awareness of the metacognitive processes (such as knowledge and skills).

Based on the perception as facilitated by engagement with the task, the fifth condition suggests that the student develops an epistemological belief (or  representation)  of  awareness  of  the  self,  which  needs  to  be  directed towards the aim of the task. Here, Knowles' (1975) process characteristically calls for a step to take the initiative with or without the assistance of others (such as peers, family members or lecturers) in diagnosing learning needs. This, theoretically at least, implies that the facilitation of perceptual metacognitive awareness promotes SDL.

Thereafter, the sixth condition calls for metacognitive knowledge to assist in formulating learning goals through planning, monitoring and evaluating the person,  task  and  strategy  knowledge.  This  indirectly  implies  an  'ongoing process of interaction between my abilities to engage with reality and the object of knowing that stimulates my abilities of knowing' (Heyns 2006:93) through identifying what perceived 'forms of human and material resources for learning' and what the 'appropriate learning strategies' (Knowles 1975:18) are.

Heyns' (2006) eighth condition suggests an overall metarepresentation of the  processes  of  metacognitive  awareness  to  instil  an  evaluation  of  the attainment of the learning outcomes. To this extent, the levels of metacognitive awareness can produce a personal epistemology of engagement. From this reasoning, the author aligns himself with this theoretical orientation to extend the argument further with the key concepts to model a conceptual-theoretical framework, which is discussed next.

The  meta-level  refers  to  the  higher-order  (or  metacognitive)  processes involved.  Efklides  (2011)  refers  to  these  processes  as  the  meta-affective domains.  Students  then  act  upon  the  task  by  determining  what  the  task requires from them (as a form of declarative knowledge). They then plan how they will acquire the necessary knowledge and skills, monitor whether they comprehend this knowledge and determine under what conditions (conditional knowledge)  and  with  what  procedures  this  knowledge  can  be  applied (procedural  knowledge).  This  is  followed  by  evaluating  the  constructed

<!-- image -->

Source : Adapted by the author with permission from Funk (2001).

or co-constructed knowledge and skills, which can be reflected upon as selfknowledge. It is possible, however, that declarative, conditional and procedural knowledge (as forms of metacognitive knowledge) can exist before, during and  after  any  metacognitive  regulation,  that  is,  planning,  monitoring  or evaluating.  On  the  meta-level,  this  process  of  thinking  and  responding  to thoughts can facilitate metacognitive awareness as a form of self-knowledge (source) and establish personal beliefs, opinions and certainties that shape the individual's epistemology. This epistemology then acts as a knowledge tool created by the engagement with assessment and informs future engagement, as shown in Figure 6.1.

## The self in assessment

Figure 6.1 is adapted, for the purpose of this chapter, with permission obtained from its original author, Funk (2001). A set of beliefs is formed about the task that is assessed, and this influences the students' perception of and thinking about the task. Ultimately, such beliefs evolve into implicit, perceptual and

metarepresentational  metacognitive  awareness.  This  awareness,  in  turn, shapes the personal epistemology, discussed next.

Figure 6.1 illustrates a dynamic and iterative process of self-direction, as conceptualised  for  the  purpose  of  this  chapter.  The  process  involves engagement with the task being assessed and suggests the task itself is presented in a way that will introduce familiarity with its ontology. On the object  level,  this  familiarity  serves  as  a  form  of  knowledge  that  can  be acquired by promoting students' thoughts about the affective, perceptual and regulatory behaviour needed to complete the task. The object level draws on the ontological elements of SDL (e.g. engagement, thinking and acting). These are the elements that one can become aware of or use as cognitive (or ontological) tools. This suggests that the task, the thinking processes and the behaviour acted on when engaging with the task can all be reflected upon to answer the question of 'what is', as in: What is the task requiring from me? What strategies do I need? What plan of action should I follow? These example questions illustrate the need for reflection on the nature of the task.  To  elaborate  on  the  nature  of  the  task,  the  reader  is guided  by  the  following  brief  discussion  of  the  role  of  ontology  in assessment.

## The use of assessment as an epistemological tool

In the ensuing discussion, the author now draws assessment, metacognition and SDL together -  advocating  the  use  of  assessment  to  facilitate  metacognitive awareness and promote SDL. This discussion therefore relies on the above conception as illustrated in Figure 6.1.

In order for assessment to serve as an epistemological tool that facilitates metacognitive  awareness  and  promotes  SDL,  the  framework  by  Heyns' (2006) epistemology of engagement (see Table 6.2) needs to be followed. According to the interpretation of Table 6.2, Condition 1 suggests that an ontological space should be provided through an ontological design. This will establish the perspective (e.g. interests, aims and beliefs - Heyns 2006). Along  with  this  condition,  Condition  2  suggests  that  engaging  with  this ontological design, the student will become implicitly aware of the knowledge and regulation skills they have about the various aspects of reality that this engagement  brings  to  mind.  This  implicit  experiential  awareness  of  the knowledge of the task, strategies and skills on either a conditional, procedural or  declarative  level  can  advocate  them  to  take  the  initiative  to  use  the feedback from diagnostic assessment. In turn, the diagnostic assessment can  promote  thinking  about  identified  learning  needs  and  the  required learning  resources.  This  can  occur  with  or  without  the  help  of  others (Knowles 1975).

Condition 3 requires representations and perspectives about this ontological design (or task) along with Condition 4's truth-finding about the task - that is: What knowledge is embedded in the task that relates to own experiences? In addition, Condition 5 requires a reflection on what self-knowledge and skills this task requires from the student - and how the knowledge relates to the use or application of particular task-related skills. Because these three conditions facilitate perceptual  awareness,  the  assessment  practice  further  fosters opportunities  to  formulate  learning  objectives  and  identifying  human  and material resources for future learning.

Metarepresentational awareness transcends the learning experience from these perceptions that developed up to Condition 5. In Condition 6, knowledge is  constructed  through  engagement  with  the  existing  pre-knowledge  and skills and that which is familiar about the assessment task. Such engagement can then stimulate the capacity to plan, monitor and evaluate own learning, thereby directing the learning experience. This awareness then promotes the selection and the application of appropriate learning strategies in Condition 7. Once these strategies have been implemented, the student can engage with the result of these strategies, thereby determining whether the strategy they selected  fits  with  the  conditions  of  the  assessment  task.  As  a  result,  the student  can  engage  with  the  assessment  task  whilst  being  aware  of  the appropriateness  of  the  strategies,  thereby  monitoring  and  evaluating  the extent to which the learning outcome has been reached or the assessment task completed.

## Conclusion

Assessment practices in education remain a single factor to determine whether students are ready to continue on their education journey, with the learning experience  at  its  core.  The  peripheral  questions  or  choices  concerning assessment -for example, which assessment task is more suitable, what assessment strategy is best applicable to the particular task, whether the assessment projects promote SDL skills and how the task facilitates the relevant knowledge and skills for students' lifelong learning - all indicate how important SDL is for education. Besides these, there seems to be a global concern about exactly how assessment practice should take place, with such a  variety  of  principles  and  approaches  to  acknowledge  (e.g.  Khani  2020; Roberts 2019; Setlhodi 2019). It is recommended that assessment practices concentrate  on  facilitating  metacognitive  awareness.  Figure  6.1  has  been conceptualised to illustrate this view. What remains is to explore the possibilities of how students' and lecturers' metacognitive awareness of the conditions of assessment  tasks  reveal  the  nature  of  this  framework  and  to  what  extent assessment practice can assist in the advancement and understanding of the

concepts of metacognition and SDL. To some extent, assessment seems to originate  from  the  absence  of  existing  metacognitive  and  self-directed guidelines,  in  many  instances  outside  of  the  conditions  of  a  personal epistemology. How this awareness is encouraged and what role metacognitive awareness plays in such situations are also unknown. Metacognitive awareness needs to unequivocally form part of the assessment practice, and in turn, SDL can be promoted.

## Chapter 7

## Value of feedback during the implementation of the group-individual-group cooperative learning method of assessment

## Elsa Mentz

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Anitia Lubbe

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Abstract

Assessment feedback should be an integral part of learning as it provides powerful support to students and can have a positive effect on learning. This aspect of learning is, however, often neglected by educators and hence also

How to  cite: Mentz,  E.  &amp;  Lubbe,  A.,  2021,  'Value  of  feedback  during  the  implementation  of  the  groupindividual-group cooperative learning method of assessment', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 143-163, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.07

by their students. Different views and opinions of researchers on feedback complicate this matter even further. A mismatch between the perceptions of students and of educators about the purpose and usefulness of assessment feedback seems common. The researchers investigated the group-individualgroup  (GIG)  cooperative  learning method  of  assessment  (CLMoA)  to determine  whether  it  adheres  to  the  principles  of  sustainable  assessment, specifically  in  terms  of  feedback.  The  research  was  based  on  the  social constructivist learning theory. Firstly, the GIG CLMoA was evaluated in terms of  feedback  within  a  sustainable  assessment  perspective.  Thereafter,  a qualitative interpretivist methodology was used to determine the perceptions of both educator and students regarding the value of assessment feedback during the implementation of this cooperative learning (CL) method in a firstyear Life Sciences class for pre-service teachers. The results show that the GIG CLMoA adheres to most of the sustainable assessment principles, and feedback forms an integral part of the learning process as students generate their own feedback. Both the educator and the students experienced peer feedback during the GIG CLMoA as predominantly positive; however, some aspects of its implementation need to be refined.

## Introduction

According  to  Purnomo  et  al.  (2018),  there  must  be  consistency  between teaching,  learning  and  assessment.  Assessment,  specifically  assessment feedback, should form an integral part of learning, as it should enable students to reflect on, monitor and evaluate their own learning process and progress (Ferguson  2011).  Successful  assessment  feedback  is  thus  not  primarily corrective  action  by  the  educator,  but  an  action  which  allows  and  assists students  to  gain  a  thorough  understanding  of  their  own  learning  through dialogue  and  active  participation  whilst  sharing  their  learning  experiences (Archer 2010; Carless et al. 2011). Educators should actively plan for successful feedback opportunities throughout the learning process.

## Problem statement

Despite  the  value  of  assessment  feedback  emphasised  by  Deeley  et  al. (2019), feedback often does not result in improved student learning and is therefore  a  subject  of  great  concern  (Ajjawi  &amp;  Boud  2017).  Assessment feedback is one of the most debated themes in assessment discourse, and mismatching  perceptions  of  students  and  those  of  educators  about  the purpose  and  usefulness  of  assessment  feedback  are  commonly  reported (Carless &amp; Boud 2018; Pat-El et al. 2015; Van der Kleij 2019). Boud and Molloy (2013) identify two distinct models for feedback, namely educator-driven and student-driven  feedback.  In  educator-driven  feedback,  educators  are

seen  as  the  sole  providers  of  feedback,  whilst  student-driven  feedback entails students taking responsibility for their own learning and feedback. These conceptually different views explain why the views of educators and those of students about the usefulness of assessment feedback often differ. According to Evans (2013), the dissatisfaction experienced with feedback is well  reported.  Amongst  others,  students  complain  about  the  content  of feedback or that feedback is often administered too late; hence, students perceive it as no longer relevant or as unhelpful and unclear (Price et al. 2010; Sadler 2010). Educators often complain that students are mostly not concerned about feedback but only about the marks obtained (Sadler 2010). Students  therefore  do  not  act  upon  the  feedback  to  enhance  their independence in their learning. They also do not incorporate feedback into subsequent tasks.

Different views as well as different expectations about the respective roles of the educator and of the student in the feedback process contribute to the dilemma. According to Boud and Molloy (2013), research favours the rethinking of feedback as an act that involves peers and not as the sole responsibility of the educator to provide information to the student (Boud &amp; Molloy 2013). Its implementation,  especially  within  a  CL  environment  where  peers  can  fully participate,  is  challenging  (Le,  Janssen  &amp;  Wubbels  2018).  Researchers  are aware of the fact that assessment in a CL environment can be problematic. Students often complain about inadequate feedback when working cooperatively on assessment tasks (Thondhalana &amp; Belluigi 2017).

The group-individual-group cooperative learning method of assessment (GIG CLMoA) is the focus of this chapter. The researchers wanted to determine whether this method adheres to sound assessment feedback principles from a sustainable assessment  perspective  where  students,  as  self-directed learners, take responsibility for their learning and generate their own feedback effectively. The researchers also wanted to establish the perceptions of the educator  and  those  of  students  after  implementing  the  GIG  CLMoA.  The research questions, therefore, were:

- · To what extent can the GIG CLMoA contribute to sound feedback practices from a sustainable assessment perspective?
- · How do the educator and the students respectively perceive the value of feedback provided through this method of assessment?

## Theoretical and conceptual framework

The key concepts of this study discussed within the theoretical framework of social constructivism (Vygotsky 1978) are sustainable assessment, assessment feedback, CL and the GIG CLMoA.

## Social constructivist perspective

In  agreement  with  Vygotsky  (1978),  the  researchers  believe  that  learning cannot  be  separated  from  its  social  context,  as  knowledge  is  socially constructed through interaction with others.

Within  constructivist  learning  theory,  assessment  focuses  strongly  on the process of learning and feedback, which prepares students to become lifelong learners (Boud &amp; Falchikov 2007). In terms of social constructivist learning theory, learning and  assessment  are  situated  in  the  social environment  and  occur  simultaneously  during  interaction  with  other individuals  and  the  environment  (Wenger  1998).  Feedback  should  be structured  to  develop  students'  monitoring,  evaluating  and  regulating abilities within a dialogic environment to support their learning (Ajjawi &amp; Boud  2017).  Through  collaboration  with  others,  students  can  construct their own  knowledge  by  connecting existing knowledge  with new knowledge (Jacobs 2015). Any form of collaborative learning can thus be positioned within a social constructivist perspective and could 'provide a venue for peer interaction, which in turn provides opportunities for students to build and try out their developing knowledge' (Jacobs 2015:37). From a social  constructivist  perspective,  learning  and  assessment  are  therefore seen  as  an  integrated  social  and  collaborative  activity  where  students' thinking, learning and assessment are developed and shaped whilst working together.

## Sustainable assessment

Sustainability  in  education  is  about  the  sustainability  of  all  educational practices in 'order to form and sustain learners who will be able to operate effectively in a complex society' (Boud &amp; Soler 2016:400). Students need to act as independent, self-directed learners who can continue to assess their own learning as a lifelong process (Deeley et al. 2019).

To create sustainability in education, sustainable assessment can be seen as providing students with the necessary tools to self-assess their learning progress  and  to  'reflect  on  feedback  from  those  other  than  the  'teacherexpert'' (Witts 2016:78). Sustainable assessment should therefore be adopted in order for students to become lifelong learners (Witts 2016). Assessment practices should not only equip students for their current learning but also for future learning (Boud &amp; Soler 2016). Consequently, assessment should not be viewed  as  a  'unilateral  act  done  to  students'  but  rather  as  a  'mutually constructed' action between students themselves and between students and the educator (Boud &amp; Soler 2016:402).

Assessment practices should 'equip students for a lifetime of learning and the assessment challenges they would face in the future' (Boud &amp; Falchikov

2006:400); it should 'generate meaningful feedback', which students could use for future learning (Watling &amp; Ginsburg 2019:77).

As a lifelong attribute, students should practice becoming judges of their own  learning  and  learning  by  their  peers  (Boud  &amp;  Falchikov  2006).  Boud (2010) and Boud and Soler (2016) provide some guidelines on how to promote sustainable assessment:

- · engage students in their own learning and assessment
- · include  authentic  learning  activities  and  take  challenges  from  students' future practices into account
- · include  students  as  partners  in  the  design  of  assessment  tasks  and  in providing assessment feedback
- · provide assessment tasks in which students should judge their own learning and that of others; thus, include peers in assessment and feedback
- · consider preparation of students for learning in a post-graduation environment.

When planning for sustainable assessment, strategies should be established to  engage  students  in  deep  learning  and  higher-order  cognitive  skills, opportunities for self-evaluation and peer evaluation, reflection on results and planning for future improvement (Kazlauskiene, Gaucaite &amp; Poceviciene 2016; Wickramasinghe, Weller &amp; Smith 2020). At the same time, students should be prepared for evaluative judgement outside formal education as well (Boud &amp; Soler 2016).

From this discussion, it is clear that assessment feedback is essential in sustainable  assessment  practices  and  should  be  used  to  improve  student learning - not only for a specific learning outcome but for future learning as well. Hereafter,  assessment  feedback  within  the  context  of  sustainable assessment is discussed.

## Assessment feedback within sustainable assessment

Gibbs and Simpson (2004) suggest 11 conditions under which assessment supports learning. Seven of the 11 conditions concern feedback and emphasise its importance (O'Donovan, Rust &amp; Price 2016). Assessment feedback could provide  powerful  support  and  might  have  a  positive  effect  on  learning  if administered correctly (Carless et al. 2011).

Ferguson (2011) identifies feedback as important to support and enhance students'  development  as  self-directed  learners  who  are  able  to  monitor, regulate and evaluate their own learning. Feedback can be explained as the way by which students interpret information about their learning and use such information to improve their future learning (Dawson et al. 2019). Feedback should therefore be 'a process used by the learners to facilitate their own

learning' (Boud &amp; Molloy 2013:703-704). This feedback is then acted upon after making sense of it (Henderson et al. 2019), and is aimed at 'development and  learning'  (Watling  &amp;  Ginsburg  2019:77).  Assessment  feedback  is  an integral part of learning (Cramp 2011) and an ongoing process (Carless et al. 2011), and should therefore not be seen as an end product where information is  only  provided  by  the  educator.  According  to  Boud  and  Molloy  (2013), feedback should be viewed as a way to promote learning and as a means to increase the capacity of students to make own judgements and act upon their judgements.

Boud and Molloy (2013:701) explain two directions in terms of feedback:

- · In the first direction, the prime responsibility of the educator is to provide feedback to the student (Feedback 'Mark 1'). This does not fall within the framework of sustainable assessment discussed in this chapter, as students are not involved in their own judgements or that of their peers.
- · In  the  second  direction  (Feedback  'Mark  2')  (Boud  &amp;  Molloy  2013:703), students actively seek information to inform their own judgements. This fits in with sustainable assessment.

According  to  Feedback  'Mark  2'  (Boud  &amp;  Molloy  2013:703),  assessment feedback should be viewed as a way to promote learning and as a means to increase the capacity of students to make their own judgements and act upon these.  When  planning  assessment  feedback,  students  also  need  to  be supported and encouraged to obtain skills to seek feedback from as many sources as possible (Boud &amp; Associates 2010). In planning feedback, the focus should not be on marks and grading, but rather on how to equip students 'to become judges of their own learning' (Boud &amp; Soler 2016:402) and how to engage with feedback (Harris, Brown &amp; Harnett 2014). Students also have to obtain the skills to act upon feedback to adjust, correct or manage possible actions to facilitate their own learning (Boud &amp; Molloy 2013). Feedback should encourage student reflection on their own learning (Beckers et al. 2019).

Feedback can be considered essential for sustainable assessment practices. It can be most effective when it is part of a social learning environment, such as  CL,  where  students  are  actively  involved  in  their  own  learning  through dialogue and reflection (Ajjawi &amp; Boud 2017). During peer and self-assessment, students develop skills that will enable them to make informed judgements regarding  their  learning  progress  (Boud  2009;  Nguyen  &amp;  Walker  2016). Dawson et al. (2019:35) argue that the effectiveness of feedback lies in 'what students  do  with  information  about  their  work,  and  how  this  results  in demonstrable improvements to their work and learning strategies'. Henderson et al. (2019:1405) are of the opinion that 'feedback design, [the] capacity of the people involved and the institutional culture' influence successful feedback practices. They argue that students should be actively involved in the feedback

process  and  need  to  know  how  to  use  the  information  provided  to  them (Henderson et al. 2019).

Feedback  should  provide students with the opportunity to clarify misconceptions and elaborate on future actions (Black &amp; McCormick 2010). It should encourage students to reflect on their own learning (Beckers et al. 2019),  and  should  occur  when  it  can  best  support  students  to  act  upon  it (Henderson et al. 2019). According to Henderson et al. (2019), students should develop the necessary skills to monitor and evaluate their own learning and that of their peers with a fair degree of independence.

Boud and Molloy (2013) posit that students should have the opportunity not only to practice giving feedback but also to receive it from their peers. According  to  Gibbs  and  Simpson  (2004),  the  most  effective  feedback available is that provided by students to themselves as they study or write assignments  together.  Henderson  et  al.  (2019)  found  that  collaborative learning spaces enable and support frequent feedback. Hence, it is all about the  quality  of  students'  engagement  within  such  a  collaborative  learning environment. In order for students to evaluate their own work and the work of  their  peers  effectively  and  to  produce  valuable  information,  which  can contribute to current and future learning improvement, students should be supported in terms of their feedback literacy (Deeley et al. 2019; Henderson et al. 2019). 'Preparing students to understand their role within the feedback process, particularly how they can seek, interpret and use the information, needs to occur early and continue throughout a course' (Henderson et al. 2019:1406).

## Cooperative learning environment conducive to assessment feedback

Cooperative learning is a special form of collaborative learning where students need to work together in small groups to maximise their own learning as well as  the  learning  of  each  member  of  the  group  (Johnson,  Johnson  &amp;  Smith 2006). It is a student-centred, active teaching and learning strategy, which provides a supportive and safe learning environment to students (Gedamu &amp; Shewangezaw 2020; Johnson &amp; Johnson 2013).

Five  essential  elements  are  required  within  any  CL  environment  to  be successful, namely (Johnson &amp; Johnson 2019):

- · positive interdependence between group members
- · individual accountability of all group members
- · promotive interaction between group members
- · effective social skills
- · group processing, during and after completion of a group task.

These elements need to be structured carefully and planned for in any CL environment because they are important elements in terms of assessment and the success of assessment feedback. The purpose of any CL environment is  to  maximise  each  other's  learning  (Johnson  &amp;  Johnson  2013).  Students should therefore assist and support one another through giving and receiving feedback, and by continuously clarifying uncertainties. Henderson et al. (2019) found  that  learning  spaces  where  students  work  together  could  support immediate feedback.

When CL strategies are incorporated into the assessment task, they tend to ensure  dialogue  and  active  participation  as  students  share  their  learning experiences (Johnson &amp; Johnson 2013). According to Johnson, Johnson and Holubec (2008), assessment is part of the teaching and learning process of CL groups, as CL provides the environment and context suitable for assessment to be integrated into the learning process. Group members have a common purpose and commitment to assist in each other's learning, and they therefore have to participate in assessing each other's progress and plan together how to improve in the future (Johnson et al. 2008), all of which are consistent with sustainable assessment.

However,  assessment  within  a  CL  environment  is  often  problematic,  as educators still tend to implement assessment strategies that are not rooted in social constructivism (Thondhalana &amp; Belluigi 2017) or sustainable assessment. Educators often still act as if they are the sole providers of all knowledge. They argue that involving students in assessment may cause confusion because peers  could  provide  incorrect  feedback  (Jacobs  2015).  Students  often complain of no or incomplete feedback when working cooperatively because no opportunity for feedback was built into the learning process. Peer and selfassessment feedback practices are, however, 'useful learning tools' and are seen  as  'means  of  enhancing  [students']  proclivity  toward  and  ability  at engaging  in  lifelong  learning'  (Jacobs  2015:38).  This  fits  perfectly  into  the sustainable assessment perspective.

It is important that CL environments be planned carefully. There should be a challenging task, which might have more than one answer or more than one way of solving (Willis 2007), which will enhance students' motivation to participate. The learning environment should provide opportunities for dialogue, knowledge seeking, and reflection between students in order to build a trust relationship (Boud &amp; Molloy 2013) in terms of knowledge sharing and peer feedback.

## The group-individual-group cooperative method of assessment

The GIG CLMoA was introduced by Johnson et al. (2008). It is an integrated learning and assessment method, which includes assessment feedback within

a CL group. The GIG CLMoA builds on the principles of CL, and all the elements of a successful CL environment should be included in the planning.

According to this method of assessment, students prepare during class and in a CL group for a test as the first phase of the method. Thereafter, each student takes the test individually and submits the test for grading. This is the second phase of the GIG CLMoA. During the third and final phase and directly after submitting all individual tests, the same group that prepared together retakes the  same  test  cooperatively  and  submits  the  test  for  grading.  During  the cooperative test-taking, they have the opportunity to discuss each question and attempt to provide the best possible answer to all questions. They have to reflect on their own answers in the individual test and compare the answers from their individual tests with those of their peers. Group members have to communicate their reasoning and have to reach a consensus on answers for each  question,  ensuring  that  all  members  can  explain  the  answers.  During phases 1 and 3, students have the opportunity to ask questions within a closed environment where they feel comfortable to ask for explanations and clarity. When completing the retake of the test as a group, they should reflect on their work as a group and learn from their interaction as part of the normal group process during any CL activity. After this reflection, the educator can also lead a  discussion  to  facilitate  final  feedback,  if  needed.  During  the  GIG  CLMoA, students  can  prepare  for  the  test  together  and  review  the  test  afterwards. According to Johnson et al. (2008), this not only optimises students' preparation for a test but also provides immediate clarification and remediation to students about content that they did not understand or know. The group is responsible to ensure that all students can explain the answer and understand the rationale for each answer (Johnson et al. 2008). The grades of the group as well as the grades of each individual group member can be shared with the whole group.

Cox (2015) implemented a GIG CL model on a large enrolment of first-year chemistry students over a two-year period. The goal was to use CL with connected assignments and emphasise individual accountability. Students in the treatment group needed to complete group and individual assignments. Cox found that participants  in  the  GIG  model  reported  greater  satisfaction  than  groups  not participating in such model. A few students indicated that the group work had a negative influence on their performance. Some weaker students tended not to participate and share their ideas with the group. It was nevertheless reported that the GIG model implemented was successful in promoting problem-solving, individual accountability and better understanding of concepts (Cox 2015).

Examples of how the five elements of CL (Johnson &amp; Johnson 2013, 2019) can be included in the GIG CLMoA include the following:

- 1. Positive interdependence: There should be a challenging task, preferably related to a real-life  situation  where  students  can  apply  knowledge and skills required for the stated learning outcomes. The instruction to the group

should be to prepare for the assessment together, and students should be made aware that they would receive a group grade for their achievement during the third phase. This goal to complete the task together will create a feeling of 'sink or swim together' amongst group members. They will be motivated to contribute by preparing for the test and using every possible source to complete the task successfully. Roles allocated to the different group members (e.g. recorder , checker for understanding, encourager of participation  and elaborator of  knowledge)  might  further  contribute  to positive interdependence during the process.

- 2. Individual accountability: The average of the individual grades can also be part of the grade of each group. Students are then even more committed to preparing for the test to obtain clarification about aspects of the work that they do not understand, to assist their group members in terms of explaining and clarifying difficult concepts and to obtain different sources of information in order to assist the group in their learning.
- 3. Promotive interaction: Students should be informed of what is expected of them. The main aim of CL, namely to contribute to optimal learning of all members of the group, should be communicated clearly. The nature of the GIG CLMoA requires students to assist each other in their learning and preparation  as  well  as  providing  them  with  feedback  on  their  learning during the third phase.
- 4. Social skills: Students should know exactly what is expected of them in terms  of  acceptable  communication  and  listening  skills  and  how  they should  participate  and  cooperate  during  the  GIG  CLMoA.  The  educator should facilitate this process during phases 1 and 3.
- 5. Group  processing: After  completion  of  the  GIG  CLMoA,  a  short  group discussion  about  what  was  helpful,  what  might  be  improved  in  future collaboration  and  what  was  gained  from  working  together  should  be scheduled. This reflection of their learning could contribute to future learning.

In Figure 7.1, a graphic representation of the GIG CLMoA clearly indicates the three phases as well as the planning and processing phases to complete the

FIGURE 7.1: Graphical representation of the group-individual-group cooperative learning method of assessment.

<!-- image -->

process.  The  task  or  assignment  should  be  selected  carefully  in  order  for students to be motivated to engage in the completion of the task as a group. A challenging problem, where a single right or wrong answer is not required, contributes to the success of the method. Careful planning of group selection, roles and responsibilities of each member of the group is needed.

Hereafter,  the  methodology to evaluate the effectiveness of assessment feedback in the GIG CLMoA is discussed.

## Effectiveness of the assessment feedback in the group-individual-group cooperative learning method of assessment

To determine whether the GIG CLMoA adheres to sound assessment feedback principles within a sustainable assessment perspective, we evaluated the method against the criteria for sustainable assessment and feedback as discussed in the theoretical and conceptual framework. To explore and understand the perceptions of the educator and students regarding the value of assessment feedback during a  GIG  CLMoA,  a  basic  qualitative  interpretivist  research  method  was  used. Qualitative research can facilitate the meaning-making process (Krauss 2005), which  is  a  fundamental  aspect  of  the  understanding  of  human  and  social interaction and therefore suitable to determine the perceptions of students and educators on feedback during GIG activities.

Of the 79 first-year Life Sciences students enrolled for a course in a preservice teacher training programme at a university in South Africa, 71 as well as  one  educator,  voluntarily  took  part  in  this  research.  The  overwhelming majority of students who participated were in the age group 18-19 years. Most of  them  had  completed  Grade  12  the  previous  year  and  had  selected  Life Sciences as one of the major subjects in their teacher qualification programme. The majority of the students were female (77%) whilst only 23% were male.

The GIG CLMoA was implemented as part of a normal class activity and served as an intervention in the current study. The students knew they had to prepare for an assessment on a specific topic. In this particular instance, the assessment  was  on  a  topic  in  the  study  unit  on  Basic  Chemistry  and Biochemistry,  which  students  always  find  difficult  to  comprehend.  The assessment  consisted  of  higher-order  questions  where  students  could  not merely provide memorised facts but had to apply their knowledge in new situations. The GIG CLMoA was initially explained, as well as their roles and responsibilities. The educator divided participants into groups of four. As part of  the  first  phase,  they  had  15  min  together  as  a  group  to  clarify  difficult concepts  arising  from  their  preparation.  In  the  second  phase,  each  group member received a copy of the assessment to complete individually. After 45 min, the individual assessments were submitted for grading, and students

had to meet in the original groups where they prepared for the assessment. During the third phase, a copy of the same assessment was handed to each group, and they had 30 min to complete the assessment within the group and submit it for grading. During this phase, the group had to share their knowledge, explain  their  reasoning  to  one  another  and  try  to  correct  mistakes  whilst completing the assessment together. They had to ensure that each student in the  group  agreed  and  understood  the  answer  given  by  the  group.  Mutual support and guidance had to be provided to each other.

After  implementing  the  GIG  CLMoA,  the  participating  students  and educator had to express their experiences and perceptions about the method in the form of individual narratives. The probing question was: Explain in a paragraph how you experienced the GIG CLMoA. No specific mention was made of feedback as such, as the researchers wanted to determine whether students identified feedback as an integral part of the assessment.

The analysis of the narrative data focused on experiences mentioned by participants specifically related to assessment feedback. The two researchers analysed the data individually, and then compared and discussed themes to ensure credibility and trustworthiness. Meticulous attention was given to the conceptualisation of certain themes, comparing the analysis of the researchers and eventually arriving at a consensus. Thematic analysis of narratives was done to categorise aspects related to assessment feedback in order to answer the research question.

Ethical clearance for this research had been obtained as part of a larger research  project.  The  implementation  of  the  GIG  CLMoA  was  part  of  the normal class activity within this Life Sciences module, but the completion of the narratives was voluntary. The educator and all the students who agreed to participate in this research signed informed consent forms and agreed that their  data  could  be  used  for  research  purposes.  All  students  participated anonymously in the writing of the individual narratives, and it was explained to them that their participation would under no circumstance have any effect on their overall grading. Analysis of data only started after the module marks had been finalised.

## Results

## Evaluation of the group-individual-group cooperative learning method of assessment according to sustainable assessment principles

In  this  section,  we  evaluate  the  GIG  CLMoA  whilst  taking  into  account  the principles on assessment feedback within sustainable assessment identified and  discussed  in  this  chapter.  In  Table  7.1  and  Table  7.2,  the  principles  of

TABLE 7.1: Group-individual-group cooperative learning method of assessment measured against principles of sustainable assessment.

| Principles of sustainable assessment                                                                                                                                                                                                                                                               | GIG CLMoA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Engaging students in their own learning and  assessment (Boud 2010; Boud &amp; Soler 2016)                                                                                                                                                                                                             | During all three phases of the GIG CLMoA, students are  actively engaged in their own learning and assessment.  This happens, firstly, when they prepare together, then  when they complete the individual test and reflect  on what they are able to do, and lastly, when they  complete the same test as a group, judging their own  performance and that of their peers.                                                                                                                                                                                                                                                                                                                                                    |
| Including authentic learning activities and taking  challenges of students' future practice into  account (Boud 2010; Boud &amp; Soler 2016).                                                                                                                                                          | It is possible to design a task for a GIG assessment  and take this requirement into account. The educator  should, however, specifically plan in this regard.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| Include students in the design of assessment tasks  as partners and in providing assessment feedback  (Boud 2010; Boud &amp; Soler 2016).                                                                                                                                                              | Students are not included in the development of  the assessment task but should be informed about  the scope and purpose of the assessment. However,  students are involved in providing assessment  feedback during phases 1 and 3 of the GIG CLMoA.                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| Provide assessment tasks in which students judge  their own learning and that of others; thus, include  peers in assessment and feedback (Boud 2010;  Boud &amp; Soler 2016).                                                                                                                          | During phase 3 of the GIG CLMoA, students have to  complete the test as a group, communicating, arguing  and clarifying their answers. They not only receive  feedback on their own individual assessment but also  provide feedback to their peers.                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| Keep the preparation of students for learning in  a post-graduation environment in consideration  (Boud 2010; Boud &amp; Soler 2016).                                                                                                                                                                  | During the GIG CLMoA, students get the opportunity  to work and solve problems in a group, simulating the  environment of work where they will have to work as a  team to reach the goal.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| Engage students in deep learning and higher-order  The extent to which students are engaged in deep  cognitive skills, opportunities for self-evaluation  and peer evaluation, reflection on results and  planning for future improvement (Kazlauskiene et  al. 2016; Wickramasinghe et al. 2020). | learning and higher-order cognitive skills depends on  the task given during the GIG activity and requires  careful planning by the educator. There are clear  opportunities for self-evaluation during all three phases  of the GIG CL method. Peer evaluation opportunities  are found in phases 1 and 3 and reflection on results  during the group processing at the end of the  assessment. Although planning for future improvement  is not explicitly included in the GIG CLMoA, it can  be implicitly structured as part of group processing.  Engaging in the learning process through ongoing  dialogic feedback, students are acquiring vital  skills that they will be able to use in future learning  endeavours. |

GIG CLMoA, group-individual-group cooperative learning method of assessment.

sustainable assessment are listed in the first column, and in the second column, we provide some evidence of the extent to which these principles can be identified in the GIG CLMoA.

From Table 7.1, it is clear that not all the principles can be accomplished to the  same  degree  when  evaluating  the  GIG  CLMoA.  It  depends  on  the instructional planning of the educator to incorporate the five elements of CL, the expectation in terms of student preparation before the implementation of the  GIG  CLMoA,  as  well  as  the  nature  of  the  assessment  given.  It  further depends on the student culture  whether  students  will  apply  the  feedback

Value of feedback during the implementation of the group-individual-group cooperative

TABLE 7.2: Group-individual-group cooperative learning method of assessment measured against principles of successful feedback.

| Principles for successful feedback  practices within sustainable assessment                                                                                         | GIG CLMoA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Feedback should be planned to  develop students' own skills in terms of  judgement and critical appraisal.                                                          | During the first and third phases of group preparation, students  have the opportunity of taking the test together to communicate  and motivate their views and to evaluate everyone's contribution                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| Students should be judges of their  own learning and each other's learning  (Boud &amp; Molloy 2013; Boud &amp; Soler 2016;  Henderson et al. 2019; Nguyen &amp; Walker  2016). | critically in order to reach the desired outcome. The fact that  this is a small group in which they feel comfortable sharing  what they know and do not know might also contribute to the  development of their judgement ability and critical appraisal.  Students no longer depend on the educator to provide them  with the correct answers or solutions to a problem, but they are  actively involved in finding the correct answers and solutions  by interacting, arguing, communication and sharing information  with each other. If they believe their answers or solutions are  correct, they have to justify their answers, evaluate each other's  arguments and adjust their answers accordingly, if necessary. |
| Feedback should be an integral part of  learning (Cramp 2011).                                                                                                      | During the process, students learn together, perform  assessments together and at the same time provide feedback to  each other.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| Feedback should be employed from a  variety of sources (Boud &amp; Associates  2010).                                                                                   | If students are aware of the fact that they will have to participate  during the GIG activity, they will be motivated to consult a  variety of sources and bring them to class for preparation  purposes. This principle therefore depends on the instructional  planning of the GIG activity and could well be included in the  GIG CLMoA.                                                                                                                                                                                                                                                                                                                                                                                 |
| Students should act upon the feedback  to adjust, correct or manage own  learning (Boud &amp; Molloy 2013).                                                             | The GIG CLMoA provides students with feedback on what  they know and what they can achieve whilst preparing for the  test as a group. There are many opportunities for clarification,  adjustment or correction before the individual test (phase 1) as  well as during the group test (phase 3). The fact that students  realise that they have to answer the test individually motivates  them to ask questions, assist each other and clarify any aspect  that they do not understand. This is therefore a way to promote  learning and increase the capacity of students to correct, adjust  and act upon their own judgement.                                                                                          |
| Feedback should encourage student  reflection (Beckers et al. 2019).                                                                                                | During the group test (phase 3), all group members have to  reflect on their own answers from the individual test (phase 2)  and motivate their reasoning. Students have to explain, defend  and/or adjust their strategies during phase 3, which will provide  opportunities for reflection. The group processing also serves as  an opportunity for reflection on the learning experience.                                                                                                                                                                                                                                                                                                                                |
| Feedback should actively involve  students in the feedback process  (Henderson et al. 2019).                                                                        | The GIG CLMoA comprises only a small number of students in  one group (2-4), which makes it difficult for any one student  not to be actively involved. The CL elements, which are built  into the method, ensure positive interdependence, individual  accountability and promotive interaction amongst group  members. The fact that the individual and group tests have  to be submitted for grading contributes to all students' active  involvement and participation.                                                                                                                                                                                                                                                 |
| Feedback should provide students with  the opportunity to clarify misconceptions  and elaborate on future actions (Black &amp;  McCormick 2010).                        | Within this small group setting, students tend to ask for  clarification much more than they would have done in a whole- class environment where they do not have the courage to admit  when they do not understand. They are comfortable asking  assistance from peers, as well as sharing ideas within the group.                                                                                                                                                                                                                                                                                                                                                                                                         |

GIG CLMoA, group-individual-group cooperative learning method of assessment.

Table 7.2 continues on the next page →

TABLE 7.2 (Continues...): Group-individual-group cooperative learning method of assessment measured against principles of successful feedback.

| Principles for successful feedback  practices within sustainable assessment                                          | GIG CLMoA                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
|----------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Students should know how to use the  information provided to them to correct  their actions (Henderson et al. 2019). | The GIG CLMoA provides an environment in which students  can grow and practice to correct future actions. They have the  opportunity to clarify uncertainties with their peers immediately  and ask for explanations and assistance when they realise  that they do not understand. During group processing after  completion of the GIG CLMoA, group members can discuss how  they learn from their mistakes and how they will apply this in  future assessments.                                                                     |
| it can best support the student to act  upon it (Henderson et al. 2019).                                             | Feedback should be given at a time when  Feedback during the GIG CLMoA is provided during phase 1  when the group studies together, as well as during phase 3  where they complete the task or assessment together. Feedback  is immediately available before and after the individual test is  taken. The students can therefore still remember the questions  where they were uncertain or those they did not know how to  answer. From the discussions within the group, members receive  the necessary feedback and clarification. |
| There should be opportunity to practice  giving and receiving feedback (Boud &amp;  Molloy 2013).                        | There is continuous interaction within the group in phases 1 and  3 of the GIG activity in order to give feedback to one another  and to receive feedback from the group.                                                                                                                                                                                                                                                                                                                                                              |

GIG CLMoA, group-individual-group cooperative learning method of assessment.

obtained  during  the  GIG  CLMoA  to  future  learning.  Students  need  to  get accustomed to working in groups to provide constructive feedback to peers, to assist peers with their learning and to explain their own views logically (see Johnson &amp; Johnson 2013). The success of the GIG CLMoA might increase if it is  implemented  repeatedly,  as  the  environment  is  conducive  to  reflection, critical appraisal and judgement. Students will then gradually gain exposure to being discerning and they will become increasingly critical about their own learning and that of their peers. Increasing students' level of feedback literacy might also contribute towards the success of the GIG CLMoA.

In the current research, assessment feedback was thus integrated into the social learning environment and all students were in a position to provide the necessary support and guidance to members of their group in order to reflect and monitor their own learning and adjust their learning process accordingly.

## Results Related to Student and Teacher Perceptions of Feedback

The analysis of the narratives provided by the students after completion of the GIG  CLMoA  revealed  the  following  themes  that  can  be  conceptually  and theoretically connected to their perceptions on feedback during the implementation of the method.

## ncreased learning and knowledge acquisition I

Although not all students specifically mentioned the fact that feedback was provided  whilst  completing  the  test  as  a  group,  almost  every  student mentioned that they gained additional knowledge about the specific learning outcomes  during  that  time.  They  indicated  that  this  resulted  in  better understanding  and  improved  achievement.  All  quotations  are  reproduced verbatim and unedited. One student declared, 'I understood better after we wrote the test together' (S1, Life Sciences education student, first year). Four students did not explicitly mention that they had gained more knowledge and learned more, and another six students specifically indicated that they did not gain academically from the interaction during the implementation.

## Broadened horizons

Students indicated that the discussion and reasoning during the implementation of the method broadened their horizons and thus equipped them with more than only knowledge required for the specific test. A student said, 'I have better insights after writing it with the group' (S35, Life Sciences education  student,  first  year).  It  seems  as  if  they  valued  the  feedback received  during  phase  3  more  than  the  studying  together  before  the individual test (i.e. phase 1).

## Acknowledgement of multiple answers and perspectives

Students indicated that they had engaged in their own learning and actively participated in rewriting the test in order to achieve a good score. They learned to  reason,  defend  their  answers  and  respect  other  students'  viewpoints  in their  efforts  to  complete  the  test  successfully.  Because  of  the  feedback provided to them, they realised that there was more than one possible way to solve the same problem, more than one possible correct answer and more than one possible correct viewpoint on a particular issue. A student remarked, 'It makes me see another point of view other than my own' (S9, Life Science education student, first year).

## Motivation for future learning

Students  were  of  the  opinion  that  the  implementation  of  the  GIG  CLMoA motivated them to learn, and they enjoyed working together. Some responses about the motivation aspect reported by students were: 'It motivates everyone in the group' (S14, Life Sciences education student, first year) and 'It was an enjoyable experience' (S61, Life Sciences education student, first year).

Students  further  indicated  that  they  valued  the  way  in  which  learning, assessment and assessment feedback were incorporated in the GIG CLMoA.

However, three students indicated that they did not enjoy the GIG CLMoA and gave the following reasons: 'It is depressing' (S38, Life Sciences education student, first year), 'I like to answer on my own' (S42, Life Sciences education student, first year), and 'I am studying hard and others is just using me when they did not study' (S59, Life Sciences education student, first year).

## Exposure to different learning strategies and study skills for future learning

Apart from the learning gain, students also indicated that the GIG CLMoA introduced them to different learning strategies and study skills which they could utilise in future learning, for example. 'Insight in others' way of learning was valuable' (S27, Life Sciences education student, first year). They obtained not only further knowledge but also skills that might be transferred to new learning situations in future.

## mproved understanding and clarification I

The  students  argued  that  the  opportunity  they  had  to  discuss  their  own learning, argue and reason about possible answers to questions and defend their  own  answers  led  to  improved  understanding  and  clarification  of  the learning content and related directly to assessment feedback. One student revealed,  'I  struggle  to  understand  when  studying  alone  […]  my  group explained  it  to  me  and  now  I  understand'  (S48,  Life  Sciences  education student,  first  year).  From  the  students'  responses,  it  seemed  that  peers explaining difficult concepts to one another - in their own words - were much more  successful  than  explanations  in  a  textbook  or  explanations  by  the educator. Students explained that they were by far more comfortable with asking their peers when they did not understand something than asking the educator.

## dentification of own gaps I

The group discussion assisted in self-assessment, as everyone realised their own limitations in terms of achieving the outcomes. A typical answer was, 'I realised that I made some mistakes' (S12, Life Sciences education student, first year). This provided  them  with  opportunities  to  adjust  their learning accordingly.

## Timely assistance

Students  indicated  that  they  appreciated  immediate  feedback  after  the assessment and acknowledged that the GIG CLMoA did just that. They could still recall their own answers to the questions and received immediate feedback

to  correct  their  own  mistakes.  'It  helps  to  compare  answers  immediately afterwards', a student said (S44, Life Sciences education student, first year).

Analysis of the narrative of the educator revealed that themes related to the educator's perception of the feedback to students during the GIG CLMoA can  be  grouped  into  two  distinct  categories  within  active  participation  in students' own learning, namely peer interaction and peer assistance .

## Peer interaction

The  educator  (E1,  Life  Sciences  teacher,  date  unspecified)  indicated  that active  peer  interaction  took  place  in  all  groups.  'I  was  amazed  to  see  the interaction within the groups', she commented. Students were eager to work together and complete the test together. Students visually explained the work to one another and used mind maps and diagrams to explain their reasoning and convince group members of their answers. They communicated effectively and no group conflict was visible:

'The  whole  atmosphere  in  class  was  productive,  positive  and  exciting.  […]  They went on and on explaining and discussing the work […], I could not identify a single group  in  which  no  peer  interaction  took  place.'  (E1,  Life  Sciences  teacher,  date unspecified)

## Peer assistance

The assistance given to one another was visible as students were not shy or uncomfortable asking each other questions and using each other as resources. They  communicated  effectively  and  the  educator  witnessed  several  aha moments when students  realised  their  own  misconceptions.  The  educator also mentioned that she noticed considerable in-depth discussion of higherorder learning outcomes, which indicated that the students grew beyond their current level of competency. According to the educator, this was an indication that  the  GIG  CLMoA was constructive, effective and helpful to students in terms of feedback on their own assessment. The educator indicated, '[t]here was no need to provide additional feedback to students' (E1, Life Sciences teacher,  date  unspecified).  Nevertheless,  she  provided  the  opportunity  for students to ask questions after the group processing at the end of the GIG activity.

## Discussion

Educators would like their students to be active participants in the learning and  assessment  process  and  not  only  passive  receivers  of  knowledge. According to the educator participating in this research, it was exactly the fact  that  all  students  were  active  participants  in  the  learning  that  excited

her most. Students were actively involved in feedback on their own individual assignments and on that of their peers during phase 3 of the GIG CLMoA. It was  clear  from  the  responses  of  the  educator  and  the  students  that  the feedback  provided  was  adequate  and  that  it  addressed  the  needs  of  the students.

During the GIG CLMoA, learning and assessment occurred simultaneously whilst students were actively involved in their own learning and in that of their peers.  From  the  literature,  it  was  clear  that  students  and  educators  often complain  about  assessment  feedback  and  hold  incompatible  views  on  its effectiveness (see, for instance, Ajjawi &amp; Boud 2017; Deeley et al. 2019). In this study, it  was clear that most of the students and the educator viewed the feedback in the GIG CLMoA as valuable in terms of its timeliness, clarity, ability to foster self-reflection amongst students, stimulation of their motivation for learning, and an increase in knowledge and skills acquisition.

The findings of this research show compliance with the requirement stated by Archer (2010) and Carless et al. (2011) that feedback should assist students to  gain  their  own  understanding through dialogue and active participation when they share their learning experiences. The students' responses revealed that  the  GIG  CLMoA also assisted in the eradication of misconceptions, to which  Black  and  McCormick  (2010)  suggest  feedback  should  contribute. Students  reported  feeling  comfortable  asking  questions  for  clarification  in their groups.

Although most participating students showed their willingness to partake in this  method of assessment and indicated that it broadened their horizons - which could have an effect on their future learning - a few students indicated that they did not see any advantages for their own learning. They still preferred to work  individually,  which  concurred  with  findings  by  King  (1993)  and  Cox (2015). King (1993) found that high achievers tend not to be satisfied with working in a group, as they experienced not learning something new, always wasting time helping others. Cox (2015) found that these students were of the opinion that the collaboration might even have a detrimental effect on their own performance. The fact that only four of the 71 participants in this research commented negatively on group participation during the GIG CLMoA, might be an indication that more careful planning in terms of the inclusion of the two CL  elements  -  positive  interdependence  and  individual  accountability  -  is needed. Although the GIG CLMoA accommodates individual (phase 2) as well as group accountability (phases 1 and 3), the recommendation of Gedamu and Shewangezaw (2020) - that there should be a balance between individual and group accountability when performing assessment within a CL environment - should not be ignored when planning to use this assessment method. It might be an indication that additional emphasis should be placed on planning, specifically to strengthen positive interdependence and individual

accountability. Students need to get used to working in groups (see Johnson &amp; Johnson 2013), especially first-year students in South Africa, who come from a schooling system where they were not used to collaborating with their peers, and  who  are  often  reluctant  to  work  cooperatively.  From  the  students' comments, it seemed that some were negative about the method, preferred to work alone and did not want to waste time assisting others, as King (1993) also found. Because research data were obtained anonymously, no reference could be made to confirm the achievement pattern of these students. One of the students preferring to work alone complained that some students did not participate, and the ones who worked had to provide all the answers. This is a complaint commonly found in literature when positive interdependence and individual  accountability  within  a  CL  environment  are  not  structured  well. Although  only  a  few  students  complained  about  the  free-riding  of  some students,  this  might  be  an  indication  that  positive  interdependence  and individual accountability should be structured more carefully during planning. It might also be an indication that those students should have more practice and training in working together as a group. They clearly do not realise that the  value  of  explaining  difficult  concepts  to  others  contributes  to  the deepening of  their  own  understanding.  Nevertheless,  no  complaints  about inadequate feedback were received from any student.

According to the participating students, an important aspect of the GIG CLMoA is the increased motivation for future learning. Motivation is one of the three broad outcomes of assessment feedback, as identified by Nelson and Schunn  (2009).  From  the  results  of  this  study,  no  mismatch  was  noted between perceptions of the students and those of the educator in terms of feedback. Not even the students who complained that they did not like the GIG  CLMoA,  as  they  did  not  like  working  in  a  group,  complained  about incomplete or inadequate feedback.

In line with Deeley et al. (2019), little evidence could be found in students' narratives that they would be able to apply the feedback received in their future learning. This might be because no direct question was asked about it for students to report on. Although it cannot be stated that students would not be able to use the feedback in their future learning, this research did not find clear evidence of the measurement of feedback for future learning. The comment that the feedback they received equipped them with more than only knowledge might be an indication that it will assist in future learning. Clearly, more should be done in terms of planning and facilitation of the GIG CLMoA to  ensure  that  the  feedback  provided  is  effective  to  support  and enhance future learning. This research however confirmed the view of Gibbs and Simpson (2004) that the most effective feedback is feedback provided by students to themselves.

## Conclusion

The results from this study indicated that the GIG CLMoA is in line with the social constructivist learning theory and complies with sustainable assessment practices during which feedback is timely, clear and useful and contributes to increased future learning and motivation. Based on this theory, we positioned assessment feedback as an integral part of the learning process within a CL environment. We found that assessment feedback is applicable within the GIG CLMoA to contribute to sustainable assessment practices.

From  the  empirical  investigation,  we  determined  the  perceptions  of students and educators regarding the value of the GIG CLMoA in terms of feedback received. The educator and the overwhelming majority of students agreed that  feedback  during  implementation  supported  their  learning  and had a positive effect on students' learning motivation.

The results of this study also indicated that careful planning is vital for the success of this method. The five elements of CL should be planned carefully when preparing for the implementation of the GIG method. The assignment should include challenging problems, which require high-order thinking and reasoning.  Students  should  be  informed  of  their  responsibilities  and  they should be allowed to bring any other sources related to the assessment to their group preparation.

The GIG CLMoA should be used more often in order to support learning and assessment feedback and to address the limitations of unfair assessment practices  in  cooperative  groups.  Although  based  on  a  relatively  small population, this research could be an indication of the value of this method for future learning in general.

## Acknowledgements

This chapter is based on a research project supported by the NRF of South Africa (Grant Number 90387). The grant holders acknowledge that opinions, findings and conclusions or recommendations expressed in any publication generated by the NRF-supported research are those of the authors, and that the NRF accepts no liability whatsoever in this regard.

## Assessment: The driving force behind self-directed learning in English teacher training

## Marike Annandale

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Elizabeth M. Reyneke

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Abstract

Based on the significant role played by the English language as an international tool for education, business, trade and commerce (Rao 2019:65), governmental policies  on  education  in  many  parts  of  the  world  have  prioritised  the improvement of English language learning outcomes (Galaczi et al. 2018:5). This  directly  affects  English  language  teacher  training.  Chong  and  Cheah

How  to  cite: Annandale,  M.  &amp;  Reyneke,  E.M.,  2021,  'Assessment:  The  driving  force  behind  self-directed learning in English teacher training', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 165-185, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021.BK280.08

(2009:16)  emphasise  that  SDL  should  be  established  and  nurtured  during initial teacher training. They argue that it is during this phase that teachers are equipped for lifelong learning in an ever-demanding professional environment, and where they develop a problem-solving attitude and the skill to learn from experience through reflection. Based on the extended role of English in South Africa, English teachers need a high level of disciplinary knowledge in various subject-related  fields,  pedagogical  knowledge  and  pedagogical  content knowledge. This requires thorough training in the theory of language teaching and learning, including the theory on second language acquisition, linguistics and all literary genres. In light of this, pre-service English teachers should be equipped with SDL skills that allow them to perform cognitively demanding tasks. With a view to quality assessment that encourages SDL, this chapter critically explores the English for Education teaching, learning and assessment practices of a selected institution.

## Introduction

In a multilingual country such as South Africa where English - as the mother tongue of a mere 8.1% of the population (BusinessTech 2019) - is preferred as the medium of instruction by the majority (Gordon &amp; Harvey 2019), there is a pressing need to improve the effectiveness of English language teaching and learning at all levels of education. In order to achieve this, it is crucial that pre-service English teachers are trained well. Most important in initial teacher training is critical engagement and the establishment and nurturing of SDL. According to Chong and Cheah (2009:16), it is during this phase that teachers are equipped for lifelong learning in an ever-demanding professional environment, and where they develop a problem-solving attitude and the skill  to  learn  from  experience through reflection. Outcomes such as these ought to be facilitated by a curriculum and assessment system focused on unlocking  and  promoting  rather  than  thwarting  students'  true  academic potential, their ongoing learning and pre-professional identity development by  means of  current  best  or  innovative  practices  (Burns  2011:132).  It  also means immersing pre-service teachers in high-quality learning experiences with  instructors  who  model  the  characteristics  of  good  teachers  (Burns 2011:133).

This  chapter examines a particular tertiary institution's B.Ed. Senior and Further  Education  and  Training  (FET)  teacher  training  programme.  This programme  is  aimed  at  immersing  pre-service  English  teachers  in  quality, assessment-driven learning experiences focused on the promotion of critical engagement and SDL. The discussion  starts  with  a  look  at  English  as  the global lingua franca, the status of English in South Africa and its implications for English Senior and FET teacher training, and the qualities these teachers should exhibit.

## English as the global lingua franca

Crystal  (2003:6)  states  that  there  is  no  other  language  in  the  world  that corresponds  with  English  in  terms  of  its  growth  as  a  global  medium  of communication. It is also seen as a language that helps with access to jobs and advancement (Van der Walt &amp; Evans 2019:16). Graddol (2006) remarks that an 'English factor' is found:

[ ]n  virtually  every  key  macro trend: whether it is business process outsourcing, I the  rise  of  urban  middle  classes  around  the  world,  the  development  of  new communications  technology  such  as  the  Internet,  the  global  redistribution  of poverty, the changing nature and control of news media, or the reform of education in universities and school. (p. 20)

The latest statistics reported by the British Council (2020) indicate that more than 1.75 billion people speak English worldwide - this comes down to 1 in every 4 people around the globe. This figure is projected to grow to 2 in 4 by 2050 (The Economist 2001).

The increased growth and the status of English as a tool for communication in the 21st century have to do with the reciprocally connected nature of the continents of the world (Plonski, Teferra &amp; Brady 2013:3). It follows that the more the countries of the world become connected through development, the more established the English language will become (Mydans 2007:2), and the higher the demand will become for English language instructors. Teaching English  as  a  Foreign  Language  (TEFL)  has  already  been  established  as  a global industry with an estimated market value of $200 billion (International TEFL Academy 2020). Numerous service providers offer TEFL courses online and are working in close collaboration with various agencies that are looking to  recruit  TEFL  instructors  across  the  world  to  teach  either  remotely  or  in face-to-face  environments.  In  most  cases,  the  role  of  these  instructors  is simply  to  present  prepared  material,  tailor-made  in  terms  of  content  and pedagogical approach, to fit the needs of learners at any particular level of education  in  any  particular  country  (International  TEFL  Academy  2020). Across the world, in countries like China, Brazil, Argentina, India, Russia and Singapore, English is spoken by a small percentage of the population (Graddol 2006:55-56; Smith 2017), but there is a pressing need to learn English as a foreign language as it is seen as the language that helps with access to jobs and advancement (Van der Walt &amp; Evans 2019:16).

The  notion  of  English  as  an  international  language  corresponds  with Kachru's  'expanding  circle'  of  English  (McKay  2018:10).  Kachru  (1985) identifies three circles: the inner circle (where English is spoken as a first language), the outer circle (where English is one of several official languages of a country) and the expanding circle (where English is required as a foreign language  but  has  no  special  status  as  an  official  language)  (cf.  Kachru 1997:66-87).  The  official  status  of  the  English  language  in  South  Africa

places  it  in  all  of  Kachru's  circles.  English  is  used  and  taught  as  a  home language in public schools in South Africa, English First Additional Language (EFAL) is the subject with the highest number of enrolments of all subjects that  form  part  of  the  National  Senior  Certificate  examinations  each  year (Department  of  Basic  Education  2014:71)  as  it  enjoys  official  status  and serves as a common medium of communication amongst people of all ages in all spheres of life in the multilingual context of South Africa and finally, English  is  the  dominant  medium  of  instruction  in  public  schooling  (Uys, Reyneke &amp; Kaiser 2020:ii). This extended role of English in the South African community greatly affects English teacher training at institutions of higher learning in the country.

## The role of English in South Africa and its implications for English teacher training

Based on the extended role of English in South Africa, English teachers need a  high  level  of  disciplinary  knowledge  in  various  subject-related  fields, pedagogical knowledge and pedagogical content knowledge. This requires thorough training in the theory of language teaching and learning, including the theory on second language acquisition, linguistics and all literary genres. Furthermore, English Additional Language (EAL) is the dominant LoLT. It is often perceived as a barrier for learning and thus of learner attainment (DBE 2013:2). English language teachers in South Africa must therefore be equipped with the knowledge and skill to effectively teach and promote learners' basic interpersonal communication skills (BICS) as well as their cognitive academic language proficiency (CALP) (Cummins  2000:67). Basic interpersonal communication skill refers to the language skills that people need for social interactions.  This  language  is  not  specialised  and  the  context  in  which  the language  is  used  is  normally  'rich',  in  other  words,  there  are  embedded interpersonal  cues  such  as  facial  expressions,  gestures  and  intonation  that help with understanding and communicating a particular message. Cognitive academic  language  proficiency,  on  the  other  hand,  develops  in  formal academic settings such as classrooms, where activities such as demonstrations, scientific  experiments,  calculations  and  explanations  take  place  as  subject content is taught and learned. The context is reduced as there are fewer nonverbal cues and the language is more abstract (Uys et al. 2020:17-18). It is important for English language teachers to note the difference between BICS and  CALP  development  and  to  support  learners  in  academic  language learning.  Van  der  Walt  and  Evans  (2019:xiii)  note  that  the  foundation  of academic  literacy  must  be  laid  in  the  English  classroom  and  remark  that English language teachers are often 'perceived as, or unwillingly made, the gatekeepers  to  further  higher  education  since  a  certain  level  of  English proficiency  is  required  for  successful  study  and  training  after  school'.  It  is

important for English teachers to be aware of these expectations and to be prepared to justify their decisions in terms of assessment (Van der Walt &amp; Evans 2019:23), content and pedagogy.

As far as pedagogy is concerned, student teachers have to learn how to teach each  component  of  an  English  school  curriculum  in  culturally  and linguistically diverse settings. This implies that student teachers, in preparation for teaching English literary texts in the South African context, ought to be challenged  to  critically engage  with  the  curriculum,  heeding  calls  for decolonisation  and  the  appreciation  of  indigenous  knowledge.  Kramsch (1993:357)  believes  that  there  are  benefits  to  be  derived  from  a  language pedagogy  that  does  not  only  present  authentic  documents  but  also  the contexts of production and reception. The teacher thus focuses on the  circumstances  in  and  the  purposes  for  which  a  text  was  produced ( context of production ) as well as the different interpretations by readers or hearers of a text ( context of reception ). It is important for learners in diverse contexts to experience that different interpretations are possible and valid and that different opinions are valued and not criticised as they contribute to academic  discourse.  This  allows  learners  at  school  and  English  student teachers  to  develop  their  voices  in  expressing  their  understanding  and  in defending their interpretations, also during formal assessments. Linked to the notion  of  diversity,  Van  der  Walt  and  Evans  (2019:17)  caution  that  English teachers should constantly be aware of other languages around them and when they teach English, they should realise that their learners also use other languages and different patterns of thinking, even as they complete tasks in English.  Whilst  literature  is  seen  as  a  cultural  artefact,  it  is  important  to remember that culture is dynamic and that what is valued in one culture is not necessarily valued in another culture (Van der Walt &amp; Evans 2019:211).

Violetta-Irene (2015:75) and Dominguez Romero, Bobkina and Stefanova (2019:36) argue that literature is taught for three main reasons. The first is to build language proficiency (focus on linguistics), the second is to develop learners' critical thinking (focus on methodology) and the third reason why we teach literature is to raise learners' awareness of the human condition (motivational reason). Van der Walt and Evans (2019:215) add that literature has a social function (it is a socially acceptable way of communicating and by  studying  various  texts,  learners  learn  about  the  history,  society  and politics of the setting); literature is stimulating and interesting; it engages the  imagination  and  creativity  of  learners;  it  is  a  vehicle  for  language enrichment and vocabulary acquisition; and it gives depth and meaning to the language learning experience. With specific reference to English literature study in South Africa, these authors highlight the fact that literature teaching and learning can lead to cultural enrichment and insight into human nature (Van der Walt &amp; Evans 2019:215). They argue that literature studies promote

multicultural  understanding,  which  plays  an  important  role  in  a  budding democracy. English teachers can only realise these aims of literature teaching when they are self-directed in their search for and analysis of appropriate texts in terms of linguistic value and their suitability to promote both critical thinking  and  understanding  of  the  human  condition.  With  this  goes  the ability to implement assessment aimed at the promotion of learning in each of these aspects.

The arguments above highlight the fact that English language teachers in South Africa ought to be prepared to teach English Home Language (EHL), EFAL  as  well  as  English  across  the  Curriculum,  empowered  by  deep disciplinary knowledge across various components of the different language curricula and in a variety of subject-related fields. They furthermore require critical  language  awareness,  thorough  knowledge  of  language  pedagogy (which includes theories on language acquisition and a variety of methods and approaches to language teaching that developed over time), and a high level  of  assessment  literacy  in  order  to  promote  learners'  meaningful engagement with content and the acquisition of listening, speaking, reading and  writing  skills.  The  English  language  teacher's  ability  to  implement assessment practices that are of a high quality and that drive sustainable learning becomes particularly important in the FET phase (Grade 10 to Grade 12).  It  is  during  this  phase  that  English  is  seen  as  'a  tool  for  thought  and communication', 'a cultural and aesthetic means' that learners use 'to make better sense of the world they live in', a medium to 'acquire knowledge, to express identity, feelings and ideas, to interact with others, and to manage their world' (DBE 2011:8). In a general education context, the term 'assessment literacy'  refers  to  the  knowledge  teachers  should  have  about  assessment (Berry, Sheehan &amp; Munro 2019:113). In practical terms, this means that the teacher should have a clear understanding of what should be assessed and how it should be assessed. In the context of the language classroom, it is about understanding what should be assessed and how it should be assessed in  effectively promoting the acquisition of linguistic knowledge and skills. The implication is that the language teacher must be able to evaluate diverse learners' individual responses to and interpretations of texts and give due credit. Language assessment is never as exact as is the case in, for example, the sciences.

Subsequently,  the  third-year  English  for  Education  modules  of  a  higher education institution in South Africa are examined to explore how they have been  designed  in  the  quest  for  critical  student  engagement  to  advance cognitive and affective student development in preparation for the practice of English language teaching in the FET phase. The ways in which assessment contributes to quality teaching and learning and SDL in these modules are emphasised.

## English teacher training in the third year of the B.Ed. Senior and Further Education and Training phase at a higher education institution in South Africa

As pointed out above, Chong and Cheah (2009:16) emphasise that SDL should be established and nurtured during initial teacher training. They argue that it is during this phase that teachers are equipped for lifelong learning in an everdemanding professional environment, and where they 'develop a problemsolving  attitude'  and  the  skill  'to  learn  from  experience  through  reflection' (Chong &amp; Cheah 2009:16). The call for the developers of the English curriculum at this particular institution was to set outcomes that would ensure student immersion in quality, albeit cognitively challenging, learning experiences to unlock and promote their academic potential and their personal growth in preparation for the profession. As the third-year modules in the B.Ed. Senior and FET programme, which are offered in contact as well as distance mode, are  rolled  out  each  year,  the  presenters  carefully  plan  the  programme  of assessment, fully aware of two important facts: students' academic performance  and  development  and  the  curriculum  are  dependent  on  the assessment of the students (Mohan 2016:33) and instructors have to model the characteristics of good teachers (Burns 2011:133).

## Outcomes of the English for Education third-year modules

The English for Education course at the selected university exposes students to linguistics, literature and didactics, which all become progressively more advanced from the first to the fourth year of study. This English for Education course  follows  an  integrated  approach,  where  didactics  and  content  are learned in tandem and not as isolated strands of the teaching course. During the first semester of the third year, the students:

- · learn about semantics and pragmatics
- · critically analyse the novel Disgrace by J.M. Coetzee
- · engage with a variety of short stories, with a focus on applying literary lenses
- · critically analyse the play Julius Caesar by William Shakespeare.

In the second semester of the third year, students:

- · learn about tenses and textual editing
- · critically analyse the novel The God of Small Things by Arundhati Roy
- · critically analyse the novel Atonement by Ian McEwan
- · analyse a variety of postmodern poetry
- · develop their teaching skills, with a specific focus on teaching visual literacy.

It is thus clear that these third-year students are expected to develop extensive knowledge of the English language and to develop their skills as teachers of the language.

Before elaborating on how high-quality learning experiences are ensured, it is necessary to provide a brief overview of the outcomes for these third-year modules. In the first semester, the outcomes include:

- · accounting for the central concepts in semantics
- · accounting for the difference between semantic and pragmatic meanings
- · analysing words and sentences using semantic methods and concepts
- · offering opinions on the actions and characters in the novel Disgrace
- · discussing  the  major  themes  and  symbols  in Disgrace and  how  these contribute to the message of the novel
- · applying literary theories to short stories
- · understanding  the  themes,  characters,  language,  background,  literary devices and dramatic devices of the play, Julius Caesar
- · having awareness of the major critical debates around the play.

## The outcomes of the second semester include:

- · knowing why EFAL learners struggle with tenses
- · designing worksheets that are suitable for learners, focused on the tenses
- · applying the rules of grammar and editing common errors in texts
- · differentiating between modern and postmodern literature, with a specific focus on poetry
- · understanding  how The  God  of  Small  Things qualifies  as  a  postmodern novel
- · evaluating the unique writing style of Arundhati Roy as proof of her own voice
- · discussing the political and social structures in The God of Small Things
- · evaluating Atonement as a postmodern novel, specifically focusing on the text as a metafictional work
- · applying knowledge of linguistics to a novel
- · designing  pre-,  whilst-  and  post-reading  activities  for  a  visual  literacy lesson
- · assessing visual literacy effectively
- · designing an entire visual literacy lesson plan.

Even though not all of the outcomes of the third-year modules are included in the previous paragraph, it is clear that these outcomes address a variety of skills and various cognitive levels of performance. It is apparent that students are expected to perform at higher cognitive levels by analysing, evaluating and  creating  (Anderson  et  al.  2001:149).  Encouraging  the  development  of critical thinking is a prominent characteristic of quality teaching and learning.

It is thus necessary to explore how these modules ensure high-quality learning experiences whilst developing students' SDL skills.

## High-quality learning experiences promoting critical engagement and self-directed learning

Tadesse, Manathunga and Gillies (2018:2) state that quality is a complex and multifaceted concept. It is therefore necessary to determine what qualifies as high-level  teaching  and  learning.  Tadesse  et  al.  (2018:2-3)  conducted  a qualitative study for the purpose of determining what Ethiopian students and lecturers believed constituted quality teaching and learning. One of the main themes contributing to students' perceptions of ideal quality teaching and learning  was  that  they  desired  an  active  and  participatory  approach  to teaching  and  learning  (Tadesse  et  al.  2018:4).  In  their  interviews,  students used  terms  such  as student-centred, problem-solving, group  learning, independent  learning,  hands-on  learning  and  interactive  instruction to describe  their  views  of  ideal  quality  learning  and  teaching  (Tadesse  et  al. 2018:4).

The  third-year  modules  of  the  selected  higher  education  institution  in South  Africa  promote  outstanding  teaching  and  learning  in  that  they  are developed to encourage discovery learning, which is indeed student-centred, as active engagement with content and peers is required. For each module, the  English  for  Education  students  are  provided  with  an  Evidence  of Performance (EP), which is a SDL workbook. In contrast with the traditional study guides, which contain merely theoretical information, the EPs contain theoretical  information  combined  with  prompts  to  help  students  come  to their  own  conclusions  and  understandings of the topics. Students are also provided with ample resources (articles, videos, PowerPoints, websites, peer discussions, etc.) to consult, as they are expected to critically engage with resources  and  peers  to  successfully  complete  the  EP.  Two  brief  examples (Figure 8.1 and Figure 8.2) from the EP for the first semester of the third year are provided:

The first  example  indicates  that  students  are  expected  to  do  their  own research  and  apply  the  research  to  the  content  of  the  module  in  order  to come to their own interpretation of the concepts. The second example requires learners  to  draw  on  their  personal  experiences  and  opinions  to  realise  the real-life importance of learning and teaching the content. Both of these brief examples illustrate that the EPs demand active involvement from the students. Additionally, the type of tasks and questions provided in the EP encourage active participation and independent learning, and are student-centred, which are characteristics of high-quality learning and teaching (Tadesse et al. 2018:4). In most instances, the EPs are not used for assessment by the lecturer, but

## Activity 8

Why should teachers of English be familiar with grammar structures?

How was grammar taught at your school?

What do you think? How should grammar be taught?

Suggest reasons why some teachers are reluctant to teach grammar.

FIGURE 8.1: Processes of semantic change: Self-study (Example 1).

1.6. Processes of semantic change: self-study: As we can see from our discussion so far, words do not have an absolute sense, as their meanings differ across cultures and across time. Conceptual sense is the most stable, but even here there are a variety of ways in which the meaning of a word may change over time. This branch of semantics that has to do with these changes of words over time, is called diachronic semantics. There are a few of these processes, namely extension, limitation, pejoration, amelioration and transference.

1.6.1 Do self-study and find out what these processes entail as well as general examples for each. Now, try to find examples of words from your set works which have been subject to these processes. Use the space below to record your research (Romylos, Kaiser &amp; Cushman 2020a:25-26).

Process

Explanation

Example

Example from

set works

Extension

Limitation

Pejoration

Amelioration

Transference

FIGURE 8.2: Pertinent questions: Speaking and writing (Romylos et al. 2020a:18-19).

rather serve as students' SDL guides. In the study conducted by Tadesse et al. (2018:5),  the  researchers  found  that  lecturers  viewed  quality  teaching  and learning as students being facilitated and guided so that they could organise their own learning, make their own notes and learn by themselves. In this way, lecturers  model the type of practice that would be expected from English language teachers in working towards realising the general and developmental aims and the subject-specific outcomes of the CAPS for EHL and EFAL in the FET phase (DBE 2011). Even though the third-year modules at the particular higher education institution also rely on direct instruction to a limited extent, students are provided with sufficient guidance and structure to direct their own learning. Additionally, during the direct instruction sessions, students in the  contact  programme  are  seated  at  round  tables  and  engage  in  group discussions and activities, which also enhances quality teaching and learning in that active engagement and participatory learning are ensured. Interaction amongst the distance learning students is also promoted, as they are expected to participate in online video discussions with peers and lecturers and to work together on written group tasks.

In addition to providing opportunities for interaction during learning and teaching and providing students with prompts to direct their own learning, using a variety of teaching and learning methods also contributes to quality learning and teaching (Loughran 2018). The third-year English for Education course caters for various learning styles: students are expected to provide their opinions on particular topics in writing (in the EP), as well as verbally (during contact sessions). Students are also expected to present posters in groups,  plan,  prepare  and  present  micro-lessons,  enact  scenes  from  their plays,  write  traditional  tests,  write  academic  essays,  conduct  online  group debates and so on. Thus, students are exposed to various learning opportunities whilst, likewise, teaching varies from facilitation, direct instruction and concept capturing with the use of electronic platforms. In addition to this, the learning management system used by the students at this university contains sites for each  individual  module.  The  sites  for  the  English  for  Education  students contain electronic sources (articles, videos, quizzes, online forum discussions, etc.) that support what is contained in the EP. Students are expected to not only  decide  which  information  in  these  resources  should  be  used  for  the completion  of  specific  tasks  but  also  to  find  their  own  resources  in  many instances, as previously indicated in the first example from the third-year EP. The online platform that contains a vast array of resources that students can consult is also used by the distance students to interact with their peers. Thus, various resources, teaching methods and learning opportunities ensure a wellbalanced,  high-quality  teaching  and  learning  experience.  Moreover,  this promotes SDL as students are encouraged to select which resources they would like to consult in an effort to successfully complete the EP or other

activities  (learning  goals),  which  enhances  student  autonomy  (Knowles 1975:18). Students are also encouraged to employ various learning styles as a means to meet the learning goals (Knowles 1975:18). Organising one's own learning also calls for critical thinking skills.

According to Soulé and Warrick (2015:183), higher cognitive thinking and personalised learning are essential components of learning in the 21st century. In  a  study  conducted with first-year English for Education students at this higher education institution, it became apparent that students did not have sufficient critical thinking skills necessary to perform the cognitively demanding tasks of the English course (Strydom 2020:70). Insufficient critical thinking skills also signifies a lack of self-directedness, as these two concepts are interdependent (Paul &amp; Elder 2005:7). It is thus vitally important that the English for Education modules challenge student teachers to think critically and learn independently, as these are skills they will have to apply to cope with 21st-century teaching and learning and that they will have to develop in their future learners (Guglielmino 2013:2). The EP, online learning management system site and contact sessions contain pertinent questions at the start of each instructional unit. These pertinent questions prompt students to think critically,  as  they  are  open-ended  and  require  students  to  evaluate  various responses before providing their own. An example of such a pertinent question in the didactics unit of the second semester is: 'Do you believe visual literacy should form an integral part of the English (EFAL and EFL) FET phase CAPS? Justify  your  answer'  (Romylos  et  al.  2020b:82).  Such  questions  enhance students'  critical  thinking  skills  and  ensure  active  engagement,  as  these questions are discussed in groups during contact sessions.

## Quality assessment that enhances critical engagement and self-directed learning

This section explores four characteristics of assessment that enhance critical engagement  and  SDL.  Winstone  and  Carless  (2020:3)  postulate  that  SDL requires receiving and interacting with feedback. Thus, the first characteristic explored  in  this  section  is  effective  feedback.  Secondly,  to  encourage independent learning, assessment should be innovative and cater for a variety of 21st-century students (Tadesse et al. 2018:10). In addition, critical thinking, which encapsulates problem-solving and the assessment thereof, is necessary for improving one's learning (Paul &amp; Elder 2005:7) and is discussed thirdly. Lastly, the importance of assessing content holistically, which often reveals the real-life relevance of the content (Deneme &amp; Ada 2010:9; Murthy &amp; Ram 2015:102), is discussed. Table 8.1 below provides an overview of how each of these  assessment  characteristics  enhances  SDL,  as  well  as  guidelines  that could be applied across the curriculum to ensure quality, self-directed learningdriven assessments.

TABLE 8.1: Guidelines for employing the four characteristics of quality assessment to enhance self-directed learning.

| Characteristics of  quality assessment     | Link to the development of SDL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Guidelines when creating assessment  opportunities                                                                                                                                                                                                                                                                                                                                    |
|--------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Effective feedback                         | Feedback is defined as a process in  which the students gain insight into the  differences and similarities of the expected  standards for learning and the quality  of their work, in order to improve their  performance in future assessment tasks  (Boud &amp; Molloy 2013:6). Additionally, Morris  (2018:637) states that feedback enhances  independent learning. Feedback is thus  used to reflect on one's learning progress,  which is integral to SDL.                                                                                                                                                                                                                                                          | •  Use multiple sources of feedback  (Hamilton 2019:571), such as peer  feedback, feedback from rubrics,  immediate lecturer feedback, etc. •  Ensure students' active  engagement with and  interpretation of the feedback  (Winstone &amp; Carless 2020:8).                                                                                                                             |
| A variety of  innovative  assessment tasks | Costa and Kallick (2004:2) state that  alternative and authentic assessments  are required for the assessment of self- directedness. Moreover, because of the  ever-changing educational environment,  adapting and varying assessments are of  utmost importance (Greenstein 2012:2).  Providing students with a variety of  innovative tasks will ensure that all learning  styles are accommodated and will ensure  adaptability, which is necessary for the                                                                                                                                                                                                                                                        | •  A variety of task types should be  given to ensure that a variety of  skills are assessed, for example  longer writing pieces, oral  assignments, electronic posters or  websites, group performances or  debates, traditional tests, etc. •  Set assessment tasks that allow  students to be creative and  innovative, whilst realising the  real-life value of the skill/s being |
| Critical thinking and  problem-solving     | Cash (2017:2) postulates that critical  thinking skills will enable students to  maintain functional relationships, manage  individual goals, make wise choices  and participate meaningfully to society.  Additionally, Geisinger (2016:246) states  that 'problem-solving skills are essential in  a rapidly-changing world'. Thus, to develop  one's SDL skills, one should have the ability  to manage one's learning goals and employ  strategies to solve problems that arise  during the learning process.                                                                                                                                                                                                      | •  Set assessment tasks that allow  students to do their own research,  evaluate the resources and  come to their own conclusions.  These tasks are usually set on  the analysing, evaluating and  creating levels of Bloom's Revised  Taxonomy (Anderson et al.  2001:149). •  Set assessment tasks that allow  for a variety of responses to a  particular problem or scenario,     |
| Integration of topics  and their relevance | According to Arndt (2017:38), SDL requires  students to make decisions about how  to progress their learning beyond the  traditional classroom context. In addition  to this, Schleicher (2012:34) says that the  integration of various skills and disciplines  is a characteristic of the 21st century.  Self-directed learning is not restricted to  monitoring one's learning progress in an  isolated task or topic but rather manifests  as reflection on one's overall learning (Arndt  2017:45), which includes one's ability to  make connections amongst various strands  of knowledge and skills. Moreover, SDL  entails monitoring one's learning progress in  real-world situations (Greenstein 2012:22). | •  Ensure that students are expected  to make connections between  different topics and skills in your  subject, but also topics and skills  outside the discipline. •  Make certain that the integration  of topics and skills will allow  students to see the relevance of  the topic and/or skill in its real- world context.                                                      |

Additionally, more detailed accounts of each of the four characteristics are provided.

## Feedback 2

Feedback could be described as a process where students obtain information about completed tasks or activities so as to gain insight into where they met, exceeded and fell short of the expected standards of a task (Boud &amp; Molloy 2013:6). Feedback then provides information on the quality of the student's work in order to improve performance in future learning tasks (Boud &amp; Molloy 2013:6). In the study conducted by Tadesse et al. (2018:8), student participants complained that they never received feedback on their assessments - they only saw their scores. In light of this, Bull (2017:15) avers that learning is rarely successful if no feedback is provided. In the English for Education course, a variety of feedback methods are employed after or during assessment. Some examples from the third-year modules are provided in the next paragraph.

Before elaborating on the use of rubrics as a valuable source of feedback, it is also necessary to understand the link between interpreting these rubrics and developing SDL skills. Self-directed learning requires feedback to inform the learning process (Costa &amp; Kallick 2004:2; Jossberger et al. 2010:430). In the study conducted by Strydom (2020:60) with first-year student participants from the English for Education course, it became apparent that feedback was the  main  catalyst  for  students'  engagement  in  SDL,  thus  highlighting  the necessity for feedback in ensuring quality assessment that improves learning. However,  whilst  providing  feedback  is  essential,  it  is  just  as  important  for students to actively seek feedback and to critically engage with it. Winstone and Carless (2020:8) emphasise that feedback is effective when there is a combination of being presented with valuable input and interacting with the received input. Thus, it is not enough to merely receive comments as feedback, unless the feedback is interpreted and there is interaction with the feedback to improve future learning. This underscores the importance of feedback as part of  the  SDL  process,  where  the  student  is  responsible  for  active  engagement throughout the learning process so that future learning can be improved and adapted.  This  interaction  is  expected  when  students  receive  rubrics  as  a source of feedback.

In the English for Education course, feedback is mostly generated from the use  of  analytic  rubrics.  Analytic  rubrics  with  fixed  criteria  and  clear  level descriptors are primarily used as assessment tools in language teaching as they  clearly  express  the  level  of  performance  expected  for  an  assignment

(Winterscheid 2016:6) and allow for better feedback on multiple aspects of students' language performances (Brown 2017:24). Most of the assessment tasks  are  on  higher  cognitive  levels  and  require  the  students  to  analyse, evaluate and create. Prominent examples of the type of assessment tasks that are  assessed  with  analytic  rubrics  include  academic  essays,  PowerPoint presentations,  mock  trials,  mini-newspapers  and  speeches.  In  the  study conducted by Strydom (2020:65), first-year English for Education students were  observed  during  contact  sessions.  The  researcher  found  that  in  all instances,  students  were  provided  with  the  rubrics  that  would  be  used  to assess particular tasks (the rubrics were either included in the EPs, shared with students during contact sessions or provided on the learning management system)  (Strydom  2020:65).  Sharing  the  assessment  tools  as  a  means  of ensuring transparency regarding assessment is common practice during all years of English teacher training at this specific institution. It was shocking to find,  however,  that  the  first-year  student  participants  did  not  refer  to  their rubrics as sources of feedback (Strydom 2020:65). The study highlights that feedback can only effectively feed back into the learning process and enhance SDL once students become active assessment agents in their own learning processes. What is needed from students is to interpret and actively engage with  feedback,  for  example,  study  level  descriptors,  and  to  reflect  on performance in order to obtain a clear understanding of what needs to be done to fill gaps between poor and good performance.

Another  form  of  feedback  often  employed  in  English  for  Education  is peer feedback. Working in groups or pairs is in and of itself a valuable form of feedback (Wind 2018). If students are actively involved in the completion of the group or pair assignment, they will receive feedback from their peers whilst working on the task. Peer feedback is a valuable learning tool and should serve as assessment that takes place continuously during the learning process  and  not  merely  after  assignment  completion.  In  the  English  for Education course, students are encouraged to work in groups or pairs on a regular basis. For example, in the first semester of the third year, students are expected to, in pairs, write a dialogue between a student and lecturer, in which  the  student  flouts  Grice's  maxims  of  quantity,  quality,  relation  and manner. The students are expected to role play the dialogue for assessment by the lecturer. In the second semester, students are expected to work in groups  of  four  and  to  select  (from  a  list  provided  by  the  lecturer)  two discussion  points  on Atonement to  discuss  and  present  in  their  groups. Whilst the contact students may perform this during contact sessions, the distance  students  are  expected  to  organise  Zoom,  Google  Meet,  and/or Skype  sessions  and  record  their  live  group  discussions.  These  are  two examples from many. Nonetheless, students are expected to actively engage with peers during group work, which serves as a form of feedback during task completion.

A  similar  form  of  feedback  that  features  in  the  third-year  modules  is the  lecturer  providing  immediate  feedback  whilst  assessing.  For  example, the English for Education students receive holiday assignments to complete before commencement of the following semester so that they have ample time to read the prescribed novels and actively engage with the content. The holiday assignment for the third-year, second semester module, contains a question that requires students to select a character and theme from The God of Small Things . During a live broadcast via Google Meet, students then, in smaller groups, present their individual character analysis and exploration of the theme to their peers and their lecturer, who is also present in the online session.  Each  student  is  then  expected  to  answer  two,  thought-provoking questions  that  the  lecturer  asks  after  the  student's  presentation.  For  the contact students, this usually takes place in face-to-face group sessions with the lecturer. It is during such live sessions that the lecturer provides immediate feedback on students' responses and interpretations of the novel. This then serves as an example of immediate, verbal feedback during assessment. Thus, it  is  clear  that  various  forms  of  feedback  are  used  to  inform  the  learning process and to ensure quality learning. However, because of students' lack of exposure to critically engaging with feedback at secondary level (Strydom 2020:56), students do not always know how to reflect on, interpret and use the feedback they receive.

## A variety of innovative assessment tasks

Another characteristic of quality assessment, as mentioned by the student participants in Tadesse et al.'s (2018:10) study, is that assessment should be innovative.  This  also  denotes  that  a  variety  of  tasks  that  assess  various language skills should be incorporated. In the English for Education course, students are assessed not only on their writing skills but also their speaking skills. A variety of assessment tasks do not only ensure that various learning styles are accommodated, but also that all linguistic skills are assessed whilst maintaining innovation and creativity. Examples of creative writing assessment tasks in the first semester include writing a paragraph on how his/her selfimage  was  formed  and  whether  he/she  thinks  that  this  self-image  is  an accurate view of his/her character (in response to the short story The Lady in the  Looking-glass:  a  Reflection by  Virginia  Woolf);  writing  a  diary  entry  in which he/she reflects on Um Sabir's role as a woman in an Egyptian society (in response to the short story Sandpiper by Ahdaf Soueif); designing a mininewspaper in groups, where each group member is responsible for a different article  (in  response  to  prominent  themes  and  issues  in Disgrace by  J.M. Coetzee);  rewriting Brutus' speech  by  incorporating  rhetorical  devices (in response to Shakespeare's Julius Caesar ); and analysing the visual literacy questions in a previous Grade 12 EFAL exam paper. In addition to this, students

also write tests, especially on linguistics. These tests also incorporate creative questions that require students to apply their linguistic knowledge in particular contexts.

As mentioned, students are not merely assessed on their writing skills, but also on their speaking skills. Creative speaking assessment tasks include:

- · A live PowerPoint presentation (the distance students add voice-overs to their presentations) on the themes and symbols apparent in Disgrace.
- · A mock trial on Disgrace (for this task, students perform the mock trial at the  law  faculty  and  they  are  expected  to  dress  appropriately,  use  the correct law terminology and fulfil their respective personas - they should enact a real trial, with David Lurie accused for the rape of Melanie Isaacs).
- · Creating posters on Padlet (an online platform for creating posters and pages) and add voice notes to these posters.
- · Conduct group discussions on specified discussion points on Atonement .

It is clear that students are exposed to a range of assessment tasks that play to different strengths and assess different skills. This is in contrast to what the literature reveals about English assessment at secondary school level. In most classrooms, learners are not exposed to a variety of innovative assessments, but rather coached for high-stakes examinations, which leads to assessment tasks that replicate probable examination questions (Berry 2011:98; Kapp &amp; Arend 2011:8;  Reyneke  2016:1).  This  denotes  that  assessment  at  secondary level does not encourage learners to think critically.

## Critical thinking and problem-solving

According to education experts, assessment is shallow if it does not promote critical  thinking  and  problem-solving  skills  (Reyneke  2016:1;  Tadesse  et  al. 2018:8). Most first-year student teachers in South Africa are not self-directed learners, as they favour 'spoon-feeding' to approaches that promote critical thinking, active engagement and lifelong learning (De Beer &amp; Gravett 2016:46). This is a result of a secondary education system where too much emphasis is placed on rote learning in preparation for high-stakes examinations (Breed 2016:1;  Chetty  2015;  Frempong,  Reddy  &amp;  Mackay  2013;  Reyneke  2016:1).  In light of this, the study conducted by Strydom (2020:86) found that first-year English  for  Education  students  were  challenged  to  critically  engage  with assessment tasks, but that they did not know how to do so effectively. With critical thinking being a prominent criterion for assessment tasks in the English for Education course, it is necessary for students to develop critical thinking skills that allow them to engage with the content actively and deeply.

The type of assessment tasks that students are expected to complete at a third-year level are dependent on critical thinking for successful execution.

In every semester of the English for Education course, students are expected to write academic, research-based (from the second year onwards) essays. Below  is  a  list  of  the  academic  essay  topics  on The  God  of  Small  Things , provided to the third-year students in 2020 (these topics change every year) (Romylos et al. 2020b:40):

- 1. Gender inequality is no doubt prevalent in the novel. However, this inequality is not just supported and accepted by the men, but also by some female characters. Discuss this statement in an essay of 1000 words. Provide your essay with its own title.
- 2.  Love  between  man  and  woman  is  a  failed  union  when  considering  the relationships  in  the  novel.  Argue  this  point  in  an  essay  of  1000  words. Provide your essay with its own title.
- 3.  Consider  the  following  statement:  The  politics  of  Baby  Kochamma, Inspector Matthew and of K.N.M. Pillai in relation to Ammu and Velutha highlight their own interest in self-preservation at the cost of Ammu and Velutha's lives. Discuss this statement in an essay of 1000 words. Provide your essay with its own title.

Students  are  also  expected  to  use  at  least  two  sources  in  addition  to  the primary source, which is the novel. These essay topics require students to consider a variety of stances, to do research to inform their opinions, to select a  thesis  statement  for  the  topic  and  to  develop  arguments  to  support  the thesis statement. In addition to this, students are expected to reference their sources correctly and to write coherently and grammatically correctly. This assessment task requires higher-order cognitive skills and the application of a variety  of  skillsets.  It  also  encourages  the  development  of  SDL  skills,  as students are obliged to find sources that could assist them in attaining the learning goal (Knowles 1975:18). They also have to make decisions regarding the topic selection, the planning of the essay (using the most effective learning style), the inclusion or exclusion of sources and information, the arguments that will contribute to the thesis statement and so forth.

All the assessment tasks of the third year require and develop students' critical thinking skills in different ways. English for Education students write linguistics tests every semester, with the linguistics becoming progressively more complex with each semester. The questions included in these 'traditionaltype' tests encourage students to analyse, evaluate and create. For example, students  are  expected  to  add  their  own,  specific  types  of  phrases  and/or clauses to sentences; classify sentences according to their clausal structure; evaluate specific fictitious classroom scenarios and assist 'learners' with the errors they made; and rewrite whole, contextual passages in reported speech in an authentic manner. Additionally, more creative assessment tasks such as the Disgrace mock trial and the Disgrace mini-newspaper encourage the use and development of critical thinking skills. For the mock trial, students are

expected  to  assign  various  roles  to  their  group  members  (analysing);  do research on these roles, the terminology and the procedures of real-life trials; conceptualise coherent arguments for and against David Lurie's accusation; closely study the characters that they have to represent; practise performing the mock trial (this includes effective presentational skills); and, eventually, perform the mock trial in front of a panel of lecturers and their peers, acting as  the  audience.  This  assessment  task  encapsulates  every  level  of  Bloom's Taxonomy as students are expected to remember, understand, apply, analyse, evaluate and create (Anderson et al. 2001:149). This once again confirms the importance of developing critical thinking skills to perform at the expected level in the third year of English for Education. One way, in which assessment tasks that develop critical thinking skills are ensured, is to integrate the topics being  studied,  as  opposed  to  teaching  and  assessing  these  as  isolated components of language (Deneme &amp; Ada 2010:9; Murthy &amp; Ram 2015:102).

## Integration of topics and their relevance

In order to ensure quality assessment and learning, various strands of studying the English language should be assessed and taught in an integrated manner that  reveals  the  real-life  relevance  of  these  topics  (Deneme  &amp;  Ada  2010:9; Murthy  &amp;  Ram  2015:102).  In  Tadesse  et  al.'s  (2018:6)  study,  an  educational expert mentioned that practical skills and theoretical knowledge need to be well  integrated  to  ensure  quality  teaching,  learning  and  assessment.  In addition,  Goodman  (2015)  maintains  that  teaching  through  relationships embeds formal knowledge in the world in which it actually exists and from which it originates. This places emphasis on considering the context within which the particular topic/s could be encountered in real-life situations. In the English for Education course at the particular higher education institution, the assessment  tasks  signify  real-life  application  of  the  skills  being  learned (examples  follow  in  the  next  paragraph).  Additionally,  language  skills  are assessed in an integrated way (e.g. with the Disgrace PowerPoint presentation, speaking skills and writing skills are assessed simultaneously). In addition to this,  the  language  topics  being  taught  are  also  integrated  to  ensure  that students make meaningful connections amongst the various topics.

If one  considers  the  linguistics  tests  that  the  third-year  students  are expected to write in the second semester, it is apparent that the questions situate the content (tenses and textual editing) in the real-life scenarios the student teachers will encounter in their future careers, for example: Mr Ndala teaches his learners the present indefinite tense and informs his learners that the time word, 'always', is associated with this tense. Comment on why this may  confuse  learners  by  referring  to  examples . This  clearly  situates  the students in a probable classroom scenario, whilst expecting them to apply their  knowledge and skill pertaining to the content (tenses). Moreover, the

language questions are not asked in isolation, devoid of context, as is usually the norm with traditional language tests. These tests include questions that are  based  on  extracts  from  the  prescribed  literature  of  the  semester,  thus integrating language and literature (as suggested by CAPS for EFAL Grade 10 to Grade 12) (DBE 2011:15) so that a meaningful context is created for language assessment.  For  example,  a  particular  question  provides  students  with  an extract from Atonement and students are expected to comment on the use of the past tense in this extract and to indicate in which instances other tenses could have been applied successfully. The dialogue assessment task, where students are expected to create and perform a dialogue between a student and lecturer in which the student flouts Grice's maxims of quantity, quality, relation and manner, is also an example of how language is assessed in an integrated  way,  with  its  relevance  made  apparent.  In  this  assessment  task, students are placed in a real-life situation (a conversation between a student and  lecturer)  and  expected  to  apply  the  content  knowledge  and  skills  in context. Assessment tasks such as these force students to make connections amongst various topics of study and to see the everyday relevance of the content  and  skills  they  are  learning.  These  assessment  tasks  also  allow lecturers  to  assess  students'  critical  thinking  skills  as  opposed  to  merely applying remembered or studied rules and content.

Thus, the third-year English for Education modules at the particular higher education institution ensure quality assessment and the development of SDL skills  in  that  feedback  is  regarded  as  essential,  a  variety  of  innovative assessment tasks are administered, critical thinking skills are developed and language is assessed in an integrated manner, which ensures that the real-life relevance of the tasks become apparent.

## Conclusion

Quality English teacher training in preparation for teaching the language as a tool for communication in diverse linguistic and cultural societies (promoting learners' BICS) and as an academic language (promoting learners' CALP) that is used across the curriculum places a huge responsibility on the shoulders of teacher  trainers  at  institutions  of  higher  learning  in  South  Africa.  Student teachers should become aware of the fact that English language teachers are often 'perceived as, or unwillingly made, the gatekeepers to further higher education since a certain level of English proficiency is required for successful study  and  training  after  school'  (Van  der  Walt  &amp;  Evans  2019:xiii)  and  that proficiency in English not only helps to secure jobs but also allows for active participation in international business, trade and commerce (Rao 2019:65). In South  Africa,  where  English  is  not  only  taught  and  learned  for  functional purposes (as a tool for communication and education, addressing proficiency in listening, speaking, reading and writing) but also for aesthetic purposes for

example in literature study, student teachers have to be prepared to equip their learners with linguistics and literary knowledge and skills, as well as the ability to think critically, solve problems and consider various opinions of and approaches to any particular topic. Attaining these high-level outcomes in English  teacher  training  requires  quality  assessment  that  promotes  critical engagement and SDL. In addition, it is important for teacher educators to model to the students the type of practice that educators would like to see being implemented in English classrooms in basic education (Burns 2011:133).

This chapter considered the third-year English for Education modules at a particular  tertiary  education  institution  to  establish  how  teaching,  learning and the curriculum can be structured to enhance quality assessment and SDL. Four characteristics of quality assessment were highlighted in the discussion. Firstly, feedback, which necessitates active engagement by the student, was discussed as a vital component of quality assessment and SDL. Additionally, a variety  of  assessment  tasks  that  encourage  critical  thinking  and  problemsolving were discussed as components that enhance quality assessment and SDL. Lastly, encouraging the study of language as a holistic field instead of isolated components, as well as making the real-life relevance of the content pertinent were established as contributing factors to quality assessment and SDL. The guidelines provided in this chapter could be used to assist lecturers with the development of quality assessment opportunities for the purpose of developing self-directedness in their students.

## Using digital technology as formative assessments to enhance self-directed learning

## Byron J. Bunt

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Vanderbijlpark, South Africa

## Gideon van Tonder

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Vanderbijlpark, South Africa

## Abstract

With  the  outbreak  of  COVID-19  during  the  first  quarter  of  2020,  several universities found themselves in a situation where their doors were closed and a remote online teaching strategy was adopted. COVID-19 left several academics and lecturers in a constant state of anxiety, where the resounding choir sang, ' But how will we assess our students? ' This prevailing question has

How to cite: Bunt, B. &amp; Van Tonder, G., 2021, 'Using digital technology as formative assessments to enhance self-directed learning', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed  Learning (NWU  Self-Directed  Learning  Series  Volume  7),  pp.  187-215,  AOSIS,  Cape  Town. https:/ /doi.org/10.4102/aosis.2021.BK280.09

merit,  as  lecturers  who  were  used  to  assessing  paper-based  assessments were left puzzled as to how they could effectively carry out assessment tasks and give useful feedback. A critical factor in moving to a digital approach, or online teaching and learning, came with a new need to expose lecturers to several new technological approaches to teaching, learning and assessment. The main aim of the chapter was to determine and explore the consequences of  online  marking  and  feedback  in  a  school-wide  community  of  practice project,  utilising  teaching  strategies  for  the  development  of  SDL  amongst pre-service  teacher  students.  As  SDL  is  the  core  variable,  it  is  crucial  to understand the relationship between adult learning and SDL, which is a topic investigated  in  the  literature  review.  The  literature  review  indicated  that synchronous e-learning was complicated because of a lack of infrastructure. Literature  and  the  findings  revealed  that  feedback  is  only  beneficial  on academic  assignments  if  comments  and  specific  changes  given  to  the students concentrate on the criteria of the assignment rather than just get the correct answer to the student. The students' voice through reflection on feedback has been outlined as well.

## Introduction

In  the  education  sector,  it  is  well  recognised  that  there  is  a  significant interest  in  providing  reliable  and  effective  formative  assessment,  making it a crucial element of learning (Spector &amp; Yuen 2016). According to Bhagat and Spector (2017:314), however, several prior studies focusing on formative assessment did not focus on the use of technology. The use of a technology platform as a tool for online classroom formative assessment is a valuable benefit, as it allows a way to make the subject more engaging and enables students to get detailed individualised feedback. 'Feedback is seen as a process  that  makes  a  difference  to  what  students  do'  (Henderson  et  al. 2019:4). When students' work is returned to them, feedback does not end. Without the student's action, feedback cannot be meaningful. This shift in thought 'from a teaching-centred process to a learning-centred process' suggests  different  ways  of  thinking  about  feedback  quality  (Henderson et  al.  2019:4).  Besides  instant  and  thorough feedback, the application of technology provides valuable  data  to  teachers/lecturers  (Dakka  2015:17) because it provides a quick, visual review if students are making progress or having difficulties. Bhagat and Spector (2017:315) predict that improving students'  achievement,  disposition  and  encouragement  amongst  various subjects could help teachers/lecturers to implement formative assessment. Although  technology  is  increasingly  utilised  when  linking  resources  to student, it can also encourage formative assessments (Robertson, Humphrey &amp; Steele 2019).

Several applications could be considered such as Adobe Acrobat comments and  emphasis  on  feedback  aspects  that  affect:  (1)  the  way  feedback  is observed, (2) the recipient's acceptance of it, and (3) the recipient's eagerness to react to the feedback.

## Problem statement

A school-wide community of practice project, incorporating an online digital marking tool to support the development of lecturers' SDL, was launched by the School of Commerce and Social Studies in Education. The question arises how  exactly  lecturers  can  provide  useful  feedback  to  students  after  the marking of formative assessment activities. The COVID-19 pandemic affected the teaching and learning mode of delivery, which changed to remote online learning across the globe. Because of the COVID-19 pandemic, governments and tertiary institutions around the world needed to initiate numerous policy programmes to continue teaching practices in order to contain the spread of the virus. There was uncertainty and disagreement on how to teach, what to teach, lecturers and students workload and the teaching environment because of several academics not being familiar with using technology to teach (Zhang et  al.  2020:1).  During  the  COVID-19  pandemic,  comprehensive  nationwide attempts to use technology as a tool for remote learning (asynchronous), distance  education  (asynchronous  and  synchronous)  and  online  learning (synchronous) were emerging and developing rapidly. Romero-Ivanova et al. (2020:81) explained COVID-19 developed new expectations during the first semester and transformed the lives of individuals  towards  a  'new  normal'. Higher  education  institutions  with  lecturers  and  students  transitioning  to online  synchronous  and  asynchronous  teaching  and  multimedia  activities were impacted by these changes (Romero-Ivanova et al. 2020:81). Most of the lecturers were not familiar with remote learning, especially the use of an online marking tool. The Centre of Teaching and Learning (CTL) (2020) from the North-West University (NWU) provided online training to lecturers who requested to get training to utilise the online marking tool.

How adequately will the digital feedback develop SDL? With this question in mind,  the  study  has  the  following  primary  question:  What  are  the consequences of online marking and feedback in a school-wide community of practice project, for the development of SDL amongst first- to fourth-year pre-service teachers in different subjects within the School of Commerce and Social Studies in Education?

The secondary questions of this investigation were as follows:

- · How self-directed was the first- to fourth-year pre-service teacher students before the intervention?

- · What was the influence of online feedback on students' SDL skills?
- · What  were  the  perceptions  of  pre-service  teacher  students  regarding online feedback?
- · What were the perceptions of lecturers  using  an  online  digital  marking tool?

The use of Adobe Acrobat comments on PDF files, embedded voice notes, feedback through social media, as well as the use of video recordings, will be outlined in this chapter.

The  chapter  subsequently  focuses  on  the  theoretical  and  conceptual framework adopted in the research.

## Theoretical-conceptual framework

As a central element of the theory of adult learning, the authors will explore SDL  (Louws  et al. 2017:171). Mattar (2018:213) explained that 'social connectivism  or  distributed  learning  should  be  considered  as  an  updated version  of  social  constructivism,  understood  as  a  general  philosophy  of education for the digital age'. The authors took that into consideration but decided  to  keep  their  focus  on  social  constructivism  because  of  Mattar's findings (2018) that 'further research is needed to explore the application of social connectivism in education technology'.

Vygotsky's approach of the social constructivist theory was used as a lens by  exploring  the  impact  of  the  Zone  of  Proximal  Development  (ZPD)  and scaffolding  of  learning  with  students  with  the  focus  on  effective  feedback using  technology  as  an  assessment  strategy  to  develop  self-directedness. According to Shabani, Khatib and Ebadi (2010):

[ T/thinspace ]he primary  purpose  of  scaffolding (techniques  used  to move  students progressively toward more robust understanding and, ultimately, greater independence  in  the  learning  process)  in  teaching  and  learning  is  to  assign responsibility for the assignment to the student. (p. 241)

Self-directedness does not mean that learning occurs in isolation, but rather that  a  student  should  work  with  or  without  the  help  of  others  (Brookfield 2009).  The  project  focused  on  the  theory  of  social  constructivism,  which relates  to  collaborative  learning  and  social  interaction  in  order  to  assist  in developing  SDL  (Geduld  2014:15).  Individuals  develop  knowledge  through social  experiences  and  mutual  learning,  which  increase  cognitive  levels (Bozkurk 2017:211).

This  research  concentrates  on  the  following  key  concepts:  SDL,  digital learning, formative assessment and feedback.

## Self-directed learning

As SDL is the core variable in this study, it is crucial to understand what it entails.  According  to  Candy  (1991),  'the  interaction  between  adult  learning and SDL is worth exploring for both theoretical and practical purposes'. Since the term SDL was first formulated by Knowles (1975) almost 40 years ago, several  academic  works  of  literature  have  been  released,  each  including various definitions.

Mezirow (1985:17) specifies that 'no concept is more central to what adult education is all about than SDL'. Knowles (1975) defines SDL as:

[ A ] process of learning in which individuals have the ability to identify their learning needs, set learning objectives, identify human and learning resources, choose and implement effective learning strategies, and assess their learning objectives with or without the support of others. (p. 18)

Self-directed students exhibit several specific and observable characteristics. King (2011:259) listed 'intrinsic motivation, the capacity to choose personal goals, self-discipline, self-assessment ability and metacognitive skills are key features of self-directed students'. He (King 2011) goes on to further state that:

[ S ]elf-directed  students,  who  are  emotionally  engaged  in  the  learning  process, retain high rates of self-generated encouragement to achieve their objectives and priorities and are easy to track and change their own learning. (p. 259)

Self-directed students thus have a high degree of commitment, perseverance and  self-motivation  (Guglielmino  2013:6).  In  other  contexts,  self-directed students can apply subject information independently, have a significant level of  self-efficiency  and  can  communicate  successfully  with  peers  during  the task's completion.

Individual students will be attracted to SDL as a function of their persona, but all students can be driven towards successful SDL in this way, as more self-motivated and reflective thinking students would want to direct their own learning. 'Intrinsic motivation is the energy that encourages students to seek self-directed, independent learning' (Guglielmino 2013:6). Amongst the most significant,  basic  educational objectives could entail determining situations that  move  towards  intrinsic  motivation,  which  foster  an  SDL  mentality.  An individual who does not possess many of these abilities as outlined by Knowles (1975) and is unable to demonstrate adequate competence with regards to displaying  goal  setting,  implementing  effective  strategies  and  identifying adequate resources will be described as a person with a lower level of selfdirectedness (King 2011:259).

## Rogers (2004) suggests:

[ S ]elf-directed students undertake their own learning by figuring out what they need to know and how to do so, by preparing and tracking their learning through different  resources,  and  by  documenting  it  and  collaborating  with  peers  and advisors to support their learning. (p. 8)

Self-directed  learning  does  not  happen  naturally  in  an  environment.  The setting, society, culture and educational facilities can stimulate or hinder the key features of the process of SDL.

Knowles' (1975) adult education philosophy has shown that adults prosper in settings where they are extremely inspired, they can contribute to learning and where learning resources have realistic purposes. According to Knowles (1975:18),  adults  prefer  a  comfortable  learning  environment.  They  want accurate descriptions of what they want, ways to bring their novel knowledge and skills into practice and constructive feedback into their learning experience. Knowles  (1975) argues that students are valuable teaching resources themselves; they enable and incorporate rich experience into the teaching content, making it more meaningful. The teaching of adult students must also go beyond the diffusion of information to support individuals to handle and develop their own learning, which is the cornerstone of SDL. Adult education focused  on  skills  that  should  also  provide  a  work-friendly  social  climate (Manning 2007:104). Amongst the founders, Tough (1978:250) and Knowles (1975) described how adults learn on their own and outlined the main decisionmaking factors on how to choose what, how and where to learn. They were the  pioneers  to  urge  the  integration  of  SDL  into  adult  structured  learning (Abdullah et al. 2008:68). Greater autonomy of learners means that learners are given ample opportunities and the ability to think what they would like to learn  (which  is  essential  or  beneficial  to  them),  how  they  want  to  learn (strategies, resources required, venue and tempo), and what measures would be  selected  to  decide  whether  the  learning  process  was  adequate  and beneficial (Abdullah et al. 2008:68).

The influence of seven years of work on adult learning, change and growth was published by Tough (1978:253). The research of Tough was not just about why individuals  learn;  it  is  also  about  how  they  learn.  According  to  Tough (1978:253),  adults  based  their  learning  experiences  on  assignments,  which were presented as a set of interrelated events to develop and retain explicit knowledge and ability, or to establish some permanent improvement. Tough (1978:255) recommended that adult learners pass through several phases of the learning process. Manning (2007:106) speculated that one successful way to enhance students learning might be to decrease assistance, which could be one  effective  way  to  improve  their  SDL.  Several  scales  can  assess  these degrees of self-directedness in learning. The scale of Guglielmino (1978) tests SDL learner  readiness,  whilst  Williamson's  self-rating  scale  of  self-directed

learning (SRSSDL) (Williamson 2007) tests learners' levels of self-directedness. The SRSSDL was selected as the measurement tool in this research (Mishra et al. 2013):

A  lot  of  research  on  self-directed  learning  has  been  done,  but  the  context  has changed  with  the  growth  of  online  learning,  greater  access  to  technology  and connections to information and resources. (p. 11)

According  to  Guglielmino  (2013:5),  'online  learning  has  offered  a  rich opportunity  for  increasing  SDL  skills  and  attitudes'.  Students  appear  to overestimate their knowledge and skills in contrast to the perception of their lecturers or mentors about the knowledge and skills of their students (Dunning, Heath &amp; Suls 2004:94). Kruger and Dunning (1999:31) confirmed that students wrongly score themselves at a far higher level than is right when they rate themselves.  This  phenomenon  is  called  the  effect  of  illusory  superiority. According to Pietroni and Hughes (2016:252), 'illusory superiority, also known as the above-average effect, superiority bias or leniency error, is a cognitive bias whereby individuals overestimate their own qualities and abilities, relative to others'.

A technological approach is advocated in this chapter, which will make use of digital learning.

## Digital learning

Anyone who has ever worked in a conventional classroom setting as a teacher or facilitator knows first-hand that with different classes or individual learners, the  same  content  will  never  yield  the  same  results  (Shahabadi  &amp;  Uplane 2015:132). In addition, information may be relevant to the learning style of an individual,  whilst  the  same  information  may  be  worthless  in  fulfilling  the learning goals in the case of another individual (Masie 2002; Zenger &amp; Uehlein 2001:56).  The  researchers  can  suggest  the  following  argument  from  this empirical  reality  and  from  considering  its  ramifications  for  any  means  of delivering  teaching  materials  through  online  platform:  in  the  end,  it  is  the behavioural indicators of students who need to be considered when creating and  implementing  e-learning  programmes  to  develop  SDL  (Shahabadi  &amp; Uplane  2015:132).  Consequently,  the  researchers  agree  with  Codreanu  and Vasilescu  (2013)  that  the  emphasis  is  on  the  student  and  their  needs  and requirements, and given the point of this study which is to focus on developing SDL through digital  assessment,  it  is  crucial  to  evaluate  the  effect  on  any programme  developed  and  delivered  through  Internet-based  technology. From this point on, we will use the broad term of e-learning.

According to Rosenberg and Foshay (2002:51), e-learning is described 'as the use of information communication technology to provide information and guidelines  to  individuals,  predominantly  via  the  intranet  or  the  Internet'.

Research has shown that, whilst terminology such as computer-based learning, remote learning, digital  learning  or  web-based  training  is  sometimes  used, e-learning will ultimately prevail as most organisations preferred concept.

Less prominent is synchronous e-learning, which is 'absolute' and necessitates all participants to be at the same time in front of their computers. There are a number of synchronous e-learning types. Shahabadi and Uplane (2015:131)  describe  'synchronous  e-learning  [as]  live,  real-time  (and  usually scheduled),  facilitated  instruction  and  learning-oriented  interaction.  In  this type  of  learning,  learning  experiences  are  in  real  time'.  Another  popular method includes actual 'chat' session times when students sign in simultaneously  to  collaborate  on  certain  themes  (Shahabadi  &amp;  Uplane 2015:131).

Today,  the  bulk  of  e-learning  is  asynchronous  in  nature.  Shahabadi  and Uplane  (2015:132)  describe  'asynchronous  e-learning  as  a  learner-centred process, which uses online learning resources to facilitate information sharing regardless of the constraints of time and place amongst a network of people'. The benefits of asynchronous e-learning are (Shahabadi &amp; Uplane 2015):

[ C ]omputer-mediated communication to achieve the promises of learning anytime and anywhere through asynchronous online discussions, which is based on  the  constructivist  theory,  a  learner-centred  approach  that  emphasises  the importance of peer-to-peer interactions. (p. 132)

The researchers argue that in order to develop SDL in an online environment, the system needs to cater for learner-centeredness, which is embedded in constructivist  theory,  as  alluded  to  above.  The  researchers  utilised  this asynchronous method in this project, by using screencasting or interactive PDFs  and  PowerPoints  of  study  units,  which  has  been  pre-recorded  for students. This learner-centered method was difficult to follow because of a lack of infrastructure.

Comer and Lenaghan (2013:262) argued that asynchronous online learning offers an  excellent  probability  to  build  a  learning-centred  surrounding that stimulates rich interactions between lecturers and students and amongst students.  Through  an  online  asynchronous  panel,  'computer  and  Internet technologies enable communication via the generation of discussion messages amongst  participants'  (Han  &amp;  Hill  2006:30),  which  will  generate  more constructive  engagement and connection compared to many conventional face-to-face environments. This links to the constructivist approach advocated in the intervention, which is to develop SDL through the use of online formative assessments. Students can interact with the lecturer by asking live questions. Synchronous coordination (via chat rooms and WhatsApp groups) between team members is taking place as they work together to create and present evaluations as a part of this study. In order to facilitate the assessment of these sessions, the researchers turn their attention to the use of online marking.

## Online marking

Online testing is gaining prominence. All major e-Learning environments, such as  WebCT  or  BlackBoard,  offer  resources  to  assist  with  online  student evaluation (Zhou et al. 2016:2463). Because of advantages such as reduced time compared to paper-based assessment, increasingly educational institutions  are  preferring  online  assessment  rather  than  traditional  paper tests (Heinrich &amp; Wang 2003). There are two important aspects of the online assessment. In the first place, it means that students submit their answers online, and in the second place, an automated system marks those answers. However, this second part restricts online assessment, as is usually known, to really  limited  types  of  online  assessment,  consisting  of  multiple-choice questions, ordering or matching questions or simply filling in blank questions (Heinrich  &amp;  Wang  2003;  Zhou  et  al.  2016:2463).  This  online  evaluation approach is not sufficiently advanced to evaluate the perception of complex content and cognitive traits of students. (Heinrich &amp; Wang 2003; Zhou et al. 2016:2463). According to Nicol and Macfarlane-Dick's (2006:205) principles of good formative feedback practice, the feedback is not simply giving the correct answer, it is also part of the teaching and learning strategy to encourage SDL. Therefore, the students received immediate feedback, with reference to the page in the prescribed book for incorrect answers. This should help them to track and change how they learn theoretical concepts. Tests in the form of assignments, reviews or essays are expected to assess the abilities of students in a more comprehensive way.

Automatic marking is not successful if lecturers follow this route of using essay assignments, as the processing of information today is not advanced enough to analyse and understand this kind of complex intellectual content (Zhou  et  al.  2016:2463).  Human  markers  who  manually  review  essay-style assignments in a friendly online environment are the requirement. Therefore, the online marking of these assignments by a human marker should continue with a framework with the most essential features of the online submission of essay-type assignments and advanced feedback to students. On the basis of this core structure of digital marking, an open atmosphere must be created that gives students access to comprehensive evaluations and peer assessment (Heinrich  &amp;  Wang  2003).  This  does,  however,  only  focus  on  summative assessments, and the researchers are aware that the students themselves can also assess each other in an online setting. The researchers could not control whether the students themselves could use digital marking, hence only the focus  on  the  lecturer  assessment.  This  is  mostly  focusing  on  the  lecturer marking more extended questions.

Limited research specifically discussed the problem of 'the impact of mode effects on online and traditional forms of a course-based assessment' (Hewson 2012:490). Eighteen years ago, research conducted by Goldberg and Pedulla

(2002:1065), discovered a 'pen and paper group outperformed a computer group when taking a test'. A more recent study by Backes and Cowan (2019:97) 'estimate online test effects of -0.10 and -0.24' when compared to traditional pen and paper tests, controlling for prior test scores. This implies large effect sizes when comparing the two groups, meaning there is a big difference in taking an online test versus a pen and paper test. Hewson (2012:490) reported evidence  for  performance  effects  inside  a  test  setting  that  more  trained students outperform those with little exposure to online learning. Therefore, students who are appropriately oriented towards an online assessment will perform  better  when  online  marking  is  carried  out.  Goldberg  and  Pedulla (2002:1066) also reported finding evidence that the time to complete the test had a more negative effect on results in computer-based modes than in paperbased modes, concluding that it is vital to evaluate whether more time will be needed when carrying out computer-based assessments than in traditional paper-based modes. More recent research conducted by Karay et al. (2015) found that:

[ T/thinspace ]he test results from the paper and computer versions did not differ. The groups remained  within  the  allotted  time,  but  students  using  the  computer  version (particularly the high performers) needed significantly less time to complete the test. (p. 57)

A text in PDF format can be converted to almost any printable text. As they can be accessed on any platform and any Internet browser, PDF documents are ideal for the online environment. Choosing PDF as a paper format means that only one software package, PDF Writer software, needs to be purchased by the university to convert student submissions into PDF format. The software of  their  choice  can  be  used  by  students  to  compose  assignments  (Grieve, Padgett  &amp;  Moffitt  2016:11).  After  they  have  been  created  from  the  source content, PDF documents cannot be easily updated. Compared with the use of a word processing format as the basis of our online marking system, this is an essential  advantage.  Using  word  processing  tools  to  mark  essays,  such  as Microsoft  Word's  'Comments'  or  'Track  Changes'  functionality,  the  marker may unintentionally alter the initial assignment (Grieve et al. 2016:11).

Adobe Acrobat Reader is a PDF file opening and reading programme and has proven to be efficient for students sharing one-way audio input files (Zhou et  al.  2016:2463).  The  software  is  a  free  download  that  requires  minimal functionality without the entire Adobe Acrobat software being purchased. No configuration of the account or additional online hosting is needed (Grieve et al. 2016:12). The documented comments can be added as needed after the lecturer saves the uploaded student paper as a PDF file and opens it using Adobe Acrobat Reader.  The  comments  are  portrayed  by  the  icons  of  tiny speakers  in  the  written  assignment.  Text  and  audio  files  become  a  single packaged  text  when  saved  and  can  be  re-shared  via  email  or  learning management system (LMS) as an attachment (Zhou et al. 2016:2463).

Grieve et al. (2016:11) summarise a few other advantages of the PDF format as follows:

- · 'Neutral Platform: can be used across different platforms
- · Widespread: one of the Internet's most popular file formats
- · Integrity and correctness: protects records from modification, automatically adds up total marks
- · Easy to publish: it is possible to convert any printable text into PDF
- · Efficient: provides compression of data, usually limited in size and easy to transmit over the Internet
- · Secure: provides the data encryption Privacy Protection System'.

Based on the previous discussions on digital learning as well as online marking, it is now crucial to understand formative assessment, in order to ensure that the  online  marking  feedback  and  tasks  given  to  students  assist  in  the development of SDL.

## Formative assessment

Black and Wiliam (1998:10) describe formative assessment in a specific manner to cover all tasks that lecturers and students perform to 'gain knowledge that can be used diagnostically to change teaching and learning'. Regarding this definition,  the  evaluation  requires  lecturer  observation,  classroom  conversation, and  review  of  student  performance,  including  all  smaller  activities  and assignments which informed the teaching and learning experience.

Hardiman and Whitman (2014:39) and James (2008) provide the following sociocultural general assessment guidelines:

- · learning and assessment should not be divided
- · group learning assessment is just as critical as individual learning
- · in the use of resources or instruments (intellectual, human and material), the emphasis should be on how well a person is self-directed
- · the  assessment  should  be  more  comprehensive  and  qualitative,  not segregated and quantified
- · the  assessment  should  determine  the  abilities  and  provisions  and  not merely determine the amount of knowledge/facts memorised
- · assessment should entail a challenge and promote SDL
- · assessment should include clear activities or concerns
- · assessment should not just focus on what students should know about an imminent test or examination.

As experts, lecturers are used to adapting teaching and learning to meet the  needs  of  students.  They  will  use  this  assessment  data  to  make  the necessary  curriculum  improvements,  such  as  exploring  new  learning strategies, or offering an extra opportunity for practice if lecturers know

how students are doing and when they are having difficulties. Such practices can lead to better SDL.

Because formative assessment aims to obtain a better awareness of what students know and do not know to allow responsive teaching and learning changes, techniques such as observation and discussion play a significant role alongside performance review and homework (Hardiman &amp; Whitman 2014:39). However, in a digital learning context, these strategies became increasingly more challenging to use. Hardiman and Whitman (2014:39) emphasise that when an assessment is created, long-term learning, deep thinking, problemsolving and the cognitive skills of students should be promoted.

According to Earl (2013),  assessment  has  'three  interwoven  but  distinct approaches to assessment: assessment of learning, assessment for learning and assessment as learning'. Each of these approaches plays a role to enhance learning.

In  all education  sectors,  AoL  is  predominant  (Hardiman  &amp;  Whitman 2014:39). The goal is to provide summative grades, regarding the progress of students, typically in comparison with other students. Teachers and lecturers set assessments to measure the quantity and precision of the work of students to cover a broad spectrum of skills and expertise (Earl 2013). These forms of assessments take place at the end of the learning process. According to Earl (2013):

Assessment  for  learning  moves  the  emphasis  from  summative  to  formative assessments, which continually occurs during learning and encourages teachers to change teaching and learning practices to meet the needs of individual learners. (p. 27)

Teachers and lecturers use various methods to gather a wide range of data, such as group activities, peer assessment, worksheet completion, individual assignments,  test  and  quizzes  and  online  activities.  Students  are  provided with  input  on  their  strengths  and  shortcomings,  with  different  forms  of feedback in order to improve further learning.

Assessment for learning focuses not only on what students know but also on how, when and whether the knowledge and skills they have obtained are used and applied (Earl 2013). This is the type of assessment, where students develop their skill of SDL.

' Assessment as learning is an extension of assessment for learning', which uses assessment to promote the growth of metacognitive skills of students (Earl 2013). Regarding their own success and development, students serve as critical  thinkers.  Students  assess  individual  learning  growth  and  success against previous performance (Earl 2013).

Table 9.1 summarises the main characteristics of assessment of , for and as learning.

TABLE 9.1: Assessment OF, FOR and AS learning.

| Assessment of learning                                          | Assessment for learning                            | Assessment as learning                                                                                |
|-----------------------------------------------------------------|----------------------------------------------------|-------------------------------------------------------------------------------------------------------|
| Summative - at the end of learning  Formative - during learning |                                                    | Reflective - self-monitoring                                                                          |
| Learning = to be taught                                         | Learning = constructing meaning                    | Enhance motivation and  commitment to learn                                                           |
| Judging learning against norms                                  | Constructive feedback to enhance  future learning  | Self-assessment                                                                                       |
| Focused final results                                           | Based on meeting the needs of  individual learners | Learners are involved in learning,  tracking their own growth and  progress - Transformation oriented |

Source : Earl (2013).

Based on Earl (2013), it is suggested that substantial consideration should be given to the FOR and AS learning assessment in order to improve SDL through digital assessment.

Assessment  for  learning  is  based  on  constructive  feedback  to  enhance future learning. It is, therefore, crucial to understand how quality feedback ought  to  be  given  to  students  which  can  enhance  their  motivation  and commitment to direct their own learning, which could lead to assessment as learning.

## Feedback

Askew and Lodge (2000) describe feedback as 'all dialogue in both formal and informal situations to facilitate learning'. Feedback is a reciprocal mode of communication, not a one-way form of communication. Feedback contributes to  higher-order  skills  growth,  relating  new  information  to  what  students already know and to the building of information (Nicol 2010:506).

Feedback  is  one  of  the  most  essential  methods  for  lecturers  to  affect learning  (Hattie  &amp;  Timperley  2007:81).  According  to  Bahari  (2020:4),  in 'exploring  the  potential  affordances  of  multimodal  digital  feedback,  it  is reported to develop fluency and accuracy of learners' oral feedback, promoting more interaction, enhancing attentive engagement and personalised learning'. Feedback  enables  to  eliminate  the  gaps  'between  the  students'  current understanding or achievement and anticipated understanding or achievement' (Hattie &amp; Timperley 2007:82). 'However, once the feedback is provided, the receiver must analyse and react to the feedback. The feedback to students is as important as the planning of the feedback' (Ilgen, Fisher &amp; Taylor 1979:379).

Feedback  is  described  as  a  two-way  conversation  by  Boud  and  Molly (2013:703).  Planar  and  Moya  (2016:198)  define  feedback  as  'the  one  that facilitates  and  the  one  that  receives'.  Input  should  be  accompanied  by discussion and events (Geitz, Brinke &amp; Kirschner 2015) which:

[ N ]ot  only  informs  students  about  their  current  performance  but  also  support them to seek and ask for feedback on possible results. This will give more control

for  students.  It  will  also  encourage  them  to  add  sense  to  the  feedback  and  to discuss the feedback with their peers. (p. 278)

They not only inform students about their present results but also encourage them to get feedback on current performance. This will give students better control over their learning. It would also encourage students to 'add meaning to the feedback through reflecting and communication to their teammates about the feedback' (Geitz et al. 2015:278).

According to Hattie, Gan and Brooks (2017), for feedback to be obtained and used by the student, 'the quality of feedback is more important than the quantity'.  Feedback  does  not  guarantee  learning,  but  the  quality  of  the feedback was evaluated (Brookhart 2012:25; Sadler 2013:535). Carless et al. (2011:406) indicated that most research findings show that the majority of feedback from lecturers is rarely used and adopted by students. A crucial prerequisite for efficient feedback practice is clarifying the requirements and criteria for the students (Molloy &amp; Boud 2013). Students also say that they value data that are consistent with the assessment criteria (Peterson &amp; Irving 2008:240).

In order to facilitate SDL, there are many resources that teachers can use, 'such as, using thinking maps (Hay 2007:43), cross-cultural communication (Osman  &amp;  Herring  2007:133),  podcasting  (Pegrum,  Bartle  &amp;  Longnecker 2015:145) and asynchronous online conversations' (Du, Harvard &amp; Li 2005:208). Feedback given after the formative assessment allows students to identify and direct those strategies through the actions required to achieve the aim of the feedback, in order to address any gaps existing between their desired goal and their current experience, understanding or ability (Sadler 2010:538). According to Henderson et al. (2019:4), the quality of comments made by lecturers can no longer be exclusively concerned, 'but whether these comments and indeed comments or knowledge from other outlets have a positive effect on student learning'. The importance of feedback is captured in the 'quality of the whole process, including the active position of students', instead of just concentrating on the quality of the lecturer's feedback. The emphasis needs to  be  on:  does  it  make  a  difference,  and  how  does  it  make  a  difference? (Henderson et al. 2019:4).

The most beneficial feedback on academic assignments involves detailed comments and specific changes and allows students to concentrate on the assignment carefully rather than just get the correct answer. Reflection is based on aspects that a student can focus on in future assignments as a form of feeding forward feedback. For instance, it may be more beneficial for students to reflect and give three strategies on how they can improve in the  next  assignments,  instead  of  providing  detailed  information  on  the particular assignment the lecturer is busy marking (Hounsell 2006; Torrance 1993:336).

## Research methodology

## Research approach

A concurrent mixed-method triangulation approach was applied in this study. Both a quantitative descriptive survey and a qualitative experiment were used to investigate responses to a range of content presentations for data collection. The various quantitative and qualitative data sets were triangulated to identify whether there are convergences, variations or combinations (Creswell &amp; Plano Clark 2018).

## Population and sample

In this study, the researchers purposively focused on first to fourth-year preservice teachers in Business Studies, Economics, Accounting and History from the NWU on the Vanderbijlpark Campus within the School of Commerce and Social Studies in Education.

The manner in which the project was implemented was asynchronous, as not all students had access to data or hardware, and all assessment tasks were communicated at least a month in advance, to give students sufficient time to complete them.

To keep students interested, multiple interactive strategies (e.g. hyperlinks and  buttons)  have  been  implemented  for  the  student  to  engage  with  the module content (Subandi et al. 2018:246). Engagement and understanding, including multiple choices and transfer files, are also encouraged by different modes of instruction.

The researchers chose the PDF from Adobe Systems Integrated (Grieve et al. 2016:10) for the implementation of online marking.

However, because of the essence of the teaching and learning during the COVID-19 pandemic, the university opted for a fully online remote teaching strategy, as no classroom-based learning could be used. In order to facilitate this  specific  online assessment (testing) approach, the researchers allowed students a month to complete their work, so that they had sufficient time to plan and complete their work. The specific format that students needed to submit their work is in PDF. Feedback plays a crucial role in this online learning approach,  specifically  in  a  digital  environment.  Several  strategies  were implemented  to  facilitate  user  feedback  using  the  institution's  own  LMS platform. Chatroom discussions, PDF annotations and WhatsApp groups all served a purpose in giving feedback to students.

The  sample  could  also  be  considered  convenient,  as  the  participants were located on the same site where the researchers work. The aim of the research  was  to  determine  and  establish  the  consequences  of  online

marking and feedback in a school-wide community of practice project for the development of SDL. Although 407 students enrolled for the schoolbased project which focused on effective teaching strategies which may support  the  development  of  SDL,  only  277  of  them  completed  the quantitative questionnaire although the school-based project was compulsory  as  part  of  the  course;  however,  it  was  not  compulsory  to complete the measuring instruments. The scores of all participants in this study  were  included  in  the  data  analysis  to  take  into  account  students' propensity to overestimate their abilities to be a self-directed learner, as no student scored low in the pre-test.

## Quantitative methods and instruments

Participating students were invited to complete the Williamson's SRSSDL. The SRSSDL includes '60 items divided into five distinct SDL domains, namely awareness, learning strategies, learning activities, evaluation and interpersonal skills'  (Williamson 2007). Using a four-point scale, responses for each item were classified. The researchers modified the Likert scale to prevent students from choosing option 3 in the five-point scale, namely, 'sometimes' to get clear and precise answers from the participants. In the research, Simms et al. (2019:7)  'show  that  changing  the  number  of  response  options  has  a  nonnegligible  impact  on  basic  scale  norms'.  The  modified  Likert  scale  was statistically  approved by a qualified statistician from the Statistical Consultation Services of the NWU.

## Qualitative methods and instruments

After  the  completion  of  each  summative  assignment,  the  application  of the assessment strategies of the participants was assessed through an online marking  tool  by  giving  them  thorough  feedback.  The  participants  were requested to reflect  on  the  feedback  they  received  by  explaining  how  the feedback affect their SDL. The purpose of these reflections was to explore if the participants became more self-directed and if the feedback they received become  less  comprehensive.  Participants  were  also  requested  to  write reflections  to  support  their  development  of  SDL.  Reflections  were  written immediately  after  the  completion  of  a  summative  assessment.  Reflections were also requested from lecturers how they experienced the online marking and the effect of the feedback made to the students' SDL.

Questions asked to the student participants were as follows:

- 1. Explain  in  short  how  did  you  experience  the  online  marking  of  your assignments in comparison with manual marking by your lecturer.
- 2.  Explain in short, how did you experience the feedback on your assignments from your lecturer (positive or negative and why).

- 3.  Could you understand your mistakes from the feedback you got from your lecturer? (Y/N)
- 4.  Please explain why you answer yes or no in the previous question.
- 5.  The feedback you got, did it help you to make fewer mistakes in the next assignment? (Y/N)
- 6.  Explain your answer from the previous question.
- 7. With the feedback you got, could you become more self-directed by using the strategies you have learned? (Y/N)
- 8.  Explain your answer from the previous question.

Questions asked to the lecturer participants were:

- 1. How would you compare marking by hand to marking digitally?
- 2.  In terms of time spent, how do you feel about marking digitally?
- 3.  How do you provide feedback whilst marking digitally?
- 4.  How have the students reacted or engaged with your digital feedback? Has it been constructive?
- 5.  Please  explain  whether  learning  to  mark  digitally  and  provide  feedback digitally was difficult or not.

## Findings

In this section, both quantitative and qualitative findings will be outlined.

## Quantitative finding

Figure 9.1 indicates the number of participants per year group. Most of the participants 71.33% was third or fourth-year students. Figure 9.2 indicates the number of participants divided into different subject areas that were exposed to digital feedback and assessment.

FIGURE 9.1: Number of student participants per year group .

<!-- image -->

FIGURE 9.2: Number of student participants per subject area.

<!-- image -->

The largest group of participants represent the Business Studies subject area ( n = 61). Economics is the second largest group ( n = 33) with Accounting ( n = 32) shortly behind, whilst History shows the lowest number ( n = 24) of participants.  All  of  these  students  who  participated  ranged  from  first  to fourth-year BEd students.

For the SRSSDL questionnaire (Williamson 2007), the student participants were divided into three particular groups regarding their SDL, namely low (48-112), moderate (113-176) and high (177-240). Figure 9.2 shows the number of student participants divided into the three distinct groups of SDL, according to Williamson (2007). As no participants were identified within the low group, the emphasis of this study was on the results attained by the moderate and high groups.

According to Figure 9.3, the majority of the participants fall into the group, which shows a high rate of self-directing skills before the application of the digital feedback and pre-test assessment.

According to Taber (2018:1282), 'Cronbach alpha values of 0.7 or higher indicate as acceptable as internal reliability'. All the reported Cronbach alpha values according to Table 9.2 were above the guideline value of 0.7, which indicate that they are reliable. As part of a bigger research project, the SRSSDL has already been used at the same South African university ( n = 403), and they obtained a Cronbach's alpha coefficients between 0.76 and 0.88 for the SRSSDL for the five categories of the questionnaire indicating the SRSSDL was reliable in the South African context (Petersen &amp; Mentz 2016:49). The means of the resulting factors ranged between 38.57 (SD = 4.73) and 40.15 (SD = 4.24) and the reported means of the overall SRSSDL score is 196.87 (SD = 18.18) indicating that participants' SDL is high.

FIGURE 9.3: Number of participants in a specific category of self-directed learning.

<!-- image -->

TABLE 9.2: Construct reliability for each section.

| Construct            | Questions    |   Cronbach's alpha |   Mean |    SD |
|----------------------|--------------|--------------------|--------|-------|
| Awareness            | Q1.1 - Q1.12 |              0.755 |  40.15 |  4.24 |
| Learning strategies  | Q2.1 - Q2.12 |              0.714 |  38.6  |  4.33 |
| Learning activities  | Q3.1 - Q3.12 |              0.8   |  38.57 |  4.73 |
| Evaluation           | Q4.1 - Q4.12 |              0.749 |  39.85 |  4.44 |
| Interpersonal skills | Q5.1 - Q5.12 |              0.806 |  39.71 |  4.8  |
| SRSSDL               | Q1.1 - Q5.12 |              0.867 | 196.87 | 18.18 |

- SD, standard deviation; SRSSDL, self-rating scale of self-directed learning.

## Qualitative findings

The student and lecturer reflections on electronic feedback were analysed by means of inductive thematic analysis. From the data, meaningful parts were grouped  under  initial  codes  followed  by  grouping  the  initial  codes  under categories.  From  the  categories,  the  themes  emerged  (Braun  &amp;  Clarke 2006:77). The categories under each theme will be supported by verbatim quotes from the various year groups.

TABLE 9.3: Themes and categories.

| Themes                                                                 | Categories                                                                                                                                                      |
|------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| The effect of electronic feedback on  student's learning               | • A basis for being independent • Detailed feedback, self-assessment and self-reflection • Feedback to guide the improvement of learning • Improved end product |
| Experiences of electronic marking and  feedback                        | • Quality of feedback • Speed of feedback                                                                                                                       |
| Future implementation of electronic marking                            | • Attitude towards electronic feedback                                                                                                                          |
| Factors that influence the electronic marking  and feedback experience | • Emergency remote teaching and learning • Minimal interaction for students                                                                                     |

<!-- image -->

## The effect of electronic feedback on student's learning

## A basis for being independent

Student participants indicated that the electronic feedback acted as a basis for  them  to  become  the  initiators  of  their  own  learning,  which  is  a  core characteristic  of  SDL.  Self-directed  students  can  apply  subject  information independently; have a significant level of self-efficiency and can communicate successfully with peers during the task's completion (Guglielmino 2013:6):

'It allows me to be in control of my own work and to see how I can improve myself when working.' (Student, 1st Year, History)

'Because it encourages me to do research on my own.' (Student, 2nd year, Business studies)

'Now I'm confident to work alone.' (Student, 3rd year, Economics)

'The feedback guided for my next assignment in terms of what to do and what not do without consulting the lecture.' (Student, 4th year, Accounting)

## Detailed feedback, self-assessment and self-reflection

Student participants indicated that the feedback made it easier to self-assess and also to reflect on their own learning:

'The feedback has helped me learn where my problems areas are and where I can improve.' (Student, 1st Year, Accounting)

'Positive,  I  am  able  to  reflect  on  my  mistakes  and  fix  them.'  (Student,  2nd  Year, Business Studies)

'I saw my mistakes that I'm doing more and more.' (Student, 3rd Year, History)

'Encouragement of self introspection is what I've noticed with online learning […] He explained where I made a mistake and how I should improve on my learning.' (Student, 4th Year, Business Studies)

## Feedback to guide the improvement of learning

Student participants indicated how the feedback improved their own learning by pointing out that the feedback contained additional instruction on how to improve not just what to improve:

'The feedback has helped me learn where my problems areas are and where I can improve.' (Student, 1st Year, Accounting)

'I need less help with the next assignment.' (Student, 2nd Year, Business Studies)

'Because they really help me to improve on my work.' (Student, 3rd Year, History)

'This is because I can work on my own and be able to correct myself by using what the lecture showed and taught me.' (Student, 4th Year, Business Studies)

## Improved end product

Lastly,  the  students  indicated  that  their  marks  improved  with  the  next assignments when they paid attention to the feedback:

'My marks on the next assignment improved because of following the guidelines from the previous feedback.' (Student, 1st Year, Accounting)

'Yes  because  next  time  I  will  be  able  to  answer  in  detail  and  answer  correctly.' (Student, 2nd Year, Business Studies)

'It allowed me to improve my marks.' (Student, 3rd Year, History)

'I made fewer mistakes in the next assignment and got good marks.' (Student, 4th Year, Business Studies)

## Experiences of electronic marking and feedback

## Perceived quality of feedback

Most of the student participants reported that the quality of the feedback in terms of knowing what they did wrong and in terms of using the feedback to improve learning was high:

'It is a more efficient way as I am able to see where I had made mistakes and where I can improve.' (Student, 1st Year, History)

'It was positive because she managed to explain thoroughly to us where we gone wrong and helped us on how to improve.' (Student, 2nd Year, Business Studies)

'Online marking is the best because you get feedback on where you went wrong, manual marking the is no feedback.' (Student, 3rd Year, Economics)

'Positive as it was very clear and detailed in terms what to improve and what I did right.' (Student, 4th Year, Accounting)

The above-mentioned affirmed most of the lecturer participant's responses that they gave quality feedback using multiple applications:

- 'I provide general feedback to all the students via WhatsApp  or  efundi Announcements  and  individual  feedback  via  PDF  comments.'  (Lecturer  3,  date unspecified, subject unspecified)

'Track changes and voice notes in Pdf Reader.' (Lecturer 5, date unspecified, subject unspecified)

'I usually type out text comments next to the area that needs correction, or I also like to use the free hand pencil in Adobe, where I cross out incorrect paragraphs or sentences. I also like to mark on the Turnitin report, offering another layer of feedback.' (Lecturer 8, date unspecified, subject unspecified)

## Speed of feedback

Most of the student participants indicated that the rate at which they received feedback on their assignments was fast:

'Online marking is faster than the manual.' (Student, 1st Year, Accounting)

'It  is  good  and  fast..  giving  us  an  opportunity  to  early  evaluation  of  your  own performance, to improve on the coming assignment.' (Student, 3rd Year, History)

'Is the best method ever as the lecturer gives feedback faster.' (Student, 4th Year, History)

Even though most of the student participants were satisfied with the pace of the feedback, the lecturer participants mostly indicated that the electronic marking was taking longer to complete than the manual marking:

'Marking by hand is much more quick and effective. Marking digitally takes up more time.' (Lecturer 7, date unspecified, subject unspecified)

'Marking  digitally  takes  much  longer  than  marking  by  hand.'  (Lecturer  8,  date unspecified, subject unspecified)

'Digital  marking  is  more  time  consuming.'  (Lecturer  6,  date  unspecified,  subject unspecified)

The sentiment of the lecturers was shared by a few students:

'It take time for the lecturer to finish marking, but the job gets done.' (Student, 1st Year, Accounting)

'It is time consuming because our lecturer take more time to give us our script back when using online marking.' (Student, 4th Year, Accounting)

## Future implementation of electronic marking

## Attitude towards electronic feedback

Compared to manual marking, the majority of student participants reported that the feedback they got was the same as the manual feedback. Students have suggested that they prefer the electronic platform rather than the manual and  that  they  would  not  mind  permanently  converting  to  the  electronic platform:

'It is a more efficient way as I am able to see where I had made mistakes and where I can improve.' (Student, 1st Year, History)

'Positive, now I can know my mistakes as there are comments teachers.' (Student, 2nd Year, Business Studies)

'I guess its different from the manual one but better.' (Student, 3rd Year, Economics)

'It's still the same for me and I actually prefer online.' (Student, 4th Year, Fourth Year)

The lecturer participants also indicated that even though electronic marking is more time consuming, that with practice they will permanently switch over from manual:

'I feel that with the correct software and support, I would really consider shifting all marking in future to electronic (which saves paper and space).' (Lecturer 2, date unspecified, subject unspecified)

'Marking digitally allows me more control over the management of submissions and administration.' (Lecturer 3, date unspecified, subject unspecified)

'It  was  difficult  for  me,  but  I  am  getting  there.  I  learned  a  lot  from  my  younger colleagues and my own kids. And still learning. I actually prefer marking digitally.' (Lecturer 13, date unspecified, subject unspecified)

## Factors that influence the electronic marking and feedback experience

## Emergency remote teaching and learning

The  student  participants  that  responded  negatively  had  a  bad  experience with the current emergency remote teaching and learning mode of delivery.

These student participants indicated that their own performance dropped significantly:

'It hard and it seems like it very strict, the passing rate is low now.' (Student, 1st Year, History)

'Online marking requires a lot, lost lot of marks with it.' (Student, 2nd Year, Business Studies)

'I feel like some lectures are strict marking our assignments even in online learning.' (Student, 3rd Year, History)

'Feedback is not as effective as personal interaction.' (Student, 4th Year, Accounting)

## Minimal interaction for students

There was a clear indication of insufficiency with communication during the emergency remote teaching and learning between the lecturer and some of the student participants when using the online platform:

'Some students take the feedback to heart and apply it, while other tend to ignore and make the same mistakes.' (Lecturer 2, date unspecified, subject unspecified)

'Some  respond  others  are  thankful,  most  are  unresponsive.'  (Lecturer,  4,  date unspecified, subject unspecified)

'No feedback from students.' (Lecturer 7, date unspecified, subject unspecified)

## Discussion

The School of Commerce and Social Studies in Education at the Vanderbijlpark Campus of the NWU follows a digital asynchronous approach with an online teaching and learning strategy. The school-based project aimed to implement digital  feedback  and  assessment  to  enhance  SDL  to  support  pre-service teachers to think and work on their own without direct instructions from the lecturers. Although the project-based approach was compulsory as part of the course, it was not mandatory to complete the questionnaires and only 277 student participants out of 407 (68%) took part in this study.

According  to  the  quantitative  results  which  were  obtained  from  the Williamson's Self-Rating Scale of SDL, the majority of the student participants (cf. Figure 9.2) specified high self-directedness when beginning the project. The findings showed there were none of the participants with a low SDL level before the intervention. When comparing the results of the qualitative data analysis to the quantitative results, the qualitative results indicated that the student  participants  overestimated  their  own  self-directedness,  perhaps because of a misunderstanding of the key characteristics of what SDL entails. The literature predicted that the students would overestimate their own selfdirectedness, as students who are not fully aware of what SDL entails tend to make  assumptions  regarding  their  own  levels  of  SDL  (Petersen  &amp;  Mentz 2016:52). The prediction came to fruition when the qualitative and quantitative findings were compared, as the qualitative results were oftentimes in complete contradiction to what was found in the quantitative results.

Literature reveals that, amongst other things, greater autonomy of learners, as  a  fundamental  cornerstone  of  SDL  (Guglielmino  2013:6),  means  that learners are given ample opportunities and the ability to think about how they want to learn using various strategies (Abdullah et al. 2008:68). From the qualitative findings, it is clear that the students are using multiple strategies to assist them in improving their own learning, which is a characteristic of selfdirection (Knowles 1975:18). This is evident as students are quoted as saying 'It is a more efficient way as I am able to see where I had made mistakes and where I can improve'.

From  the  qualitative  findings,  several  themes  emerged  from  the  data analysis. The first theme identified was the effect that the electronic feedback had  on  SDL.  A  category  emerged  from  the  data,  namely  that  electronic feedback formed the basis for being independent. Students participants felt

that the feedback they received digitally acted as a foundational basis for them to  become drivers  of  their  own  learning.  This  is  clearly  apparent  from  the quotation  below:  'Because  it  encourages  me  to  do  research  on  my  own' (Student, 3rd Year, History).

Literature reveals that students can work with or without the help of others to promote SDL (cf. Brookfield 2009). Self-directed learning requires the need for the theory of social constructivism, which relates to collaborative learning and social interaction in order to intensify self-direction. From the student responses, as well as when comparing the quantitative data, it is evident that independence  was  encouraged  when  providing  electronic  feedback  to students.  It  seems  that  the  feedback  enabled  students  to  do  their  own research,  as  it  allowed  them  to  take  the  initiative  and  direct  their  learning goals.

Another qualitative finding that emerged was that the students deemed the  feedback  to  be  detailed  enough  to  contribute  towards  their  learning. Furthermore,  student  participants  alluded  to  the  fact  that  the  electronic feedback  they  received  helped  them  to  reflect  and  self-assess  their  own learning. This is noticeable in the next quote: 'The feedback has helped me learn where my problems areas are and where I can improve' (Student, 1st Year, Accounting).

Literature reveals that the concept of reflection (cf. Hounsell 2006; Torrance 1993:336)  relies  on  what  a  student  can  focus  on  in  future  assignments  to alleviate  errors.  Self-assessment  ability  and  metacognitive  skills  are  key features of self-directed students, who are able 'to identify their own learning needs and set learning goals' (cf. King 2011:259), as well as (Knowles 1975):

[ H ]ave the ability to identify their learning needs, set learning objectives, identify human and learning resources, choose and implement effective learning strategies, and assess their learning objectives with or without the support of others. (p. 18)

Thus, it is possible to infer that digital feedback assisted students in becoming more  self-directed,  as  they  were  displaying  self-assessment  and  reflective characteristics.

Strategies to improve learning is another qualitative category that surfaced. A major SDL characteristic is the ability to 'choose and implement effective learning  strategies'  (Knowles  1975:18).  Student  participants  felt  that  the feedback they received helped them to enhance their learning. This is clear in the following quote: 'Because the strategies give directions on how to answer the questions without making any mistakes and also the lecturer is giving us good  practice  through  his  powerpoint  presentations'  (Student,  4th  Year, Business Studies).

Improving the end product of learning was another qualitative finding. This could  be  translated  into  student  participants  believing  that  useful  online/

electronic  feedback  leads  to  an  improvement  in  marks  obtained  in  their assignments. According to Guglielmino (2013:5) 'online learning has offered a rich  opportunity  for  increasing  SDL  skills  and  attitudes',  which  would  be evident from the findings. This is apparent in the following quote: 'My marks on the next assignment improved because of following the guidelines from the previous feedback' (Student, 4th Year, Accounting).

The  literature reported that feedback  given  through  the  formative evaluation allows students to identify and direct those through the actions required  to  achieve  learning  aims,  as  well  as  to  address  any  gaps  existing between their desired goal and their current experience, understanding or ability (cf. Sadler 2010:538). With regards to SDL, this also points to students 'having the ability to identify their learning needs and set learning objectives' as  stated  by  Knowles  (1975:18).  This  is  apparent  in  the  responses  of  the students, as they felt that the feedback and instruction supported them to achieve their learning aims.

From the qualitative findings, the theme on the experiences of electronic marking and how the feedback was given to students, the majority of students saw electronic marking as a tool to improve learning and to highlight errors where they went wrong, as seen with the following quote: 'Online marking was in depth, the lecturer unlike manual marking with just a tick or cross with no comment' (Student, 1st Year, History).

Even lecturer participants were positive in their evaluation of the quality of online feedback. The question asked was ' How do you provide feedback whilst marking digitally? '.  The type of feedback was detailed, as is seen from this lecturer's quote: 'By making comments as well as indicating whether or not answers were right or wrong' (Lecturer 2, date unspecified, subject unspecified

According to previous research, online feedback is not sufficiently advanced to evaluate the perception of complex content and cognitive traits of students (cf. Heinrich &amp; Wang 2003). Human markers are required when dealing with advanced assignment types, such as essays. Therefore, when comparing the quantitative results with this qualitative finding, it is evident that the addition of detailed comments assisted students in developing SDL. This could have also  assisted  in  scaffolding  student  learning,  and  anticipating  where  errors could occur in future assignments. Manning (2007:106) speculated that one successful way to enhance students' learning might be to decrease assistance, which could be an effective way to improve their SDL. This approach, with the detailed feedback, could allow students to scaffold their learning and improve on future tasks.

Another facet of electronic feedback that was noted, from both student and lecturer participants, was the issue of turnaround time for the feedback. Majority of  the  student  participants  agreed  that  they  received  their  assessments

back digitally  a  lot  faster  than  paper-based  assessments.  It  is  evident  in  a quote: 'The online marking is quite faster than the manual marking, the marking tools  my  lecture  use  are  very  effective  and  reliable'  (Student,  2nd  Year, Business Studies). However, a discrepancy is noted between the student and lecturer participants, as the majority of lecturers stated that the online marking was taking far too long, as is evident in the following quote: 'Marking by hand is  much  more  quick  and  effective.  Marking  digitally  takes  up  more  time' (Lecturer 7, date unspecified, subject unspecified).

Literature states that online assessments have restrictions, which limit the types of online assessment used to mark automatically to save time, which consist  of  multiple-choice  questions,  ordering  or  matching  questions,  or simply filling  in  blank  questions  (cf.  Heinrich  &amp;  Wang  2003).  However,  this means that very comprehensive and detailed feedback is not given, but the participants received immediate feedback, similar to the formative assessment, with reference to the page in the prescribed book for incorrect answers. This feedback is not simply the correct answer; it is also part of the teaching and learning strategy to encourage SDL (cf. Nicol &amp; MacFarlane-Dick 2006:205).

The lecturers themselves also want to assess higher-order thinking, and therefore the assessment of essays will require more time to assess.

When interpreting the qualitative findings, another major theme emerged, relating to the future implementation of electronic marking, and their views of moving to implement it fully. As is evident from a student participant quote: 'It's  still  the  same  for  me  And  I  actually  prefer  online'  (Student,  3rd  Year, History).

Several lecturer participants indicated that despite the longer turnaround time, they might consider switching over permanently to digital marking if given the proper support. This is evident from the following quote: 'I feel that with  the  correct  software  and  support,  I  would  really  consider  shifting  all marking in future to electronic (which saves paper and space)' (Lecturer 5, date unspecified, subject unspecified).

Further analysis of the qualitative findings revealed another theme, relating primarily to the variety of factors that could influence the electronic feedback experience. With regard to the emergency online remote teaching adopted by the  institution,  it  is  evident  that  the  student  participants  had  a  negative experience regarding their performance. This is evident in the following quote: 'My marks dropped with the online marking compared to manual marking' (Student, 3rd Year, Economics).

Literature reveals that the 'level of computer experience was also found to have an impact on student performance; more trained students outperform those  with  little  exposure',  implying  orientation  towards  this  mode  would improve performance (cf. Hewson 2012:490). As mentioned in a previously,

SDL requires computer literacy skills in this modern world (cf. Mishra et al. 2013:11). Therefore computer-related skills are necessary to still perform at an optimal level (Han &amp; Hill 2006:30).

Another factor that influenced the electronic feedback was the minimal interaction with the students in the online learning mode of delivery. From the responses obtained from student participants, a clear indication is noted that there was very little interaction on the part of the lecturers, as is evident in the following quote: 'Online marking is good, the only disadvantage is that we can't go through our work with our lecturers' (Student, 4th Year, Accounting).

The  findings  and  literature  (Carless  et  al.  2011:406)  indicated  that  the feedback from lecturers was seldom used and adopted by students. Rogers (2004:8) suggests that SDL does not happen naturally in an environment and that  the  setting,  society,  culture  and  educational  facilities  can  stimulate  or hinder the key features of the process of SDL. This may have happened in this case, where the environment and facilities hampered student SDL.

From the responses of the lecturers, the following quote is evident: 'Did not receive a lot engagement from them. I receive more in contact class' (Lecturer 1, date unspecified, subject unspecified). Therefore, it can be interpreted that the student was not too willing to reach out and find assistance and to interact with the lecturer,  which  might  indicate  that  they  might  not  be  highly  selfdirected and that this intervention did not enhance their SDL as much as what was hoped. Knowles (1975:18) defines SDL as 'a process of learning in which individuals have the ability to identify human and learning resources', which from  the  evidence,  it  would  appear  that  students  are  not  able  to  identify human resources, such as their peers of lecturer, for assistance, implying a low-level SDL. This is also true for the majority of feedback received from the students.

Literature  reflected  asynchronous  online  learning  offers  an  excellent opportunity  to  build  a  'learning-centred  environment  that  stimulates  rich interactions between lecturers and students and among students' (cf. Comer &amp;  Lenaghan  2013:262).  This  may  not  have  occurred  in  this  study,  perhaps because of the difficulty experienced with using the technology, both on the part of the lecturer as well as the students.

## Conclusion

In terms of the research questions, the first of which focuses on the level of self-directedness of students, it was evident that the students overestimated their SDL levels at the beginning of the study. In terms of the research question that focused on the influence of online feedback on student SDL, it was also clear  that  various  perceptions  emerged,  some  students  stating  that  the feedback assisted them to avoid mistakes in future assignments, whilst others

stated that online assessment and feedback was more challenging to them and they scored lower than in a face-to-face session. The following research question looked at the perceptions of students regarding the online feedback. Several  students  felt  that  the  feedback  was  clear  and  more  detailed,  as opposed  to  mere  ticks  and  crosses.  Lastly,  the  lecturers  themselves  were asked about their perceptions of using online marking. The majority found that in the beginning, the use of digital marking and feedback was challenging and that they still fail to communicate with students, but a good point was that the feedback was still useful, some even claiming more valuable compared to face-to-face sessions.

The  21st-century  students  of  today  live  in  a  modern  environment  with technology in every aspect of life. Although technology is mostly utilised to link resources to students, it may furthermore enable formative assessment. Therefore,  it  is  natural  to  expect  a  paradigm  shift  towards  digital  online marking. With sufficient practice and support, the future looks promising for online feedback, as the responses from students indicate positive trends with regards to the quality of the feedback they received. Self-directed learning, as  an  attainable  goal,  necessitates  the  understanding  of  the  types  of learning  that  could  facilitate  21st-century  skills,  such  as  computer  literacy and technologically rich environments. It can be argued that the paradigm shift towards online feedback is in the best interest of developing SDL.

## Chapter 10

The role of teachers' assessment beliefs in fostering self-directed learning skills within the school learning context and its implications for higher education

## Effiness Kamanga

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Josef de Beer

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

## Anitia Lubbe

Research Unit Self-Directed Learning, Faculty of Education, North-West University, Potchefstroom, South Africa

How to cite: Kamanga, E., De Beer, J. &amp; Lubbe, A., 2021, 'The role of teachers' assessment beliefs in fostering self-directed learning skills within the school learning context and its implications for higher education', in E. Mentz &amp; A. Lubbe (eds.), Learning through assessment: An approach towards Self-Directed Learning (NWU Self-Directed Learning Series Volume 7), pp. 217-250, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2021. BK280.10

## Abstract

In this chapter, the authors look at the role of teachers' assessment beliefs in fostering SDL skills within the school learning context, and its implications for higher education. The chapter reports on empirical findings obtained from five purposively sampled teachers consisting of two males and three females from five different schools located around the Bojanala school district in the NorthWest province. In each school, five randomly selected learners also participated with a total of 25 learners consisting of 11 male and 14 female learners. The data were  collected  based  on  individual  semi-structured  teacher  interviews  and learner  focus  group  interviews,  and  the  data  were  analysed  by  means  of inductive  content  analysis.  The  analysis  of  the  data  revealed  that  teachers' assessment beliefs were more focused on the improvement of teaching and learning, learner accountability and less on teacher accountability and relevance to  teaching  and  learning.  The  influence  of  teachers'  assessment  beliefs  on learners'  SDL  behaviours  were  conceptualised  based  on  Weiner's  (2000) interpersonal theory of motivation. The findings revealed that the belief that assessment improves teaching and learning has a positive influence on learners' SDL behaviours. These behaviours include the willingness to take responsibility for learning, displaying an ability to use effective learning strategies, displaying an  increased  motivation,  displaying  effort  attributions  and  engaging  in  selfevaluations. In contrast, the assessment beliefs of holding learners accountable and irrelevance  of  assessment  to  teaching  and  learning again  impede  the development  of  learners'  SDL  behaviours.  The  authors  advocate  for  higher education  to  include  more  structured  programmes  for  teachers  that  would support them in becoming cognisant of their beliefs and changing negative belief systems that work against appropriate learner developmental needs.

## Introduction

In the context of science education in the South African school curriculum (the Curriculum and Assessment Policy Statement, or CAPS) (Department of Basic Education 2011), learners are expected to:

(a)  identify  and  solve  problems  and  make  decisions  using  critical  and  creative  thinking, (b) work effectively as individuals and together with others as members of a team, (c) organise and manage themselves and their activities responsibly and effectively, (d) collect, analyse, organise and critically evaluate information, (e) communicate effectively using visual, symbolic and/or language skills in various modes, (f) use science  and  technology  effectively  and  critically  showing  responsibility  towards the environment and the health of others; and (g) demonstrate an understanding of the world as a set of related systems by recognising that problem-solving contexts do not exist in isolation. (p. 5)

These skills are typical aspects of SRL, a feature of SDL (Saks &amp; Leijen 2014:191). This implies that to achieve the above-mentioned goals stipulated in the South African school curriculum, science education instruction needs to be tailored

to address SDL. Fostering SDL in school is of great importance and has farreaching benefits, such as developing skills that will enable learners to adjust and cope in higher education when they become tertiary students.

Self-directed  learning  within  the  school  context  is  viewed  from  a 'collaborative  constructivist'  perspective,  namely,  that  a  'learner  takes responsibility for constructing meaning whilst acknowledging the participation  of  others  (peers  and  teachers)  in  confirming  worthwhile knowledge' (Garrison 1997:19).  Considering  this  collaborative  perspective, teachers bear, in part, the responsibility to assist learners in developing SDL capabilities. This chapter considers the role that teachers' assessment beliefs play in fostering SDL skills in schools. The focus on assessment beliefs is based  on  compelling  evidence  from  literature  that  beliefs  are  related  to classroom  behaviours,  because  they  influence  the  way  teaching,  learning and assessment is approached (Barnes, Fives &amp; Dacey 2015; Brown 2002; Jane 2013; Remesal 2011). There has not been much formal discussion on the impact of teacher assessment beliefs in fostering SDL skills. This chapter will address this void, by reporting on an empirical study on the influence of teachers' assessment beliefs on learners' SDL behaviour. The purpose of the study was to obtain a greater understanding of how Grade 9 Natural Sciences (NS)  teachers'  assessment  beliefs  influence  learners'  SDL  behaviour  in schools in the Rustenburg area. The following empirical research questions were developed to guide the study:

- 1. What are the assessment beliefs of Grade 9 NS teachers in the Rustenburg area?
- 2.  What  is  the  influence  of  Grade  9  NS  teachers'  assessment  beliefs  on learners' SDL behaviour in the Rustenburg area?

The rest of the chapter will unfold as follows: the conceptual and theoretical framework on which the empirical study was based will be briefly discussed. Next, the methods used and the results obtained will be discussed. Finally, the results are discussed, by exploring the implications of the findings for higher education. There is strong empirical evidence of the link between educational beliefs and educational practice (Northcote 2009) in higher education, and the methods used to assess students in higher education institutions (HEIs) are often not linked to student learning (Carless 2015; Rawlusyk 2018). This might negatively influence SDL.

## Conceptual and theoretical framework

The theory on beliefs was utilised as a theoretical framework for exploring teacher  assessment  beliefs.  Beliefs  are  described  as  'part  of  a  group  of constructs that describes the structure and content of an individual's thinking presumed to drive his/her actions' (Bryan &amp; Atwater 2002:823). Beliefs are said to be far more influential than knowledge in discerning how individuals

make and enact decisions (Nespor 1987:323).  In  this  regard,  many  studies related  to  teacher  beliefs  have  reported  on  how  teachers'  beliefs  about teaching, learning, curriculum and teacher efficacy impacts on the quality of their classroom practices (Belo et al. 2014; Calveric 2010; De Vries, Van de Grift &amp; Jansen 2014; Remesal 2011; Wallace &amp; Priestley 2011).

The focus of these studies centred on the link between teacher beliefs and classroom  practices,  whereas  the  focus  of  the  study  by  Kamanga  (2020) centred on exploring the influence of teacher beliefs on learner behaviour. This  study  uses  Weiner's  (2000)  'interpersonal  theory  of  motivation'.  This theory is concerned with an individual's desire to search for the causes of their successes and failures, known as attributions (Hunter &amp; Barker 1987:51). These attributions  serve  as  an  important  stimulant  for  motivation,  which  in  turn drives  learner  behaviour  (Kamanga  2020:42).  The  focus  was  on  learner behaviour that reflects SDL skills, and teacher beliefs on assessment.

Figure 10.1 illustrates the way the study was theorised and conceptualised by  looking  at  the  connection  between  teachers'  assessment  beliefs  and learners' SDL behaviour.

Figure 10.1 depicts the link between assessment belief, actual assessment practices  and  SDL  behaviour  which  is  built  upon  the  attribution  theory.

<!-- image -->

Source : Based on Kamanga (2020:40).

TABLE 10.1: Brown's (2002:27) categories of teacher assessment conceptions, which include Opre's (2015:229) implications for practice.

| Assessment conception ('belief')                                                                                       | Implications for classroom practice                                                                                                                                                                                                                                                                                                                                                                                                               |
|------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Assessment is 'useful because it can  provide information that can improve  instruction and learning' (Brown  2002:27) | Teachers with this belief would attempt to optimise the learners'  learning process. They would tend to employ methods that give  learners useful feedback 'through the process of self- or peer- assessment according to Dayal and Lingam (2015)' (Opre 2015:229).  Teachers would also use feedback to obtain information to optimise  their own teaching activities. Therefore, assessment methods are  perceived as serving a formative role. |
| ' Assessment is a necessary process  for making learners accountable for  their learning' (Brown 2002:27)              | Teachers with this belief would favour formal summative assessment  as the focus is not on learners' learning processes but on 'the  position learners occupy in comparison with other learners who are  in the same year of study' (Opre 2015:229).                                                                                                                                                                                              |
| Assessment is a process of making  schools and teachers accountable                                                    | Teachers would emphasise the generation of marks that can be  reported to external agencies.                                                                                                                                                                                                                                                                                                                                                      |
| Assessment is 'irrelevant to the work  of teachers and the lives of learners'  (Brown 2002:27)                         | Teachers would avoid formative assessment and 'take a haphazard  approach to summative assessment, creating a self-fulfilling  prophecy that assessment is a waste of time' (Brown 2002:27).                                                                                                                                                                                                                                                      |

Source : Kamanga (2020:8).

According to Hunter and Barker (1987:51), the attribution theory is 'concerned with our constant search for the causes of our successes and failures'. In other words, this theory puts emphasis on what individuals think is the cause of a certain outcome, known as perceptions of causality. According to Hunter and Barker  (1987:51),  these  perceptions  of  causality  influence  individuals'  selfconcept, feeling of potency, expectations for future situations and subsequent motivation to put forth effort. To this end, the attribution theory can be applied to learners and teachers based on the assumption that, in forming perceptions of causality (also known as attributions), individuals make use of situational cues of the meanings they have acquired through prior experiences (Schunk 2012:370). In other words, teachers can hold assessment beliefs relating to the purpose of assessment, which are influenced by their attributions, which can then  give  rise  to  feelings  of  potency  and  subsequent  motivation  to  put forth the assessment practice. Similarly, learners can also develop attributions through  situational  cues  obtained  from  their  teacher's  beliefs  and  their learning environment, which can influence their belief system, which, in turn, drives their behaviour (Hunter &amp; Barker 1987:51).

## The link between assessment beliefs and actual assessment actions

A study conducted in South Africa by Vandeyar and Killen (2007:110) revealed that teachers' observed assessment actions appeared to be highly consistent with the assessment beliefs that were expressed during follow-up interviews. Another study by Jane (2013) conducted in South Africa also revealed that teachers' actual assessment practices were a reflection of their assessment beliefs. Using Brown's (2002) model, teachers' differing assessment beliefs

could be conceptualised and identified. Because having identified four basic beliefs regarding assessment, researchers have formulated models of assessment  beliefs  which  correspond  to  the  potential  enactment  of  their assessment practices (see Table 10.1).

Table 10.1 provides a description of the four categories associated with teachers' assessment beliefs which could provide a better understanding of the nature of a teacher's subsequent assessment practices. The authors of this chapter acknowledges that there could be a variation between what teachers  believe  and  how  they  act  in  classroom  settings.  This  fact  was observed  in  Jane's  (2013)  study,  whereby  the  two  teacher  participants conducted assessments to adhere to what is expected from them , and thus  incorporated  practices  that  went  against  their  belief  system.  Jane (2013) attributed this variation because of certain contextual factors that were  mediating  the  dynamics  between  the  assessment  beliefs  and  the assessment  practice.  This  implies  that  when  examining  the  issues  of assessment  beliefs,  there  is  a  need  for  more  explicit  discussion  and understanding  that  recognises  the  interaction  of  individuals  with  other people and with their context.

## The link between attributions and learner behaviour

According  to  Weiner's  (2000)  'interpersonal  theory  of  motivation',  after  a performance a learner and observer (teacher, parent or peer) can consciously or  unconsciously  look  for  causal  factors  observed  from  their  classroom interactions. For example, a (Hunter &amp; Barker 1987):

[ T ]eacher's annoyance with a less-than satisfactory performance could say to a learner that he or she has the ability to perform successfully and his or her lack of effort is responsible for the low performance. (p. 53)

n so doing, this convinces a learner of the teacher's belief that he or she has the ability to be successful when he or she puts forth more effort. Consequently, such beliefs can result in learner behaviour that is proactive and motivated to put  forth  more  effort  in  order  to  obtain  future  success  (Hunter  &amp;  Barker 1987:53).  On  the  other  hand,  sympathy  and  understanding  for  a  less-than satisfactory  performance  could  say  to  a  learner  that  he  or  she  cannot accomplish the task regardless of how much effort he or she puts in (Hunter &amp; Barker 1987:53). In so doing, this convinces a learner of the belief that, even with effort, he or she does not have the ability to meet the expectations. Such beliefs could result in learner behaviour that is reactive to the environment and not motivated to put forth any effort, thereby perpetuating future failure (Hunter  &amp;  Barker  1987:53).  This  shows  that  the  concept  of  motivation  is important because it is intimately linked with learning and subsequent learning behaviour (Schunk 2012:340).

Thus, motivation can be regarded as an explanatory concept that can assist us  in  understanding  the  reason  why  learners  behave  in  a  specific  manner (Schunk 2012:346).  For  example,  learners  who  feel  they  have  little  control over academic outcomes have an external locus of causality and believe that the ability to be successful emanates from unstable factors like luck and help from others (Hunter &amp; Barker 1987:53). Consequently, learners who hold such negative  attributions  would  unlikely  be  motivated  to  engage  in  taskappropriate activities that encourage SDL behaviours. The assumption is that such  negative  attributions  can  be  promoted  by  assessment  beliefs  that emphasise  summative  assessment  practices  that  promote  surface-level learning strategies such as memorisation and rehearsal of information. This is because  the  feedback  obtained  from  summative  assessment  emphasises current  'learner  achievement  and  may  not  highlight  the  importance  of  the processes, skills and strategies underlying task completion' (Schunk 2012:376).

Contrariwise, when the factors attributed to their outcomes are regarded as internal, stable and controllable, learners believe that their 'successes are primarily due to their effort and ability and would therefore have stronger motivation  and  staying  power  to  complete  challenging  work'  (Cauley  &amp; McMillan 2010:5). Such positive attributions can thus be promoted through assessment beliefs that favour  formative  assessment  practices.  This  assumption is based on the fact that formative assessments inform learners 'about their own learning and their progress in meeting their goals' (Cauley &amp; McMillan 2010:2). This is important because formative assessments can allow learners to see concretely how they can improve, which leads to increased motivation and  involvement  (Cauley  &amp;  McMillan  2010:2).  Therefore,  articulation  and identification of assessment beliefs can serve as a lens for understanding how learners'  SDL  behaviour  is  impacted  by  their  teachers'  assessment  beliefs using the theory of attributions. To achieve this goal, the study by Kamanga (2020) characterised SDL behaviour according to the 'process' and 'person' elements  of  SDL  and  is  based  on  many  researchers'  contributions  to  SDL models  (Garrison  1997;  Hiemstra  &amp;  Brockett  2012;  Long  1989,  2000).  The person  element  includes individual characteristics such  as motivation, enthusiasm, creativity and critical reflection. The process element focuses on the learner activities. Organising SDL behaviour into these elements served as a  guide  for  identifying  learner  SDL  behaviour  within  the  school  context. According  to  Hiemstra  and  Brockett  (2012),  a  holistic  understanding  of learners' self-direction requires the interactions of three elements (process, person and context). Thus, the study included the SDL context element using sociocultural elements from cultural-historical activity theory (CHAT).

The CHAT framework offers a cross-disciplinary perspective for analysing what individuals do in a specific context, the roles that individuals have in this particular context and the interpersonal relationships in which learners learn (Mentz &amp; De Beer 2017:101). It is important to note that there are other factors

other than teachers' assessment beliefs that can also affect classroom actions and behaviour, and that a teacher's assessment belief may not necessarily reflect  what  is  actually  done  in  practice  (Luft  &amp;  Roehrig  2007:41).  These shortcomings can be addressed by using data collection methods that allow the researcher insight into the thinking of participants. The data obtained can then be further analysed using CHAT. This framework helps to (Taylor 2014):

[ D ]irect attention to who is carrying out activities (division of labour), what tools are at their disposal, which cultural norms and rules govern their behaviour, and what the desired outcomes are. (p. 98)

In  the  CHAT framework, the activity system is the primary unit of analysis, which  comprises  the  following  sociocultural elements: subject, object, outcomes, tools, rules, community and division of labour (Engeström 2009). Activity theorists make use of an activity triangle to depict and explain the levels of contradictions that the subject might experience in an activity system (Roth &amp; Lee 2007), depicted in Figure 10.2.

Figure  10.2  depicts  the  six  activity  system  elements.  The  'subject'  is described as the individual or group of individuals whose viewpoint is adopted; the  subject  is  the  protagonist  who  works  towards  the  achievement  of  the 'object'  as  the  object  is  described  as  the  problem  at  which  the  activity  is directed and which is moulded and transformed into 'outcomes' with the help

<!-- image -->

Source : Authors' own example, based on third-generation cultural-historical activity theory as developed by Engeström (2009).

of tools (Bourke, Mentis &amp; O'Neill 2013:36). The tools element is described as 'mediating artefacts that take part in the transformation of the object into an outcome,  which  can  be  desired  or  unexpected'  (Murphy  &amp;  RodriguezManzanares 2008:443). Rules are 'explicit and implicit norms that regulate actions and interactions within the system' (Murphy &amp; Rodriguez-Manzanares 2008:443). The community element refers to 'the participants of an activity system who share the same object'. The division of labour involves 'the division of tasks and roles among members of the community and the divisions of power and status' (Murphy &amp; Rodriguez-Manzanares 2008:443).

## Research methods

This chapter reports on a multiple-case study carried out in five schools which were  randomly  selected  in  the  Rustenburg  area  in  the  Bojanala  Platinum district, North West province, which comprised 139 secondary schools in total. From the five selected schools, the NS teacher(s) responsible for teaching the Grade 9 learners were purposively selected. The study sought to explore the complex  issues  around  individuals'  assessment  beliefs  (amongst  teachers) and SDL behaviour (amongst learners). An understanding of these complex issues requires an approach that elicits the individual's views and opinions (Creswell et al. 2007:245). Therefore, the study used a qualitative methodology and data were collected by means of face-to-face interviews.

## Capturing teachers' assessment beliefs

To elicit teachers' assessment beliefs, the study used face-to-face individual semi-structured  interviews  with  five teachers  who  were  purposively sampled  from  five  different  schools  situated  around  the  North  West Bojanala  school  district  which  consisted  of  two  male  and  three  female teachers. The research on 'teachers' assessment beliefs: validation of an abridged  instrument'  by  Brown  (2006)  guided  the  development  of  the following interview questions:

- 1. In your opinion, what is the purpose of assessment?
- 2.  What do you think is the best way of assessing learners' understanding?
- 3.  Tell me more about your experiences with assessment within the Grade 9 NS subject.

The first interview question probed for teachers' assessment beliefs. Once identified  they  could  be  categorised  into  four  main  assessment  belief systems,  namely,  (1)  assessment  is  irrelevant  for  teaching  and  learning, (2)  assessment  holds  teachers  and  schools  accountable,  (3)  assessment holds  learners  accountable,  and  (4)  assessment  improves  teaching  and learning  (based  on  Brown's  2004  model  of  assessment  conceptions) (Brown 2016).

The  second  interview  question  probed  for  teachers'  beliefs  related  to specific  choices  of  assessment  methods,  which  provided  access  into  the teachers'  thinking  regarding  the  purpose  of  assessing  learners.  The  third interview  question  provided  a  further  means  of  determining  teachers' assessment  experiences  and  uncovering  their  beliefs  -  specifically  in  the context of Grade 9 NS teaching and learning.

## Capturing learners' self-directed learning behaviour

To identify learners' SDL behaviour, the study used focus group interviews with five randomly selected learners taught by the five teacher participants at their respective schools. 1  The following interview questions were developed to assess learners' SDL behaviours:

- 1. Describe your role as a learner during NS lessons?
- 2.  What are some of the activities which enable you to understand the topics taught in NS lessons better?
- 3.  What type of studying methods help you to perform well in NS?
- 4.  What are your views about assessing your own NS activities instead of your teacher assessing your work?
- 5.  Tell me a bit more of your experiences with assessment within NS?

The five questions were phrased to identify SDL behaviour amongst learners, specifically within the context of NS. In doing so, this helped to determine the influence of their teachers' assessment beliefs on their SDL behaviour in the analysis of the data.

## Procedures

The first author developed the interview questions, conducted the interviews, and  transcribed,  analysed  and  interpreted  the  data.  Informed  consent  was requested  from  all  potential  research  participants  after  obtaining  ethical clearance from NWU as well as the North West Department of Basic Education. The gatekeepers (school principals) were also consulted before collecting the data.  Because  the  participating  Grade  9  learners  were  under  the  age  of  18, parental assent was requested. The primary researcher started with the data collection  after  an  independent  person  (another  teacher  at  the  school) administered the informed consent process, and the willing participants have signed. Aspects covered in the consent form included: what the research was about; what was expected of the participants; benefits and risks of participating; assurance of confidentiality and protection of identity; dissemination of findings

1. In total, 25 learners were involved in the study consisting of 11 male and 14 female learners.

and a declaration section. Permission to use an audio-recorder was requested before interviews began. Participants were not subjected to any risk of loss of self-esteem, or embarrassment during the entire interview process. The primary researcher did not use descriptors or names that could lead to the identification of any of the participants during data collection, analysis and interpretation. The focus group participants were also requested to respect each other and to keep the discussions and other participants' identities confidential.

Once all recorded interview data were transcribed, the data were inductively analysed using open coding on convergent data from different participants to build a coherent justification of themes (Nieuwenhuis 2016:116). Passages in the  transcribed  interviews  were  further  analysed  and  interpreted  within their  context  to  establish  the  influence  of  teachers'  assessment  beliefs  on learner SDL behaviour by exploring the motivational consequences of learner attributions.  Data  were  further  analysed  using  third-generation  CHAT  as  a lens, which  exposed  contradictions,  intentionality,  and  the  relationships amongst and between social elements. Teachers' views on assessment, as one activity system, was juxtaposed with learners' experiences of assessment, as the second activity system, as suggested by Mentz and De Beer (2017) based on the work of Engeström (2009).

When classifying data all codes were developed from the transcripts using participant words in order to establish trustworthiness of the data. Member checking  with  teacher  participants  was  conducted,  credibility  was  also enhanced by converging data from different participants during the analysis process to build a coherent justification of themes. Dependability was achieved by providing an extensive and detailed presentations and interpretations of the  findings.  Conformability  was  achieved  by  verifying  the  analysis  and interpretations  of  findings  by  consulting  the  second  and  third  author  who served  as  knowledgeable  peers  in  the  field  of assessment  and  SDL. Transferability was achieved through the triangulation process obtained from different participants' data as the study worked with five teacher participants and a total of 25 learner participants so as to obtain a wide variety of opinions as possible.

## Research findings

## Teachers' assessment beliefs

The following emerging themes were obtained inductively based on codes emerging from the interview data:

- 1. assessment is for the improvement of learning
- 2.  assessment is for the improvement of teaching
- 3.  assessment is for certifying learners

- 4.  assessment serves as a way of certifying learning
- 5.  assessment provides insight into teacher effectiveness
- 6.  assessment has a negative impact on learners
- 7. assessment has little impact on teaching and learning.

Each of the themes will be discussed to articulate and understand teachers' assessment beliefs.

<!-- image -->

## Assessment is for the improvement of learning

Teacher A, Teacher B, Teacher C and Teacher D believed that the purpose of assessment is to establish what learners know or what they have learned so that  they  can  identify  learners'  areas  of  weakness  in  order  to  help  them improve. It is worrying that teachers, in general, seem to be focused only on the cognitive domain in their assessment. Rotherham and Willingham (2010), state that the teaching for affective outcomes (and the assessment thereof) remains:

[ A ] matter of chance rather than the deliberate design of our school system […] we cannot afford a system in which receiving a high-quality education is akin to a game of bingo. (p. 17)

It is noteworthy that teachers in their assessment practices do not seem to pay much attention to the affective domain. Hiemstra and Brockett (2012) consider  affective outcomes,  such  as  enthusiasm  and  motivation,  as important attributes of a self-directed learner; yet research shows that such outcomes  are  often  marginalised  because  of  this  exclusive  focus  on  the cognitive domain.

## Assessment is for the improvement of teaching

Teacher B and Teacher D believed that the purpose of assessment is to guide or inform teachers' decisions on instruction, with the aim of advancing learning during  teaching.  Additionally,  Teacher  B  used  assessment  results  to  group learners  for  differentiated  teaching  and  learning  with  the  aim  of  helping learners improve their performance. This suggests that the teachers realised that they could alter their teaching to improve the quality of learning.

## Assessment is for certifying learners

Teacher  A  and  Teacher  C  believed  that  the  purpose  of  assessment  is  for placing  learners  into  the  next  grade  and  assigning  grades.  This  view  of assessment  is  regarded  as  serving  an  administrative  goal,  which  targets government agencies, parents and other stakeholders interested primarily in reports on the level of learners' work.

## Assessment serves as a way of certifying learning

Teacher A believed that the purpose of assessment is to determine learning success at the end of a learning experience, with the aim of making learners accountable  for  their  learning.  Assessment  is  thus  regarded  as  a  way  of establishing what learners have learned. Teacher A said:

'[ T ]he problem is exams […] this is a problem and we are not in control of it […] because a child has to read at home […] if he can't read at home […] he cannot be disciplined enough to say I am going to study my work at home […] they won't fail.' (Teacher A, male, 29 August 2019)

Teacher E considered assessment as a means of finding out how much learners have learned from teaching, which is shown by the following quote: 'to test whether the learner has captured what I taught them' (Teacher E, female, 10 September 2019).

This suggests that the measurement mission for the assessment of learners is to establish how well or how poorly they are doing based on what they have learned.

## Assessment provides insight into teacher effectiveness

Teacher B believed that the purpose of assessment was to provide a personal indicator as to how well she is doing, whereas Teacher E believed that the purpose  of  assessment  is  to  determine  whether  she  is  on  a  par  with  the content coverage. This shows that these teachers made use of assessment results to take accountability for their actions, which can contribute to positive pressure to improve performance.

<!-- image -->

## Assessment has a negative impact on learners

Teacher A believed that assessment can be an obstacle to learners based on a bias in the weighting distribution used for assessment grading. None of the other teachers held the same view as Teacher A on assessments being unfair and being an 'enemy of learners'. Teacher A said:

'I want to tell you the biggest enemy of all these children is exams and they fail it […] all the countries […] exams is the problem […] learners they don't read […] teachers are teaching […] we are giving them questions that are relevant but the enemy is the examinations.' (Teacher A, male, 29 August 2019)

Interesting to note is that Teacher A was also of the opinion that assessment could be used to establish whether learners have understood the work, yet also believed that assessment could be an 'enemy' to learners. This seems to suggest that the teacher assumed that one assessment is 'good' and the other 'bad', which could lead to a dysfunctional approach to classroom assessment.

Teacher A said: 'so the most important thing about assessment is to get the feedback from the learners whether they understood the work' (Teacher A, male, 29 August 2019).

These differing views about the purpose of assessment suggest that these teachers had  naïve understandings  of the purpose  and  principles of assessment.

## Assessment has little impact on teaching and learning

Teacher A believed that assessment practices, which involved learners making models and projects, had a minor impact on teaching and learning, as they did not help learners develop the necessary memorisation and recalling skills. This teacher's viewpoint is cause for concern as, in the current and future job market, knowing basic facts are important, but knowing how to think critically, work collaboratively  and  solve  problems  are  essential  (Rotherham  &amp;  Willingham 2010:17). This response  suggests  that  this teacher's teaching  approach emphasises  recall  and  rote  memorisation,  providing  little  opportunity  for learners to develop structures of knowledge for reasoning and problem-solving. This teacher probably had insufficient knowledge about learning, the principles of instruction, and the aims and purpose of education in a complex 21st century.

The identified themes were further organised into four families, based on Brown's (2004) model of assessment conceptions. In so doing, the study was able to address the research question: ' What are the assessment beliefs of Grade 9 NS teachers in the Rustenburg area? ' (Kamanga 2020).

Table 10.2 presents a summary of the teachers' beliefs about assessment, which revealed that teachers held assessment beliefs in different combinations.

The  pattern  of  beliefs  held  by  the  participants  shows  that  most  of  the participants believe that assessment improves teaching and learning, and that assessment holds learners accountable. Fewer believed that assessment holds teachers accountable, and only one teacher from this group of participants believed that assessment is irrelevant to teaching and learning. The pattern obtained also shows that teachers held more than one type of assessment belief. This finding corresponds with Brown's (2002) study which showed that teachers could simultaneously hold multiple interacting assessment beliefs as opposed to just having one assessment belief. According to Opre (2015:231), this  finding  can  be  attributed  to  the  fact  that  'assessment  serves  multiple purposes  ranging  from  providing  information  about  learning  progress, teaching quality and institutional accountability'. In addition to characteristics of teachers holding multiple assessment beliefs, what is unknown at this stage is how these multiple interacting beliefs inter-relate and how strongly teachers may hold each of these assessment beliefs (Brown 2002:50).

TABLE 10.2: Summary of Natural Sciences teachers' assessment beliefs.

| Natural Science teacher   | Assessment beliefs                                                                                                                |
|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| Teacher A                 | Assessment improves teaching and learning Assessment holds learners accountable Assessment is irrelevant to teaching and learning |
| Teacher B                 | Assessment improves teaching and learning Assessment holds teachers accountable                                                   |
| Teacher C                 | Assessment improves teaching and learning Assessment holds learners accountable                                                   |
| Teacher D                 | Assessment improves teaching and learning                                                                                         |
| Teacher E                 | Assessment holds learners accountable Assessment holds teachers accountable                                                       |

Source : Kamanga (2020:79).

## How do teachers' assessment beliefs influence the self-directed learning behaviour of learners?

To address the following research question: ' What is the influence of Grade 9 NS teachers' assessment beliefs on learners' SDL behaviour in the Rustenburg area? ' (Kamanga  2020);  data  relating  to  learners'  SDL  behaviour  were identified. The transcribed interviews were analysed and interpreted in their context. The following themes with regard to learners' SDL behaviour emerged:

- 1. social skills should be developed in the NS classroom
- 2.  learning strategies that foster transmission mode
- 3.  learning strategies that foster making sense of ideas
- 4.  approach to studying is characterised by lack of motivation
- 5.  goal setting is focused on aiming for good results
- 6.  taking responsibility for learning
- 7. learners could evaluate their own learning progress
- 8.  learners have a strong dependency on teachers to evaluate their work
- 9.  attribute success or failure to task difficulty
- 10.  attribute success or failure to effort taken towards a task
- 11.  the tendency of learners to become motivated.

The  identified  themes  will  be  briefly  discussed  to  demonstrate  the  SDL behaviour of Grade 9 learners.

## Social skills should be developed in the Natural Sciences classroom

This theme is concerned with learners' social-behavioural implementation of the learning process. Most learners in this study identified 'listening' as their role  during  an  NS  lesson.  It  appears  that  learners  identify  with  the  role  of

passive  recipients  of  information  presented  to  them  by  the  teacher.  Other social skills identified by some learners included communication, expression of  feelings,  cooperation  and  respecting  their  teacher's  authority.  This  is depicted by the following quotes:

- '[…] there's nothing that we can know without communicating […]' (Learner C3, male, 04 September 2019)
- '[…] to listen and express my feelings with what my teacher has taught me […]' (Learner D2, female, 06 September 2019)
- '[…]  to  cooperate  in  class  and  respect  the  NS  teacher.'  (Learner  B1,  male,  02 September 2019)

'[…] focusing in [ sic ] answering as many questions as you can.' (Learner D1, female, 06 September 2019)

- '[…] to listen and concentrate in class.' (Learner A2, female, 29 August 2019)

## Learning strategies that foster transmission mode

Learners indicated that their classrooms were characterised by learning strategies  that  foster  basic  reproduction  of  surface  learning,  such  as, recalling, memorising and revising. This finding suggests that classroom activities are dominated by three modes of learning - reading, writing and correcting - none of which encourage SDL. This does not bode well for the  development  of  21st  century  skills  or  the  effective  preparation  of learners  for  a  complex  21st  century.  This  is  depicted  by  the  following quotes:

'[…] to read your notes and to study them and revise your classwork.' (Learner A2, female, 08 August 2019)

'[…] I read my notes and make my own notes out of what my teacher as taught me.' (Learner D4, male, 06 September 2019)

- '[…] you write what you remember, and you refer back to your NS book […].' (Learner B5, female, 02 September 2019)
- '[…] every time after each lesson, I go and read it over and over again and that's how it stays […].' (Learner B4, female, 09 September 2019)

' After each lesson, go home practise the work that we did in the class […].' (Learner C2, female, 04 September 2019)

## Learning strategies that foster making sense of ideas

Learners used learning strategies that foster deep transformation of learning, including researching, working in groups, experimentation and seeking help

from peers or teachers. Such learning strategies are consistent with the social constructivist view of learning, as cognitive interactions are regarded as being developed through socially supported interactions. This is depicted by the following quotes:

'[…] it's good if you work with someone else like your classmates so that you can understand each other.' (Learner B2, male, 02 September 2019)

'For me, the easiest way to learn is to doing [ sic ] things practically and experimenting […].' (Learner C3, male, 04 September 2019)

'I read, when I don't understand I go to another person to help me.' (Learner D5, female, 06 September 2019)

'I use my phone to research, and it gives me more information one that's even not in the notes and the textbook.' (Learner E5, female, 10 September 2019)

'I get into research; I maybe go to the library and take books for Science [ sic ] […].' (Learner C4, male, 04 September 2019)

## Approach to studying is characterised by lack of motivation

Learners expressed a lack of motivation to study, as they were easily distracted, felt  lazy  to  read,  had  limited  concentration  and  preferred  to  play.  This  is depicted by the following quotes:

'I want to go to play [ sic ] […] instead of studying NS.' (Learner A5, male, 29 August 2019)

'I'm still facing some problems' cause I'm lazy to read […] I don't like reading […] it's not my stuff [ sic ].' (Learner B2, male, 02 September 2019)

'[…] we don't put our full concentration on the studying [ sic ].' (Learner A4, female, 29 August 2019)

'[…] that's why most of us fail […] we just read for the sake of studying.' (Learner A1, male, 29 August 2019)

'I'm tired […] will be reading things for the sake of studying […] not like […].' (Learner A3, female, 29 August 2019)

This  is  a  cause  for  concern  because  low  motivation  is  associated  with  low levels of learner engagement (Demetriou 2011:16), which is evident from this theme. Whilst analysing the data from the interviews with teachers, it became clear that the teachers did not pay attention to the assessment of affective outcomes (such as values and interest). It is, therefore, not surprising that learners lack affective skills as teachers, in Rotherham and Willingham's (2010) parlance, go about teaching the affective domain as if it is a game of bingo hoping  learners  will  achieve  affective  outcomes,  but  not  identifying  these outcomes for their lessons.

## Goal setting is focused on aiming for good results

Passing Grade 9, improving grades and career choices were some of the goals that were identified. This is depicted by the following quotes:

- 'I always read stuff about NS, because when I grow up, I want to do […] I want to be a doctor […].' (Learner B1, male, 02 September 2019)
- 'I must like try [ sic ] to improve my levels of Natural Science.' (Learner E4, female, 10 September 2019)
- '[…] and getting to process that information and getting educated and then getting to pass.' (Learner B4, female, 02 September 2019)
- 'I know Grade 9 is a very challenging grade […] so many learners must work very hard […] to go to the next grade.' (Learner C5, female, 04 September 2019)
- '[…] so I heard that to do engineering, you need physics and maths […]' (Learner B2, male, 02 September 2019)

When  goal  setting  is  focused  on  improving  grades  and  passing  this is associated with a performance-oriented classroom that prioritises demonstration  of  competence  over  the  gaining  of  competence,  which  is associated  with  mastery-oriented  classrooms  (Daniels  &amp;  Poth  2017:837). Best practices related to goal setting involves learners thinking about their own work in terms of goals to develop the capacity to work at a metacognitive level (Schunk  2012:346)  as  this further develops  a  mastery-oriented classroom.

## Taking responsibility for learning

This theme is concerned with learners' capability of taking responsibility for the  construction  of  personal  meaning.  Learners  expressed  a  capability  of taking initiative for the construction of personal meaning. This is evident in the following quotes:

- '[…]  the  topics  that  we  are  going  to  talk  about  next  week,  I  read  it  earlier  […].' (Learner C4, male, 04 September 2019)
- 'I do my own work personally at home […] maybe before the lesson […].' (Learner C4, male, 04 September 2019)
- '[…] on my phone, I have the learning application to help me - that's how I assess myself.' (Learner D2, female, 06 September 2019)
- 'I use my phone to research, and it gives me more information; one that's even not in the notes and the textbook […].' (Learner E5, female, 10 September 2019)

Other learners expressed a passive learning orientation (as noted in the social skills theme).

## Learners could evaluate their own learning progress

This theme is based on specific attributes of a learner's ability to evaluate and assess the quality of learning outcomes and to improve strategies for further learning activities. Learners expressed that assessing their own work, instead of  the  teacher,  was  a  good  idea.  Learners  were  in  support  of  learner  selfevaluations. This is evident in the following quotes:

- '[…] we get to assess our activities […] we get to see our mistakes better than when the teacher is assessing our activities.' (Learner B1, male, 02 September 2019)
- '[…]  you  can  see  where  your  weak  points  are  and  strong  points  are  [ sic ]  […].' (Learner B5, female, 02 September 2019)
- '[…]  assessing  yourself,  it's  much  better  because  you  understand  yourself  more than anybody else.' (Learner B4, female, 02 September 2019)
- '[…] when I fail the formal task, I learn from my mistakes from them.' (Learner D4, male, 09 September 2019)
- '[…] for example, my class works I use to take them and compare them how am understanding [ sic ] […].' (Learner E3, male, 10 September 2019)

## Learners have a strong dependency on teachers to evaluate their work

Learners  were  against  self-evaluations  and  seemed  to  believe  they  were incapable of assessing their own work as they emphasised that they needed their teacher's guidance. This is evident from the following quotes:

- 'I think it's best for teachers to assess our work, because we need their guidance and they must correct us.' (Learner C5, female, 04 September 2019)
- '[…] it's better to have someone who's going to judge you with your work.' (Learner D3, male, 06 September 2019)

'Because assessing your work […] you can cheat ma'am […] on yourself.' (Learner A3, female, 29 August 2019)

'I prefer the teacher to assess my work […] so that he or she can explain to me why I went wrong […] where I need to fix my mistakes.' (Learner A1, male, 29 August 2019)

This theme suggests that these learners were not active in critiquing their own work as part of their learning; hence, they did not see the important supporting role that self-assessment could play in improving their learning. The latter is supported by the fact that none of the participating teachers made mention of using self-assessment methods as part of learning.

## Attribute success or failure to task difficulty

This theme involves how learners interpreted the causes of their successes and failures in reaction to their tasks. Learners attributed their failure to the task being difficult and attributed their success to the task being easy. This attribution is evident in the following quotes:

- '[…] when we write class works in NS, it's not that difficult […] but in exams ma'am […] it's more difficult and it's like its heavy […]' (Learner A3, female, 29 August 2019)
- '[…] what I have experienced, Natural Sciences is a very challenging subject - you can either pass or fail […].' (Learner D1, female, 06 September 2019)
- '[…]  so  you  can  understand those [ topics ]  who are easy and fail those who are difficult […].' (Learner D2, female, 06 September 2019)

Such  attributions  can  result  in  learner  behaviour  that  is  reactive  to  the environment and not motivated to put in any effort because learners ultimately believe that, regardless of how much effort they put in, they cannot accomplish the task because it is difficult (Hunter &amp; Barker 1987:53).

## Attributes success or failure to effort taken towards a task

With  effort  attributions,  learners  attribute  their  success  to  the  ability  to perform a given task successfully and attribute their failures to their lack of effort in a particular task. This is depicted by the following quotes:

'I pass them [ formal tasks ] because I read.' (Learner D4, male, 06 September 2019)

- '[…] it was really hard at first […] but then if you get more understanding about it […] you see that it's not that hard […].' (Learner B4, female, 02 September 2019)
- '[…]  when  it  [ marks ]  becomes low, I like  ask  myself  where  did  I  go  [ sic ]  wrong […] and I start reminding myself like [ sic ] I wasn't focusing on NS too much […].' (Learner E4, female, 10 September 2019)

## The tendency of learners to become motivated

This theme is based on learners' perceived values, attitudes, feelings and goals towards their learning. Some aspects expressed by learners had the potential to influence their motivation, such as, love for the subject, finding the subject interesting  and  fun,  and  their  teacher  making  lessons  enjoyable.  This  is depicted by the following quotes:

'NS is my second favourite subject […].' (Learner A2, female, 29 August 2019)

- '[…]  and  NS  is  a  very  fun  and  interesting  subject  […].'  (Learner  C5,  female,  04 September 2019)
- 'I love it [ Natural Sciences subject ] very much […].' (Learner C4, male, 04 September 2019)

- 'I always read stuff about NS, because when I grow up, I want to do […] I want to be a doctor […].' (Learner B1, male, 02 September 2019)
- '[…] in class, we pay more attention to her, listen to what she say [ sic ] so that it would be easier when we get to the next grade.' (Learner E5, female, 10 September 2019)
- '[…] he [ their Natural Sciences teacher ] makes sure that we enjoy the lesson […].' (Learner C3, male, 04 September 2019)

The above-mentioned themes depict learner behaviour associated with both process and personal SDL  elements. The contributions of teachers' assessment beliefs towards learners' SDL behaviour are discussed below by considering  the  motivational  consequences  arising  from  the  learners' attributions.  The  discussion  is  based  on  literature  that  clearly  establishes that attributions serve as important stimulants to motivation, which, in turn, drives learner behaviour (Demetriou 2011; Weiner 2000). The contribution of each of the teacher's assessment beliefs on learners' SDL behaviour will be discussed  to  demonstrate  how  teachers'  assessment  beliefs  influence learners' SDL behaviour.

## The influence of the belief that assessment holds learners accountable

The findings show that teachers who held the belief that assessment holds learners accountable, tended to favour summative assessments practices over formative practices, as was the case with Teacher A. Summative assessments promote feedback about current learner achievement and this encourages task-related attributions (Cauley &amp; McMillan 2010:1). This was evident in learner A3, taught by Teacher A, who displayed task-related attributions. This learner believed that success is determined by factors beyond her control, such as, the level of difficulty of a given task. Learner A3 said: 'when we write class works in NS it's not that difficult […] but in exams ma'am […] it's more difficult and it's like its heavy' (Learner, female, 29 August 2019).

Such task attributions promote low expectations for success, as learners believe that they are not in control of outcomes, which results in low levels of motivation (Cauley &amp; McMillan 2010:1). Low levels of motivation were more prevalent  amongst  learners  taught  by  Teacher  A,  which  is  depicted  in  the following quotes:

- '[…] we don't put our full concentration on the studying […] because we just like […] nah it's just for the test nothing more nothing less.' (Learner A4, female, 29 August 2019)
- '[…] when I study NS, I get distracted.' (Learner A5, male, 29 August 2019)
- '[…] that's why most of us fail […] we just read for the sake of studying.' (Learner A1, male, 29 August 2019)

These  low  levels  of  motivation  displayed  by  the  learners  negatively impacted the actualisation of meaningful SDL behaviour. This is evident from the findings, which showed that none of the learners taught by Teacher A expressed the capability of taking more responsibility for their own learning.

Vandeyar and Killen (2007:102) state that teachers who hold the belief that assessment  holds  learners'  accountable  'tend  to  absolve  themselves  from responsibility for learner failure'. This is evident from the following quotation:

'[ T ]he problem is exam […] no we must face reality […] is it fair? […] that somebody must go home and read for the exam and he comes back and he did not read the exam and he fails exam now I must stand there and explain why this person […].' (Teacher A, male, 29 August 2019)

This tendency to absolve himself from responsibility for learner failure suggests that this teacher regarded the success and failures of learners as occurring independently of how he behaved or taught, because he believed that he was not in control of learners' success or failure.

## Teacher A said:

'[ T ]his is a problem and we are not in control of it […] because a child has to read at home […] if he can't read at home […] he cannot be disciplined enough to say I am going to study my work at home […] they will fail.' (Teacher A, male, 29 August 2019)

Teacher A attributed learner failure to a lack of effort in studying for exams; hence,  it  is  not  surprising  that  he  viewed  exams  as  the  learners'  greatest enemy. Such attributions reinforce the belief that assessment holds learners accountable.

## The influence of the belief that assessment holds teachers accountable

From the findings, the belief that assessment holds teachers accountable is linked to Teacher B and Teacher E. According to Brown's (2002) model of assessment belief (see Table 10.1), in this belief set, the purpose of assessment can  be  classified  as  summative  because  it  serves  to  evaluate  teacher effectiveness. When the roles of assessment focuses on forming or planning instruction and  improving  the  learners'  learning,  then  the  purpose  of assessment can be classified as formative (Atjonen 2014:239). When the roles of  assessment  focuses  on  demonstrating  learner  performance  in  order  to make final judgements about learner achievement or instructional effectiveness, then the purpose of assessment can be classified as summative (Atjonen 2014:239).

However, in the case of these teachers, their focus on summative assessment seemed to serve a different measurement mission than simply indicating how well or bad the teacher was doing. This is evident from their responses, which

suggest that the summative assessment is used to make inferences about the learner  for  the  purpose  of  prompting  further  learning  and  teaching  when needed. Teacher B said: 'so it [common assessments] must be properly set […] and the learner should be exposed to those papers so that I for one can see that I'm doing ok [and] my learners know what is expected from them' (Teacher B, female, 02 September 2019). Teacher B added: 'you know you have to actually see what the children can do and then how can you improve on it a bit further' (Teacher B, female, 02 September 2019).

Teacher E said: 'the one that is giving me the exact of what is happening in class is when they are writing the formal one, whereby they are sitting alone in their tables' (Teacher E, female, 10 September 2019). Teacher E also said: 'I assess so as to change the […] if learners don't understand what I'm doing so as to change the method of teaching' (Teacher E, female, 10 September 2019).

When teachers use assessments either summative or formative to make inferences about learning improvement, unintended messages to learners can be conveyed which can convince them of the teacher's assessment beliefs. This is evident in the case of Learner E3, who was taught by Teacher E, made use  of  her  summative  results  to  evaluate  her  own  progress,  which  led  to positive pressure to improve performance. Learner E3 said:

'I use to take my reports and look from term 1 to term 2 or term 3 how far I am […] for example my marks […] I use to take my marks [ to see ] how far I am […] If I'm low I start to improve my marks in the class.' (Leaner E3, male, 10 September 2019)

In the case of Learner E3, the summative results encouraged SDL behavioural processes related to learner self-evaluation, whereas in the case of Learner E4, the summative results encouraged effort-related attributions as the learner attributed her low performance to a lack of effort. Learner E4 said:

'[ W ]hen we are writing assessments or formal [ sic ],  the  marks  become low […] when it becomes low, I like [ sic ] ask myself where did I go wrong […] and I start reminding myself like I wasn't focusing on NS too much.' (Learner E4, female, 10 September 2019)

However, according to Loyens, Magda and Rikers (2008:415), the link between assessment practices and SDL lies in the fact that, in an educational setting, where learning is often attuned to summative assessment, learners come to view  the  teacher's  approach  to  assessment  and  instruction  as  controlling. Consequently, the responsibility of ownership and self-direction in learning by learners are undermined (Loyens et al. 2008:415). Extending this argument, Mumm,  Karm  and  Remmik  (2016:787)  assert  that  formative  practices  are inhibited when summative assessment practices are dominant, which inhibits maximum growth and possible development of self-directed learners. Based on the above-mentioned arguments, it can be concluded that the assessment belief  that  holds  teachers  accountable  has  no  place  in  SDL  because  of  its reliance on summative assessment, as such summative practices emphasise learner  performance  and  may  not  necessarily  highlight  the  importance  of

strategies, skills and the processes underlying task completion. However, the findings obtained in this study confirm that summative assessment practices do offer some support in fostering SDL behaviour when such practices are used to make inferences about learner improvement.

## The influence of the belief that assessment improves teaching and learning

From the  empirical  research  findings,  the  belief  that  assessment  improves teaching and learning is linked to Teacher A, Teacher B, Teacher C and Teacher D.  Further,  these  teachers believed that the best way to determine learner understanding is through formative assessment practices, such as dialogue with learners, using technology and collecting written work. This is depicted by the following quotes:

'[ S ]ometimes,  I  like  making  them  write  summaries  […].'  (Teacher  D,  female,  06 September 2019)

'If you are teaching a particular topic […] give them work on that day […]' (Teacher A, male, 29 August 2019)

'[ Y ]ou project, then underneath your projections they [ sic ] will be checkpoints [ sic ] activities […].' (Teacher C, male, 04 September 2019)

'[ W ]ithin  the  class  the  [ sic ]  is  oral  questions  and  answers  during  a  lesson  […] the next few days is recapping of what you know and what they don't know […] so  basically  that's  more  of  an  informal  oral  type  of  testing  thing  […]  then  daily homework is given.' (Teacher B, female, 02 September 2019)

The  feedback  obtained  from  such  formative  assessments  informs  learners about their own learning and their progress. Learner B5, who was taught by Teacher B, demonstrated SDL behaviour by evaluating his own work as part of his learning. Learner B5 said:

'[ B ]y assessing yourself you can see where your weak points are and strong points are so then if the teacher also assess you will get more information on that topic and get better at it.' (Leaner B5, female, 02 September 2019)

Evaluating the quality of their learning through formative assessments can influence  the  factors  to  which  learners  attribute  their  success  (Cauley  &amp; McMillan 2010:1). This was demonstrated by Learner B4, taught by Teacher B, who reported effort attributions because she recognised that a given task got easier when more effort was made to understand it. Learner B4 said: 'it was really hard at first […] but then if you get more understanding about it […] you see that it's not that hard' (Learner B4, female, 02 September 2019).

Such effort attributions led to learners feeling more in control of learning outcomes. This was also shared by the same learner, who felt the more she read, the more she was in control of her learning. Learner B4 said: 'I just feel like […] I learn more when I read so every time after each lesson I go and read

it over and over again and that's how it stays' (Learner, female, 02 September 2019).

Learners who acquire effort attributions believe they can successfully apply strategies  and  are  thus  more  likely  to  be  motivated  to  take  up  more responsibility for their learning (Cauley &amp; McMillan 2010:2). This is supported by Learner C2, Learner C1 and Learner C4, all taught by Teacher C and who all reported a tendency to take responsibility for the construction of personal meaning:

'[ S ]o every time when I learn, I want to read things for myself […] and I understand.' (Learner C2, female, 04 September 2019)

'I preferred reading a topic before a teacher explains it […] because when I read, I gain knowledge and when the teachers read, I understand what I did not understand and I get it better.' (Learner C1, female, 04 September 2019)

'[ T ]he  topics  that  we  are  going  to  talk  about  next  week,  I  read  it  [ sic ]  earlier.' (Learner C4, male, 04 September 2019)

When learners take more responsibility for their learning, they are more likely to  become successful  in  achieving  their  learning  outcomes,  which,  in  turn, leads to increased motivation and involvement (Cauley &amp; McMillan 2010:2). This is also observed amongst the same learners taught by Teacher C, who reported  more  engagement  with  their  learning  activities  and  the  subject matter:

'[ ]f I come across something that I don't understand it is then I go to a teacher and I ask him or her.' (Learner C2, female, 04 September 2019)

'[ Y ]ou know as you grow up […] we have many myths how the earth was created […] the moon is created […] so in Natural Science we can prove those myths wrong.' (Learner C1, female, 04 September 2019)

'I  research  […]  I  get  into  research  I  maybe  go  to  the  library  and  take  books  for Science […] and […] I do my own work personally at home […] maybe before the lesson.' (Learner C4, male, 04 September 2019)

Therefore, according to Cauley and McMillan (2010:4) 'to ensure an optimal level of motivation, learners need to make facilitated attributions concerning the  outcomes  of  their  learning'.  To  this  end,  more  specific  principles  of classroom assessment require that 'expectations and intermediate steps for improvement  be  made  visible'  to  learners  to  enable  active  involvement  in learners' evaluation of their own work (Cauley &amp; McMillan 2010:4).

## The influence of the belief that assessment is irrelevant to teaching and learning

From the findings, the belief that assessment is bad for learners is linked to Teacher A, which falls into the category of 'assessment is irrelevant to teaching and learning'. The teacher strongly believed that formal assessments are an

'enemy' of learners. Teacher A said, 'with Grade 9 my experiences eeh […] the learners  their  [ sic ]  greatest  enemy  is  the  final  examination  and  the  formal task' (Teacher A, male, 29 August 2019).

Such a belief can provide learners with attribution cues through feedback that have an emotional impact on them, causing them unwarranted worry and anxiety. In the case of Learner A3 and Learner A1, taught by Teacher A, they reported high levels of anxiety about writing examinations: Learner A3 said, 'and it's like its heavy […] itjoo [sighs] ma'am […] exam' (Learner A3, female, 29 August 2019), and Learner A1 said, '[exams] makes us sweat' (Learner A1, male, 29 August 2019).

These  negative  emotions  can  lead  to  feelings  of  resentment  and  great frustrations, which decrease motivation (Brown 2002:43). This is evident in the case of Learner A3, taught by Teacher A, who expressed how she struggled just to study her work:

'[ L ]ike when I'm studying […] I eish […] ma'am I feel like I just open my book and I just look at it […] I'll be like […] aaaa I'm tired […] then like […] like when but no […] I'm tired […] will be reading things for the sake of studying.' (Learner A3, female, 29 August 2019)

When learners show a lack of motivation, they are not likely to engage in SDL behaviour, such as, planning, monitoring and evaluating their learning process. This is evident from the findings, which revealed that all the learners taught by Teacher A did not support the notion of self-evaluations and preferred the teacher to evaluate their work.

## Discussion

In  response  to  the  research  question,  ' What are  the  assessment  beliefs  of Grade 9 NS teachers in the Rustenburg area? ', the following can be concluded: Teachers' assessment beliefs were focused on the improvement of teaching and learning, and learner accountability; and less focus was given to teacher accountability  and  the  relevance  of  assessment  to  teaching  and  learning (Kamanga  2020).  Further  evidence  from  the  findings  showed  that  the teachers' assessment beliefs were shaped by their personal beliefs regarding (1)  how learners learn, (2) perceptions of the nature of science, (3) beliefs about  learners,  and  (4)  how  they  attribute  the  success  and  failure  of  the learners they teach. This finding shows that teachers' assessment beliefs are linked to other salient beliefs about teaching and learning (Brown 2002:50). This finding is of significance as it shows that studies on teacher beliefs can use different approaches to elicit these beliefs, for example, by interrogating their beliefs about teaching, learning or knowledge acquisition. According to Luft and Roehrig (2007:41), researchers of beliefs should be looking for new ways  of  revealing  teacher  'beliefs  to  understand  the  relationship  between beliefs and practices'.

In  response  to  the  research  question,  ' What  is  the  influence  of  Grade  9 Natural Sciences teachers' assessment beliefs on learners' SDL behaviour in the Rustenburg area? ', the following can be concluded: The belief that assessment improves teaching and learning promoted the following learner SDL behaviour willingness  to  take  responsibility  for  learning,  displaying  an  ability  to  use effective learning strategies, displaying increased motivation, displaying effort attributions and engaging in self-evaluations (Kamanga 2020).

Whilst the belief that assessment  'holds  learners accountable' and assessment is 'irrelevant to teaching and learning', influenced the following behaviour:  lack  of  motivation,  strong  dependency  on  teachers  to  evaluate their work, lack of engagement with learning activities, frustration and anxiety, and  task-related  attributions.  The  belief  that  assessment  'holds  teachers accountable',  encouraged  learners'  SDL  behaviour  associated  'with  effort attributions and self-evaluations'.

A limitation of this study was that teachers' assessment beliefs were not studied in the context of their classroom practices. Because factors outside of the classroom and unrelated to the teacher can impact practice, additional data  sources  would  have  enriched  our  understanding  of  the  relationship between teacher assessment beliefs and classroom reality. However, the role of  'social  context'  in  understanding  the  influences  of  teachers'  assessment beliefs  on  learners'  self-direction  was  investigated  using  an  interpersonal third-generation CHAT analysis.

The CHAT framework is an interdisciplinary approach used for exploring and describing human activities through the use of an activity system which comprises of the following common elements: object, subject, tools, rules, division of labour, community and outcome (Greenhow &amp; Belbas 2007). The CHAT  framework  has  undergone  a  historical  development  referred  to  as generational (Nussbaumer 2012:38). The first-generation CHAT framework is rooted in a Vygotskian sociocultural understanding of learning, which looks at the influences of individuals and tools in developing understanding (Vygotsky 1978).  The  second-generation  CHAT  framework  considers  the  'interrelationships between  the  individual  and  the  community,  history,  and  context;  and  the interaction  between  the  situation  and  the  activity'  (Taylor  2014:98).  With third-generation CHAT, Engeström (2001) elaborated on a broader concept of activity to include interacting activity systems that 'deal with tensions and contradictions that encourage collective learning through change' (Nussbaumer 2012:39). According to Mentz and De Beer (2017:88), CHAT can be utilised as a research lens on an interpersonal level when the interactions involve subjects from different stakeholders, as in this study involving teachers and learners as different subjects of interest.

To establish the third-generation CHAT framework at an interpersonal level, two interdependent activity systems were used: Teachers' views on assessment

<!-- image -->

Source : Based on Kamanga (2020:108).

as one activity system, and learners' experiences of assessment in NS as the second  activity  system  (depicted  in  Figure  10.3).  All  codes  used  when classifying the separate activity system elements of the two activity systems were  developed  by  making  casual  links  between  the  emerging  themes obtained from the individual and focus group interview data. At no point were pre-existing codes utilised.

In Figure 10.3, we show how CHAT has been used on an interpersonal plane (with  the  respective  subjects  being  the  NS  teacher  and  the  learner),  and juxtaposing two interdependent activity systems (namely teaching and learning). The following critical issues were identified when data were analysed and interpreted using CHAT as a lens: (1) emphasis by teachers is on preparing learners for examinations; (2) emphasis by learners is on obtaining good grades; (3) absence of assessment tools like peer- and self-assessment is evident; (4) dominance of teacher-centred approaches were observed; (5)

threatening  learning  environments;  (6)  contextual  factors  which  hinder learning were identified, that is, large classroom sizes, learner discipline issues, syllabus coverage, inadequate parental involvement, poor learner engagement and lack of resources; and (7) inadequate implementation of the assessment policy  was  observed.  The  identified  themes  will  be  elaborated  in  order  to show the critical issues that impede learners' SDL.

## Emphasis by teachers was on preparing learners for examinations

In the third-generation CHAT framework, Engeström (2001) expanded CHAT to include a network of interacting systems with shared objectives resulting in a  potentially  shared  outcome.  Applying  this  explanation,  the  potentially shared outcome of NS teachers' assessment activity system and the Grade 9 learners' learning activity system is preparing learners for the next grade. This is evident from the following teacher and learner quotes:

'[ T ]o check whether they ready for the next grade by that assessment.' (Teacher C, male, 04 September 2019)

'[ A ]ssessment basically […] it's as I said it's coached a lot more for this group of learners to try and let them progress into the next grade.' (Teacher B, female, 02 September 2019)

'[ ]n class we pay more attention to her, listen to what she say [ I sic ] so that it would be easier when we get to the next grade.' (Learner D2, female, 06 September 2019)

'[…] and getting to process that information and getting educated and then getting to pass.' (Learner B4, female, 02 September 2019)

The above-mentioned shared outcome by learners and teachers necessitates the use of assessment as a means of certifying learning, which offers little support in fostering SDL behaviour when such practices are dominant. The findings  revealed  that  teachers'  assessment  tasks  were  not  focused  on developing  21st  century  skills  to  cope  in  a  complex  society,  but  rather  on preparing  learners  to  pass  their  examinations.  Furthermore,  the  findings revealed that assessment was considered in terms of the cognitive domain with no consideration for the affective or psychomotor domains. This resulted in  most  learners  showing  a  lack  of  motivation  because  of  the  absence  of positive  values,  like  interest,  which  develop  as  result  of  affective  domain outcomes.

## Emphasis by learners was on obtaining good grades

In  the  third-generation  CHAT  framework,  the  object  in  an  activity  system  is described 'as the problem at which the activity is directed, and which is moulded and transformed into 'outcomes' with the help of tools' (Bourke et al. 2013:36).

Applying  this  explanation,  the  'object'  of  this  group  of  learners'  learning  is centred on obtaining good grades, to achieve the outcome of passing to the next grade. This objective was congruent with that of teachers, that is, focusing on  preparing  learners  for  examinations.  Both  the  teachers'  and  learners' objectives are contrary to the more conventional notion that learners should see their tasks as objectives to develop cognitive processes such as monitoring and planning their learning process, as required from a self-directed learner. The  findings revealed that learners put more  emphasis  on  recall and memorisation, which are lower-order cognitive skills and do not form part of a meaningful SDL approach.

## Absence of assessment methods like self- and peer-assessment

The assessment methods used by teachers to assess learners did not include self- and peer-assessments. However, if the desire is for learners to become authors of their own understanding, and assessors of their own learning, then self- and peer-assessments need to be incorporated (Atjonen 2014; McMillan &amp; Hearn  2008).  This  implies  that  extensive  efforts  must  be  made  to  raise awareness  of  the  important  role  that  self-  and  peer-assessment  play  in fostering SDL. Evidence from literature reveals that self- and peer-assessment promote SDL (McMillan &amp; Hearn 2008).

## Dominance of teacher-centred approaches

When examining the division of labour amongst learners and teachers, it was evident that teachers did not engage with SDL in the learning environment and relied  heavily  on  teacher-centred  approaches.  This  is  illustrated  in  the following quotes:

'[ W ]hen Miss TPE [ teacher participant from school E ] write [ sic ] the notes in the chalk board, I take them to my notebook.' (Learner E3, male, 10 September 2019)

'[ S ]he shows us that if she's talking about the digestive system, she draws it on the board and then she labels it […] that's how I understand my topics.' (Learner E1, female, 10 September 2019)

'[ W ]hat makes me to understand all the topics in Natural Sciences is ma'am TPE [ teacher participant from school E ] always try to make us learners to understand by showing things on chalk board so that we can all understand.' (Learner E2, male, 10 September 2019)

'[ What ] helps me understand the topics that ma'am gives us is that whenever we start a new topic, she will write notes on the black board and also makes examples about things in real life.' (Learner E5, female, 10 September 2019)

Evidence from the findings revealed that such teaching approaches encouraged learners  to  become  passive  listeners,  which  does  not  develop

social  and  communication  skills,  and  which  does  not  reflect  a  meaningful approach to SDL. This is illustrated with the following quotes:

'[ S ]o  my role  as  a  Natural  Sciences  learner  is  to  do  class  works  and  homework that the teacher gives us and answer in class when the teacher asks us questions.' (Learner E1, female, 10 September 2019)

'[…] and my role is to listen while the teacher is teaching and take notes while she is teaching.' (Learner E2, male, 10 September 2019)

'[ M ]y role in Natural Sciences, we are supposed to keep quiet in class so that we can understand what the teacher is saying.' (Learner E3, male, 10 September 2019)

'[ M ]y role in Natural Sciences class is to listen and express my feelings with what my teacher has taught me.' (Learner E4, male, 10 September 2019)

'[ W ]hile in the classroom other learners they don't listen to the teacher when they ask him question and they bully other learners in the class.' (Learner E5, female, 10 September 2019)

However,  interesting  to  note  is  how  the  learners'  social  skills  reflected affective outcomes - such as expressing one's feelings and cooperation in class - which were missing from the teachers' interview data. This finding implies that consideration should be given to understanding the type of connections learners make from their learning environment. This information could be very useful when designing learning environments that enhance SDL.

## Threatening learning environments

The findings revealed that grouping low-performing learners to receive  differential  instruction  for  the  purpose  of  helping  them  improve their  performance  has  limited  effectiveness  in  supporting  meaningful classroom engagement. It was learned from the empirical study that such a grouping leads to a threatening learning environment as a learner was not  free  to  ask  questions  in  class.  This  is  illustrated  with  the  following quotes:

'[ B ]ut this year we decided that we gonna take out the weaker learners and put them into one class so that we can basically move much further and better with other  classes  and  the  weaker  class  we  wanted  to  help  them  cope.'  (Teacher  B, female, 02 September 2019)

'[ T ]here is a problem because I can't ask Madam TPB [ teacher participant from school B ] […] because sometimes I feel scared to ask her cause [ sic ] some people they say NS is easy and it will look stupid if you ask […] so I don't usually ask her […] I just do it for myself.' (Learner B2, male, 02 September 2019)

For SDL to thrive in classrooms, the learning environment must change into a supportive and a non-threatening environment because teaching and learning are deeply embedded in interpersonal processes.

## Contextual factors that hinder learning

Teachers reported the following factors as barriers that impacted on teaching, learning  and  assessment  routines  within  the  learning  community:  large classroom  sizes;  learner  discipline  issues;  syllabus  coverage;  inadequate parental involvement; poor learner engagement and lack of resources. The insights gained from this study revealed that such factors may compel teachers to  teach  in  ways  that  best  suit  their  circumstances,  which  may  lead  to  a 'watering  down'  of  the  prescribed  syllabus  content  and  an  emphasis  on minimum competencies that provide learners with limited opportunities to learn. Problem-based approaches are often replaced by transmission mode teaching. This is illustrated in the following quote:

'[ W ]hen are you going to analyse stuff, when are you going to apply stuff, when are you going to solve a problem using […] there is not a lot of time […] there's just too many things.' (Teacher D, female, 06 September 2019)

## Inadequate implementation of the assessment policy

When considering the social aspect of 'rules', it was revealed that the goals of CAPS have not materialised in NS classrooms, especially when it comes to the development  of  21st  century  skills,  higher-order  cognitive  thinking  and affective outcomes (Department of Basic Education 2011:4). Teachers in this study  did  not  focus  on  developing  and  encouraging  critical  and  active approaches  to  learning  but  focused  on  rote  learning  of  given  facts  and uncritical thinking:

'[ A ]ssessing them with formal assessment it becomes a real problem because they can't memorize […] they cannot recall information […] eeh […] they cannot […] their memory is so poor to grasp the information.' (Teacher A, male, 29 August 2019)

The data obtained from learners' responses revealed that such approaches to  teaching  science  fail  to  promote  the  development  of  thinking  and reasoning skills in favour of mere recall of information. This is illustrated by learners' responses to the question, ' What are some of the activities, which enable  you  to  understand  the  topics  taught  in  Natural  Science  lessons better? ':

'[ L ]et me think ma'am […] by reading the notes […] doing your classwork […] ja.' (Learner A1, male, 29 August 2019)

'[ A ]hmm […] to read your notes and to study them and revise your classwork.' (Learner A2, female, 29 August 2019)

'[ A ]hmm […] is to go back to my notes and read them […] and then I like […] I go back to my classwork and revise them.' (Learner A4, female, 29 August 2019)

'I read my notes […]. I go back to my classwork and corrections.' (Learner A5, male, 29 August 2019)

In  addition,  the  lack  of  teachers'  attention  to  affective  learning  outcomes results  in  learners'  not  developing  positive  values  and  interest  towards  NS activities.  This  finding  suggests  that  teachers  still  struggle  to  meet  the demands which are stipulated in the assessment policy, exacerbating their ineffectiveness in promoting SDL behaviour. Thus, one challenge lies in how best to assist teachers to implement the assessment policy.

Although  the  findings  cannot  be  generalised  to  the  whole  population because of the small sample size, they can serve as a point of reflection on where  we  are  now  and  where  we  are  going  in  terms  of  the  successful implementation of SDL in the Grade 9 NS curriculum.

## Implications for higher education and conclusion

Research on teacher beliefs has attracted a lot of interest given the critical role that beliefs play in shaping classroom pedagogical acts (Bliem &amp; Davinroy 1997:1).  The  findings  from  this  study  build  on  this  knowledge  by  providing empirical evidence showing how various teacher assessment beliefs impact learners' SDL abilities. It was shown that some assessment beliefs serve to facilitate SDL behaviour, whilst some hindered SDL behaviour. It is, therefore, necessary  to  identify  and  address  such  negative  beliefs  by  promoting assessment  initiatives  and  teacher  development  programmes  that  seek  to facilitate changes in teacher's assessment belief systems. This has implications for higher education in terms of how to help prospective teachers uncover and critique their own assessment beliefs, and help them become critically conscious of their beliefs before they enter the teaching profession (Bryan &amp; Atwater 2002:823).

Although much has been written about the need for new ways of revealing the beliefs of teachers, very little has been done in examining the types of experiences that impact their beliefs (Luft &amp; Roehrig 2007:49). Moreover, in reviewing literature on teacher assessment beliefs, there are few documented studies  of  higher  education  programmes  which  specifically  address  the infusion of teacher assessment beliefs in their educational courses/ programmes.  Thus,  a  goal  for  higher  education,  specifically  in  faculties  of education, should be to design and implement teacher education programmes that attempt to facilitate a change in the belief systems of pre-service and practicing teachers.

Furthermore,  the  unfortunate  reality,  revealed  by  the  findings,  is  that teachers'  assessment  practices  within  the  school  context  are  focused  on preparing  learners  to  pass  their  examinations.  Hence,  less  opportunity  for learners to develop the necessary 21st century skills needed to enable them to cope  and  adjust  to  the  demands  of  higher  education,  is  provided.  This

unfortunate reality leaves higher education with the greater burden of bridging this gap by providing more innovative opportunities of fostering the SDL skills of prospective graduates across the different faculties.

## Conclusion

In this chapter, we reflect on research that was carried out in five schools in the  Rustenburg  area  in  North-West  province  involving  a  total  of  five  NS teachers  and  twenty-five  (25)  Grade  9  learners.  The  study  was  aimed  at understanding the influence of teachers' assessment beliefs on learners' SDL behaviour using a semi-structured interview process (Kamanga 2020). The findings  revealed  that  the  belief  that  assessment  improves  teaching  and learning  and  assessment  holds  teachers  accountable  positively  influenced learner SDL behaviour (Kamanga 2020). Against this background, this chapter advocates for higher education to include more structured programmes for teachers that would support them in becoming cognisant of their beliefs and changing  negative  belief  systems  that  work  against  appropriate  learner developmental needs. The use of the CHAT framework as a research lens in this study has proven to be appropriate in research related to teaching beliefs because  the  complex  interplay  of  institutional,  managerial  and  discipline constraints often lead to a belief-practice divide.

## References

## Foreword

Carless, D., 2015a, 'Exploring learning-oriented assessment processes', Higher Education 69(6), 963-976. https:/ /doi.org/10.1007/s10734-014-9816-z

Carless,  D.,  2015b, Excellence in university assessment: Learning from award-winning practice , Routledge, London.

Carless, D. &amp; Boud, D., 2018, 'The development of student feedback literacy: Enabling uptake of feedback', Assessment and Evaluation in Higher Education 43(8), 1315-1325. https:/ /doi.org/10 .1080/02602938.2018.1463354

## Chapter 1

Abell, S. &amp; Siegel, M., 2011, 'Assessment literacy: What science teachers need to know and be able to do', in D. Corrigan, J. Dillon &amp; R. Gunstone (eds.), The professional knowledge base of science teaching , pp. 205-221, Springer, Dordrecht.

Abell,  S.  &amp;  Volkmann,  M.,  2006, Seamless assessment in science: A guide for elementary and middle school teachers , Heinemann, Portsmouth, NH.

Bachman, L. &amp; Palmer, A., 2010, Language assessment in practice , Oxford University Press, Oxford.

Baird,  J.,  Hopfenbeck,  T.,  Newton,  P.,  Stobart,  G.  &amp;  Steen-Utheim,  A,  2014,  'Assessment  and learning: State of the field review', Knowledge Centre for Education, Oslo.

Barnes, M., 2016, 'The student as teacher educator in service-learning', Journal of Experiential Education 39(3), 238-253.

Beaumont, C.,  O'Doherty,  M.  &amp;  Shannon,  L.,  2011,  'Reconceptualising  assessment  feedback:  A key to improving student learning?', Studies in Higher Education 36(6), 671-687. https:/ /doi. org/10.1080/03075071003731135

Ben-Zvi Assaraf, O., 2011, 'Learning from failure: A case study of where an extracurricular science program went wrong', Journal of Science Education and Technology 20(1), 592-607.

Binkley,  M.,  Erstad,  O.,  Herman,  J.,  Raizen,  S.,  Ripley,  M.,  Miller-Ricci,  M.  et  al.,  2012,  'Defining twenty-first  century  skills',  in  B.  McGaw  &amp;  E.  Care  (eds.), Assessment and teaching of 21st century skills , pp. 17-66, Springer, New York, NY.

Blair, A. &amp; McGinty, S., 2013, 'Feedback-dialogues: Exploring the student perspective', Assessment &amp; Evaluation in Higher Education 38(4), 466-476. https:/ /doi.org/10.1080/02602938.2011.649 244

Boud, D., 2007, 'Reframing assessment as if learning were important', in D. Boud &amp; N. Falchikov (eds.), Rethinking assessment in higher education: Learning for the longer term ,  pp.  14-25, Routledge, Abingdon.

Boud, D., 2015, 'Feedback: Ensuring that it leads to enhanced learning', The Clinical Teacher 12(1), 3-7. https:/ /doi.org/10.1111/tct.12345

Boud,  D.  &amp;  Falchikov,  N.,  2007,  'Introduction  assessment  for  the  longer  term',  in  D.  Boud  &amp; N. Falchikov (eds.), Rethinking assessment in higher education: Learning for the longer term , pp. 3-13, Routledge, Abingdon.

Box, C., Skoog, G. &amp; Dabbs, J., 2015, 'A case study of teacher personal practice assessment theories and  complexities  of  implementing  formative  assessment', American  Educational  Research Journal 52(2), 956-983. https:/ /doi.org/10.3102/0002831215587754

Brandt, W., 2020, Measuring student success skills: A review of the literature on self-direction , National Center for the improvement of Educational Assessment, Dover, NH.

- Brockett, R. &amp; Hiemstra, R., 1991, Self-direction in adult learning: Perspectives on theory, research, and practice , Routledge Series on Theory and Practice of Adult Education in North America, Routledge, Chapman &amp; Hall, New York, NY.
- Brockett, R. &amp; Hiemstra, R., 2012, 'Reframing the meaning of self-directed learning: An updated model',  in Proceedings  of  the  54th  Annual  Adult  Education  Research  Conference ,  vol.  45, Saratoga Spring, New York, NY, United States of America, June 01, 2012, pp. 155-161.

Brookfield,  S.,  2009,  'Self-directed  learning',  in  R.  Maclean  &amp;  M.  Wilson  (eds.), International handbook of education for the changing world of work , pp. 2615-2627, Springer, Dordrecht.

- Brown, G., Andrade, H. &amp; Chen, F., 2015, 'Accuracy in student self-assessment: Directions and cautions for research', Assessment in Education: Principles, Policy &amp; Practice 22(4), 444-457. https:/ /doi.org/10.1080/0969594X.2014.996523
- Brydges, R., Dubrowski, A. &amp; Regehr, G., 2010, 'A new concept of unsupervised learning: Directed self-guided learning in the health professions', Academic Medicine 85(10), S49-S55. https:/ / doi.org/10.1097/ACM.0b013e3181ed4c96
- Candy, P., 1991, Self-direction for lifelong learning: A comprehensive guide to theory and practice , Jossey-Bass, San Francisco, CA.
- Carless, D., 2007, 'Learning oriented -assessment: Conceptual bases and practical implications', Innovations  in  Education  and  Teaching  International 44(1),  57-66.  https:/ /doi. org/10.1080/14703290601081332
- Carless, D., 2014, 'Exploring learning-oriented assessment processes', Journal of Higher Education 68(4), 936-976.
- Carless, D., 2015a, Excellence in university assessment: Learning from award-winning teaching , Routledge, Abingdon.
- Carless, D., 2015b, 'Exploring learning-oriented assessment processes', Higher Education 69(6), 963-976. https:/ /doi.org/10.1007/s10734-014-9816-z
- Carless, D., Joughin, G. &amp; Mok, M., 2006, 'Learning-oriented assessment: Principles and practice', Assessment &amp; Evaluation in Higher Education 31(4), 395-398.
- Carless, D., Salter, D., Yang, M. &amp; Lam, J., 2011, 'Developing sustainable feedback practices', Studies in Higher Education 36(4), 395-407. https:/ /doi.org/10.1080/03075071003642449
- Chapman, C. &amp; King, R., 2013, Planning and organizing standards-based differentiated instruction , Corwin Press, Thousand Oaks, CA.
- Clark,  I.,  2012,  'Formative  assessment:  Assessment  is  for  self-regulated  learning', Educational Psychology Review 24(2), 205-249. https:/ /doi.org/10.1007/s10648-011-9191-6
- Coombs, A., DeLuca, C. &amp; MacGregor, S., 2020, 'A person-centered analysis of teacher candidates' approaches  to assessment', Teaching and Teacher Education 87, 102952. https:/ /doi. org/10.1016/j.tate.2019.102952
- DeLuca,  C.,  Coombs,  A.  &amp;  LaPointe-McEwan,  D.,  2019,  'Assessment  mindset:  Exploring  the relationship between teacher mindset and approaches to classroom assessment', Studies in Educational Evaluation , 61, 159-169. https:/ /doi.org/10.1016/j.stueduc.2019.03.012

DeLuca, C., LaPointe-McEwan, D. &amp; Luhanga, E., 2016, 'Teacher assessment literacy: A review of international standards and measures', Educational Assessment, Evaluation and Accountability 28(3), 251-272. https:/ /doi.org/10.1007/s11092-015-9233-6

DeLuca, C. &amp; Volante, L., 2016, 'Assessment for learning in teacher education programs: Navigating the  juxtaposition  of  theory  and  praxis', Journal  of  the  International  Society  for  Teacher Education 20(1), 19-31.

- Delva,  D.,  Sargeant,  J.,  Miller,  S.,  Holland,  J.,  Brown,  P.,  Leblanc,  C.  et  al.,  2013,  'Encouraging residents to seek feedback', Medical Teacher 35(12), 1625-1631. https:/ /doi.org/10.3109/0142 159X.2013.806791

- Deneen, C. &amp; Brown, G., 2016, 'The impact of conceptions of assessment on assessment literacy in a teacher education program', Cogent Education 3(1), 1-14. https:/ /doi.org/10.1080/233118 6X.2016.1225380
- Dixon, D. &amp; Worrell, F., 2016, 'Formative and summative assessment in the classroom', Theory into Practice 55(2), 153-159. https:/ /doi.org/10.1080/00405841.2016.1148989

Douglas, C. &amp; Morris, S., 2014, 'Student perspectives on self-directed learning', Journal of the Scholarship of Teaching and Learning 14(1), 13-25. https:/ /doi.org/10.14434/josotl.v14i1.3202

Duckworth, A., Taxer, J., Eskreis-Winkler, L., Galla, B. &amp; Gross, J., 2019, 'Self-control and academic achievement', Annual Review of Psychology 70, 373-399.

Du Toit-Brits, C., 2019, 'A focus on self-directed learning: The role that educators' expectations play in the enhancement of students' self-directedness', South African Journal of Education 39(2), 1-11. https:/ /doi.org/10.15700/saje.v39n2a1645

- Dynan, L., Cate, T. &amp; Rhee, K., 2008, 'The impact of learning structure on students' readiness for self-directed learning', The Journal of Education for Business 84(2), 96-100. https:/ /doi. org/10.3200/JOEB.84.2.96-100

Earl, L. &amp; Katz, S., 2006, Rethinking classroom assessment with a purpose in mind , viewed 20 April 2020, from http:/ /www.edu.gov.mb.ca/k12/assess/wncp/rethinking\_assess\_mb.pdf.

Earl, L., 2013, Assessment as learning: Using classroom assessment to maximize student learning , 2nd edn., Sage, Twin Oaks, CA.

- Edwards, F., 2017, 'A rubric to track the development of secondary pre-service and novice teachers' summative assessment literacy', Assessment in Education: Principles, Policy &amp; Practice 24(2), 205-227. https:/ /doi.org/10.1080/0969594X.2016.1245651
- Ertmer,  P.  &amp;  Newby,  T.,  2013,  'Article  update:  Behaviorism,  cognitivism,  and  constructivism: Connecting 'yesterday's' theories to today's contexts', Performance Improvement Quarterly 26(2), 65-71. https:/ /doi.org/10.1002/piq.21143
- Evans, C., 2013, 'Making sense of assessment feedback in higher education', Review of Educational Research 83(1), 70-120. https:/ /doi.org/10.3102/0034654312474350
- Evans, J., Davies, B. &amp; Penny, D., 1999, 'The social construction of teaching and learning: The politics of  pedagogy' in  C.  Hardy  &amp;  M.  Mawer  (eds.), Learning and teaching in physical education , pp. 9-21, Falmer Press, London.

Falchikov, N., 2005, Improving assessment through student involvement: Practical solution for aiding learning in higher education , Routledge, New York, NY.

- Ferris, D. &amp; Hedgcock, J., 2014, Teaching L2 composition: Purpose, process, and practice , 3rd edn, Routledge, New York, NY.
- Flavell,  J.,  1976,  'Metacognitive  aspects  of  problem  solving',  in  L.  Resnick  (ed.), The nature of intelligence , Lawrence Erlbaum, Hillsdale, NJ.
- Flint, N. &amp; Johnson, B., 2011, Towards fairer university assessment: Recognizing the concerns of students , Routledge, London.
- Gandomkar,  R.  &amp;  Sandars,  J.,  2018,  'Clearing  the  confusion  about  self-directed  learning  and self-regulated  learning', Medical  Teacher 40(8),  862-863.  https:/ /doi.org/10.1080/014215 9X.2018.1425382
- Gardner, J., 2010, 'Developing teacher assessments: An introduction', in J. Gardner, W. Harlen, L. Hayward, G. Stobart &amp; M. Montgomery (eds.), Developing teacher assessment , pp. 1-11, Open University Press, New York, NY.
- Gibbs, G. &amp; Simpson, C., 2004, 'Conditions under which assessment supports students' learning', Learning and Teaching in Higher Education 1, 3-31.
- Gotch, C. &amp; French, B., 2014, 'A systematic review of assessment literacy measures', Educational Measurement: Issues and Practice 33(2), 14-18. https:/ /doi.org/10.1111/emip.12030
- Guglielmino, L.M., 1978, 'Development of the self-directed learning readiness scale', unpublished PhD dissertation, University of Georgia.

Guglielmino, L.M. &amp; Long, H., 2011, 'Perspectives: The international society for self-directed learning and the international self-directed learning symposium', International Journal of Self-Directed Learning 8(1), 1-6.

Hanrahan, S. &amp; Isaacs, G., 2001, 'Assessing self- and peer-assessment: The students'views', Higher Education Research &amp; Development 20(1), 53-70.

- Harris,  L.  &amp;  Brown,  G.,  2013,  'Opportunities  and  obstacles  to  consider  when  using  peer-  and self-assessment  to  improve  student  learning:  Case  studies  into  teachers'  implementation', Teaching and Teacher Education 36, 101-111.

Hattie, J. &amp; Timperley, H., 2007, 'The power of feedback', Review of Educational Research 77(1), 81-112. https:/ /doi.org/10.3102/003465430298487

- Hay, P., Tinning, R. &amp; Engstrom, C., 2015, 'Assessment as pedagogy: A consideration of pedagogical work and the preparation of kinesiology professionals', Physical Education and Sport Pedagogy 20(1), 31-44.
- Hodges, D., Eames, C. &amp; Coll, R., 2014, 'Theoretical perspectives on assessment in cooperative education placements', Asia-Pacific Journal of Cooperative Education 15(3), 189-207.
- Hussey, T. &amp; Smith, P., 2010, 'Transitions in higher education', Innovations in Education and Teaching International 47(2), 155-164. https:/ /doi.org/10.1080/14703291003718893
- International  Symposium  for  Self-Directed  Learning,  2020, ISSDL  adopts  a  definition  of  SDL , viewed n.d., from https:/ /www.sdlglobal.com/single-post/2020/02/16/ISSDL-adopts-adefinition-of-SDL.
- Jossberger, H., Brand-Gruwel, S., Boshuizen, H. &amp; Van de Wiel, M., 2010, 'The challenge of selfdirected  and  self-regulated  learning  in  vocational  education:  A  theoretical  analysis  and synthesis of requirements', Journal of Vocational Education &amp; Training 62(4), 415-440. https:/ / doi.org/10.1080/13636820.2010.523479

Kahl, S., Hofman, P. &amp; Bryant, S., 2012, Assessment literacy standards and performance measures for  teacher  candidates  and  practicing  teachers ,  Council  for  the  Accreditation  of  Educator Preparation, Measured Progress, Dover, NH.

Kasworm,  C.,  1983,  'Self-directed  learning  and  lifespan  development', International  Journal  of Lifelong Education 2(1), 29-46. https:/ /doi.org/10.1080/0260137830020103

- Knowles, M., 1975, Self-directed learning: A guide for learners and teachers ,  Association Press, New York, NY.

Kramarski,  B.  &amp;  Michalsky,  T.,  2009,  'Investigating  preservice  teachers'  professional  growth  in self-regulated  learning  environments', Journal  of  Educational  Psychology 101(1),  161-175. https:/ /doi.org/10.1037/a0013101

Kvale, S., 2007, 'Contradictions of assessment for learning in institutions of higher learning', in D. Boud &amp; N. Falchikov (eds.), Rethinking assessment in higher education: Learning for the longer term , pp. 57-71, Routledge, Abingdon.

Lam, R., 2015, 'Language assessment training in Hong Kong: Implications for language assessment literacy', Language Testing 32(2), 169-197.

Ljungman, A. &amp; Silén, C., 2008, 'Examination involving students as peer examiners', Assessment &amp; Evaluation in Higher Education 33(3), 289-300.

Looney, A., Cummings, J., Van der Kleij, F. &amp; Harris, K., 2017, 'Reconceptualising the role of teacher as  assessors:  Teacher  assessment  identity', Assessment  in  Education:  Principles,  Policy  &amp; Practice 25(5), 442-467. https:/ /doi.org/10.1080/0969594X.2016.1268090

Lopez-Pastor,  V.  &amp;  Sicilia-Camacho,  A.,  2017,  'Formative  and  shared  assessment  in  higher education: Lessons learned and challenges for the future', Assessment &amp; Evaluation in Higher Education 42(1), 77-97.

Lord, S., Chen, J., Stolk, J., Nottis, K., Stefanou, C. &amp; Price, M., 2010, 'Role of faculty in promoting lifelong learning: Characterizing classroom environments', Paper presented at the Education Engineering Conference (EDUCON), Madrid, Spain, n.d., 2010, n.p.

Lubbe,  A.,  2020,  'Cooperative  learning-embedded  assessment:  Implications  for  students' assessment literacy and self-directedness in learning', PhD thesis, North-West University.

MacLellan, E., 2004, 'Initial knowledge states about assessment: Novice teachers' conceptualizations', Teaching and Teacher Education 20(5), 523-555. https:/ /doi.org/10.1016/j. tate.2004.04.008

- McMorran,  C.,  Ragupathi,  K.  &amp;  Luo,  S.,  2017,  'The  promise  and  pitfalls  of  gradeless  learning: Responses to an alternative approach to grading', Journal of Further and Higher Education 44(7), 925-938. https:/ /doi.org/10.1080/0309877X.2019.1619073
- Mertler,  C.,  2009,  'Teachers'  assessment  knowledge  and  their  perceptions  of  the  impact  of classroom assessment professional development', Improving Schools 12(2),  101-113.  https:/ / doi.org/10.1177/1365480209105575
- Mok,  M.,  2009, Self-directed  learning  oriented  assessment:  Theory,  strategy  and  impact ,  The Hong Kong Institute of Education, viewed 20 April 2020, from https:/ /repository.eduhk.hk/en/ publications/self-directed-learning-oriented-assessment-theory-strategy-and-im-5.
- Mok,  M.,  2013,  'Assessment  reform  in  the  Asia-Pacific  region:  The  theory  and  practice  of self-directed learning oriented assessment', in M. Mok (ed.), Self-directed learning oriented assessment in the Asia-Pacific , pp. 3-22, Springer, Dordrecht.
- Morris, T., 2019, 'Adaptivity through self-directed learning to meet the challenges of our everchanging world', Adult Learning 30(2), 56-66.
- Morrison, D. &amp; Premkumar, K., 2014, 'Practical strategies to promote self-directed learning in the medical curriculum', International Journal of Self-Directed Learning 11(1), 1-12.
- Mulliner,  E.  &amp;  Tucker,  M.,  2015,  'Feedback  on  feedback  practice:  Perceptions  of  students  and academics', Assessment &amp; Evaluation in Higher Education 42(2), 266-288. https:/ /doi.org/10.1 080/02602938.2015.1103365
- National  Research  Council,  2001, Classroom  assessment  and  the  national  science  education standards ,  National  Academies  Press,  viewed  20  April  2020,  from  https:/ /www.csun.edu/ science/ref/curriculum/reforms/nses/nses-complete.pdf.
- Nepal, K. &amp; Stewart, R., 2010, 'Relationship between self-directed learning readiness factors and learning outcomes in third year project-based engineering design course', Paper presented at the AaeE Conference, Sydney, Australia, December 05-08, 2010, pp. 496-503.
- Nicol, D., 2009, 'Assessment for learner self-regulation: Enhancing achievement in the first year using learning technologies', Assessment &amp; Evaluation in Higher Education 34(3),  335-352. https:/ /doi.org/10.1080/02602930802255139
- Nicol, D. &amp; Macfarlane-Dick, D., 2006, 'Formative assessment and self-regulated learning: A model and seven principles of good feedback practice', Studies in Higher Education 31(2), 199-218. https:/ /doi.org/10.1080/03075070600572090
- Nicol, D., Thomson, A. &amp; Breslin, C., 2014, 'Rethinking feedback practices in higher education: A peer review perspective', Assessment &amp; Evaluation in Higher Education 39(1), 102-122. https:/ / doi.org/10.1080/02602938.2013.795518
- O'Donovan, B., Rust, C. &amp; Price, M., 2016, 'A scholarly approach to solving the feedback dilemma in practice', Assessment &amp; Evaluation in Higher Education 41(6), 938-949. https:/ /doi.org/10.1 080/02602938.2015.1052774
- Orsmond, P., Merry, S. &amp; Callaghan, A., 2004, 'Implementation of a formative assessment model incorporating peer and self-assessment', Innovations in Education and Teaching International 41(3), 273-290. https:/ /doi.org/10.1080/14703290410001733294
- Orsmond, P., Merry, S. &amp; Reiling, K., 2002, 'The use of exemplars and formative feedback when using student derived marking criteria in peer and self-assessment', Assessment and Evaluation in Higher Education 27(4), 309-323. https:/ /doi.org/10.1080/0260293022000001337
- Papert, S., 1998, 'Child power: Keys to the new learning of the digital century', Paper presented at the 11th Colin Cherry Memorial Lecture on Communication, London, 02 June.
- Popham, J., 2011, 'Assessment literacy overlooked: A teacher educator's confession', The Teacher Educator 46(4), 265-273. https:/ /doi.org/10.1080/08878730.2011.605048
- Poulos, A. &amp; Mahony, M., 2008, 'Effectiveness of feedback: The students' perspective', Assessment &amp; Evaluation in Higher Education 33(2), 143-154. https:/ /doi.org/10.1080/02602930601127869

Price, M., Rust, C., O'Donovan, B., Handley, K. &amp; Bryant, R., 2012, Assessment literacy: The foundation of  improving  student  learning ,  ASKe,  Oxford  Centre  for  Staff  and  Learning  Development, Oxford.

Pritchard,  A.,  2014, Ways  of  learning:  Learning  theories  and  learning  styles  in  the  classroom , 3rd edn., Routledge, Abingdon.

- Quesada-Serra, V., Rodríguez-Gómez, G. &amp; Ibarra-Sáiz, M., 2016, 'What are we missing? Spanish lecturers' perceptions of their assessment practices', Innovations in Education and Teaching International 53(1), 48-59. https:/ /doi.org/10.1080/14703297.2014.930353
- Reddy, C., Le Grange, L., Beets, P. &amp; Lundie, S, 2015, Quality assessment in South African schools , Juta, Cape Town.
- Redelius,  K.  &amp;  Hay,  P.,  2009,  'Defining,  acquiring  and  transacting  cultural  capital  through assessment in physical education', European Physical Education Review 15(3), 275-294.
- Roberts,  J.,  2010, Promoting  self-directed  learning  skills  in  first  year  students , School  for Mathematics and Computer Sciences, Heriot-Watt University, Edinburgh.
- Rust, C., O'Donovan, B. &amp; Price, M., 2005, 'A social constructivist assessment process model: How the research literature shows us this could be best practice', Assessment &amp; Evaluation in Higher Education 30, 231-240.
- Rust,  C.,  Price,  M.  &amp;  O'Donovan,  B.,  2003,  'Improving  students'  learning  by  developing  their understanding  of  assessment  criteria  and  processes', Assessment  &amp;  Evaluation  in  Higher Education 28(2), 147-164.
- Sadler,  D.,  2013,  'Assuring  academic  achievement  standards:  From  moderation  to  calibration', Assessment in Education: Principles, Policy &amp; Practice 20(1), 5-19. https:/ /doi.org/10.1080/09 69594X.2012.714742
- Saks, K. &amp; Leijen, A., 2014, 'Distinguishing self-directed learning and self-regulated learning and measuring  them  in  the  e-learning  context', Procedia  -  Social  and  Behavioral  Sciences 112, 190-198. https:/ /doi.org/10.1016/j.sbspro.2014.01.1155

Sambell, K., Brown, S. &amp; Race, P., 2019, 'Assessment as a locus for engagement: Priorities and practicalities', Italian Journal of Educational Research 2019, 45-62.

Sambell, K., McDowell, L. &amp; Montgomery, C., 2013, Assessment for learning in higher education , Routledge, Abingdon.

- Schraw,  G.,  Croppen,  K.  &amp;  Hartley,  K.,  2006,  'Promoting  self-regulation  in  science  education: Metacognition as part of a broader perspective on learning', Research in Science Education 36(1/2), 111-139.
- Seibert, S., Kraimer, M. &amp; Crant, J., 2001, 'What do proactive people do? A longitudinal model linking proactive personality and career success', Personnel Psychology 54(4), 845-874.
- Shepard, L.A., 2000, 'The role of assessment in a learning culture', Educational Researcher 29(7), 4-14. https:/ /doi.org/10.3102/0013189X029007004
- Shepard, L.A., Hammerness, K., Darling-Hammond, L. &amp; Rust, F., 2005, 'Assessment', in L. DarlingHammond &amp; J.  Bransford  (eds.), Preparing  teachers  for  a  changing  world:  What  teachers should learn and be able to do , pp. 275-326, Jossey-Bass, San Francisco, CA.

Shepard,  L.A.,  Penuel,  W.  &amp;  Pellegrino,  J.,  2018,  'Using  learning  and  motivation  theories  to coherently link formative assessment, grading practices, and  large scale -assessment', Educational Measurement: Issues and Practice 37(1), 21-34.

Slavin, R., 2012, Education psychology: Theory and practice , 10th edn., Person, Boston, MA.

Smith, C., Worsfold, K., Davies, L., Fisher, R. &amp; McPhail, R., 2013, 'Assessment literacy and student learning:  The  case  for  explicitly  developing  students'  assessment  literacy', Assessment  &amp; Evaluation in Higher Education 38(1), 44-60. https:/ /doi.org/10.1080/02602938.2011.598636

Stiggins, R.J., 1991, 'Assessment literacy', The Phi Delta Kappan 72(7), 534-539.

Stiggins, R.J., 1995, 'Assessment literacy for the 21st century', The Phi Delta Kappan 77(3), 238-245.

- Stiggins, R.J., 1999, 'Assessment, student confidence, and school success', The Phi Delta Kappan 81(3), 191-198.

Stobart, G., 2008, Testing times: The uses and abuses of assessment , Routledge, Abingdon.

Tee,  D.  &amp;  Ahmed,  P.,  2014,  '360-degree  feedback:  An  integrative  framework  for  learning  and assessment', Teaching in Higher Education 19(6), 579-591.

- Teo, P., 2019, 'Teaching for the 21st century: A case for dialogic pedagogy', Learning, Culture and Social Interaction 21(1), 170-178. https:/ /doi.org/10.1016/j.lcsi.2019.03.009

Tholin, J., 2008, 'Learner autonomy, self-directed learning and assessment: Lessons from Swedish experience', Independence 43, 9-12.

Tierney,  R.D.,  2006,  'Changing  practices:  Influences  on  classroom  assessment', Assessment in Education 13(3), 239-264. https:/ /doi.org/10.1080/09695940601035387

Toffler,  A.,  1991, Powershift:  Knowledge,  wealth,  and  violence  at  the  edge  of  the  21st  century , Bantam Books, New York, NY.

Urquhart, L., Rees, C. &amp; Ker, J., 2014, 'Making sense of feedback experiences: A multi-school study of  medical  students'  narratives', Medical  Education 48(2),  189-203.  https:/ /doi.org/10.1111/ medu.12304

- Van der Kleij, F., Vermeulen, J., Schildkamp, K. &amp; Eggen, T., 2015, 'Integrating data-based decision making, assessment for learning and diagnostic testing in formative assessment', Assessment in  Education:  Principles,  Policy  &amp;  Practice 22(3),  324-343.  https:/ /doi.org/10.1080/096959 4X.2014.999024
- Vanderlelie, J. &amp; Alexander, H., 2016, 'Learning-oriented assessment increases performance and written  skills  in  second  year  metabolic  biochemistry  course', Biochemistry  and  Molecular Biology Education 44, 412-420.

Van Staden, C.,  2016,  'A  learning-oriented  framework  for  e-portfolio  development  in  distance education', Suid-Afrikaanse Tydskrif vir Natuurwetenskappe en Tegnologie 35(1), 1-12.

Volante,  L.  &amp;  Fazio,  X.,  2007,  'Exploring  teacher  candidates'  assessment  literacy:  Implications for teacher education reform and professional development', Canadian Journal of Education 30(3), 749-770. https:/ /doi.org/10.2307/20466661

Warburton,  N.  &amp;  Volet,  S.,  2012,  'Enhancing  self-directed  learning  through  a  content  quiz group  leaning  assignment', Active  Learning  in  Higher  Education 14(1),  9-22.  https:/ /doi. org/10.1177/1469787412467126

Wiliam, D., 2011, Embedded formative assessment , Solution Tree Press, Bloomington, IN.

Willis,  J.,  Adie,  L.  &amp;  Klenowski,  V.,  2013,  'Conceptualising  teachers'  assessment  literacies  in  an era of curriculum and assessment reform', Australian Educational Research 40(2), 241-256. https:/ /doi.org/10.1007/s13384-013-0089-9

Winstone, N., Nash, R.,  Rowntree,  J.  &amp;  Parker,  M.,  2017,  ''It'd  be  useful,  but  I  wouldn't  use  it': Barriers to university students' feedback seeking and recipience', Studies in Higher Education 42(11), 2026-2041. https:/ /doi.org/10.1080/03075079.2015.1130032

Xu, Y. &amp; Brown, G., 2016, 'Teacher assessment literacy in practice: A reconceptualization', Teaching and Teacher Education 58, 149-162. https:/ /doi.org/10.1016/j.tate.2016.05.010

## Chapter 2

Antony,  L.,  2020, Laurence  Anthony's  AntConc ,  viewed  03  August  2020,  from  https:/ /www. laurenceanthony.net/software/antconc/.

Bailin, A. &amp; Grafstein, A., 2016, Readability: Text and context , Palgrave MacMillan, London.

Beckers, J., Dolmans, D.H., Knapen, M.M. &amp; Van Merriënboer, J.J., 2019, 'Walking the tightrope with an  e-portfolio:  Imbalance  between  support  and  autonomy  hampers  self-directed  learning', Journal of Vocational Education &amp; Training 71(2), 260-288. https:/ /doi.org/10.1080/13636820 .2018.1481448

Brockett,  R.G.  &amp;  Hiemstra,  R.,  2019, Self-direction  in  adult  learning:  Perspectives  on  theory, research and practice , Routledge, London.

Bull, B.D., 2017, Adventures in self-directed learning: A guide for nurturing learner agency and ownership , Wipf &amp; Stock, Eugene, OR.

- Catalano,  A.,  2015,  'The  effect  of  a  situated  learning  environment  in  a  distance  education information literacy course', The Journal of Academic Librarianship 41(5), 653-659. https:/ /doi. org/10.1016/j.acalib.2015.06.008

Cavalcanti, M.K., 2017, Libro , viewed 03 August 2020, from http:/ /librejo.sourceforge.net/.

- Cheng, S.F., Kuo, C.L., Lin, K.C. &amp; Lee-Hsieh, J., 2010, 'Development and preliminary testing of a selfrating instrument to measure self-directed learning ability of nursing students', International Journal of Nursing Studies 47(9), 1152-1158. https:/ /doi.org/10.1016/j.ijnurstu.2010.02.002
- Christiansen,  I.  &amp;  Aungamuthu,  Y.,  2012,  'Language  issues,  'misconceptions'  and  confusion:  A qualitative analysis of KZN grade 6 learners' responses on a Mathematics test', Education as Change 16(1), 51-67. https:/ /doi.org/10.1080/16823206.2012.691713
- Clark, S., 2017, 'Cultivating classroom  curiosity: A  quasi-experimental,  longitudinal  study investigating  the  impact  of  the  question  formulation  technique  on  adolescent  intellectual curiosity', PhD dissertation, School of Education, Boston University.
- Coetzee-Van Rooy, S.,  2016,  'Multilingualism  and  social  cohesion:  Insights  from  South  African students (1998, 2010, 2015)', International Journal of the Sociology of Language 2016(242), 239-265. https:/ /doi.org/10.1515/ijsl-2016-0041
- Coetzee-Van Rooy, S., 2020, 'Dominant language constellations in the language repertoires of multilingual South African students', in J. Lo Bianco &amp; L. Aronin (eds.), Dominant language constellations , pp. 139-165, Springer, Cham. https:/ /doi.org/10.1007/978-3-030-52336-7\_8
- Coleman, M. &amp; Liau, T.L., 1975, 'A computer readability formula designed for machine scoring', Journal of Applied Psychology 60(2), 283. https:/ /doi.org/10.1037/h0076540
- Costa, A.L. &amp; Kallick, B., 2004, Assessment strategies for self-directed learning , Sage, Thousand Oaks, CA.
- Cowie, B., Moreland, J. &amp; Otrel-Cass, K., 2013, Expanding notions of assessment for learning: Inside science and technology primary classrooms , Sense, Rotterdam.
- Cummings,  K.M.,  2020,  'A  mixed-method  case  study  of  the  effects  of  question  formulation technique on classroom engagement in a secondary earth science classroom and teachers' perceptions of this shift', PhD dissertation, School of Education, St. John's University.
- Desai, Z., 2016, 'Learning through the medium of English in multilingual South Africa: Enabling or disabling learners from low income contexts?', Comparative Education 52(3), 343-358. https:/ / doi.org/10.1080/03050068.2016.1185259
- Donaldson,  J.P.,  Barany,  A.  &amp;  Smith,  B.K.,  2020,  'Situated  learning  through  situating  learners as  designers',  in  M.J.  Bishop,  E.  Boling,  J.  Elen  &amp;  V.  Svihla  (eds.), Handbook of research in educational communications and technology , pp. 819-835, Springer, Cham.
- Flesch, R., 1979, How to write plain English: A book for lawyers and consumers , Harper and Row, New York, NY.
- Gibbons,  M.,  2002, The  self-directed  learning  handbook:  Challenging  adolescent  students  to excel , Jossey-Bass, San Francisco, CA.
- Gipps, C., 1999, 'Socio-cultural aspects of assessment', Review of Research in Education 24(1), 355-392. https:/ /doi.org/10.3102/0091732X024001355
- Heugh, K. &amp; Stroud, C., 2019, 'Multilingualism in South African education: A southern perspective', in R. Hickey (ed.), English in multilingual South Africa: The linguistics of contact and change , pp. 216-238, Cambridge University Press, Cambridge.
- Horsley, T., O'Neill, J. &amp; Campbell, C., 2009, 'The quality of questions and use of resources in self -directed learning: Personal learning projects in the maintenance of certification', Journal of Continuing Education in the Health Professions 29(2), 91-97. https:/ /doi.org/10.1002/chp.20017
- Horsley, T., O'Neill, J., McGowan, J., Perrier, L., Kane, G. &amp; Campbell, C., 2010, 'Interventions to improve question formulation in professional practice and self directed learning', -Cochrane Database of Systematic Reviews 5, 1-26. https:/ /doi.org/10.1002/14651858.CD007335.pub2

Johnson, D.W. &amp; Johnson, F., 2009, Joining together: Group theory and group skills ,  10th edn., Allyn and Bacon, Boston, MA.

Johnson, D.W. &amp; Johnson, R.T., 2019, 'The impact of cooperative learning on self-directed learning', in E. Mentz, J. De Beer &amp; R. Bailey (eds.), Self-directed learning for the 21st century: Implications for higher  education , pp.  37-66,  AOSIS,  Cape  Town.  https:/ /doi.org/10.4102/aosis.2019. BK134.02

Kicken, W., Brand Gruwel, S. &amp; Van Merriënboer, J.J., 2008, 'Scaffolding advice on task selection: -A  safe  path  toward  self directed  learning  in  on demand  education', --Journal  of  Vocational Education and Training 60(3), 223-239. https:/ /doi.org/10.1080/13636820802305561

- Lave, J. &amp; Wenger, E., 2008, Situated learning: Legitimate peripheral participation ,  Cambridge University Press, New York, NY.
- Lindberg, D.L., 2013, 'Automatic question generation from text for self-directed learning', MSc thesis, School of Computing Science, Simon Fraser University.

Lombard,  B.J.J,  2018, Assessment  to  support  self-directed  learning:  The  case  of  the  NWU , Inaugural Lecture, North-West-University, Vanderbijlpark.

- Martin,  J.R.  &amp;  White,  P.R.R.,  2005, The  language  of  evaluation:  Appraisal  in  English ,  Palgrave Macmillan, Houndmills.
- Martín-Chazeaud, A., 2017, 'Success or failure? The effect of the language of test on students' academic achievement in rural Senegal', PhD dissertation, Department of Modern Languages and Literatures and of English Studies, University of Barcelona.

McDonald,  M.E.,  2007, The  nurse  educator's  guide  to  assessing  learning  outcomes ,  Jones  &amp; Bartlett Learning, Sudbury, MA.

- Merriam, S.B., 2009, Qualitative research: A guide to design and implementation ,  Jossey-Bass, San Francisco, CA.

Mok, M.M.C., 2009, Self-directed learning oriented assessment: Theory, strategy and impact , The Hong Kong Institute of Education, Hong Kong.

- Mok, M.M.C., 2013, 'Assessment reform in the Asia-Pacific region: The theory and practice of selfdirected learning oriented assessment', in M.M.C. Mok (ed.), Self-directed learning-oriented assessment in the Asia-Pacific , pp. 3-22, Springer, Dordrecht.
- Olivier, J., 2020a, 'Self-directed multimodal learning to support demiurgic access', in D. Burgos (ed.), Radical solutions and eLearning , pp. 117-130, Springer, Singapore.
- Olivier,  J.,  2020b,  'Self-directed  multimodal  learning  within  a  context  of  transformative  open education',  in  J.  Olivier  (ed.), Self-directed  multimodal  learning  in  higher  education (NWU Self-Directed Learning Series Volume 5), pp. 1-49, AOSIS, Cape Town. https:/ /doi.org/10.4102/ aosis.2020.BK210.01
- Olivier,  J.,  2020c,  'Situated  and  culturally  appropriate  self-directed  multimodal  learning',  in J.  Olivier  (ed.), Self-directed  multimodal  learning  in  higher  education (NWU  Self-Directed Learning  Series Volume  5),  pp.  235-284,  AOSIS,  Cape  Town.  https:/ /doi.org/10.4102/ aosis.2020.BK210.07
- Priest, K.L., Saucier, D.A. &amp; Eiselein, G., 2016, 'Exploring students' experiences in first-year learning communities  from  a  situated  learning  perspective', International  Journal  of  Teaching  and Learning in Higher Education 28(3), 361-371.

Rothstein, D. &amp; Santana, L., 2011, Make just one change: Teach students to ask their own questions , Harvard Education Press, Cambridge, MA.

- Sambell, K., McDowell, L. &amp; Montgomery, C., 2012, Assessment for learning in higher education , Routledge, London.
- Semin, G.R. &amp; De Poot, C.J., 1997, 'The question-answer paradigm: You might regret not noticing how  a  question  is  worded', Journal  of  Personality  and  Social  Psychology 73(3),  472-480. https:/ /doi.org/10.1037/0022-3514.73.3.472
- Shohamy, E.,  1984,  'Does  the  testing  method  make  a  difference?  The  case  of  reading  comprehension', Language Testing 1(2), 147-170. https:/ /doi.org/10.1177/026553228400100203

Siriwongs, P., 2015, 'Developing students' learning ability by dint of self-directed learning', ProcediaSocial and Behavioral Sciences 197, 2074-2079. https:/ /doi.org/10.1016/j.sbspro.2015.07.577

Tomlinson, C.A. &amp; Moon, T.R., 2013, Assessment and student success in a differentiated classroom , ASCD, Alexandria, VA.

Yeoman,  P.  &amp;  Wilson,  S.,  2019,  'Designing  for  situated  learning:  Understanding  the  relations between material properties, designed form and emergent learning activity', British Journal of Educational Technology 50(5), 2090-2108. https:/ /doi.org/10.1111/bjet.12856

## Chapter 3

Arimoto, M. &amp; Clark, I., 2018, 'Equitable assessment interactions in the 'Open Learning Environment' (OLE)', European Journal of Education 53(2), 141-143. https:/ /doi.org/10.1111/ejed.12277

Baldwin, K.M., 2016, 'Multimodal assessment in action: What we really value in new media texts', PhD thesis, Department of English, University of Massachusetts Amherst.

Bell,  A.,  Curwood,  J.S.  &amp;  Ross,  J.,  2018,  'Assessment  in  a  digital  age:  Rethinking  multimodal artefacts in higher education', in J. Kay &amp; R. Luckin (eds.), Rethinking learning in the digital age: Making the learning sciences count, 13th International Conference of the Learning Sciences (ICLS) , vol. 3, pp. 1713-1714, International Society of the Learning Sciences, London.

Bezemer, J. &amp; Kress, G., 2008, 'Writing in multimodal texts: A social semiotic account of designs for learning', Written Communication 25(2), 166-195. https:/ /doi.org/10.1177/0741088307313177

Bezemer, J. &amp; Kress, G., 2016, Multimodality, learning and communication: A social semiotic frame , Routledge, London.

Brockett,  R.G.  &amp;  Hiemstra,  R.,  2019, Self-direction  in  adult  learning:  Perspectives  on  theory, research and practice , Routledge, London.

Cartner, H. &amp; Hallas, J., 2020, 'Aligning assessment, technology, and multi-literacies', E-Learning and Digital Media 17(2), 131-147. https:/ /doi.org/10.1177/2042753019899732

Curwood, J.S., 2012, 'Cultural shifts, multimodal representations, and assessment practices: A case study', E-Learning and Digital Media 9(2), 232-244. https:/ /doi.org/10.2304/elea.2012.9.2.232

Driver, M.K., 2019, 'Understanding equitable assessment: How preservice teachers make meaning of disability', Journal of Multicultural Affairs 4(1), 3.

Ehlers, U.D., 2013, Open learning cultures: A guide to quality, evaluation, and assessment for future learning , Springer, Heidelberg.

Fadel, C. &amp; Lemke, C., 2012, 'Multimodal learning through media', in N.M. Seel (ed.), Encyclopedia of the sciences of learning , pp. 2378-2381, Springer, New York, NY.

Fjørtoft,  H.,  2020,  'Multimodal  digital  classroom  assessments', Computers  &amp;  Education 152, 103892, 1-14. https:/ /doi.org/10.1016/j.compedu.2020.103892

Gandhi-Lee, E.N., 2018, 'Breaking the language barrier: Equitable assessment in general chemistry', PhD dissertation, Department of Chemistry and Biochemistry, University of Nevada.

Garside, J., Nhemachena, J.Z., Williams, J. &amp; Topping, A., 2009, 'Repositioning assessment: Giving students  the  'choice'  of  assessment  methods', Nurse  Education  in  Practice 9(2),  141-148. https:/ /doi.org/10.1016/j.nepr.2008.09.003

Grapin, S.E. &amp; Llosa, L., 2020, 'Toward an integrative framework for understanding multimodal L2 writing in the content areas', Journal of Second Language Writing 47, #100711. https:/ /doi. org/10.1016/j.jslw.2020.100711

Hafner,  C.A.  &amp;  Ho,  W.Y.J.,  2020,  'Assessing  digital  multimodal  composing  in  second  language writing: Towards a process-based model', Journal of Second Language Writing 47, #100710. https:/ /doi.org/10.1016/j.jslw.2020.100710

Hlatshwayo, M.N. &amp; Shawa, L.B., 2020, 'Towards a critical re-conceptualization of the purpose of higher education: The role of Ubuntu-Currere in re-imagining teaching and learning in South

African higher education', Higher Education Research &amp; Development 39(1), 26-38. https:/ /doi. org/10.1080/07294360.2019.1670146

- Jones, P., Turney, A., Georgiou, H. &amp; Nielsen, W., 2020, 'Assessing multimodal literacies in science: Semiotic and practical insights from pre-service teacher education', Language and Education 34(2), 153-172. https:/ /doi.org/10.1080/09500782.2020.1720227

Knowles, M.S., 1975, Self-directed learning: A guide for learners and teachers , Follett, Chicago, IL.

- Le Grange, L., 2019, 'Currere's active force and the concept of Ubuntu', in C. Hébert, N. Ng-AFook, A. Ibrahim &amp; B. Smith (eds.), Internationalizing curriculum studies , pp. 207-226, Palgrave Macmillan, Cham. https:/ /doi.org/10.1007/978-3-030-01352-3\_13
- Lubbe,  A.,  2020,  'Cooperative  learning-embedded  assessment:  Implications  for  students' assessment literacy and self-directedness in learning', PhD thesis, Faculty of Education, NorthWest University.
- Lubbe,  A.  &amp;  Mentz,  E.,  2019,  'Participative  assessment  practices  and  its  contribution  to  the development  of  self-directed  learning  skills',  in  E.  Mentz,  J.  De  Beer  &amp;  R.  Bailey  (eds.), Self-directed  learning  for  the  21st  century:  Implications  for  higher  education ,  pp.  341-368, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2019.BK134.11
- McGrail,  E.  &amp;  Behizadeh,  N.,  2017,  'K-12  multimodal  assessment  and  interactive  audiences:  An exploratory  analysis of existing frameworks', Assessing  Writing 31, 24-38.  https:/ /doi. org/10.1016/j.asw.2016.06.005
- Mok, M.M.C., 2009, Self-directed learning oriented assessment: Theory, strategy and impact , The Hong Kong Institute of Education, Hong Kong.
- Montenegro,  E.  &amp;  Jankowski,  N.A.,  2017, Equity  and  assessment:  Moving  towards  culturally responsive assessment , Occasional Paper No. 29, University of Illinois and Indiana University, National Institute for Learning Outcomes Assessment (NILOA), Urbana, IL.
- Montenegro, E. &amp; Jankowski, N.A., 2020, A new decade for assessment: Embedding equity into assessment  praxis ,  Occasional  Paper  No.  42,  University  of  Illinois  and  Indiana  University, National Institute for Learning Outcomes Assessment (NILOA), Urbana, IL.
- Nouri, J., 2019, 'Students multimodal literacy and design of learning during self-studies in higher education', Technology,  Knowledge  and  Learning 24(4),  683-698.  https:/ /doi.org/10.1007/ s10758-018-9360-5
- O'Brien,  E.,  Chlochasaigh,  K.N.  &amp;  Ó'Ceallaigh,  T.J.,  2019,  'The  role  of  assessment  literacy  in encouraging students to choose alternative assessment modes', in International Conference on Engaging Pedagogy (ICEP) , University of Limerick, Limerick, Ireland, December 12-13, 2019, n.p.
- Olivier,  J.,  2019a,  'Short  instructional  videos  as  multimodal  open  educational  resources  for  a language  classroom', Journal  of  Educational  Multimedia  and  Hypermedia  (JEMH) 28(4), 381-409.
- Olivier, J., 2019b, 'Towards a multiliteracies framework in support of self-directed learning through open educational resources', in E. Mentz, J. De Beer &amp; R. Bailey (eds.), Self-directed learning for the 21st century: Implications for higher education , pp. 167-201, AOSIS, Cape Town. https:/ / doi.org/10.4102/aosis.2019.BK134.06
- Olivier, J., 2020a, 'Self-directed multimodal learning to support demiurgic access', in D. Burgos (ed.), Radical solutions and eLearning , pp. 117-130, Springer, Singapore.
- Olivier,  J.,  2020b,  'Self-directed  multimodal  learning  within  a  context  of  transformative  open education',  in  J.  Olivier  (ed.), Self-directed  multimodal  learning  in  higher  education (NWU Self-Directed Learning Series Volume 5), pp. 1-49, AOSIS, Cape Town. https:/ /doi.org/10.4102/ aosis.2020.BK210.01
- Olivier,  J.,  2020c,  'Situated  and  culturally  appropriate  self-directed  multimodal  learning',  in J.  Olivier  (ed.), Self-directed  multimodal  learning  in  higher  education ,  (NWU  Self-Directed Learning  Series Volume  5),  pp.  235-284,  AOSIS,  Cape  Town.  https:/ /doi.org/10.4102/ aosis.2020.BK210.07
- Ross, J., Curwood, J.S. &amp; Bell, A., 2020, 'A multimodal assessment framework for higher education', E-Learning and Digital Media 17(4), 290-306. https:/ /doi.org/10.1177/2042753020927201

Russell,  M,  2019,  'Digital  technologies:  Supporting  and  advancing  assessment  practices  in  the classroom', in S.M. Brookhart &amp; J.H. McMillan (eds.), Classroom assessment and educational measurement , pp. 224-242, Routledge, New York, NY.

- Schmeck, A., Mayer, R.E., Opfermann, M., Pfeiffer, V. &amp; Leutner, D., 2014, 'Drawing pictures during learning from scientific text: Testing the generative drawing effect and the prognostic drawing effect', Contemporary  Educational  Psychology 39(4), 275-286.  https:/ /doi.org/10.1016/j. cedpsych.2014.07.003

Siemens, G. &amp; Long, P., 2011, 'Penetrating the fog: Analytics in learning and education', Educause Review 46(5), 30-40.

- Silseth, K. &amp; Gilje, Ø., 2019, 'Multimodal composition and assessment: A sociocultural perspective', Assessment in Education: Principles, Policy &amp; Practice 26(1), 26-42. https:/ /doi.org/10.1080/0 969594X.2017.1297292
- Smith,  A.,  Leeman-Munk,  S.,  Shelton,  A.,  Mott,  B.,  Wiebe,  E.  &amp;  Lester,  J.,  2019,  'A  multimodal assessment  framework  for  integrating  student  writing  and  drawing  in  elementary  science learning', IEEE  Transactions  on  Learning  Technologies 12(1),  3-15.  https:/ /doi.org/10.1109/ TLT.2018.2799871
- Tan, L., Zammit, K., D'warte, J. &amp; Gearside, A., 2020, 'Assessing multimodal literacies in practice: A critical review of its implementations in educational settings', Language and Education 34(2), 97-114. https:/ /doi.org/10.1080/09500782.2019.1708926
- Tran,  D.,  2019,  'Multimodal  assessment  and  like  for  like  feedback:  What's  the  point?', Student Engagement in Higher Education Journal 2(2), 161-180.
- Wylie,  E.C.  &amp;  Lyon,  C.J.,  2019,  'The  role  of  technology-enhanced  self-and  peer  assessment  in formative assessment', in S.M. Brookhart &amp; J.H. McMillan (eds.), Classroom assessment and educational measurement , pp. 170-191, Routledge, New York, NY.
- Yeh, H.-C., 2018, 'Exploring the perceived benefits of the process of multimodal video making in  developing  multiliteracies', Language  Learning  &amp;  Technology 22(2),  28-37.  https:/ /doi. org/10125/44642
- Zeng, W., Huang, F., Yu, L. &amp; Chen, S., 2018, 'Towards a learning-oriented assessment to improve students' learning - A critical review of literature', Educational Assessment, Evaluation and Accountability 30(3), 211-250. https:/ /doi.org/10.1007/s11092-018-9281-9

## Chapter 4

American  Library  Association,  2000, Information  literacy  competency  standards  for  higher education , viewed 22 November 2020, from https:/ /alair.ala.org/bitstream/handle/11213/7668/ ACRL Information Literacy Competency Standards for Higher Education.pdf.

Association of College &amp; Research Libraries, 2015, Framework for information literacy for higher education , viewed 21 November 2020, from http:/ /www.ala.org/acrl/standards/ilframework.

Berners-Lee, T. &amp; Fischetti, M., 2000, Weaving the web: The original design and ultimate destiny of the World Wide Web by its inventor , HarperCollins, New York, NY.

Bloom, B.S., 1956, Taxonomy of educational objectives: The classification of educational goals , Longman Group, London.

Bosch, C., Mentz, E. &amp; Goede, R., 2019, 'Self-directed learning: A conceptual overview', in E. Mentz, J. De Beer &amp; R. Bailey (eds.), Self-directed learning for the 21st century: Implications for higher education , (NWU Self-Directed Learning Series Volume 1), pp. 1-36, AOSIS, Cape Town. https:/ / doi.org/10.4102/aosis.2019.BK134.01

- Breed,  B.  &amp;  Bailey,  R.,  2018,  'The  influence  of  a  metacognitive  approach  to  cooperative  pair problem-solving on self-direction in learning', The Journal for Transdisciplinary Research in Southern Africa 14(1), 1-11. https:/ /doi.org/10.4102/td.v14i1.516

Brockett,  R.G.  &amp;  Hiemstra,  R.,  2019, Self-direction  in  adult  learning:  Perspectives  on  theory, research and practice , Routledge, London.

- Candy, P.C., 1991, Self-direction for lifelong learning: A comprehensive guide to theory and practice , Jossey-Bass Publishers, San Francisco, CA.
- Candy, P.C., 2004. Linking thinking: Self-directed learning in the digital age ,  Commonwealth of Australia, Canberra.
- Costa, A.L. &amp; Kallick, B., 2004, Assessment strategies for self-directed learning , Sage, Thousand Oaks, CA.
- Darby, F., 2020, Emotions in online teaching: A powerful tool for helping online students engage, persist, and succeed , viewed 24 November 2020, from https:/ /www.facultyfocus.com/articles/ online-education/emotions-in-online-teaching-a-powerful-tool-for-helping-online-studentsengage-persist-and-succeed/.
- Earl,  L.M.,  2013, Assessment  as  learning:  Using  classroom  assessment  to  maximize  student learning , 2nd edn., Corwin Press, Thousand Oaks, CA.
- Efklides, A., Schwartz, B.L. &amp; Brown, V., 2018, 'Motivation and affect in self-regulated learning: Does metacognition play a role?', in D.H. Schunk &amp; J.A. Greene (eds.), Handbook of self-regulation of learning and performance , pp. 64-82, Routledge, New York, NY.
- Evans, G.J., 2018, 'Windmills of your mind: Metacognition and lifelong learning', in Proceedings of the Canadian Engineering Education Association (CEEA) ,  University  of  British  Columbia, Vancouver, Canada, June 03-06, 2018, n.p.
- Flavell, J.H., 1976, 'Metacognitive aspects of problem solving', in L.B. Resnick (ed.), The nature of intelligence , pp. 231-235, Lawrence Erlbaum, Hillsdale, NJ.
- Flavell, J.H., 1979, 'Metacognition and cognitive monitoring: A new area of cognitive-developmental inquiry', American Psychologist 34(10), 906-911. https:/ /doi.org/10.1037/0003-066X.34.10.906
- Freire, P., 2000, Pedagogy of the oppressed , 30th anniversary edn., Continuum, New York, NY.
- Garrison, D.R., 1992, 'Critical thinking and self-directed learning in adult education: An analysis of  responsibility  and  control  issues', Adult  Education  Quarterly 42(3),  136-148.  https:/ /doi. org/10.1177/074171369204200302
- Garrison,  D.R.,  1997,  'Self-directed  learning:  Toward  a  comprehensive  model', Adult  Education Quarterly 48(1), 18-33. https:/ /doi.org/10.1177/074171369704800103
- Gibbons,  M.,  2002, The  self-directed  learning  handbook:  Challenging  adolescent  students  to excel , Jossey-Bass, San Francisco, CA.
- Hawe,  E.  &amp;  Dixon,  H.,  2017,  'Assessment  for  learning:  A  catalyst  for  student  self-regulation', Assessment &amp; Evaluation in Higher Education 42(8), 1181-1192. https:/ /doi.org/10.1080/02602 938.2016.1236360
- Herman, L. &amp; Mandell, A., 2004, From teaching to mentoring: Principle and practice, dialogue and life in adult education , Routledge Falmer, London.
- Houle, C.O., 1961, The inquiring mind: A study of the adult who continues to learn , The University of Wisconsin Press, Madison, WI.
- Jacobson, T., Mackey, T. &amp; O'Brien, K., 2018, Metaliterate learner roles ,  Metaliteracy.org, viewed 21 November 2020, from https:/ /metaliteracy.org/ml-in-practice/metaliterate-learner-roles/.
- Jacobson, T.E. &amp; Friedman, S., 2019, 'Teaching critical thinking and metaliteracy through OER: Theory  and  practice  in  a  course  collaboration', International  Journal  of  Open  Educational Resources 2(1), 173-189. https:/ /doi.org/10.18278/ijoer.2.1.11

Jacobson,  T.E.,  Mackey,  T.,  O'Keeffe,  E.  &amp;  Forte,  M.,  2018, Metaliteracy  goals  and  learning objectives , Metaliteracy.org, viewed  21 November  2020,  from  https:/ /metaliteracy.org/ learning-objectives/.

- Jacobson,  T.E.  &amp;  Mackey,  T.P.,  2013,  'Proposing  a  metaliteracy  model  to  redefine  information literacy', Communications  in  Information  Literacy 7(2),  84-91.  https:/ /doi.org/10.7548/cil. v7i2.255

Kincannon, J., Gleber, C. &amp; Kim, J., 1999, 'The effects of metacognitive training on performance and use of metacognitive skills in self-directed learning situations', in Proceedings of Selected Research and Development Papers Presented at the National Convention of the Association

for  Educational  Communications  and  Technology ,  Houston,  TX,  United  States  of  America, February 10-14, 1999, n.p.

Knowles, M.S., 1975, Self-directed learning: A guide for learners and teachers , Follett, Chicago, IL. Krathwohl, D.R., 2002, 'A revision of Bloom's taxonomy: An overview', Theory into Practice 41(4), 212-218. https:/ /doi.org/10.1207/s15430421tip4104\_2

Landow, G.P., 1992, Hypertext: The convergence of contemporary critical theory and technology , Johns Hopkins University Press, Baltimore, MD.

Lexico, 2020, Meta, viewed 24 November 2020, from https:/ /www.lexico.com/definition/meta-. Lindeman, E.C., 1926, The meaning of adult education , New Republic, New York, NY.

Loeng, S., 2020, 'Self-directed learning: A core concept in adult education', Education Research International 2020, #3816132. https:/ /doi.org/10.1155/2020/3816132

Lubbe,  A.  &amp;  Mentz,  E.,  2019,  'Participative  assessment  practices  and  its  contribution  to  the development of self-directed learning skills', in E. Mentz, J. De Beer &amp; R. Bailey (eds.), Selfdirected learning for the 21st century: Implications for higher education (NWU Self-Directed Learning Series Volume 1), pp. 341-368, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2019. BK134.11

Lumen Learning, n.d.a, Educational planning ,  viewed 21 November 2020, from https:/ /courses. lumenlearning.com/suny-esc-educationalplanning/.

Lumen Learning, n.d.b, Self-directed learning ,  viewed 21 November 2020, from https:/ /courses. lumenlearning.com/suny-esc-educationalplanning/chapter/self-directed-learning/.

Mackey, T.P., 2019, 'Empowering metaliterate learners for the post-truth world', in T.P. Mackey &amp;  T.E.  Jacobson  (eds.), Metaliterate  learning  for  the  post-truth  world ,  pp.  1-32,  ALA  NealSchuman, Chicago, IL.

Mackey, T.P., 2020, 'Exploring metaliterate learning through the frames of information literacy', in H. Julien, M. Gross &amp; D. Latham (eds.), The information literacy framework: Case studies of successful implementation , pp. 206-219, Rowman &amp; Littlefield, Lanham, MD.

Mackey, T.P. &amp; Jacobson, T.E., 2011, 'Reframing information literacy as a metaliteracy', College &amp; Research Libraries 72(1), 62-78. https:/ /doi.org/10.5860/crl-76r1

Mackey, T.P. &amp; Jacobson, T.E., 2014, Metaliteracy: Reinventing information to empower learners , Neal-Schuman, Chicago, IL.

Mackey,  T.P.,  Jacobson,  T.E.  &amp;  O'Brien,  K.L.,  2020, Integrated  metaliterate  learner  figure , Metaliteracy.org,  viewed  25  November  2020,  from  https:/ /metaliteracy.org/ml-in-practice/ integrated-metaliterate-learner-figure/.

Mariano, G.J. &amp; Batchelor, K., 2018, 'The role of metacognition and knowledge transfer in selfdirected learning', in F.G. Giuseffi (ed.), Emerging self-directed learning strategies in the digital age , pp. 141-159, IGI Global, Hershey, PA.

Mentz, E. &amp; Van Zyl, S., 2018, 'The impact of cooperative learning on self-directed learning abilities in  the  computer applications technology class', International  Journal  of  Lifelong  Education 37(4), 482-494. https:/ /doi.org/10.1080/02601370.2018.1513426

Metaliteracy.org, 2014, Metaliteracy badging system ,  viewed 25 November 2020, from https:/ / metaliteracy.org/ml-in-practice/metaliteracy-badging/.

Metaliteracy.org, 2019, Goals and learning objectives translated , viewed 25 November 2020, from https:/ /metaliteracy.org/learning-objectives/goals-and-learning-objectives-translated/.

Mok, M.M.C., 2009, Self-directed learning oriented assessment: Theory, strategy and impact , The Hong Kong Institute of Education, Hong Kong.

Oades-Sese, G.V., Matthews, T.A. &amp; Lewis, M., 2014, 'Shame and pride and their effects on student achievement', in R. Pekrun &amp; L. Linnenbrink-Garcia (eds.), International handbook of emotions in education . pp. 246-264, Routledge, New York, NY.

O'Brien, K.L., 2018, 'Failing better: Scaffolding learning with the metaliteracy badging system', in K. O'Brien &amp; T.E. Jacobson (eds.), Teaching with digital badges: Best practices for libraries, innovations in information literacy , pp. 183-197, Rowman &amp; Littlefield, Lanham, MD.

O'Brien, K.L., Forte, M., Mackey, T.P. &amp; Jacobson, T.E., 2017, 'Metaliteracy as pedagogical framework for  learner-centered  design  in  three  MOOC  platforms:  Connectivist,  coursera  and  canvas', Open Praxis 9(3), 267-286. https:/ /doi.org/10.5944/openpraxis.9.3.553

Pekrun, R. &amp;, Linnenbrink-Garcia, L., 2014, 'Introduction to emotions in education', in R. Pekrun &amp;  L.  Linnenbrink-Garcia  (eds.), International  handbook  of  emotions  in  education ,  pp.  1-10, Routledge, New York, NY.

Pintrich, P.R., 1999, 'The role of motivation in promoting and sustaining self-regulated learning', International Journal of Educational Research 31(6), 459-470. https:/ /doi.org/10.1016/S08830355(99)00015-4

Robinson,  J.D.  &amp;  Persky,  A.M.,  2020,  'Developing  self-directed  learners', American  Journal  of Pharmaceutical Education 84(3), 847512. https:/ /doi.org/10.5688/ajpe847512

Scholes, R.E., 1985, Textual power: Literary theory and the teaching of English ,  Yale  University Press, New Haven, CT.

Seraphin, S.B.,  Grizzell,  J.A.,  Kerr-German,  A.,  Perkins,  M.A.,  Grzanka,  P.R.  &amp;  Hardin,  E.E.,  2019, ' A conceptual framework for non-disposable assignments: Inspiring implementation, innovation, and research', Psychology Learning &amp; Teaching 18(1), 84-97. https:/ /doi. org/10.1177/1475725718811711

Sharot, T., 2017, The influential mind: What the brain reveals about our power to change others , 1st edn., Henry Holt and Company, New York, NY.

Tough, A., 1968, Why adults learn. Monographs in adult education , The Ontario Institute for Studies in Education, Toronto.

Van der Walt, H., 2016, 'The feasibility of grafting self-directed learning theory onto capability theory', in E. Mentz &amp; I. Oosthuizen (eds.), Self-directed learning research ,  pp.  1-34, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2016.sdlr14.01

WikiEdu, n.d., Inspiring learning , Enriching Wikipedia, viewed 25 November 2020, from https:/ / wikiedu.org/.

Zhu, M., Bonk, C.J. &amp; Doo, M.Y., 2020, 'Self-directed learning in MOOCs: Exploring the relationships among motivation, self-monitoring, and self-management', Educational Technology Research and Development 68, 2073-2093. https:/ /doi.org/10.1007/s11423-020-09747-8

## Chapter 5

Alotaibi,  K.N.,  2015,  'The  learning  environment  as  a  mediating  variable  between  self-directed  learning readiness and academic performance of a sample of Saudi nursing and medical emergency students', Nurse Education Today 36, 249-254. https:/ /doi.org/10.1080/1355800990360202

Andrade,  H.,  2010,  'Students  as  the  definitive  source  of  formative  assessment:  Academic self-assessment and the self-regulation of learning', in H. Andrade &amp; G. Cizek (eds), Handbook of formative assessment , pp. 90-105, Routledge, New York, NY.

Andrade,  H.L.,  2019,  'A  critical  review  of  research  on  student  self-assessment', Frontiers  in Education 4(87), 1-13. https:/ /doi.org/10.3389/feduc.2019.00087

Banna, J., Grace Lin, M.F., Stewart, M. &amp; Fialkowski, M.K., 2015, 'Interaction matters: Strategies to  promote engaged learning in an online introductory nutrition course', Journal of Online Learning and Teaching 11(2), 249-261.

Barr, L., Dittmar, M., Roberts, E. &amp; Sheraden, M., 2002, 'Enhancing student achievement through the  improvement  of  listening  skills',  Master  of  Arts  Action  Research  Project,  Saint  Xavier University, Chicago, IL.

Bichi, A.A., 2016, 'Classical test theory: An introduction to linear modeling approach to test and item analysis', International Journal for Social Studies 2(9), 27-33.

Birnbaum, A., 1968, 'Some latent trait models and their use in inferring an examinee's ability', in F.  Lord &amp; M. Novick (eds.), Statistical theories of mental test scores ,  pp.  397-479, AddisonWesley, Reading, PA.

- Boud, D., 1995, Enhancing learning through self-assessment , Kogan Page, London.
- Boud, D. &amp; Falchikov, N., 2007, Rethinking assessment in higher education , Kogan Page, London.
- Boud, D. &amp; Molloy, E., 2013, 'What is the problem with feedback?', in D. Boud &amp; E. Molloy (eds.), Feedback in higher and professional education , pp. 1-10, Routledge, London.

Brew,  A.,  1995,  'What  is  the  scope  of  self-assessment?',  in  D.  Boud  (ed.), Enhancing  learning through self-assessment , pp. 48-63, Kogan Page, London.

Broadfoot, P., 1996, Education, assessment and society , Open University Press, Buckingham.

- Brosnan, M., 1999, 'Computer anxiety in students: Should computer-based assessment be used at all?', in S. Brown, P. Race &amp; J. Bull (eds.), Computer-assisted assessment in higher education , pp. 47-54, Kogan Page, Birmingham.
- Bull, J. &amp; Mckenna, C., 2000, 'Computer-assisted assessment center (TLTP3) update', in M. Danson (ed.), 4th  International  CAA  Conference , Loughborough  University,  Loughborough,  United Kingdom, June 21-22, 2000, n.p.
- Bull,  J.  &amp;  McKenna,  C.,  2004, Blueprint  for  computer-assisted  assessment ,  Routledge  Falmer, London.
- Bunderson,  C.V.,  Inouye,  D.K.  &amp;  Olsen,  J.B.,  1988,  'The  four  generations  of  computerized educational measurement', ETS Research Report Series 1988(1), i-148. https:/ /doi. org/10.1002/j.2330-8516.1988.tb00291.x
- Canfield, W., 2001, 'ALEKS: A web-based intelligent tutoring system', Mathematics and Computer Education 35(2), 152-158.
- Chappell,  S.,  Arnold,  P.,  Nunnery,  J.  &amp;  Grant,  M.,  2015,  'An  examination  of  an  online  tutoring program's impact on low-achieving middle school students' Mathematics achievement', Online Learning 19(5), 37-53. https:/ /doi.org/10.24059/olj.v19i5.694
- Chappell, S., Nunnery, J., Pribesh, S. &amp; Hager, J., 2011, 'A meta-analysis of supplemental educational services (SES) provider effects on student achievement', Journal of Education for Students Placed at Risk 16(1), 1-23. https:/ /doi.org/10.1080/10824669.2011.554140
- Chin, P., 2016, 'Peer assessment', New Directions in the Teaching of Physical Sciences 3(1), 13-18. https:/ /doi.org/10.29311/ndtps.v0i3.410
- Conejo, R., Guzmán, E., Millán, E., Trella, M., DeLa-Cruz, J.L.P. &amp; Río, A., 2004, 'A web-based tool for adaptive testing', International Journal of Artificial Intelligence in Education 14(1), 29-61.
- Conole,  G.  &amp;  Warburton,  B.,  2005,  'A  review  of  computer-assisted  assessment', Research  in Learning Technology 13(1), 17-31. https:/ /doi.org/10.3402/rlt.v13i1.10970

De Boeck, P. &amp; Wilson, M., 2004, Explanatory item response models , Springer, New York, NY.

- Dodd, B.G.,  De  Ayala,  R.J.  &amp;  Koch,  W.R.,  1995,  'Computerized  adaptive  testing  with  polytomous  items', Applied Psychological Measurement 19(1), 5-22. https:/ /doi.org/10.1177/014662169501900103
- Double, K., McGrane, J. &amp; Hopfenbeck, T.N., 2020, 'The impact of peer assessment on academic performance: A meta-analysis of control group studies', Educational Psychology Review 32(1), 481-509. https:/ /doi.org/10.1007/s10648-019-09510-3

Earl, L. &amp; Katz, S., 2006, 'Rethinking classroom assessment with purpose in mind', Brock Education 16(1), 1-15. https:/ /doi.org/10.26522/brocked.v16i1.29

- Goold, E., 2016, 'Enhancing student learning by narrowing the gap between feedback giving and feedback receiving', in 3rd Teaching &amp; Education Conference , Barcelona, Spain, June 28, 2016, pp. 113-123. https:/ /doi.org/10.20472/TEC.2016.003.010

Hattie, J. &amp; Timperley, H., 2007, 'The power of feedback', Review of Educational Research 77(1), 81-112. https:/ /doi.org/10.3102/003465430298487

- Huang, M.H., 2013, 'After-school tutoring and the distribution of student performance', Comparative Education Review 57(4), 689-710. https:/ /doi.org/10.1086/671346
- Hughes, G., 2011, 'Aiming for personal best: A case for introducing ipsative assessment in higher education', Studies in Higher Education 36(3), 353-367. https:/ /doi.org/10.1080/03075079.20 10.486859

- Hughes, G.,  2014, Ipsative  assessment  and  personal  learning  gain:  Motivation  through  making progress , Palgrave Macmillan, New York, NY.
- Hughes, G., 2017, Ipsative assessment and personal learning gain: Exploring international case studies , Palgrave Macmillan, New York, NY.
- Hughes, G., Hawkes, D. &amp; Neumann, T., 2017, 'Use of digital technology to capture and support student  progress  across  a  taught  Postgraduate  Programme',  in  G.  Hughes  (ed.), Ipsative assessment and personal learning gain , pp. 105-128, Palgrave Macmillan, London. https:/ /doi. org/10.1057/978-1-137-56502-0\_6
- Hughes, G., Smith, H. &amp; Creese, B., 2015, 'Not seeing the wood for the trees: Developing a feedback analysis tool to explore feed forward in modularised programmes', Assessment &amp; Evaluation in Higher Education 40(8), 1079-1094. https:/ /doi.org/10.1080/02602938.2014.969193
- Hughes, G., Wood, E. &amp; Kitagawa, K., 2014, 'Use of self-referential (ipsative) feedback to motivate and  guide  distance  learners', The  Journal  of  Open,  Distance  and  e-Learning 29(1),  31-44. https:/ /doi.org/10.1080/02680513.2014.921612
- Kimura, T., 2017, 'The impacts of computer adaptive testing from different perspectives', Journal of Educational Evaluation for Health Professions 14, 12. https:/ /doi.org/10.3352/jeehp.2017.14.12
- Kirk, J., 2012, 'Self-directed learning: A potential predictor for technology integration among K-12 teachers', Doctoral dissertation, University of Tennessee.
- Lee, K., Tsai, P.S., Chai, C.S. &amp; Koh, J.H.L., 2014, 'Students' perceptions of self-directed learning and collaborative learning with and without technology', Journal of Computer Assisted Learning 30(5), 425-437. https:/ /doi.org/10.1111/jcal.12055
- Long,  H.B.,  1994,  'Resources  related  to  overcoming  resistance  to  self-direction  in  learning', New  Directions  for  Adult  and  Continuing  Education (64),  n.p. https:/ /doi.org/10.1002/ ace.36719946404
- Luo,  H.,  2015, Applying  the  case-based  method  in  designing  self-directed  online  instruction , viewed 26 August 2020, from https:/ /surface.syr.edu/etd/254.
- Lütticke, R., 2004,  'Problem  solving  with  adaptive  feedback:  Adaptive  hypermedia  and adaptive web-based system', Lecture Notes in Computer Science 3137, 417-420. https:/ /doi. org/10.1007/978-3-540-27780-4\_64
- Magno, C., 2009, 'Demonstrating the difference between classical test theory and item response theory using derived test data', The International Journal of Educational and Psychological Assessment 1(1), 1-11.
- Matteucci, M. &amp; Veldkamp, B.P., 2013, 'On the use of MCMC computerized adaptive testing with empirical  prior  information  to  improve  efficiency', Statistical  Methods  Applications 22(2), 243-267. https:/ /doi.org/10.1007/s10260-012-0216-1
- McBride, J.R., 2001, 'Research antecedents of applied adaptive testing', in W.A. Sands, B.K. Waters &amp; J.R. McBride (eds.), Computerized adaptive testing: From inquiry to operation ,  American Psychological Association  Washington, DC. ,
- Nicol, D. &amp; Macfarlane Dick, D., 2006, 'Formative assessment and self regulated learning: A model --and seven principles of good feedback practice', Studies in Higher Education 31(2), 199-218. https:/ /doi.org/10.1080/03075070600572090
- Noijons, J.,1994, 'Testing computer assisted language tests: Towards a checklist for CALT', CALICO Journal 12(1), 37-58.
- Nulty,  D.,  2012, A  guide  to  peer  and  self-assessment  approaches  and  practice  strategies  for academics , viewed  19  September  2020,  from  http:/ /cei.ust.hk/files/public/guide\_to\_peer\_ and\_self\_assessment\_griffith\_university.pdf.
- Oczkus, L.D., 2018, Reciprocal teaching at work: Powerful strategies and lessons for improving reading comprehension , 3rd edn., ASCD, Alexandria, VA.
- Ogina, T.A. &amp; Mampane, S.T., 2013, 'Experiences of tutorial sessions as learning support for distance education students', Progressio 35(1), 104-118.

Oppl, S., Reisinger, F. &amp; Eckmaier, A., 2017, 'A flexible online platform for computerized adaptive testing', International Journal of Education Technology in Higher Education 14, 2. https:/ /doi. org/10.1186/s41239-017-0039-0

Park, J.Y., Joo, S.H. &amp; Cornillie, F., 2019, 'An explanatory item response theory method for alleviating the cold-start problem in adaptive learning environments', Behavioral Research 51, 895-909. https:/ /doi.org/10.3758/s13428-018-1166-9

Partti,  H.,  Westerlund,  H.  &amp;  Lebler,  D.,  2015,  'Participatory  assessment  and  the  construction of  professional  identity  in  folk  and  popular  music  programs  in  Finnish  and  Australian music  universities', International  Journal  of  Music  Education 33(4),  476-490.  https:/ /doi. org/10.1177/0255761415584299

Price,  J.,  2012, Peer and self-assessment: Promoting learner involvement and personal responsibility , Kindle Version, Amazon, Seatle, WA.

Race,  P.,  2001,  'A  briefing  on  self,  peer  and  group  assessment',  Assessment  Series  No.  9, viewed  29  August  2020,  from  http:/ /internt.iha.dk/paedagogik/seminarer/Chris%20Rust/ ASS009PhilRace.pdf.

Reckase, M.D., 1989, 'Adaptive testing: The evolution of a good idea', Educational Measurement Issues and Practice 8(3), 11-15. https:/ /doi.org/10.1111/j.1745-3992.1989.tb00326.x

Rennie, F. &amp; Morrison, T., 2013, E-learning and social networking handbook , Routledge, London.

Reinholz,  D.,  2016,  'The  assessment  cycle:  A  model  for  learning  through  peer  assessment', Assessment &amp; Evaluation in Higher Education 41(2), 301-315. https:/ /doi.org/10.1080/026029 38.2015.1008982

Rezaie,  M.  &amp;  Golshan,  M.,  2015,  'Computer  adaptive  test  (CAT):  Advantages  and  limitations', International Journal of Educational Investigations 2(5), 128-137.

Rogers, P.C., Graham, C.R., Rasmussen, R., Campbell, J.O. &amp; Ure, D.M., 2003, 'Case 2: Blending face-to-face and distance learners in a synchronous class: Instructor and learner experiences', Quarterly Review of Distance Education 4(3), 245-251.

Rudner,  L.M.,  2001, Measurement  decision  theory (SuDoc  ED  1.310/2:457164),  U.S.  Dept.  of Education, Office of Educational Research and Improvement, Educational Resources Information Center, Washington, DC.

Salmon, G., 2003, E-moderating , 2nd edn., Routledge Falmer, London.

Savage, J. &amp; Fautley, M., 2016, 'Assessment processes and digital technologies', in A. King &amp; E. Himonides (eds.), Music, technology, and education: Critical perspectives , SEMPRE Studies in The Psychology of Music, pp. 210-224, Routledge, London, UK.

Segall, D., 2004, ' A sharing item response theory model for computerized adaptive testing', Journal of Educational  and  Behavioral  Statistics 29(4), 439-460.  https:/ /doi. org/10.3102/10769986029004439

Spiller, D., 2012, Assessment matters: Self-assessment and peer assessment , viewed 17 September 2020, from http:/ /cei.ust.hk/files/public/assessment\_matters\_self-assessment\_peer\_ assessment.pdf.

Seifert, T. &amp; Feliks, O., 2019, 'Online self-assessment and peer-assessment as a tool to enhance student-teachers'  assessment  skills', Assessment  &amp;  Evaluation  in  Higher  Education 44(2), 169-185. https:/ /doi.org/10.1080/02602938.2018.1487023

Stafford,  R.E.,  Runyon,  C.R.  &amp;  Casabianca,  J.M.,  2019,  'Comparing  computer  adaptive  testing stopping  rules  under  the  generalized  partial-credit  model', Behavioral  Research 51(3), 1305-1320. https:/ /doi.org/10.3758/s13428-018-1068-x

Stewart, V., 2012, A world-class education: Learning from international models of excellence and innovation , ASCD, Alexandria, VA.

Stocking, M.L.,1994, Three practical issues for modern adaptive testing item pools , ETS Research Report RR-94-5, Educational Testing Service, Princeton, NJ.

Teo, T., Tan, S.C., Lee, C.B., Chai, C.S., Koh, J.H.L., Chen, W.L. et al., 2010, 'The self-directed learning with technology scale (SDLTS) for young students: An initial development and validation', Computers &amp; Education 55(4), 1764-1771. https:/ /doi.org/10.1016/j.compedu.2010.08.001

Thelwall, M., 2000, 'Computer-based assessment: A versatile educational tool', Computers and Education 34(1), 37-49. https:/ /doi.org/10.1016/S0360-1315(99)00037-8

Thompson, N., 2011, 'Advantages of computerized Adaptive Testing (CAT)', White Paper, viewed 14 October 2019, from https:/ /assess.com/docs/Advantages-of-CAT-Testing.pdf.

Trentin, G., 1997, 'Computerized adaptive tests and formative assessment', Journal of Educational Multimedia and Hypermedia 6(2), 201-220.

Veldkamp,  B.P.  &amp;  Matteucci,  M.,  2013,  'Bayesian  computerized  adaptive  testing', Ensaio: Avaliação  e  Políticas  Públicas  em  Educação 21(78),  57-82.  http:/ /doi.org/10.1590/S010440362013005000001

Wainer, H. &amp; Eignor, D., 2000, 'Caveats, pitfalls, and unexpected consequences of implementing large-scale computerized testing', in H. Wainer (ed.), Computerized adaptive testing: A primer , pp. 271-299, Lawrence Erlbaum Associates Inc., Mahwah, NJ.

Wainer, H. &amp; Mislevy, R.J., 2000, 'Item response theory, item calibration, and proficiency estimation', in H. Wainer (ed.), Computerized adaptive testing: A primer ,  pp. 61-100, Lawrence Erlbaum Associates, Hillsdale, NJ.

Wauters, K., Desmet, P. &amp; Van den Noortgate, W., 2010, 'Adaptive item-based learning environments based on the item response theory: Possibilities and challenges', Journal of Computer Assisted Learning 26(6), 549-562. https:/ /doi.org/10.1111/j.1365-2729.2010.00368.x

Way, W.D. &amp; Robin, F., 2016, 'The history of computer-based testing', in C.S. Wells &amp; M. FaulknerBond (eds.), Educational measurement: From foundations to future , pp. 185-207, The Guilford Press, New York, NY

Weiss, D.J. &amp; Kingsbury, G.G.,1984, ' Application of computerized adaptive testing to educational problems', Journal of Educational Measurement 21, 361-375. https:/ /doi. org/10.1111/j.1745-3984.1984.tb01040.x

Youngeun, C. &amp; Anderson, W., 2016, 'Self-directed learning with feedback', Journal of College Science Teaching 46(1), 32-38.

## Chapter 6

Brinck,  I.  &amp;  Liljenfors,  R.,  2013,  'The  developmental  origin  of  metacognition', Infant  and  Child Development 22(1), 85-101. https:/ /doi.org/10.1002/icd.1749

Brookfield,  D.,  2020, Self-directed  learning ,  viewed  20  October  2020,  from  https:/ /infed.org/ mobi/self-directed-learning/.

Brown, A.,  1987,  'Metacognition,  executive  control,  self-regulation,  and  other  more  mysterious mechanisms', in F.E. Weinert &amp; R.H. Kluwe (eds.), Metacognition, motivation, and understanding , pp. 65-116, Lawrence Erlbaum, Hillsdale, MI.

Chatzipanteli,  A.,  Grammatikopoulos,  V.  &amp;  Gregoriadis,  A.,  2014,  'Development  and  evaluation of  metacognition  in  early  childhood  education', Early  Child  Development  and  Care 184(8), 1223-1232. https:/ /doi.org/10.1080/03004430.2013.861456

Chekwa, E., McFadden, M., Divine, A. &amp; Dorius, T., 2015, 'Metacognition: Transforming the learning experience', Journal of Learning in Higher Education 11(1), 109-112.

- Du Toit-Brits,  C.  &amp;  Van  Zyl,  C.M.,  2017,  'Self-directed  learning  characteristics:  Making  learning personal, empowering and successful', Africa Education Review 14(3-4), 122-141. https:/ /doi.or g/10.1080/18146627.2016.1267576

Dunlosky, J. &amp; Kane, M.J., 2007, 'The contributions of strategy use to working memory span: A comparison of strategy assessment methods', Quarterly Journal of Experimental Psychology 60(9), 1227-1245.

Efklides, A., 2009, 'The role of metacognitive experiences in the learning process', Psicothema 21(1), 76-82.

Efklides,  A.,  2011,  'Interactions  of  metacognition  with  motivation  and  affect  in  self-regulated learning: The MASRL model', Educational Psychologist 46(1), 6-25. https:/ /doi.org/10.1080/0 0461520.2011.538645

Egenti, M.C. &amp; Okoli, S.I., 2020, 'Teaching and learning in a digital age: Challenges and prospects', PREORC Journal of Arts and Humanities 5(1), 41-47.

Erlin, E., Rahmat, A. &amp; Rejeki, S., 2020, 'Use of metacognitive regulation strategies to increase student academic achievement in microbiology course', Journal of Physics: Conference Series 1521(4), 042016. https:/ /doi.org/10.1088/1742-6596/1521/4/042016

Flavell, J.H., 1979, 'Metacognition and cognitive monitoring: A new area of cognitive-developmental inquiry', American Psychologist 34(10), 906. https:/ /doi.org/10.1037/0003-066X.34.10.906

Funk, K., 2001, What is a worldview? , viewed 20 October 2020, from http:/ /web.engr.oregonstate. edu/~funkk/Personal/worldview.html.

Gavrilova, T., 2003, 'Teaching via using ontological engineering', in Proceedings of XI International Conference 'Powerful ICT for Teaching and Learning' PEG-2003 , St. Petersburg, Russia, June 22-26, 2003, pp. 23-26.

Google Scholar, 2020a, 'problem-based learning' 'self-directed learning' 'metacognitive awareness' 'higher education' &amp; 'teacher preparation' , viewed 26 January 2020, from https:/ / scholar.google.com/scholar?q=%22problem-based+learning%E2%80%99,+%E2%80%98selfdirected+learning%E2%80%99,+%E2%80%98metacognitive+awareness%E2%80%99,+%E2%8 0%98higher+education%E2%80%99+and+%E2%80%98teacher+preparation%E2%80%99&amp;hl =nl&amp;as\_sdt=0,5.

Google Scholar, 2020b, 'Problem-based learning' 'self-directed learning' 'metacognitive awareness' 'higher education' &amp; 'teacher preparation' , viewed 26 January 2020, from https:/ / scholar.google.com/scholar?q=%22problem-based+learning%E2%80%99%2C+%E2%80%98s elf-directed+learning%E2%80%99%2C+%E2%80%98metacognitive+awareness%E2%80%99% 2C+%E2%80%98higher+education%E2%80%99+and+%E2%80%98teacher+preparation%E2% 80%99&amp;hl=nl&amp;as\_sdt=0%2C5&amp;as\_ylo=2015&amp;as\_yhi=2020.

Heyns, M., 2006, 'An epistemology of engagement', Koers: Bulletin for Christian Scholarship 71(1), 73-99.

- Inbar-Lourie, O. &amp; Levi, T., 2020, 'Assessment literacy as praxis: Mediating teacher knowledge of  assessment-for-learning  practices',  in  M.E.  Poehner  &amp;  O.  Inbar-Lourie  (eds.), Toward  a reconceptualization of second language classroom assessment , pp. 241-259, Springer, Cham.
- Jagals, D., 2015, 'Metacognitive locale: A design-based theory of students' metacognitive language and networking in Mathematics', PhD thesis, North-West University.
- Jagals,  D.,  2018,  'Metacognitive  sentience  for  impact-making  research  in  curriculum  studies: Mathematics education as case in point', in C.C. Wolhuter (ed.), Raising the impact of education research in Africa , pp. 123-147, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2018.BK53.07
- Joksimovic, S., Dowell, N., Gašević, D., Mirriahi, N., Dawson, S. &amp; Graesser, A.C., 2019, 'Linguistic characteristics of reflective states in video annotations under different instructional conditions', Computers in Human Behavior 96, 211-222. https:/ /doi.org/10.1016/j.chb.2018.03.003

Khani, F., 2020, 'The interface between EFL teachers' cognitions on teacher-student relationships and their cognitions on assessment', PhD thesis, University of Zabol.

Knowles, M., 1975, Self-directed learning: A guide for learners and teachers , Follett  Publishing Company, Chicago, IL.

Lam, R., 2020, 'Investigating assessment as learning in second language writing: A qualitative research  perspective', International  Journal  of  Qualitative  Methods 19, 1-10. https:/ /doi. org/10.1177/1609406920938572

Leshcheva,  I.,  Gorovaya,  D.  &amp;  Leshchev,  D.,  2010,  'Ontology-based  assessment  technique',  in Proceedings  of  the  2nd  International  Workshop  on  Semantic  Web  Applications  in  Higher Education , Southampton, United Kingdom, November 03, 2010, n.p.

Lian, L.H. &amp; Yew, W.T., 2020, 'Development of an assessment literacy super-item test for assessing preservice teachers' assessment literacy', Development 13(7), 870-889.

- Miller,  R.,  2000,  'A  brief  introduction  to  holistic  education',  in The  encyclopedia  of  pedagogy and  informal  education , viewed  28  October  2020,  from  https:/ /infed.org/mobi/a-briefintroduction-to-holistic-education/.
- Pillay, P., 2020, 'Role of assessments in enhancing teacher education at a rural-based university in South Africa', Gender &amp; Behaviour 18(1), 15017-15026.

Pratt,  D.D.  &amp;  Collins,  J.B.,  2000,  'The  teaching  perspectives  inventory  (TPI)',  in Conference Proceedings of the Adult Education Research Conference , Vancouver, Canada, n.d., 2000, n.p.

- Price,  M.,  Rust,  C.,  O'Donovan,  B.,  Handley,  K.  &amp;  Bryant,  R.,  2012, Assessment  literacy:  The foundation for improving student learning , Oxford Centre for Staff and Learning Development, Oxford Brookes University, London.

Proust, J., 2013, The philosophy of metacognition: Mental agency and self-awareness , OUP, Oxford.

Ramanarayanan, V., Evanini, K. &amp; Tsuprun, E., 2019, 'Beyond monologues', in K. Zechner &amp; K. Evanini (eds.), Automated speaking assessment: Using language technologies to score spontaneous speech , p. 176. Routledge, New York.

Roberts, D., 2019, 'Higher education lectures: From passive to active learning via imagery', Active Learning in Higher Education 20(1), 63-77. https:/ /doi.org/10.1177/1469787417731198

- Setlhodi, I.I., 2019, 'The value of pacing in promoting self-directed learning', in F.G. Giuseffi (ed.), Self-directed learning strategies in adult educational contexts , pp. 1-22, IGI Global, Hershey, PA.
- Siegesmund,  A.,  2017,  'Using  self-assessment  to  develop  metacognition  and  self-regulated learners', FEMS Microbiology Letters 364(11), fnx096. https:/ /doi.org/10.1093/femsle/fnx096

Strawderman,  V.W.,  2009, Math  anxiety  model , viewed  20  April  2020,  from  http:/ /www. mathgoodies.com/articles/math\_anxiety\_model.html.

Van Hout-Wolters, B., 2000, 'Assessing active self-directed learning', in P.R.J. Simons, J. Van der Linden &amp; T. Duffy (eds.), New learning , pp. 83-99, Springer, Dordrecht.

Wang, J., 2019, 'Exploring the perceived integrations between assessment and metacognition: A qualitative inquiry of three award-winning teacher educators' conceptions of assessment in  a  Hong  Kong  university  context', Frontiers  in  Education 4,  157.  https:/ /doi.org/10.3389/ feduc.2019.00157

- Wheeler, S., Waite, S.J. &amp; Bromfield, C., 2002, 'Promoting creative thinking through the use of ICT', Journal of Computer  Assisted  Learning 18(3), 367-378. https:/ /doi.org/10.1046/j.02664909.2002.00247.x

## Chapter 7

- Ajjawi, R. &amp; Boud, D., 2017, 'Researching feedback dialogue: An interactional analysis approach', Assessment &amp; Evaluation in Higher Education 42(2), 252-265. https:/ /doi.org/10.1080/02602 938.2015.1102863

Archer,  J.C.,  2010,  'State  of  the  science  in  health  professional  education:  Effective  feedback', Medical Education 44(1), 101-108. https:/ /doi.org/10.1111/j.1365-2923.2009.03546.x

Beckers, J., Dolmans, D.H., Knapen, M.M. &amp; Van Merriënboer, J.J., 2019, 'Walking the tightrope with an e-portfolio: Imbalances between support and autonomy hampers self-directed learning', Journal of Vocational Education &amp; Training 71(2), 260-288. https:/ /doi.org/10.1080/13636820 .2018.1481448

- Black, P. &amp; McCormick, R., 2010, 'Reflections and new directions', Assessment and Evaluation in Higher Education 35(5), 493-499. https:/ /doi.org/10.1080/02602938.2010.493696
- Boud, D., 2009, 'How can practice reshape assessment?', in G. Joughin (ed.), Assessment, learning and judgement in higher education , pp. 29-43, Springer, Dordrecht.
- Boud, D., 2010, 'Assessment for developing practice', in J. Higgs, D. Fish, I. Goulter, S. Lofus, J.-A. Reid &amp; F. Trede (eds.), Education for future practice , pp. 251-262, Sense, Rotterdam.

- Boud,  D.  &amp;  Associates,  2010, Assessment 2020: Seven propositions  for  assessment  reform  in higher education , Australian Learning and Teaching Council, viewed 02 October 2020, from https:/ /www.uts.edu.au/sites/default/files/Assessment-2020\_propositions\_final.pdf.
- Boud,  D.  &amp;  Falchikov,  N.,  2006,  'Aligning  assessment  with  long-term  learning', Assessment  &amp; Evaluation in Higher Education 31(4), 399-413. https:/ /doi.org/10.1080/02602930600679050
- Boud, D. &amp; Falchikov, N., 2007, Rethinking assessment in higher education: Learning for the longer term , Routledge/Taylor &amp; Francis Group, London.
- Boud, D. &amp; Molloy, E., 2013, 'Rethinking models of feedback for learning: The challenge of design', Assessment &amp; Evaluation in Higher Education 38(6), 698-712. https:/ /doi.org/10.1080/026029 38.2012.691462
- Boud, D. &amp; Soler, R., 2016, 'Sustainable assessment revisited', Assessment &amp; Evaluation in Higher Education 41(3), 400-413. https:/ /doi.org/10.1080/0262938.2015.1018133
- Carless, D. &amp; Boud, D., 2018, 'The development of student feedback literacy: Enabling uptake of feedback', Assessment &amp; Evaluation in Higher Education 43(8), 1315-1325. https:/ /doi.org/10.1 080/02602938.2018.1463354
- Carless, D., Salter, D., Yang, M. &amp; Lam, Y., 2011, 'Developing sustainable feedback practices', Studies in Higher Education 36(4), 395-407. https:/ /doi.org/10.1080/03075071003642449
- Cox,  C.T.,  2015,  'Incorporating  more  individual  accountability  in  group  activities  in  general chemistry', Journal  of  College  Science  Teaching 44(3),  30-36.  https:/ /doi.org/10.2505/4/ jcst15\_044\_03\_30
- Cramp, A., 2011, 'Developing first-year engagement with written feedback', Active Learning in Higher Education 12(2), 113-124. https:/ /doi.org/10.1177/1469787411402484
- Dawson, P., Henderson, M., Mahoney, P., Philips, M., Ryan, T., Boud, D. et al., 2019, 'What makes for  effective  feedback:  Staff  and  student  perspectives', Assessment &amp; Evaluation in Higher Education 44(1), 25-36. https:/ /doi.org/10.1080/02602938.2018.1467877
- Deeley,  S.J.,  Fischbacher-Smith,  M.,  Karadzhov,  D.  &amp;  Koristashevskaya,  E.,  2019,  'Exploring  the 'wicked' problem of student dissatisfaction with assessment and feedback in higher education', Higher Education Pedagogies 4(1), 385-405. https:/ /doi.org/10.1080/23752696.2019
- Evans, C., 2013, 'Making sense of assessment feedback in higher education', Review of Educational Research 83(1), 70-120. https:/ /doi.org/10.3102/0034654312474350
- Ferguson, P., 2011, 'Student perceptions of quality feedback in teacher education', Assessment &amp; Evaluation in Higher Education 36(1), 51-61. https:/ /doi.org/10.1080/02602930903197883
- Gedamu, A.D. &amp; Shewangezaw, G.L., 2020, 'Teachers' beliefs and practices of cooperative group work  assessment:  Selected  secondary  school  teachers  in  focus', Research  on  Human  and Social Sciences 10(7), 19-29. https:/ /doi.org/10.7176/RHSS/10-7-03
- Gibbs, G. &amp; Simpson, C., 2004, 'Conditions under which assessment supports students' learning', Learning and Teaching in Higher Education 1, 1-31.
- Harris, L.R., Brown, G.T.L. &amp; Harnett, J.A., 2014, 'Understanding classroom feedback practices: A study of New Zealand student experiences, perceptions, and emotional responses', Educational Assessment, Evaluation and Accountability 26(2), 107-133. https:/ /doi.org/10.1007/s11092-0139187-5
- Henderson, M., Phillips, M., Ryan, T., Boud, D., Dawson, P., Molloy, E. et al., 2019, 'Conditions that enable  effective  feedback', Higher  Education  Research  &amp;  Development 38(7),  1401-1416. https:/ /doi.org/10.1080/07294360.2019.1657807
- Jacobs, G.M., 2015, 'Collaborative learning or cooperative learning? The name is not important, flexibility is', Beyond Words 3(1), 32-52.
- Johnson, D.W. &amp; Johnson, F.P., 2013, Joining together: Group theory and group skills ,  11th edn., Pearson, Boston, MA.
- Johnson, D.W. &amp; Johnson, R.T., 2019, 'The impact of cooperative learning on self-directed learning', in E. Mentz, J. De Beer &amp; R. Bailey (eds.), Self-directed learning for the 21st century: Implications

for higher education (NWU Self-Directed Learning Series Volume 1), pp. 37-66, AOSIS, Cape Town. https:/ /doi.org/10.4102/aosis.2019.BK134.02

Johnson,  D.W.,  Johnson,  R.T.  &amp;  Holubec,  E.J.,  2008, Cooperation  in  the  classroom ,  8th  edn., Interaction Book Company, Edina, MN.

Johnson, D.W., Johnson, R.T. &amp; Smith, K.A., 2006, Active  learning:  Cooperative  learning  in  the college classroom , 3rd edn., Interaction Book Company, Edina, MN.

Kazlauskiene, A., Gaucaite, R. &amp; Poceviciene, R., 2016, 'Preconditions for sustainable changes in didactics applying self-directed learning in the general education school', Journal of Teacher Education for Sustainability 18(2), 105-118. https:/ /doi.org/10.1515/jtes-2016-0018

King,  L.H.,  1993,  'High  and  low  achievers'  perceptions  and  cooperative  learning  in  two  small groups', The Elementary School Journal 93(4), 399-416. https:/ /doi.org/10.1086/461731

Krauss, S.E., 2005, 'Research paradigms and meaning making: A primer', The Qualitative Report 10(4), 758-770.

Le,  H.,  Janssen,  J.  &amp;  Wubbels,  T.,  2018,  'Collaborative  learning  practices:  Teacher  and  student perceived obstacles to effective student collaboration', Cambridge Journal of Education 48(1), 103-122. https:/ /doi.org/10.1080/0305764X.2016.1259389

Nelson, M.M. &amp; Schunn, C.D., 2009, 'The nature of feedback: How different types of peer feedback affect  writing  performance', Instructional  Science 37(4),  375-401.  https:/ /doi.org/10.1007/ s11251-008-9053-x

Nguyen,  T.H.  &amp;  Walker,  M.,  2016,  'Sustainable  assessment  for  lifelong  learning', Assessment  &amp; Evaluation in Higher Education 41(1), 97-111. https:/ /doi.org/10.1080/02029999938.2014.985632

O'Donovan, B., Rust, C. &amp; Price, M., 2016, 'A scholarly approach to solving the feedback dilemma in practice', Assessment &amp; Evaluation in Higher Education 41(6), 938-949. https:/ /doi.org/10.1 080/02602938.2015.1052774

Pat-El, R.J., Tillema, H., Segers, M. &amp; Vedder, P., 2015, 'Multilevel predictors of differing perceptions of assessment for learning practices between teachers and students', Assessment in Education: Principles, Policy &amp; Practice 22(2), 282-298. https:/ /doi.org/10.1080/0969594X.2014.975675

Price,  M.,  Handley,  K.,  Millar,  J.  &amp;  O'Donovan,  B.,  2010,  'Feedback:  All  that  effort  but  what  is the  effect?', Assessment  and  Evaluation  in  Higher  Education 35(3),  277-289.  https:/ /doi. org/10.1080/02602930903541007

Purnomo, Y.W., Kaur, A., Ismail, S.N.B., Suryadi, D. &amp; Darwis, S., 2018, 'The consistency between professed teaching practices and assessment practices: A case in Mathematics class', Beta: Jurnal Tadris Matematika 11(2), 101-113. https:/ /doi.org/10.20414/betajtm.v11i2.223

- Sadler, D.R., 2010, 'Beyond feedback: Developing student capability in complex appraisal', Assessment  &amp;  Evaluation in Higher Education 35(5), 535-550. https:/ /doi. org/10.1080/02602930903541015

Thondhalana, G. &amp; Belluigi, D.Z., 2017, 'Students' reception of peer assessment of group-work contributions: Problematics in terms of race and gender emerging from a South African case study', Assessment &amp; Evaluation in Higher Education 42(7), 1118-1131. https:/ /doi.org/10.1080/ 02602938.2016.1235133

Van der Kleij, F.M. 2019, 'Comparison of teachers and student perceptions of formative assessment feedback  practices  and  association  with  individual  student  characteristics', Teaching  and Teacher Education 85, 175-189. https:/ /doi.org/10.1016/j.tate.2019.06.010

Vygotsky, L., 1978, Mind in society , Harvard University Press, London.

Watling, C.J. &amp; Ginsburg, S., 2019, 'Assessment, feedback and the alchemy of learning', Medical Education 53(1), 76-85. https:/ /doi.org/10.1111/medu.13645

Wenger, E., 1998, Communities of practice , Cambridge University Press, Cambridge.

Wickramasinghe, M., Weller, J.G. &amp; Smith, D.V., 2020, 'Assessment practices in teacher education that  support  sustainability  in  the  profession:  Perspectives  from  Australia  and  Sri  Lanka', Journal  of  Perspectives  in  Applied  Academic  Practice 7(1),  19-25.  https:/ /doi.org/10.14297/ jpaap.v7i1.340

Willis,  J.,  2007,  'Cooperative  learning  is  a  brain  turn-on', Middle School Journal ,  March,  04-13, viewed 17 October 2020, from https:/ /files.eric.ed.gov/fulltext/EJ756482.pdf.

Witts, J., 2016, 'Sustainable assessment: Developing lifelong learners', in D. Summers &amp; R. Cutting (eds.), Education  for  sustainable  development  in  further  education , pp.  77-91,  Palgrave Macmillan, London.

## Chapter 8

Anderson, L.W., Krathwohl, D.R., Airasian, P.W., Mayer, R.E., Pinctrich, P.R., Raths, J. et al., 2001, A taxonomy for learning, teaching, and assessing: A revision of Bloom's taxonomy of educational objectives , Addison-Wesley Longman, New York, NY.

Arndt,  J.D.,  2017, Self-directed  learning  for  English  language  learners ,  T amagawa  University, Machida.

Berry,  R.,  2011,  'Assessment  reforms  around  the  world',  in  R.  Berry  &amp;  R.B.  Adamson  (eds.), Assessment reform in education: Policy and practice , pp. 89-104, Springer, New York, NY.

Berry,  V.,  Sheehan,  S.  &amp;  Munro,  S.,  2019,  'What  does  language  assessment  literacy  mean  to teachers?', English  Language  Teaching  Journal 73(2),  113-123.  https:/ /doi.org/10.1093/elt/ ccy055

Boud, D. &amp; Molloy, E., 2013, 'What is the problem with feedback?', in D. Boud &amp; E. Molloy (eds.), Feedback in higher education and professional education: Understanding it and doing it well , pp. 1-10, Routledge, London.

Breed, B., 2016, 'Applying the elements of cooperative learning: Reported influence on self-directed learning and view of cooperative learning', Journal of Communication 7(1), 1-12. https:/ /doi.or g/10.1080/0976691X.2016.11884878

British  Council,  2020,  'English  language  day', Learn  English ,  viewed  06  October  2020,  from https:/ /learnenglish.britishcouncil.org/general-english/magazine/english-language-day.

Brown, J.D., 2017, 'Questions and answers about language testing statistics: Developing and using rubrics: Analytic or holistic?', Shiken 21(2), 20-26.

Bull, B.D., 2017, Adventures in self-directed learning: A guide for nurturing learner agency and ownership , Wipf &amp; Stock, Eugene, OR.

Burns, M., 2011, Distance education for teacher training: Modes, models and methods , Education Development Center, viewed 19 October 2020, from http:/ /idd.edc.org/resources/publications/ modes-models-and-methods.

BusinessTech, 2019, 'These are the most-spoken languages in South Africa in 2019', BusinessTech , viewed  11  September  2020,  from  https:/ /businesstech.co.za/news/business/319760/theseare-the-most-spoken-languages-in-south-africa-in-2019/.

Cash, R.M., 2017, Advancing differentiation: Thinking and learning for the 21st century , Free Spirit, Minneapolis, MN.

Chetty,  R.,  2015,  'Freirean  principles  and  critical  literacy  to  counter  retrograde  impulses  in the  curriculum  and  assessment  policy  statement', Reading  &amp;  Writing 6(1),  1-7.  https:/ /doi. org/10.4102/rw.v6i1.71

Chong,  S.  &amp;  Cheah,  H.M.,  2009,  'A  values,  skills  and  knowledge  framework  for  initial  teacher preparation  programmes', Australian  Journal  of  Teacher  Education 34(3),  1-17.  https:/ /doi. org/10.14221/ajte.2009v34n3.1

Costa, A.L. &amp; Kallick, B., 2004, Assessment strategies for self-directed learning ,  Corwin  Press, Thousand Oaks, CA.

Crystal, D., 2003, English as a global language

Cummins, J., 2000, Language, power and pedagogy: Bilingual children in the crossfire Matters, Clevedon.

, 2nd edn., Cambridge University Press, Cambridge. , Multilingual

De Beer, J. &amp; Gravett, S., 2016, 'The affordances of case-based teaching for self-directed learning: A case study with first-year student teachers', in E. Mentz &amp; I. Oosthuizen (eds.), Self-directed learning research: An imperative for transforming the educational landscape , pp. 35-70, AOSIS, Cape Town.

Deneme, S. &amp; Ada, S., 2010, 'An application of skills integration in language teaching', Language in India 10(9), 9-18.

Department of Basic Education, 2011, Curriculum and assessment policy statement: English first additional language, further education and training phase, grades 10-12 , Government Printers, Pretoria.

Department  of  Basic  Education,  2013, Manual  for  teaching  English  across  the  curriculum , Government Printers, Pretoria.

Department of Basic Education, 2014, The ministerial task team report on the national senior certificate (NCS) , Government Printers, Pretoria.

Dominguez Romero, E., Bobkina, J. &amp; Stefanova, S., 2019, Teaching literature and language through multimodal texts , IGI Global, Hershey, PA.

Frempong, G., Reddy, V. &amp; Mackay, K., 2013, Improving teaching and learning through the South African annual national assessment: Challenges, possibilities and solutions ,  Human Sciences Research  Council,  viewed  19  October  2020,  from  http:/ /repository.hsrc.ac.za/bitstream/ handle/20.500.11910/3007/7683.pdf?sequence=1&amp;isAllowed=y.

Galaczi, E.,  Nye,  A.,  Poulter,  M.  &amp;  Allen,  H.,  2018, Cambridge assessment English perspectives: Teacher professional development , UCLES, Cambridge.

Geisinger, K.F., 2016, '21st century skills: What are they and how do we assess them?', Applied Measurement in Education 2(4), 245-249. https:/ /doi.org/10.1080/08957347.2016.1209207

Goodman,  S.,  2015,  'The  importance  of  teaching  through  relationships', Edutopia , viewed 01 October 2020, from https:/ /www.edutopia.org/blog/importance-teaching-throughrelationships-stacey-goodman.

Gordon, S. &amp; Harvey, J., 2019, 'South Africans prefer their children to be taught in English', Quartz Africa , viewed 11 September 2020, from https:/ /qz.com/africa/1720174/south-africans-prefertheir-children-to-be-taught-in-english/.

Graddol, D., 2006, English next , British Council, London.

Greenstein, L., 2012, Assessing 21st century skills: A guide to evaluating mastery and authentic learning , Corwin, Thousand Oaks, CA.

Guglielmino,  L.M.,  2013,  'The  case  for  promoting  self-directed  learning  in  formal  educational institutions', South African Journal of Education 10(2), 1-18.

Hamilton, N., 2019, 'Leadership of self: Each student taking ownership over continuous professional development/self-directed learning', Santa Clara Law Review 58(3), 567-600.

International  TEFL  Academy,  2020, TEFL  class  registration  procedures , International  TEFL Academy, viewed 19 October 2020, from https:/ /www.internationalteflacademy.com/ registration-procedure-tefl-classes.

Jossberger, H., Brand-Gruwel, S., Boshuizen, H. &amp; Van de Wiel, M., 2010, 'The challenge of selfdirected  and  self-regulated  learning  in  vocational  education:  A  theoretical  analysis  and synthesis  of  requirements', Journal  of  Vocational  Education  and  Training 62(4),  415-440. https:/ /doi.org/10.1080/13636820.2010.523479

Kachru,  B.,  1985,  'Standards,  codification  and  sociolinguistic  realism:  English  language  in  the outer circle', in R. Quirk &amp; H. Widowson (eds.), English in the world: Teaching and learning the language and literatures , pp. 11-36, Cambridge University Press, Cambridge.

Kachru,  B.,  1997,  'World  Englishes  and  English-using  communities', Annual Review of Applied Linguistics 17(1), 66-87. https:/ /doi.org/10.1017/S0267190500003287

Kapp, R. &amp; Arend, M., 2011, 'There's a hippo on my stoep: Constructions of English second language teaching and learners in the new national senior certificate', Per Linguam 27(1), 1-10. https:/ / doi.org/10.5785/27-1-94

Knowles, M.S., 1975, Self-directed learning: A guide for learners and teachers , Association Press, New York, NY.

Kramsch, C., 1993, 'Language study as border study: Experiencing differences', European Journal of Education 28(3), 349-358. https:/ /doi.org/10.2307/1503764

Loughran, J.,  2018, The nature  of  quality  in  teaching  and  learning ,  Monash  University,  viewed 30 September 2020, from https:/ /lens.monash.edu/2018/08/14/1357398/the-nature-ofquality-in-teaching-and-learning#:~:text=Purposefully%20making%20clear%20that%20 which,ascertain%20students'%20understanding%20requires%20the.

McKay, S.L., 2018, 'English as an international language: What it is and what it means for pedagogy', Regional Language Centre Journal 49(1), 9-23. https:/ /doi.org/10.1177/0033688217738817

Mohan, R., 2016, Measurement, evaluation and assessment in education ,  PHI  Learning  Private, New Delhi.

Morris,  T.H.,  2018,  'Vocational  education  of  young  adults  in  England:  A  systemic  analysis  of teaching-learning  transactions  that  facilitate  self-directed  learning', Journal  of  Vocational Education &amp; Training 70(4), 619-643. https:/ /doi.org/10.1080/13636820.2018.1463280

Murthy,  P.K.  &amp;  Ram,  M.V.R.,  2015,  'Integrated  approach  to  English  language  teaching  in  L2 classroom: A conceptual framework', Journal of English Language and Literature 2(4), 101-104.

Mydans, S., 2007, 'Across cultures, English is the word', The New York Times , viewed 07 October 2020, from https:/ /www.nytimes.com/2007/04/09/world/asia/09iht-englede.1.5198685.html.

Paul,  R.  &amp;  Elder,  L.,  2005, A  guide  for  educators  to  critical  thinking  competency  standards: Standards, principles, performance indicators, and outcomes with a critical thinking master rubric , Foundation  for  Critical  Thinking,  viewed  30  September  2020,  from  https:/ /www. criticalthinking.org/resources/PDF/CT-competencies%202005.pdf.

Plonski, P.,  Teferra,  A.  &amp;  Brady,  R.,  2013,  'Why  are  more  African  countries adopting English as an official language?', paper presented at the African Studies Association annual conference, Baltimore, MD, United States of America, 23 November, 2013, pp. 1-26.

Rao, P.S., 2019, 'The role of English as a global language', Research Journal of English 4(1), 65-79.

Reyneke, M., 2016, 'School-based assessment in English language teaching: Weighing the cow will not fatten it', Per Linguam 32(2), 1-14. https:/ /doi.org/10.5785/32-2-624

Romylos, S., Kaiser, K. &amp; Cushman, L., 2020a, ENGV311 literary theories and philosophy for the senior/FET teacher: Study guide , North-West University, Potchefstroom.

Romylos, S., Kaiser, K., Martens, K., Bansen, C. &amp; Annandale, M., 2020b, ENGV321 English for the senior/FET teacher: Understanding text and context in a postmodern era: Study guide , NorthWest University, Potchefstroom.

Schleicher,  A.,  2012, Preparing  teachers  and  developing  school  leaders  for  the  21st  century: Lessons from around the world , OECD, viewed 21 November 2019, from https:/ /www.oecd.org/ site/eduistp2012/49850576.pdf.

Smith,  O.,  2017,  'Mapped:  Where  to  go  if  you  can't  be  bothered  to  learn  the  language', The Telegraph , viewed  21  October  2020,  from  https:/ /www.telegraph.co.uk/travel/maps-andgraphics/mapped-english-speaking-countries.

Soulé, H. &amp; Warrick, T., 2015, 'Defining 21st century readiness for all students: What we know and how to get there', Psychology of Aesthetics, Creativity, and the Arts 9(2), 178-186. https:/ /doi. org/10.1037/aca0000017

Strydom,  M,  2020,  'Developing  a  framework  for  promoting  self-directed  learning  in  first-year English for education', Med dissertation, Faculty of Education, North-West University.

Tadesse, T., Manathunga, C.E. &amp; Gillies, R.M., 2018, 'Making sense of quality teaching and learning in  higher  education in Ethiopia: Unfolding existing realities for future promises', Journal of University Teaching &amp; Learning Practice 15(1), 1-20.

The Economist, 2001, 'The triumph of English: A world empire by other means', The Economist , viewed 07 October 2020, from https:/ /www.economist.com/christmas-specials/2001/12/20/ a-world-empire-by-other-means.

- Uys,  A.H.C.,  Reyneke,  E.M.  &amp;  Kaiser,  K.,  2020, Lesson  planning  and  preparation  -  The  art  of teaching language across the curriculum in multilingual contexts , Axiom Academic Publishers, Potchefstroom.

Van der Walt, C. &amp; Evans, R., 2019 ,  Learn 2 teach - English language teaching in a multilingual context , 5th edn., Van Schaik Publishers, Pretoria.

Violetta-Irene,  K.,  2015,  'The  use  of  literature  in  the  language  classroom:  Methods  and  aims', International  Journal  of  Information  and  Education  Technology 5(1), 74-79.  https:/ /doi. org/10.7763/IJIET.2015.V5.479

Wind, D.K., 2018, 'Building 21st century skills with peer feedback', Peergrade , viewed 01 November 2019, from https:/ /www.peergrade.io/blog/21st-century-skills-with-peer-feedback/.

Winstone, N. &amp; Carless, D., 2020, Designing effective feedback processes in higher education: A learning-focused approach , Routledge, London.

Winterscheid, S.L.,  2016,  'Rubrics:  Effectiveness  of  feedback',  MSc  dissertation,  Missouri  State University.

## Chapter 9

Abdullah,  M.M.B.,  Koren,  S.F.,  Muniapan,  B.,  Parasuraman,  B.  &amp;  Rathakrishnan,  B.,  2008,  'Adult participation in self-directed learning programs', International Education Studies 1(3), 66-72. https:/ /doi.org/10.5539/ies.v1n3p66

Askew, S. &amp; Lodge, C., 2000, 'Gifts, ping-pong and loops - Linking feedback and learning', in S. Askew (ed.), Feedback for learning , 1st edn., pp. 1-17, Routledge, London.

Backes, B. &amp; Cowan, J., 2019, 'Is the pen mightier than the keyboard? The effect of online testing on measured student achievement', Economics of Education Review 68, 89-103. https:/ /doi. org/10.1016/j.econedurev.2018.12.007

Bahari, A., 2020, 'Computer mediated feedback for L2 learners: Challenges versus affordances', -Journal of Computer Assisted Learning 36(5), 1-15. https:/ /doi.org/10.1111/jcal.12481

- Bhagat, K.K. &amp; Spector, J.M., 2017, 'Formative assessment in complex problem-solving domains: The emerging role of assessment technologies', Journal of Educational Technology &amp; Society 20(4), 312-317.

Black, P. &amp; Wiliam, D., 1998, 'Assessment and classroom learning', Assessment in Education 5(1), 7-74. https:/ /doi.org/10.1080/0969595980050102

- Boud, D. &amp; Molloy, E., 2013, 'Rethinking models of feedback for learning: The challenge of design', Assessment &amp; Evaluation in Higher Education 38(6), 698-712. https:/ /doi.org/10.1080/026029 38.2012.691462

Bozkurk, G., 2017, 'Social constructivism: Does it succeed in reconciling individual cognition with social teaching and learning practices', Journal of Education and Practice 8(3), 210-216.

Braun,  V.  &amp;  Clarke,  V.,  2006,  'Using  thematic  analysis  in  psychology', Qualitative  research  in psychology 3(2), 77-101.

Brookfield, S.D., 2009, The power of critical theory: Liberating adult learning and teaching , JosseyBass, San Francisco, CA.

Brookhart, S.M., 2012, 'Preventing feedback fizzle', Educational Leadership 70(1), 24-29.

Candy, P.C., 1991, Self-direction for lifelong learning. A comprehensive guide to theory and practice , Jossey-Bass, San Francisco, CA.

Carless, D., Salter, D., Yang, M. &amp; Lam, J., 2011, 'Developing sustainable feedback practices', Studies in Higher Education 36(4), 395-407. https:/ /doi.org/10.1080/03075071003642449

- Codreanu, A. &amp; Vasilescu, C., 2013, 'E-learning behaviors and their impact on andragogy', in The International Scientific Conference eLearning and Software for Education ,  'Carol  I'  National Defence University, Bucharest, Romania, April 25-26, 2013, pp. 126-137.

Comer, D.R. &amp; Lenaghan, J.A., 2013, 'Enhancing discussions in the asynchronous online classroom: The  lack  of  face-to-face  interaction  does  not  lessen  the  lesson', Journal  of  Management Education 37(2), 261-294. https:/ /doi.org/10.1177/1052562912442384

Creswell, J.W. &amp; Plano Clark, V.L., 2018, Designing and conducting mixed methods research , 3rd edn., Sage, Thousand Oaks, CA.

Dakka, S.M., 2015, 'Using socrative to enhance in-class student engagement and collaboration', International Journal on Integrating Technology in Education 4(3), 13-19. https:/ /doi.org/10.5121/ ijite.2015.4302

- Du,  J., Havard,  B.  &amp;  Li, H., 2005,  'Dynamic  online  discussion:  Task oriented  interaction -for deep learning', Educational Media International 42(3), 207-218. https:/ /doi. org/10.1080/09523980500161221

Dunning,  D.,  Heath,  C.  &amp;  Suls,  J.M.,  2004,  'Flawed  self-assessment:  Implications  for  health, education,  and  the  workplace', Psychological  Science  in  the  Public  Interest 5(3),  69-106. https:/ /doi.org/10.1111/j.1529-1006.2004.00018.x

Earl, L.M., 2013, Assessment as learning , 2nd edn., Corwin, London.

Geitz,  G.,  Brinke,  D.J.  &amp;  Kirschner,  P.A.,  2015,  'Goal  orientation,  deep  learning,  and  sustainable feedback in higher business education', Journal of Teaching in International Business 26(4), 273-292. https:/ /doi.org/10.1080/08975930.2015.1128375

Geduld,  B.,  2014,  'Re-thinking  the  value  of  learning  theories  to  develop  self-directedness  in open-distance students', Journal of Educational and Social Research 4(6), 11-18. https:/ /doi. org/10.5901/jesr.2014.v4n6p11

Goldberg,  A.L.  &amp;  Pedulla,  J.J.,  2002,  'Performance  differences  according  to  test  mode  and computer  familiarity  on  a  practice  graduate  record  exam', Educational  and  Psychological Measurement 62(6), 1053-1067. https:/ /doi.org/10.1177/0013164402238092

Grieve, R., Padgett, C.R. &amp; Moffitt, R.L., 2016, 'Assignments 2.0: The role of social presence and computer attitudes in student preferences for online versus offline marking', Internet and Hi The gher Education 28, 8-16. https:/ /doi.org/10.1016/j.iheduc.2015.08.002

Guglielmino, L.M., 1978, 'Development of the self-directed learning readiness scale', PhD thesis, University of Georgia.

Guglielmino,  L.M.,  2013,  'The  case  for  promoting  self-directed  learning  in  formal  educational institutions', SA-eDUC Journal 10(2), 1-18.

Han, S. &amp; Hill, J.R., 2006, 'Building understanding in asynchronous discussions: Examining types of  online  discourse', Journal  of  Asynchronous  Learning  Networks 10(4),  29-50.  https:/ /doi. org/10.24059/olj.v10i4.1744

Hardiman, M. &amp; Whitman, G., 2014, 'Assessment and the learning brain', Independent School 73(2), 36-41.

Hattie, J., Gan, M. &amp; Brooks, C., 2017, 'Instruction based on feedback', in R.E. Mayer &amp; P.A. Alexander (eds.), Handbook of research on learning and instruction , pp. 290-324, Routledge, London.

Hattie, J. &amp; Timperley, H., 2007, 'The power of feedback', Review of Educational Research 77(1), 81-112. https:/ /doi.org/10.3102/003465430298487

Hay,  D.B.,  2007,  'Using  concept  maps  to  measure  deep,  surface  and  non-learning  outcomes', Studies in Higher Education 32(1), 39-57. https:/ /doi.org/10.1080/03075070601099432

Heinrich, E. &amp; Wang, Y., 2003, 'Online marking of essay-type assignments', paper presented at the World Conference on Educational Multimedia Hypermedia and Telecommunications, Hawaii, AACE Career Center, 15-17 September.

Henderson, M., Ajjawi, R., Boud, D. &amp; Molloy, E. (eds.), 2019, The impact of feedback in higher education: Improving assessment outcomes for learners , Palgrave Macmillan, Cham.

Hewson,  C.,  2012,  'Can  online  course based  assessment  methods  be  fair  and  equitable? -Relationships  between  students'  preferences  and  performance  within  online  and  offline assessments', Journal of Computer Assisted Learning 28(5), 488-498. https:/ /doi.org/10.1111/ j.1365-2729.2011.00473.x

Hounsell,  D.,  2006,  'Towards  more  sustainable  feedback  to  students',  paper  presented  at  the Northumbria EARLI SIG Assessment Conference, Darlington, 29th August - 1st September.

Ilgen, D.R., Fisher, C.D. &amp; Taylor, M.S., 1979, 'Consequences of individual feedback on behavior in organisations', Journal  of  Applied  Psychology 64(4),  349-371.  https:/ /doi.org/10.1037/00219010.64.4.349

- James,  M.,  2008,  'Assessment  and  learning',  in  S.  Swaffield  (ed.), Unlocking  assessment: Understanding for reflection and application , pp. 20-35, Routledge, Abingdon.

Karay, Y., Schauber, S.K., Stosch, C. &amp; Schüttpelz-Brauns, K., 2015, 'Computer versus paper - Does it make any difference in test performance?', Teaching and Learning in Medicine 27(1), 57-62. https:/ /doi.org/10.1080/10401334.2014.979175

King,  C.,  2011,  'Fostering  self-directed  learning  through  guided  tasks  and  learner  reflection', Studies in Self-Access Learning Journal 2(4), 257-267. https:/ /doi.org/10.37237/020403

Knowles, M.S., 1975, Self-directed learning: A guide for learners and teachers , Association Press, New York, NY.

- Kruger, J. &amp; Dunning, D., 1999, 'Unskilled and unaware of it: How difficulties in recognising one's own  incompetence  lead  to  inflated  self-assessments', Journal  of  Personality  and  Social Psychology 77(6), 1121-1134. https:/ /doi.org/10.1037/0022-3514.77.6.1121

Louws, M.L., Meirink, J.A., Van Veen, K. &amp; Van Driel, J.H., 2017, 'Teachers' self-directed learning and teaching experience: What, how, and why teachers want to learn', Teaching and Teacher Education Journal 66(1), 171-183. https:/ /doi.org/10.1016/j.tate.2017.04.004

Manning, G., 2007, 'Self-directed learning: A key component of adult learning theory', Business and Public Administration Studies 2(2), 104-115.

Masie, E., 2002, 'Blended learning: The magic is in the mix', in A. Rossett (ed.), The ASTD E-Learning Handbook , pp. 58-63, McGraw-Hill, New York, NY.

Mattar,  J.,  2018,  'Constructivism  and  connectivism  in  education  technology:  Active,  situated, authentic,  experiential,  and  anchored  learning', Revista  Iberoamericana  de  Educación  a Distancia 21(2), 201-217. https:/ /doi.org/10.5944/ried.21.2.20055

Mezirow,  J.,  1985,  'A  critical  theory  of  self-directed  learning', New  Directions  for  Continuing Education 25, 17-30. https:/ /doi.org/10.1002/ace.36719852504

Mishra, P., Fahnoe, C., Henriksen, D. &amp; Deep-Play Research Group, 2013, 'Creativity, self-directed learning and the architecture of technology rich environments', TechTrends 57(1), 10-13. https:/ / doi.org/10.1007/s11528-012-0623-z

Molloy, E. &amp; Boud, D., 2013, 'Changing conceptions of feedback', in E. Molloy &amp; D. Boud (eds.), Feedback in higher and professional education: Understanding it and doing it well , pp. 11-33, Routledge, London.

Nicol,  D.,  2010,  'From  monologue  to  dialogue:  Improving  written  feedback  processes  in  mass higher education', Assessment &amp; Evaluation in Higher Education 35(5),  501-517.  https:/ /doi. org/10.1080/02602931003786559

Nicol,  D.J.  &amp;  Macfarlane Dick,  D.,  2006,  'Formative  assessment  and  self regulated  learning:  A --model and seven principles of good feedback practice', Studies in Higher Education 31(2), 199-218. https:/ /doi.org/10.1080/03075070600572090

- Osman,  G.  &amp;  Herring,  S.C.,  2007,  'Interaction,  facilitation,  and  deep  learning  in  cross-cultural chat: A case study', The Internet and Higher Education 10(2), 125-141. https:/ /doi.org/10.1016/j. iheduc.2007.03.004

Pegrum, M., Bartle, E. &amp; Longnecker, N., 2015, 'Can creative podcasting promote deep learning? The use of podcasting for learning content in an undergraduate science unit', British Journal of Educational Technology 46(1), 142-152. https:/ /doi.org/10.1111/bjet.12133

Peterson,  E.R.  &amp;  Irving,  S.E.,  2008,  'Secondary  school  students'  conceptions  of  assessment and feedback', Learning and Instruction 18(3), 238-250. https:/ /doi.org/10.1016/j. learninstruc.2007.05.001

Petersen, N.T. &amp; Mentz, E., 2016, 'The influence of cooperative learning methods on second year tertiary student-teachers' levels of self-directedness in learning', in M.A. Mokoena &amp; I. Oosthuizen (eds.),

A kaleidoscope of advances in modern day education, pp. 41-63, Ivyline Academic Publishers, Potchefstroom.

Pietroni, D. &amp; Hughes, S.V., 2016, 'Nudge to the future: Capitalising on illusory superiority bias to mitigate temporal discounting', Mind &amp; Society: Cognitive Studies in Economics and Social Sciences 15(2), 247-264. https:/ /doi.org/10.1007/s11299-016-0193-4

Planar, D. &amp; Moya, S., 2016, 'The effectiveness of instructor personalised and formative feedback provided by instructor  in  an  online  setting:  Some  unresolved  issues', Electronic  Journal  of E-Learning 14(3), 196-203.

Robertson,  S.N.,  Humphrey,  S.M.  &amp;  Steele,  J.P.,  2019,  'Using  technology  tools  for  formative assessments', Journal of Educators Online 16(2), n.p.

Rogers, A., 2004, 'EFA and adult learning', Convergence 37(3), 3-13.

Romero-Ivanova, C., Shaughnessy, M., Otto, L., Taylor, E. &amp; Watson, E., 2020, 'Digital practices &amp;  applications  in  a  COVID-19  culture', Higher  Education  Studies 10(3),  80-87.  https:/ /doi. org/10.5539/hes.v10n3p80

Rosenberg, M.J. &amp; Foshay, R., 2002, 'E learning: Strategies for delivering knowledge in the digital -age', Performance Improvement 41(5), 50-51. https:/ /doi.org/10.1002/pfi.4140410512

Sadler, D.R., 2010, 'Beyond feedback: Developing student capability in complex appraisal', Assessment  &amp;  Evaluation in Higher Education 35(5), 535-550. https:/ /doi. org/10.1080/02602930903541015

Sadler,  D.R.,  2013,  'Opening  up  feedback',  in  S.  Merry,  M.  Price,  D.  Carless  &amp;  M.  Taras  (eds.), Reconceptualising feedback in higher education: Developing dialogue with students ,  pp. 54-63, Routledge, London.

Shabani, K., Khatib, M. &amp; Ebadi, S., 2010, 'Vygotsky's zone of proximal development: Instructional implications  and  teachers'  professional  development', English  Language  Teaching 3(4), 237-248. https:/ /doi.org/10.5539/elt.v3n4p237

Shahabadi,  M.M.  &amp;  Uplane,  M.,  2015,  'Synchronous  and  asynchronous  e-learning  styles  and academic  performance  of  e-learners', Procedia-Social  and  Behavioral  Sciences 176(20), 129-138. https:/ /doi.org/10.1016/j.sbspro.2015.01.453

Simms, L.J., Zelazny, K., Williams, T.F. &amp; Bernstein, L., 2019, 'Does the number of response options matter?  Psychometric  perspectives  using  personality  questionnaire  data', Psychological Assessment 31(4), 557. https:/ /doi.org/10.1037/pas0000648

Spector,  J.M.  &amp;  Yuen,  H.K.,  2016, Educational  technology  program  and  project  evaluation , Routledge, New York, NY.

Subandi,  S.,  Choirudin,  C.,  Mahmudi,  M.,  Nizaruddin,  N.,  Hermanita,  H.  &amp;  Hermanita,  H.,  2018, 'Building interactive communication  with Google classroom', International Journal of Engineering &amp; Technology 7(2.13), 460-463. https:/ /doi.org/10.14419/ijet.v7i2.13.18141

Taber, K.S., 2018, 'The use of Cronbach's alpha when developing and reporting research instruments in science education', Research in Science Education 48(6), 1273-1296. https:/ /doi.org/10.1007/ s11165-016-9602-2

Torrance, H., 1993, 'Formative assessment: Some theoretical problems and empirical questions', Cambridge Journal of Education 23(3), 333-343. https:/ /doi.org/10.1080/0305764930230310

Tough, A., 1978, 'Major learning efforts: Recent research and future directions', Adult Education 28(4), 250-263. https:/ /doi.org/10.1177/074171367802800403

Williamson,  S.N.,  2007,  'Development  of  a  self-rating  scale  of  self-directed  learning', Nurse Researcher 14(2), 66-83. https:/ /doi.org/10.7748/nr2007.01.14.2.66.c6022

Zenger, J. &amp; Uehlein, C., 2001, 'Why blended will win', Training &amp; Development 55(8), 54-62.

Zhang, W., Wang, Y., Yang, L. &amp; Wang, C., 2020, 'Suspending classes without stopping learning: China's education emergency management policy in the COVID-19 outbreak', Journal of Risk and Financial Management 13(3), 55. https:/ /doi.org/10.3390/jrfm13030055

Zhou, J., Yang, J., Song, H., Ahmed, S.H., Mehmood, A. &amp; Lv, H., 2016, 'An online marking system conducive to learning', Journal of Intelligent &amp; Fuzzy Systems 31(5),  2463-2471. https:/ /doi. org/10.3233/JIFS-169088

## Chapter 10

Atjonen,  P.,  2014,  'Teachers'  views  of  their  assessment  practice', Curriculum  Journal 25(2), 238-259. https:/ /doi.org/10.1080/09585176.2013.874952

Barnes, N., Fives, H. &amp; Dacey, C.M. (eds.), 2015, Teachers' beliefs about assessment: International handbook of research on teachers' beliefs , pp. 284-300, Routledge Publishers, New York, NY.

Belo, N.A., Van Driel, J.H., Van Veen, K. &amp; Verloop, N., 2014, 'Beyond the dichotomy of teacherversus student-focused education: A survey study on physics teachers' beliefs about the goals and pedagogy of physics education', Teaching and Teacher Education 39, 89-101. https:/ /doi. org/10.1016/j.tate.2013.12.008

Bliem, C.L. &amp; Davinroy, K., 1997, Teachers' beliefs about assessment and instruction in literacy: National Centre for Research on Evaluation, Standards, and Student Testing (CRESST) , pp. 1-39, Graduate School of Education &amp; Information Studies, University of California, Los Angeles, CA.

Bourke, R., Mentis, M. &amp; O'Neill, J., 2013, 'Using activity theory to evaluate a professional learning and development initiative in the use of narrative assessment', Cambridge Journal of Education 43(1), 35-50. https:/ /doi.org/10.1080/0305764X.2012.749214

Brown, G.T.L., 2002, 'Teachers' conceptions of assessment', PhD thesis, University of Auckland.

Brown, G.T.L., 2004, 'Teachers' conceptions of assessment: Implications for policy and professional development', Assessment in Education: Principles, Policy &amp; Practice 11(3), 301-318. https:/ /doi. org/10.1080/0969594042000304609

Brown, G.T.L., 2006, 'Teachers' conceptions of assessment: Validation of an abridged version', Psychological reports 99(1), 166-170. https:/ /doi.org/10.2466/pr0.99.1.166-170

Brown G.T.L., 2016, 'Improvement and accountability functions of assessment: Impact on teachers' thinking and action', in M. Peters (ed.), Encyclopedia of educational philosophy and theory , pp. 1-6, Springer, Singapore. https:/ /doi.org/10.1007/978-981-287-532-7\_391-2

Bryan, L.A. &amp; Atwater, M.M., 2002, 'Teacher beliefs and cultural models: A challenge for science teacher  preparation  programs', Science  Education 86(6),  821-839.  https:/ /doi.org/10.1002/ sce.10043

Calveric,  S.,  2010,  'Elementary  teachers'  assessment  beliefs  and  practices',  PhD  thesis,  VCU, Richmond, VA.

- Carless,  D.,  2015, Excellence  in  university  assessment:  Learning  from  award-winning  teaching , Routledge, Abington, PA.

Cauley,  K.M.  &amp;  McMillan,  J.H.,  2010,  'Formative  assessment  techniques  to  support  student motivation and achievement', The Clearing House: A Journal of Educational Strategies, Issues and Ideas 83(1), 1-6. https:/ /doi.org/10.1080/00098650903267784

Creswell, J.W., Hanson, W.E., Clark Plano, V.L. &amp; Morales, A., 2007, 'Qualitative research designs: Selection  and  implementation', The  Counselling  Psychologist 35(2),  236-264.  https:/ /doi. org/10.1177/0011000006287390

- Daniels,  L.M.  &amp;  Poth,  C.A.,  2017,  'Relationships  between  pre-service  teachers'  conceptions of  assessment,  approaches  to  instruction,  and  assessment:  An  achievement  goal  theory perspective', Educational Psychology 37(7), 835-853. https:/ /doi.org/10.1080/01443410.2017. 1293800

Dayal, H.C. &amp; Lingam, G.I., 2015, 'Fijian teachers' conceptions of assessment', Australian Journal of Teacher Education 40(8), 1-17.

Demetriou,  C.,  2011,  'The  attribution  theory  of  learning  and  advising  students  on  academic probation', NACADA Journal 31(2), 16-21. https:/ /doi.org/10.12930/0271-9517-31.2.16

De Vries, S., Van de Grift, W.J. &amp; Jansen, E.P., 2014, 'How teachers' beliefs about learning and teaching relate to their continuing professional development', Teachers and Teaching 20(3), 338-357. https:/ /doi.org/10.1080/13540602.2013.848521

Engeström,  Y.,  2001,  'Expansive  learning  at  work:  Toward  an  activity  theoretical  reconceptualization', Journal of Education and Work 14(1), 133-156. https:/ /doi.org/10.1080/13639080020028747

Engeström, Y., 2009, 'From learning environments and implementation to activity systems and expansive learning', Actio: An International Journal of Human Activity Theory 2(1), 17-33.

Garrison,  D.R.,  1997,  'Self-directed  learning:  Toward  a  comprehensive  model', Adult  Education Quarterly 48(1), 18-33. https:/ /doi.org/10.1177/074171369704800103

Greenhow, C. &amp; Belbas, B., 2007, 'Using activity-oriented design methods to study collaborative knowledge-building in e-learning courses within higher education', International  Journal  of Computer-Supported  Collaborative  Learning 2(4),  363-391.  https:/ /doi.org/10.1007/s11412007-9023-3

- Hiemstra, R. &amp; Brockett, R.G., 2012, 'Reframing the meaning of self-directed learning: An updated model', Paper presented at the Adult Education Research Conference, Saratoga Springs, NY.
- Hunter,  M.  &amp;  Barker,  G.,  1987,  'If  at  first  …  attribution  theory  in  the  classroom', Educational Leadership 45(2), 50-53.
- Jane, S.M., 2013, 'A vision of improvement of learning: South African teachers' conceptions of classroom assessment', Perspectives in Education 31(2), 14-21.

Kamanga, E.H., 2020, 'The influence of Natural Sciences teachers' assessment beliefs on grade 9 learners' self-directed learning behaviour', MEd dissertation, North-West University.

Long, H.B., 1989, 'Self-directed learning: Emerging theory and practice', in H.B. Long &amp; Associates (eds.), Self-directed learning:  Emerging  theory  and  practice ,  pp.  1-11, Oklahoma  Research Centre  for  Continuing  Professional  and  Higher  Education  of  the  University  of  Oklahoma, Norman, OK.

Long, H.B., 2000, 'Understanding self-direction in learning', in H.B. Long (ed.), Practice &amp; theory in self-directed learning , pp. 11-24, Motorola University Press, Schaumburg, IL.

- Loyens, S.M., Magda, J. &amp; Rikers, R.M., 2008, 'Self-directed learning in problem-based learning and its relationships with self-regulated learning', Educational Psychology Review 20(4), 411-427. https:/ /doi.org/10.1007/s10648-008-9082-7
- Luft,  J.A.  &amp;  Roehrig,  G.H.,  2007,  'Capturing  science  teachers'  epistemological  beliefs:  The development of the teacher beliefs interview', The Electronic Journal for Research in Science &amp; Mathematics Education 11(2), 38-60.
- McMillan, J.H. &amp; Hearn, J., 2008, 'Student self-assessment: The key to stronger student motivation and higher achievement', Educational Horizons 87(1), 40-49.

Mentz, E. &amp; De Beer, J., 2017, 'The affordances of cultural-historical activity theory as a research lens in studying education from a socio-economic perspective', in Proceedings of Teaching and  Education  Conferences (No.  4907704),  International  Institute  of  Social  and  Economic Sciences, Venice, Italy, May 2017, pp. 88-103.

Mumm, K., Karm, M. &amp; Remmik, M., 2016, 'Assessment for learning: Why assessment does not always support student teachers' learning', Journal of Further and Higher Education 40(6), 780-803. https:/ /doi.org/10.1080/0309877X.2015.1062847

Murphy,  E.  &amp;  Rodriguez-Manzanares,  M.A.,  2008,  'Using  activity  theory  and  its  principle  of contradictions to guide research in educational technology', Australasian Journal of Educational Technology 24(4), 442-457. https:/ /doi.org/10.14742/ajet.1203

Nespor, J., 1987, 'The role of beliefs in the practice of teaching', Journal of Curriculum Studies 19(4), 317-328. https:/ /doi.org/10.1080/0022027870190403

Nieuwenhuis,  J.,  2016,  'Analysing  qualitative  data',  in  K.  Maree  (ed.), First  steps  in  research , 4th edn., pp. 104-131, Van Schaik Publishers, Pretoria.

Northcote, M., 2009, 'Educational beliefs of higher education teachers and students: Implications for  teacher  education', Australian  Journal  of  Teacher  Education 34(3),  69-81.  https:/ /doi. org/10.14221/ajte.2009v34n3.3

Nussbaumer, D., 2012, 'An overview of cultural historical activity theory (CHAT) use in classroom research 2000 to 2009', Educational Review 64(1), 37-55. https:/ /doi.org/10.1080/00131911.2 011.553947

- Opre, D., 2015, 'Teachers' conceptions of assessment', Procedia-Social and Behavioural Sciences 209, 229-233.

Rawlusyk, P.E., 2018, 'Assessment in higher education and student learning', Journal of Instructional Pedagogies 21, 1-34.

Remesal, A., 2011, 'Primary and secondary teachers' conceptions of assessment: A qualitative study', Teaching and Teacher Education 27(2), 472-482. https:/ /doi.org/10.1016/j.tate.2010.09.017

Roth, W.M. &amp; Lee, Y.J., 2007, ''Vygotsky's neglected legacy': Cultural-historical activity theory', Review of Educational Research 77(2), 186-232. https:/ /doi.org/10.3102/0034654306298273

Rotherham, A.J. &amp; Willingham, D.T., 2010, '21st century skills: Not new, but a worthy challenge', American Educator 17(1), 17-20.

- Saks, K. &amp; Leijen, Ä., 2014, 'Distinguishing self-directed and self-regulated learning and measuring them in the e-learning context', Procedia-Social and Behavioural Sciences 112, 190-198. https:/ / doi.org/10.1016/j.sbspro.2014.01.1155
- Schunk, D.H., 2012, Learning theories an educational perspective ,  6th edn., pp. 1-550, Pearson, Boston, MA.
- South  African  Department  of  Education,  2011, Curriculum  and  assessment  policy  statement grades 7-9: Natural Sciences , pp. 1-90, Goverment printing works, Pretoria.
- Taylor,  A.,  2014,  'Community  service-learning  and  cultural-historical  activity  theory', Canadian Journal of Higher Education 44(1), 95-107. https:/ /doi.org/10.47678/cjhe.v44i1.183605
- Vandeyar, S. &amp; Killen, R., 2007, 'Educators' conceptions and practice of classroom assessments in post-apartheid South Africa', South African Journal of Education 27(1), 101-115.

Vygotsky, L.S., 1978, Mind in society: The development of higher psychological processes , pp. 1-159, Harvard University Press, Cambridge, MA.

- Wallace, C.S. &amp; Priestley, M., 2011, 'Teacher beliefs and the mediation of curriculum in Scotland: A socio-cultural perspective on professional development and change', Journal of Curriculum Studies 43(3), 357-381. https:/ /doi.org/10.1080/00220272.2011.563447
- Weiner, B., 2000, 'Intrapersonal and interpersonal theories of motivation from an attributional perspective', EducationalPsychology  Review 12(1),  1-14.  https:/ /doi.org/10.1023/A:1009017532121

## Index

## #

21 st -century skills, 215

## A

| African context, 33, 57, 62, 169, 204 assessment as learning, 6, 31, 55, 85, 198-199 assessment belief, 220, 224-225, 230,  238-239, 249   |
|--------------------------------------------------------------------------------------------------------------------------------------------|
| assessment feedback, 15, 24, 60, 104, 143-145,  147-150, 153-159, 161-163                                                                  |
| assessment for learning, 4, 6, 32, 55, 85,  198-199                                                                                        |
| assessment literacy, 1-2, 4, 6, 8, 10, 12, 14-20,  22, 24, 34, 56, 60, 65-66, 128-130,                                                     |
| 136, 170 assessment, 1-25, 27-40, 42-43, 45-49,                                                                                            |
| 51-69, 71-74, 76, 78, 80, 82-90, 92,  94-97, 99, 102-121, 123-136, 138-163,                                                                |
| 165-166, 168-174, 176-185, 187-191,                                                                                                        |
| 193-204, 206, 210-211, 213-215, 217-246,                                                                                                   |
| 248-250                                                                                                                                    |
| axiologolects, 27-30, 32-34, 36, 38, 40,  42-49                                                                                            |

## B

belief, 19, 103, 138, 218, 220-222, 224-225, 230, 237-243, 249-250

## C

| cooperative learning, 23, 67, 81, 134, 143-145,   |
|---------------------------------------------------|
| Cultural-Historical Activity Theory (CHAT),       |

## D

| database design, 116                        |
|---------------------------------------------|
| digital learning, 68, 190, 193-194, 197-198 |

## E

| English for Education, 166, 170-171, 173,                        |
|------------------------------------------------------------------|
| epistemological tool, 123-128, 130, 132, 134,  136-138, 140, 142 |

## F

feedback, 3, 5-10, 14-18, 20-24, 29, 31-32, 34, 46, 55, 60, 68, 86, 95-96, 100, 102-108, 111, 113, 116, 119-120, 130, 133-134, 140, 143-163, 176-180, 184-185, 188-190, 192, 195, 197-215, 220-221, 223, 230, 237, 240, 242

formative assessment, 5-8, 31, 52, 59, 87, 114, 121, 134, 188-190, 197-198, 200, 213, 215, 221, 223, 240, 244

## I

| interaction, 23, 63, 68, 94-95, 100-101, 110,       |
|-----------------------------------------------------|
| 114, 121, 131, 137-138, 146, 149, 151-153,          |
| 156-158, 160, 175, 178, 190-191, 194, 199,          |
| 206, 209, 211, 214, 222, 243                        |
| ipsative assessment, 99, 102-105, 107-109,  113-120 |

## K

knowledge surveys, 4

## L

| language of assessment, 28-29, 33                                              |
|--------------------------------------------------------------------------------|
| learning environment, 9, 18-19, 27, 108, 110,  148-150, 157, 192, 221, 246-247 |
| learning environments, 48, 74, 108, 134-135,  195, 245, 247                    |
| learning, 1-25, 27-34, 36, 38-41, 45-49,                                       |
| 51-55, 57-65, 67-69, 71-97, 99-108,                                            |
| 110-116, 118, 120-121, 123-141, 143-163,                                       |
| 165-166, 168-185, 187-215, 217-236,                                            |
| 238-250                                                                        |
| learning-oriented assessment, 1-6, 8-10, 12-14,  16, 18, 20, 22, 24, 27, 54    |

## M

| mathematics, 114                                                 |
|------------------------------------------------------------------|
| metacognition, 6-7, 9-10, 13, 21, 23, 31, 55,                    |
| 59, 68, 72, 74, 76, 82, 85-87, 90, 93,                           |
| 100, 124-125, 127-128, 130, 133, 135-136,                        |
| 140, 142                                                         |
| metacognitive awareness, 55, 123-128,  130-142                   |
| metacognitive regulation, 130, 132, 137, 139 metaliteracy, 71-97 |
| multimodal assessment, 51-54, 56-60, 62-66,  68-69               |
| multimodal learning, 27-28, 40, 52, 55, 57-60,  63-64, 69        |
| multimodality, 41, 52-53, 55, 57-58, 60,  62-64, 68-69           |

## O

| online learning, 5, 83, 100-101, 176, 189,                     |
|----------------------------------------------------------------|
| 193-194, 196, 201, 206, 209, 211, 214                          |
| online tutoring, 99-102, 104, 106, 108, 110,  112-116, 118-120 |

open educational resources, 72 ownership, 6, 14, 39, 90, 105, 107, 239

## P

problem-based learning, 86, 124 problem-solving, 104, 126, 139, 151, 166, 173, 176-177, 181, 218, 230

## Q

quality assessment, 16, 59, 166, 176-178, 180, 183-185

## R

readability, 34-35, 37-38, 43-47, 49 reflective thinking, 90, 191

## S

science education, 58, 158, 218 self-assessment, 3, 5, 7, 9-10, 15, 18, 20-24, 31-32, 43, 46, 68, 74, 82, 95, 105-107, 130, 132, 148, 159, 191, 199, 206, 211, 235, 244 self-directed learning behaviour, 220, 226, 231 self-directed learning (SDL), 1-4, 6, 8-14, 16, 19-25, 27-32, 37, 39, 42-43, 45-49, 51-52, 54-55, 57, 59, 62, 65, 67, 69, 71-77, 78, 80-97, 99-102, 104-105, 106, 108, 110, 112, 114, 116, 118, 120, 121, 123-125, 127-128, 132-134, 136, 138, 139, 140-143, 165-166, 168, 170-171, 172-174, 175-179, 180, 182, 184-185, 187-195, 196-200, 202, 204-206, 208, 210-215, 217-220, 222-228, 230-232, 234, 236-240, 242-250 self-directed learning-oriented assessment, 1-4,

6, 8-10, 12-14, 16, 18, 20, 22, 24, 27, 54 self-directed multimodal assessment, 51-52, 54, 56, 58, 60, 62-66, 68-69 self-directed multimodal learning, 28, 40

| self-directedness, 11, 19, 52-54, 60, 65, 68, 133,  176, 185, 190, 192-193, 210, 214   |
|----------------------------------------------------------------------------------------|
| self-regulated learning, 11, 13 self-sovereign identity, 194-195, 199-208              |
| SETAs, 181-182, 188, 191                                                               |
| situated learning, 27-32, 38, 45-46, 48-49                                             |
| Siyavuna Development Centre, 57, 70-71 soft skills, 134, 137, 143, 187                 |
| strategic intelligence model, 128                                                      |
| sustainable assessment, 144-148, 150,                                                  |
| 153-157, 163                                                                           |
| sustainable cities index, 6                                                            |
| Sustainable Development Goals, 5                                                       |

## T

technology, 5, 16, 22, 97, 107-109, 111, 113-114, 118-119, 121, 124, 127, 129-130, 132-137, 139-143, 146, 155-156, 158, 161-166, 168-169, 171-172, 175, 178, 180, 184-185, 196, 200, 203, 206-208, 211, 221-223, 228-229, 241, 244, 246 tourism, 54, 67, 81, 96-97 transformation, 39, 68, 108, 114, 131, 139, 147, 158, 168-169, 178, 189, 228, 234, 248-249 Triple Helix, 226, 228

## U

| Ubuntu, 54                                         |
|----------------------------------------------------|
| Umhlosinga Development Agency, 57,  66-68, 73      |
| UNESCO Cork Call to Action on Learning  Cities, 10 |

## W

World Economic Forum (WEF), 108, 114, 128-129, 133-134, 137, 139-142, 168-170, 172-173, 175, 177-179, 185, 189 World Happiness Report, 8

This book aims to contribute to the discourse of learning through assessment within a self-directed learning environment. It adds to the scholarship of assessment and selfdirected learning within a face-to-face and online learning environment. As part of the NWU Self-Directed Learning Book Series, this book is devoted to scholarship in the field of self-directed learning, focusing on ongoing and envisaged assessment practices for self-directed learning through which learning within the 21st century can take place. This book acknowledges and emphasises the role of assessment as a pedagogical tool to foster self-directed learning during face-to-face and online learning situations. Now more than ever, we need learners to be self-directed in their learning. Assessment plays a key role in learning and, therefore, we have to identify innovative ways in which learning can be assessed and which are likely to become the new norm even after the current  global  pandemic  has  been  brought  under  control.  The  goal  of  this  book, consisting of original research, is to assist with the paradigm shift regarding the purpose of assessment, as well as providing new ideas on assessment strategies, methods and tools appropriate to foster self-directed learning in all modes of delivery. Although all the chapters focus on assessment within a self-directed learning environment, different foci in each chapter contribute to the rich knowledge bank in this field. The target audience of the book includes academics and researchers in the field of self-directed learning in the education landscape.

The strength of this volume is the diversity of methodologies and points of emphasis/ exploration brought to bear on the connection between self-directed learning and assessment. Not only is self-directed learning (in formal institutions) an underexplored area of research, but the role assessment plays (or can play) in the process is also often overlooked. This collection offers researchers a diverse set of interesting explorations in this area.

Prof. Kevin Currie-Knight, Department of Special Education, Foundations, and Research, College of Education, East Carolina University, Greenville, NC, United States of America

<!-- image -->

<!-- image -->

<!-- image -->