SELF-ASSESSMENT: A LEARNER-CENTRED APPROACH TOWARDS TRANSFORMING TRADITIONAL PRACTICES AND BUILDING SELF- DIRECTED LEARNERS 

**Z. C. Sosibo**  

Senior Phase and Further Education and Training Department Cape Peninsula University of Technology 

Cape Town, South Africa 
### e-mail: SosiboL@cput.ac.za 
ABSTRACT 

During this learner-centred teaching and learning era, self-assessments may be a viable tool to enable university students to become autonomous and self-directed learners. Sadly, students rarely obtain self-assessment opportunities. This action research investigated student teachers’ self-assessment experiences, in order to establish how self-assessments contributed to self- directed  learning.  The  research  question  was  “What  are  students’  experiences  of  self- assessments?” Answers about SDL were embedded in students’ responses. Qualitative data were collected through interviews and quantitative data were obtained from students’ self-assessment and lecturer’s scores. Qualitative data analysis was done through coding and emergent themes, whereas quantitative data were analysed statistically and presented in descriptive statistics, bar graphs and scatterplots. Andragogy and constructivism informed this study. Although qualitative results revealed that students had attained some SDL skills, quantitative results showed that the students were still far from attaining these skills, as indicated by low correlations and a wide range between students’ and lecture’s scores. The researcher recommended that lecturers increase self- assessment opportunities for students; integrate self-assessments across different courses and adopt student-centred assessment approaches. 

**Keywords:**  self-assessment,  self-directed  learning,  autonomy,  andragogy,  learner-centred, student teachers 

**INTRODUCTION** 

Assessment in higher education is high on the agenda, mainly due to the students’ general dissatisfaction with assessment and feedback (Henderson, Ryan and Phillips 2019; Ferrell and Gray 2016; Office of the Independent Adjudicator ... (OIA) 2015; Nicol 2010). Ryan and Henderson (2018) maintain that students are more likely than not to reject or ignore feedback if it evokes negative emotional responses. Part of their dissatisfaction is that students seldom, if ever, participate in assessments, because assessment is still untransformed and teacher- centred.  

South African Journal of Higher Education     http://dx.doi.org/10.20853/33-5-3586** 

Volume 33 | Number 5 | 2019 | pages 76‒97     eISSN 1753-5913** 76

Sosibo  Self-assessment: a learner-centred approach towards transforming traditional practices 

Existing research reveals that assessment is an area of the curriculum that is incredible difficult to change (Bloxham 2016a; 2016b; Grant-Smith, Cathcart and Williams 2015). This situation persists in spite of the claims that curriculum has become learner-centred (Cardoso 2010). Lester (1998, 1) notes that even though it is widely accepted that students should manage their own learning, this is seldom the case with assessments. Indeed, assessments are still under the tight grip of the most-knowledgeable teacher. Scholtz (2016, 4), referring to assessment as “a patent site of hegemony”, puts it succinctly when she argues that lecturers control every aspect of assessment, for example, the assessment format, when assessment (should) take place, which aspects are (to be) assessed, and how marks or scores are (to be) distributed. Scholtz believes that lecturers’ control over assessment does not help students but is in fact a big disadvantage in terms of their growth and development. 

Ferrell and Gray (2016) and the OIA (2015) advocate that change in assessment and feedback are both desirable and necessary. This simply means that new forms of assessment need to replace the old ones. Echoing this sentiment, Lundie (2017) claims that to attain equilibrium between teacher-centred and student-centred teaching-and-learning, assessment approaches need to be revisited and be made inclusive. Commenting on the importance of the shift from traditional and teacher-centred assessment approaches and how sustainable teaching and learning can be achieved in Geography, Beets (2007, 579) asserts that,  

“In order to ensure quality tuition/training in Geography in higher education, we are left with no other  responsible  response  than  to  move  this  debate  beyond  merely  advocating  assessment processes that are safe and predictable, that are fixed and non-negotiable, and framed in a teacher- centred approach.” 

The  prevailing  conservative  attitudes  towards  assessment  are  troubling,  especially  when consideration  is  made  that  university  students  should  be  self-directed  learners  who are responsible for their learning and development. Clearly, if they are not provided with self- directed learning (SDL) opportunities in the form of self-assessments, students may not reach optimal development to take accountability for their learning and to become self-directed, autonomous, self-regulated and independent students. Growth in the interest in learner-centred teaching, coupled with the fact that university students are not children, puts pressure on universities to allow students to engage optimally in curriculum activities, part of which are assessments.  

Literature illustrates that students’ participation in assessments enhances learning (Ryan and Henderson 2018; Gehringer 2017; Nathan 2017; Deehan 2016; Ferrell and Gray 2016; Sharma et al. 2016; Boud 2003). Other literature claims that self-assessment scaffolds the 

development of independent learning (Beaumont, O’Doherty and Shannon 2011), and increases students’ consciousness about the value of their work (Andrade 2010), resulting in improved outcomes (Butler 2011). When students participate in assessments, they are not told what is wrong  or  how  to  fix  it.  Instead,  they  become  active  co-creators  and  co-constructors  of knowledge  in  line  with  Vygotsky’s  (1978)  constructivist  approach  to  learning.  Active engagement in learning invariably promotes students’ independence, autonomy, responsibility and control over their learning, all of which are ingredients of SDL. Du (2013) cites the benefits of SDL: that it offers an opportunity to attain autonomy, competence and relatedness, and self- determination; and that it promotes individual choice and responsibility.  

In this article, it is argued that self-assessment can be used as a learner-centred approach to replace outmoded, teacher-centred assessments and promote students’ self-directed learning. This article shares results of a study in which students assessed their own work. The purpose was  to  investigate  students’  self-assessment  experiences,  the  objective  being  to  establish whether self-assessments contributed to students’ SDL. The research question was: What are students’ experiences of self-assessments? The variable of SDL was embedded in the students’ responses to this question, because participants had not been taught about SDL. Before the study commenced, students underwent training on assessments as part of their Education 4 requirements.  This  training  was  important,  because  students  had  never  conducted  self- assessments before. The students’ only exposure to assessments was when they practised teaching in schools.  

The researcher does not make a claim that self-assessment is a panacea to all problems related to assessment in higher education. Neither does she propose that self-assessment should be adopted as the sole approach to assessing students’ work. She does, however, suggest that self-assessment should be incorporated into the university curriculum in order to equip students with the skills of managing their learning. The results of this study will, hopefully, appeal to both South African and international scholars, as assessment seems to be intrinsic in global higher education discourses. Literature on assessments is growing in South Africa. Scholars are beginning to argue for constructivist and learner-centred assessment approaches that place students at the centre of the teaching, learning and assessment processes (Westraadt 2017; Scholtz 2016) and promote SDL. Results of this study will potentially extend north-south engagements on assessments in higher education, which will, hopefully, assist with adding or creating new knowledge in this area. In the context of South Africa, results of this study will, likely, influence university policy-makers, especially as it pertains to how they formulate assessment policies to include constructivist approaches and promote SDL in the university curriculum.  

**FOUNDATIONS OF ANDRAGOGY AND CONSTRUCTIVISM** 

The principles of andragogy and constructivism undergird this article. According to Knowles (1975), andragogy is about how adults learn. Knowles suggests that unlike children, adult learners are intrinsically motivated; bring vast experiences and knowledge to the learning situation; are goal and practical oriented; prefer to learn material that is relevant to their needs and like to be respected. This is not to say that children do not have these characteristics. It simply means with adults; these attributes are more pronounced than in children. The terms pedagogy (how children learn) and andragogy (the art and science of helping adults to learn) (Knowles 1975) arise from the differences between how adults and children learn. Two of the main  tenets  of  andragogy  is  that  adults  are  self-directed  learners  who  take  control  and responsibility for their own learning (Knowles 1975; Wilcox 1996). Adult learners do this by identifying what their learning needs are, a process that is followed by goal development, formulating a learning plan, determining and locating learning resources, implementing the learning plan and evaluating results. When it comes to evaluating results, adults prefer to evaluate  their  own  progress  or  to  be  involved  in  the  evaluation  of  their  learning  (self- evaluation). They also like to regulate the pace of their learning. Their hands-on characteristics make  adult  learners  to  be  autonomous, self-managing,  self-monitoring  and  self-modifying (Costa and Kallick 2004; Tholin 2008). These characteristics set adult learners apart from children who mostly depend on the teacher for the teaching and learning processes. In schools where children learn, teachers determine the content and learning pace.  

There appears to be a connection between andragogy and constructivism. Like andragogy, constructivism (Vygotsky 1978; Dewey 1938) entails active engagement and involvement of students in the teaching-learning encounter. In andragogy and constructivism students co- construct and co-create, rather than passively receive knowledge. The same principle applies in self-assessments. The relevance of andragogy and constructivism to this article lies in SDL, which appears to be a central feature of both. Consequently, SDL, which is intrinsic in both andragogy and constructivism, is used as a unit of analysis in this article. 

**CONCEPTUALISING SELF-ASSESSMENTS**  

Self-assessment  involves  students  making  informed  decisions  or  judgements  about  their performance and about the outcomes of their learning (Brown and Harris 2014). Therefore, self-assessment is more than merely assigning marks or scores to yourself (Boud 1995). The central  purpose  of  self-assessment  is  learning,  which  invariably  leads  to  growth  and development. Westraadt (2017, 4) maintains that self-assessment “helps students [to] become 

aware of shortfalls in their learning”. Andrade, Hefferen and Palma (2014, 37) describe how, for practical work, self- and peer-assessment encourages students to carefully consider the quality of their work and to reflect on ways in which it could be improved. Reflection is therefore a basic tenet of self-assessment. Broadfoot (2000, 212) maintains that self-assessment cultivates ability for students to become reflective, which allows them to think back (or reflect) on what worked or did not work during the teaching-learning process, why it worked or did not work, and how the process can be improved. Because students are conscious during self- assessments (Tholin 2008), they are able to engage in reflection. This explains why reflection is an integral element of self-assessment. 

With  self-assessments,  students  account  for  their  learning,  growth  and  development, whereas exclusion directs their focus to the learning outcomes (Bourke 2016). Self-assessment forces students to be committed and task-oriented (Andrade and Valtcheva 2009). It can thus be deduced that lack of involvement in self-assessments diminishes students’ accountability and, in turn, their cognitive and reflective intelligence. Literature suggests that students’ voices remain largely silent in assessments (Scholtz 2016). Self-assessment is an alternative approach for asserting students’ voices in the teaching-learning situation (Bourke 2016).  

**REFLECTING ON SELF-ASSESSMENT AND SELF-DIRECTED LEARNING** 

The critical goal of self-assessment is to support student learning. This is particularly important if and when self-assessment is used formatively as a tool for learning (Taras 2010). Wride (2017) presents three goals of self-assessment: to measure mastery of content or subject matter; to demonstrate the achievement of learning outcomes and goals; and to promote learners’ personal development. Of the three, I find personal development to be the ultimate goal of self- assessment, as it leads to lifelong learning, a central feature of SDL.  

There is another strand of literature that suggests that SDL results in individuals that are critical,  reflective  and  lifelong  learners  (Warnick  and  Straquadine  n.d.). The  connection between self-assessment and SDL is that both constitute a learner-centred approach to teaching and learning which allow students to take control of their learning. What counts the most in many models of SDL (Tremblay and Theil 1991; Mok and Cheng 2001; Gibbons 2002) is the learners’ ability to self-assess. This explains the intricate relationship between self-assessment and SDL. 

**METHODOLOGY** 

**Design, sampling and approach**  

This study constituted a case study of thirty-nine student teachers who were at their fourth year 

of the Bachelor of Education degree at a South African university of technology. These students were specialising in a secondary teacher education programme. The sample was purposeful and convenient, as participants were knowledgeable about the issue that was investigated and also easily accessible to the researcher. Thirty-nine participants constituted the sample and whole population of this study. They consisted of 14 males and 25 females, with 15 African and 10 Coloured (mixed race) females; and seven (7) African, five (5) Coloured and two (2) White 

males. The action-research (AR) approach was used. Ferrance (2000) presents six AR stages, namely, Identifying the research problem; Collecting data; Data analysis; Acting on evidence; Evaluating results; and Next steps. These stages were adopted in this action research study. Qualitative  data  were  analysed  thematically  using  codes,  whereas  quantitative  data  were analysed statistically, as presented in the descriptive statistics, bar graphs and scatterplots below.** 

**Ferrance’s Stage 1: Identifying research problem** 

Stage 1 of the action research involved identifying the research problem (Ferrance 2000). An assessment module, which included the theory and practice of assessments, was an instrument through which the research problem was diagnosed. The theoretical aspect of the module covered  the  following  components:  conceptual  description  of  assessments;  formative  and summative assessments; and self-assessments and peer-assessments. The practical component comprised practical activities in which students conducted self-assessments. The researcher took into cognisance the fact that students had never administered self-assessments before, which she regarded as a serious gap in their knowledge and skills. In the light of this problem, she gave students self-assessment tasks so that they could apply theory in real-life situations. She believed that hands-on experiences would give them the skills they needed as future teachers and lifelong learners, and that they would contribute to SDL. The formative self- assessments took the oral and essay-type forms and were done in two AR cycles. They are presented below: 

- Oral Presentation 1: The world has become a complicated place for parents and teachers to educate children. Present at least five challenges that modern-day teachers encounter in the classrooms and the strategies that you can employ to address them. 
- Essay 1: Write a five-page, double spaced, 12-font size essay on your understanding of personality. What roles do schools and communities play in shaping the personality of children?** Use literature to support your** arguments**.** 

**Stage 2: Collecting data** 

Ferrance (2000, 17) asserts that gathering of data is an integral step which determines the action that needs to be taken. In this study, the researcher gave participants an opportunity to assess their performance on the two tasks using a rubric. The assessment criteria in the rubric (Table 1) were thoroughly explained to the students before they were used.  

**Table 1:** Assessment Rubric** 



|**Grading Strategy** |**75‒100** |**60‒74** |**50‒59** |**Below 50** |**Total** |
| - | - | - | - | - | - |
|**Assessment Criteria** |**Excellent** |**Good** |**Moderate** |**Poor** ||
|Topic Mastery/Clarity ||||||
|Conceptualisation of Ideas ||||||
|Logical Flow of Ideas/Organization ||||||
|Authenticity/Creativity ||||||
|Language ||||||
|Referencing ||||||
||
| :- |
|After  the  students  had  self-assessed  their  work,  the  researcher  collected  qualitative  and|
|quantitative  data.  She  obtained  qualitative  data  through  semi-structured,  open-ended|
|interviews, which solicited data on students’ experiences of self-assessments, namely, how they|
|felt about what they had learned; what they found challenging or fulfilling in self-assessment|
|and how it influenced their learning. The contribution of these experiences to students’ SDL|
|was subsumed in the responses given.  |
|Quantitative data were collected from the scores that students had assigned themselves|
|during the self-assessments of the two tasks, as well as from the scores that the researcher had|
|allocated the students for the two tasks. Each set of the assessment tasks weighed 100 per cent.|
|The researcher recorded and collated the scores of the different data sets separately.  |
||
|**Stage 3: Analysing data** |
|Data from interviews were analysed using coding and emergent themes. Kawulich (2004) holds|
|that coding data includes looking for patterns and themes. Different emergent data sets were|
|coded in different colours, which was followed by grouping, regrouping and categorising|
|similar and different data into separate themes and sub-themes. After categorisation of data, the|
|analysis yielded the following emergent themes: Students’ ambivalence about self-assessing|
|their work; Transparency, empowerment and motivation; and Autonomy and consciousness.  |
|Quantitative data sets were analysed statistically and presented in the form of descriptive|
|statistics, bar graphs and scatterplots, which helped in the interpretation of students’ self-|
|assessment experiences. This information would shed light on how self-assessment experiences|
|had contributed to students’ SDL. The researcher used her assessment scores to benchmark|

students’ accuracy in self-assessments, in keeping with a view held by Gholami (2016); Brown, Andrade  and  Chen  (2015)  and  Butler  (2011).  The  assumption  was  that  the  lecturer’s assessments  were  more  accurate  than  the  students’,  based  on  the  former’s  assessment experiences and capabilities. The formula used was that the wider the correlations were between self-assessment scores and lecturer assigned scores, the further away students were from being accurate in self-assessments and from attaining SDL skills as assessors. Nonetheless, these were the scores of all the students. It would be naïve to generalise these experiences to individual students, unless individuals’ scores had been separately compared and contrasted with those of the lecturer. Be that as it may, this picture provided a general idea of where the students stood in respect of self-assessments.  

The emergent themes from interviews (qualitative data) during the first AR cycle are presented in the next section, followed by statistical analysis of the quantitative results. 

**RESULTS OF THE FIRST ACTION RESEARCH CYCLE**  

**Students’ ambivalence about self-assessing their work** 

Interviews with students indicated that approximately half of them were uncertain about their self-assessment abilities. Mzingisi was one of these students who asserted that, 

“While self-assessment gave us a feeling of accomplishment and boosted our self-esteem, it also raised doubts as to whether we had mastered the skill. I’m not really sure (chuckling) ....” 

Cherylene reiterated Mzingisi’s words, expressing a feeling of self-doubt about her ability to assess her own work:  

“Having enjoyed marking my own work, I however can’t say with certainty that I did it the correct way. I can sense euphoria among students, but I wonder how many can claim to have done it correctly. Judging your own performance without being subjective ... that’s tough.” 

Juanica expressed the same sentiment: 

“My gut feeling is that I am not there yet. I do not yet have the tools good enough to be ready to assess my work.” 

Clearly, even though half of the students might have enjoyed the opportunity to assess their work, they were apparently still apprehensive about their ability to perform this task. This confirms Quoc Lap’s (2005) assertion that students’ cognitive ability or capacity, readiness and self-confidence are factors critical to their autonomy to assess their own work. Arguably, these students still operate in “expert paradigm” (Lester 1998), which assumes that there is only one way  of  correctly  doing  assessment,  that  is  the  one  used  by  lecturers.  Undoubtedly,  this ambivalence  hinders  students’  divergent  thinking.  Clearly,  Cherylene’s  assertion  about subjective  judgement  of  one’s  performance  is  misguided  and  presumably  suggests  that assessments done by lecturers are not subjective, an assertion that may not be true. Nthabiseng referred to her learning style, stating that,  

“I feel more comfortable being marked by lecturer. That’s just the way I learn. I need structure in my learning, and self-assessment disrupts everything I have learned at university so far.” 

According to Tholin (2008), students’ learning styles are different; a point which apparently justifies  Nthabiseng’s  apprehension  and  discomfort  with  self-assessments.  The  theory  of multiple intelligences advocated by Gardner (1983) provides an explanation for how students learn ‒ their learning styles and how they draw on different intelligences to solve problems. This might explain students’ apprehension about self-assessments – that they are (or might) not be compatible with their learning styles.  

**Transparency, empowerment and motivation** 

More than half of the students explained that they generally experienced assessment as a curriculum area laden with power struggles between students and lecturers, whereas others noted that self-assessment challenged these unequal power relations. Mandisa’s comment was that, 

“When we get our scripts back it’s always a struggle, with some lecturers trying to explain why and how we obtained the marks we did. This unpleasant experience leaves many students angry and disempowered. Self-assessment was a transparent experience that made it possible for us to learn from what we were doing.” 

Matheus echoed the same sentiment, mentioning that,  

“Self-assessments have no hidden agendas. We understood how we achieved our marks because we were hand-on, something that never happens with lecturer assessments.” 

Edrees focused on the power that students obtained from assessing their own work, expressing his opinion thus:  

“There was a power-shift from lecturer to us. For a change it felt good to have that power and control.” 

Nonetheless, Gcina apparently did not think that students had real power, asserting that, 

“We were not 100% empowered, because the lecturer also assessed us. She gave us some power, but took other power away from us.”  

While there may be truth in Gcina’s words, Boud (2003) points to the complexity inherent in self-assessment. If students are not monitored, they may face a situation where they are not able to deal independently with that data. Other research indicates that when students self-assess, they tend to rate themselves more highly than the teachers do (Boud and Falchikov 1989). Self- assessment is a lifelong process that students cannot master overnight (Boud, Lawson and Thompson 2013). With time, and after they have developed cognitive capabilities, students can self-assess autonomously as self-directed learners. 

Ten students reported that self-assessments inspired and motivated them to learn, as articulated by Laura, 

“Lecturer assessments can sometimes be discouraging. Self-assessments motivated us to learn, which most students hardly ever experience from lecturer assessments.”  

Evidently, judging by the students’ accounts, the positive experiences of feeling empowered and motivated brought about by self-assessments might have contributed positively to their SDL.  

**Autonomy and consciousness**  

Autonomy is a buzzword in the discourse on andragogy and SDL. Autonomy is synonymous with  freedom.  According  to  Tholin  (2008),  teachers  can  use  self-assessment  to  enhance learners’ autonomy. He holds that self-assessment and autonomous learning are intricately linked, and that self-assessment provides learners with an opportunity to become conscious of the learning process. Eight students described how self-assessments had turned them into autonomous learners, a fact expressed by Dumisani who mentioned that,  

“It really helped me to figure out on my own where and how I went wrong, especially with respect to the essay component. I am sure that if Prof. [lecturer] had marked it, we wouldn’t know where we went wrong, because, as always (chuckling), our interest would have been on the marks.” 

Dumisani’s statement implies that he took control and became responsible for his own learning, 

rather than relying on the lecturer. Taking control and responsibility are integral components of SDL. Nation (2001, 394) defines the autonomous learner as “[one that] takes control and responsibility for their own learning”. Freedom comes with responsibility. When students become autonomous, they must be accountable as well. Complementing Dumisani, Jabulile asserted that, 

“The lecturer did not point out our errors to us. Instead we found out ourselves as we went through self-assessments. We had to focus every step of the way, as at the end we were expected to take responsibility for our performance.” 

Jabulile and Dumisani’s words echo those of Andrade and Du (2007), Boud (2003) and Costa and Kallick (2004), who advocate that SDL leads to responsible learners capable of evaluating and reflecting on the learning process. Dumisani alluded to the students’ tendency to pay more attention to the marks or product rather than the process. Bourke (2010) refers to this tendency as surface learning, which is contrary to deep learning. Torrance (2007) emphasises the same point, that paying attention to the scores rather than the learning process has no value or impact on the learners. Kitsantas, Reiser and Doster (2004) concur, that focusing on the product detracts from deep learning and hinders growth and development. Jabulile was of the same view, that as conscious students (Tholin 2008), they had to “focus every step of the way”.  

**Analysing quantitative data obtained during the first action research cycle**  

It was explained earlier that the lecturer also assessed students’ work and used her scores to benchmark against students’ self-assessment scores. As indicated earlier, during the first AR cycle, students had performed two tasks weighing 100 per cent each. In Table 2 descriptive statistics represent a comparison between the students’ self-assessments and the lecturer’s scores. 

**Table 2:** Descriptive Statistics Report 1** 



|<p>**Summary Section** </p><p>**‒ Student &** </p><p>**Lecturer Scores** </p>|**Count** |**Mean** |**Standard Deviation** |**Standard Error** |**Minimum** |**Maximum** |**Range** |
| - | - | - | - | :-: | - | - | - |
|Task 1: Stud 1\_1 |39 |74\.35897 |5\.887038 |0\.9426806 |58 |88 |30 |
|Task 1: Lect 1\_1 |39 |63\.07692 |3\.428861 |0\.5490571 |58 |71 |13 |
|Task 2: Stud 1\_2 |39 |71\.02564 |2\.80495 |0\.4491515 |66 |76 |10 |
|Task 2: Lect 1\_2 |39 |60\.25641 |4\.744626 |0\.7597481 |52 |72 |20 |

Clearly, the variation noted between self-assessment scores and those assigned by the lecturer was high, as shown by the maxima of 88 per cent and 76 per cent on students’ self-assessment scores, compared with 76 per cent and 72 per cent on lecturer’s scores. This is also evident in the minimum scores for Task 2: 66 per cent on students’ self-assessment, compared with 52 per cent on lecturer’s scores. Similarly, the mean difference between self-assessment scores and those assigned by the lecturer was high, with 74 per cent and 71 per cent on students’ self- assessments, compared with 63 per cent and 60 per cent on lecturer’s scores.  

Panadero and Romero (2014) define self-assessment accuracy as the deviation that occurs between  the  student’s  self-score  and  the  evaluator’s  score.  Therefore,  wide  discrepancies between students’ self-assessments and lecturer’s mean scores might be an indication that students’ accuracy in self-assessments is (still) low. This might suggest that students have not yet attained SDL skills that enable them to regulate their own learning. Graphically, the results of students’ self-assessment and lecturer’s scores in the first task are presented in Figure 1. 

**Stud 1\_1  Lect 1\_1** 

Histogram

50 ![](Aspose.Words.f3e24798-799a-4bd9-a21e-50564069445b.001.png)

Histogram

40 ![](Aspose.Words.f3e24798-799a-4bd9-a21e-50564069445b.002.png)

40 

30 

30 

20 

20 

10 

10 

0 

0 

50 60 70 80 90 55 60 65 70 75

Stud1\_1 Lect1\_1

**Figure 1:** Stage 4: Acting on evidence  

In the light of students’ apprehension about self-assessments and discrepancies in the statistical results above, the lecturer decided to give students additional self-assessment opportunities. She gave them two oral presentations and one essay task to self-assess, as shown below: 

- Oral Presentation 3: Present two scenarios in which you experienced I-You and I-It relationships. How did each experience affect you and what did you learn? How would you use what you learnt in a classroom environment?  
- Oral Presentation 4: As a teacher, what is your interpretation of Maslow’s hierarchy of needs? What strategies can you use to ensure that learners’ hierarchy of needs are catered 

  for in your classroom? What role do you expect parents to play in meeting learners’ needs?  

- Essay 2: Write a five-page, double spaced, 12-font size essay on whether or not, in your opinion, transformation is a reality in teacher education. Align your discussion with the Policy on the Minimum Requirements for Teacher Education Qualifications (MRTEQ). Highlight some of the challenges related to implementing diversity and transformation in the classroom. 

The researcher used the same methods of data gathering and analysis as during the first AR cycle. The two emergent themes from qualitative data were “Goal-setting, independence and lifelong learning” and “Motivation and consciousness”. They are presented in the next section, followed  by  analysis  of  quantitative  data  obtained  from  students’  self-assessments  and lecturer’s scores given during the second AR cycle.  

**RESULTS OF THE SECOND ACTION RESEARCH CYCLE**  

**Goal-setting, independence and lifelong learning**  

During the subsequent AR cycle, results showed that students’ experiences of self-assessments had slightly improved than during the first cycle. Jennifer’s comment was, 

“By assessing my work, I was able to achieve my objectives that I set for myself as an aspirant teacher. With these skills, I will be able to assess my learners’ work independently and with accuracy.”  

Jennifer’s words seem to suggest that she has clear objectives that she wants to achieve, a fact that confirms that adult learners are goal-oriented. Self-assessments: have a great potential to guide students towards achieving their lifelong goals (Auda 2013). 

Like Jennifer, Samuel seemed to suggest that self-assessment develop lifelong learners by asserting that, 

“After doing self-assessments again, I realized that the lecturer was preparing us to be better teachers. The second phase facilitated more learning. Interaction encouraged us to deliberate on different answers and on finding common ground.” 

It would appear that Jennifer and Samuel were of the view that assessing their work was preparing them as lifelong teachers and citizens who could reflect and critically evaluate their actions. All these are essential components of SDL and constructivism. Mutual interaction (dialogic encounter) is an essential tool that allows students to assert their voices and through which lecturers can democratise the teaching-learning process (Mumba 2000). Pondering on divergent solutions rather than seeking one right answer is in line with Lester (1998), who criticises convergent thinking, probably because convergent thinking hinders SDL. 

**Motivation and consciousness**  

Interpretation of assessment criteria/rubric is critical in self-assessments (Boud 2003). Students were asked about their experiences of interpreting rubrics, in order to establish whether, and how, that activity had contributed to their SDL. Kenny’s response was that 

“Interpreting the rubrics was the toughest thing to do. However, it kept us focused on the task and boosted our self-concept.”  

Deducing from Kenny’s words, one gets a sense that this activity helped students to become self-directed learners. This is because motivation, focus/consciousness and self-efficacy feature prominently in andragogy and SDL (Saeid and Eslaminejad 2017). 

**Analysis of quantitative data obtained during the second action research cycle**  As during the first AR cycle, the researcher assessed alongside students’ self-assessments, using the  same  formula  as  before  to  determine  their  scoring  patterns.  Quantitative  results  are presented in Table 3. 

**Table 3:** Descriptive Statistics Report 2** 



|<p>**Summary Section** </p><p>**‒ Student &** </p><p>**Lecturer Scores** </p>|**Count** |**Mean** |**Standard Deviation** |**Standard Error** |**Minimum** |**Maximum** |**Range** |
| - | - | - | - | :-: | - | - | - |
|Task 1: Stud 2\_1 |39 |65\.4359 |3\.789146 |0\.6067489 |55 |75 |20 |
|Task 1: Lect 2\_1 |39 |64\.84615 |3\.289045 |0\.5266686 |60 |71 |11 |
|Task 2: Stud 2\_2 |39 |69\.07692 |3\.140438 |0\.5028725 |60 |76 |16 |
|Task 2: Lect 2\_2 |39 |67\.07692 |2\.92345 |0\.4681266 |60 |72 |12 |
|Task 3: Stud 2\_3 |39 |71\.35897 |2\.869872 |0\.4595474 |67 |78 |11 |
|Task 3: Lect 2\_3 |39 |69\.92308 |2\.87809 |0\.4608632 |65 |78 |13 |
||
| :- |
|Analysis of the quantitative results obtained during the second AR cycle revealed that the mean|
|difference between the self-assessment scores and those assigned by the lecturer had decreased|
|markedly. So, too, did differences in the maximum and minimum scores decrease. However,|
|the range of the differences had not changed dramatically. Therefore, the correlations between|
|the lecturer’s scores and those of students for the same items tended to stay low, as can be|
|observed in the scatterplots presented in Figure 2. |
||
**Stud 2\_1 vs Lect 2\_1   Stud 2\_2 vs Lect 2\_2**

Stud1\_1 vs. Lect1\_1

90 Stud2\_1 vs. Lect2\_1![](Aspose.Words.f3e24798-799a-4bd9-a21e-50564069445b.003.png)

75![](Aspose.Words.f3e24798-799a-4bd9-a21e-50564069445b.004.png)

80

70

70

65

60

60

50 55

55 60 65 70 75 60 65 70 75 Lect1\_1 Lect2\_1

**Stud 2\_3 vs Lect 2\_3** 

Stud2\_3 vs. Lect2\_3

80 ![](Aspose.Words.f3e24798-799a-4bd9-a21e-50564069445b.005.png)

75 

70 

65 

65 70 75 80

Lect2\_3

**Figure 2:** Correlations between the lecturer’s scores and those of students for the same items 

Ideally, one would have expected the correlations to be high, given the decrease between the mean scores of the data sets. However, this was not the case, as correlations remained relatively low between students’ self-assessment and lecturer-assigned scores. One assumption for this could be that some students lowered their self-assessment scores drastically, whereas others did not.  Therefore,  the  precision  in  students’  self-assessments  is  still  lacking.  These  results contradict those of Sung et al. (2005), that once students are taught to self-assess, agreement between teacher’s and students’ scores increases.  

**Stage 5: Evaluating results** 

Based on these results, the researcher reached a conclusion that students had not gained the rudimentary knowledge and skills of assessing their own work. This invariably meant that they had not yet attained the SDL skills. Low correlations and the wide range between the scores assigned by students to themselves and those assigned by the lecturer remained of serious concern to the lecturer. She interpreted them to mean that the students had not yet attained SDL. The implication was that there was a need to incorporate self-assessments into university curriculum and for more opportunities for students to practice self-assessments. 

**Stage 6: Follow-up remedial steps** 

Based on the results obtained from the second AR cycle, the researcher decided to add more self-assessment activities in her subject and to hone students’ skills in interpreting rubrics. She also requested two colleagues to give their students additional self-assessment activities to augment the previous ones. Boud et al. (2013) maintains that accurate self-assessment requires multiple opportunities for students to practice within and across courses. Kitsantas, Reiser and Doster (2004) support this view and state that if self-assessments are conducted frequently, many students benefit from such practice.  

**ETHICAL CONSIDERATIONS** 

When the students undertook the assessment module, the lecturer informed them that this subject was going to have a research component incorporated in it. Before the investigation commenced, student gave verbal consent to participate in the study. Ethical considerations were made to explain the details of the study and to assure participants that the study did not involve any harm. She also explained confidentiality issues, namely, that pseudonyms instead of their real names would be used in the reporting of results. Participants were given a chance to ask questions related to the study. The lecturer also explained to the participants that participation was voluntary, and that they could withdraw from participating in the study at any time if they wished  so.  With  regard  to  ethical  clearance,  the  lecturer  applied  for  it  from  the  Ethics Committee of the faculty in which students were enrolled. During the duration of the study, the lecturer was aware of her bias that could be caused by the fact that she was serving as lecturer and researcher. She therefore took precautionary measures to ensure that she did not manipulate the results to confirm her hypothesis. 

**DISCUSSION**  

This study investigated student experiences of self-assessments, with the goal of establishing how self-assessments contributed to their SDL. During the first AR cycle, there were students who  articulated  apprehension  about  self-assessments,  which  showed  high  dependency  on lecturer-assessments.  Be  that  as  it  may,  others  used  words  such  as  “transparent”,  “self- regulate”,  “reflect”,  “take  responsibility”,  “focus  on  process”,  all  of  which  are  central  to andragogy, SDL and constructivism. Mandisa’s statement, “learning from what we were doing” 

(experiential  learning)  (Kolb  2015;  Schön  1987)  links  perfectly  with  the  assumption  of andragogy (Knowles 1975), as well as with SDL and Vygotsky’s (1978) constructivist approach to learning. Similarly, the comment made by Edrees of having power and control resonates with Overlie (2009), who contends that self-assessments empower students to think and verbalize their thoughts. These responses could be an indication that students felt that their participation in self-assessments helped them to attain some SDL skills, albeit few. Nonetheless, the first benchmarking activity revealed that students had not yet reached a point where they could be deemed SDL. Similarly, the second one did not show much improvement, as correlations continued to remain low, even though the mean differences improved.  

Autonomy is one of the most central features of SDL. Gholami (2016, 47) holds that the most successful learners take responsibility for their learning. Several students articulated feeling autonomous as a result of the opportunity to assess their work. Dumisani and Jabulile mentioned “figur[ing] out on my own where and how I went wrong” and “found out ourselves”, and Mathew commented on “understood how we achieved our marks because we were hands- on”. These experiences confirm Tholin’s (2008) view, that self-assessment is intrinsic to SDL. Evidently, self-assessment allowed participants to achieve autonomy, a central feature of SDL. Taking responsibility for one’s learning is the core of SDL and constructivism. Gholami (2016, 47) maintains that “Accepting responsibility of one’s own learning is not only a gradual development  of  metacognitive  mastery  of  the  learning  process.  Autonomy  has  another dimension namely self-management.”  

Literature  shows  that  gaining  autonomy  is  not  easy.  Boud  et  al.  (2013)  assert  that mastering self-assessment ‒ and thereby attaining autonomy is a complex skill which is not developed after one or two exercises. Equally crucial is the experience of gaining lifelong (self- assessment) skills that students might have gained. Like autonomy, lifelong learning is central to  SDL.  Therefore,  self-assessments  contributed  enormously  to  students’  growth  towards becoming SDL. 

Ten students experienced being “motivated” by self-assessments. Motivation is one of the five pillars underlying andragogy and SDL (Knowles 1975; Warnick and Straquadine n.d.). One student reported that self-assessments kept them focused in the learning process and conscious of what was happening. This is unlike when they are assessed by lecturers, in which case they blindly accept marks without becoming consciously involved or learning anything from the assessment process. Tholin (2008) postulates that if learners are to be able to make informed choices that contribute to their growth and development, they must be conscious learners who are aware of what happens during the teaching and learning process. Similarly, Gardner and Miller (1999) conceive of self-assessment as a tool that raises learners’ awareness. Broadfoot (2000) maintains that being conscious of the learning process helps students to develop reflective intelligence, which invariably leads to SDL. 

Results  obtained  from  benchmarking  students’  self-assessment  against  the  lecturer’s scores cannot be underestimated. They revealed that during the AR cycles students had not attained SDL. Clearly, with more practice, greater improvement could be expected in students’ self-assessments. 

After an analysis of the students’ experiences of self-assessments, the next question is whether their experiences of self-assessments led to their becoming self-directed learners. Judging by the discrepancies that still manifested themselves in students’ self-assessment and lecturer’s scores, it is difficult to conclude that students attained SDL skills. It may be possible that, after further practices, students will eventually attain these skills. What remains clear is that during the two AR cycles, students did not reach the level of becoming self-directed learners. 

**CONCLUSION**  

The experiences reported by students on self-assessments, especially during the second AR cycle,  are  encouraging.  They  might  suggest  that  university  lecturers  need  to  transform traditional,  teacher-centred  assessment  approaches  and  replace  them  with  learner-centred approaches that include self-assessments. As shown in this study, the latter approach has great potential for contributing to SDL. During the 21st century, there is much emphasis on the use of technology and on learner-centred teaching. Therefore, applying constructivist approaches such as self-assessments are crucial, as they can assist students to become autonomous, self- regulated, reflective and self-directed citizens and employees needed in the workplace and also by the country. Nonetheless, it has to be noted that self-assessment is but one instrument that can be used to hone students’ SDL skills in a constructivist manner. Therefore, the researcher is not advocating self-assessment as a panacea for all the weaknesses in the assessment of students’ work. Rather, she argues that it should be considered in the university curriculum as a tool that can help to produce self-regulatory, autonomous and self-directed learners. 

Further research should include an analysis of individual students’ self-assessment scores, as results could highlight salient differences among students with regard to the type of support they need towards becoming self-directed learners. In an effort to produce individuals who can direct their learning and evaluate their growth and development, it is recommended that self- assessments should be integrated into the university curriculum and across different courses. To achieve this, universities should strive to transform the mind-sets of lecturers who still cling to traditional, teacher-centred assessment approaches. In addition, university policy-makers should revisit their assessment policies and make them constructivist, inclusive and learner- centred. 

**REFERENCES** 

Andrade, H. and A. Valtcheva. 2009. Promoting learning and achievement through self-assessment. 

*Theory into Practice* 48: 12–19. 

Andrade, H. and Y. Du. 2007. Student responses to criteria-referenced self-assessment. *Assessment and* 

*Evaluation in Higher Education* 32(2): 159–181. 

Andrade, H., J. Hefferen and M. Palma. 2014. Formative assessment in the visual arts. *Art Education* 

67(1): 34‒40.  

Andrade,  H.  L.  2010.  Students  as  the  definitive  source  of  formative  assessment:  Academic  self-

assessment and the self-regulation of learning*.* In *Handbook of formative assessment,* ed. H. L. Andrade and G. J. Cizek, 90–105. New York: Routledge*.*  

Auda, Z. J. 2013. The impact of using scoring rubrics in peer assessment in promoting Iraqi EFL 

learners’ speaking skill at the university. MA Thesis. University of Basrah. 

Beaumont, C., M. O’Doherty and L. Shannon. 2011. Reconceptualising assessment feedback: A key to 

improving student learning? *Studies in Higher Education* 36(6): 671–687. 

Beets, P. A. D. 2007. (Re)positioning assessment in higher education: the case of Geography in South 

Africa. *South African Journal of Higher Education* 21(4): 577–584. 

Bloxham, S. 2016a. Central challenges in transforming assessment at departmental and institutional 

level. Keynote address at the Assessment in Higher Education (AHE) Seminar Day, Transforming Assessment and Feedback in Higher Education on a Wider Scale: The Challenge of Change at Institutional Level, 30June 2016, Manchester, UK. 

Bloxham, S. 2016b. *Driving better assessment practice at the institutional level: Infrastructure, strategy* 

*and  professional  development*.    https://www.kent.ac.uk/studentsuccess/national%20context/ Innovation%20and%20Excellence%20in%20Teaching%20and%20Learning%20Speaker%20pre sentations/Professor%20Bloxham.pdf (Accessed 26 September 2017). 

Boud, D. 1995. *Enhancing learning through self assessment*. London: Kogan Page. Boud, D. 2003. *Enhancing learning through self-assessment.* London: RoutledgeFalmer. 

Boud, D. and N. Falchikov. 1989. Quantitative studies of student self-assessment in higher education: 

A critical analysis of findings. *Higher Education* 18(5): 529–549.  

Boud, D., R. Lawson and D. Thompson. 2013. Does student engagement in self-assessment calibrate their judgement over time? *Assessment & Evaluation in Higher Education* 38(3): 941–956. 

Bourke, R. 2010. *The chameleonic learner: Learning and self-assessment in context*. Wellington, New 

Zealand: New Zealand Council for Educational Research (NZCER) Press. 

Bourke, R. 2016. Liberating the learner through self-assessment. *Cambridge Journal of Education* 

46(1): 97–111. 

Broadfoot, P. 2000. Assessment and intuition. In *The intuitive practitioner: On the value of not always* 

*knowing what one is doing,* ed. T. Atkinson and G. Claxton, 199–219. Buckingham, UK: Open University Press.*  

Brown, G. T. L. and L. R. Harris. 2014. The future of self-assessment in classroom practice: Reframing 

self-assessment as a core competency. *Frontline Learning Researc*h 2(1): 22–30. 

Brown, G. T. L., H. L. Andrade and F. Chen. 2015. Accuracy in student self-assessment: Directions and 

cautions for research. *Assessment in Education: Principles, Policy & Practice* 22(4): 444–457.  

Butler,  R.  2011.  Are  positive  illusions  about  academic  competence  always  adaptive,  under  all circumstances: New results and future directions. *International Journal of Educational Research* 

50(4): 251–256. 

Cardoso,  W.  C.  2010.  *Learner  autonomy  and  self-assessment:  indispensable  tools  for  successful* 

*learning,* 24–25.* Sao Paulo: Instituto Cervantes.  

Costa, A. L. and B. Kallick. 2004. *Assessment strategies for self-directed learning*. Thousand Oaks, CA: 

Corwin Press. 

Deehan, J. 2016. *Self-assessment: A powerful tool to improve student learning and understanding*. 

Edutopia.  https://www.edutopia.org/discussion/self-assessment-powerful-tool-improve-student- learning-and-understanding (Accessed 4 June 2019). 

Dewey, J. 1938. *Experience and education*. Toronto: Collier-MacMillan Canada Ltd. 

Du, F. 2013. Student perspectives of self-directed language learning: Implications for teaching and 

research*. International Journal for the Scholarship of Teaching and Learning* 7(2): 1–16. 

Ferrance, E. 2000. *Action research*. Providence, RI: LAB at Brown University. 

Ferrell, G. and L. Gray. 2016. *Changing assessment and feedback practice*.  https://www.jisc.ac.uk/ 

guides/changing-assessment-and-feedback-practice (Accessed 4 June 2019).  

Freire, P. 1973. *Pedagogy of the oppressed*. New York: Seabury Press. 

Gardner, H. 1983. *Frames of mind: The theory of multiple intelligences*. New York, NY: Basic Books. 

Gardner, D. and L. Miller. 1999. *Establishing self-Access: Theory to practice*. Cambridge: Cambridge 

University Press.  

Gehringer, E. F. 2017. Self-asessment to improve learning and evaluation. *Proceedings of the 2017* 

*American Society for Engineering Education (ASEE) Conference*, 1–10. Columbus, Ohio, 25‒28 June 2017. 

Gholami, H. 2016. Self assessment and learner autonomy. *Theory and Practice in Language Studies* 

6(1): 46–51. 

Gibbons, M. 2002. *The self-directed learning handbook: Challenging adolescent students to excel*. San 

Francisco: Jossey-Bass. 

Grant-Smith, D., A. Cathcart and P. Williams. 2015. *Enhancing management students’ professional* 

*presentation  skills  through  self  and  peer  assessment  calibrating  judgement  using  the  3D presentation framework* (Griffith University, Australia, the Australian and New Zealand Academy of Management Secretariat Office). http://www.anzam.org/wp-content/uploads/2017/02/Grant- Smith-Cathcart-2015.pdf (Accessed 10 May 2018). 

Henderson, M., T. Ryan and M. Phillips. 2019. The challenges of feedback in higher education. *Assessment and Evaluation in Higher Education*. DOI: 10.1080/02602938.2019.1599815.  

Kawulich, B. 2004. *Data analysis techniques in qualitative research*.  https://www.researchgate.net/ 

publication/258110388\_Qualitative\_Data\_Analysis\_Techniques (Accessed 20 October 2018). 

Kitsantas, A., R. A. Reiser and J. Doster. 2004. Developing self-regulated learners: Goal setting, self-

evaluation,  and  organizational  signals  during  acquisition  of  procedural  skills.  *Journal  of Experimental Education* 72(4): 269–287. 

Knowles, M. 1975. *Self-directed learning*. Chicago: Follet. 

Kolb, A. D. 2015. *Experiential learning: Experience as the source of learning and development.* 2nd

Edition. Australia: Pearson Education Inc. 

Lester, S. 1998. Assessment v self-directed learning: A way forward. Paper produced for the Higher 

Education for Capability, Department of Education and Employment Conference, “Standards for the Assessment and Capability”, 10 June 1998. 

Lundie,  S.  2017.  [RE]conceptualising  assessment  within  a  higher  education  curriculum.  Thesis 

submitted  for  the  degree  Doctor  Philosophiae  in  Curriculum  Development,  North-West University. 

Mok, M. M. C. and Y. C. Cheng. 2001. A theory of self‐learning in a networked human and IT environment: Implications for education reforms. *Journal of Educational Management* 15(4): 

172–186.  

Mumba, P. 2000. Democratisation of primary classrooms in Zambia: A case study of its implementation 

in a rural primary school in Mpika. Paper presented at International Special Education Congress 2000,  24‒28  July  2000,  University  of  Manchester,  UK.   http://www.isec2000.org.uk/ abstracts/papers\_m/mumba\_2.htm (Accessed 10 July 2018). 

Nathan,  P.  2017.  Why  self  assessments  improve  learning.  https://www.oreilly.com/ideas/why-self-

assessments-improve-learning (Accessed 4 June 2019).  

Nation, I. S. P. 2001. *Teaching and learning vocabulary in another language*. Cambridge: Cambridge 

University Press. 

Nicol, D. 2010. “From monologue to dialogue: Improving written feedback processes in mass higher 

education”. *Assessment and Evaluation in Higher Education* 35(5): 501‒517. 

Office  of  the  Independent  Adjudicator  for  Students  in  Higher  Education  Annual  Report.  2015.  http://www.oiahe.org.uk/media/109675/oia-annual-report-2015.pdf (Accessed 4 June 2019). 

OIA see Office of the Independent Adjudicator for Students in Higher Education Annual Report. 

Overlie, J. 2009. Creating confident, capable learners. In *The teacher assessment leader,* ed. T. R. 

Guskey, 181‒201. Bloomington, Indiana: Solution Tree Press.* 

Panadero, E. and M. Romero. 2014. To rubric or not to rubric? The effects of self-assessment on self-

regulation,  performance  and  self-efficacy.  *Assessment  on  Education:  Principles,  Policy  & Practice* 21(2): 133–148.  

Quoc  Lap,  T.  2005.  Stimulating  learner  autonomy  in  English  language  education:  A  curriculum 

innovation  study  in  a  Vietnamese  context.  Unpublished  thesis.  University  of  Amsterdam.  https://pure.uva.nl/ws/files/3923660/49962\_Thesis.pdf (Accessed 17 October 2018). 

Ryan,  T.  and  M.  Henderson.  2018.  Feeling  feedback:  Students’  emotional  responses  to  educator 

feedback. *Assessment & Evaluation in Higher Education* 43(6): 880–892. 

Saeid, N. and T. Eslaminejad. 2017. Relationship between student’s self-directed-learning readiness and 

academic self-efficacy and achievement motivation in students. *International Education Studies* 10(1): 225–232. 

Sharma, R., A. Jain, N. Gupta, S. Garg, M. Batta and S. K. Dhir. 2016. Impact of self-assessment by 

students on their learning. *International Journal of Applied Basic Medical Research* 6(3): 226– 229. 

Scholtz, D. 2016. The assessment strategy: An elusive curriculum structure. *South African Journal of* 

*Higher Education* 30(1): 245–264.* 

Schön, D. A. 1987. *Educating the reflective practitioner.* San Francisco: Jossey-Bass. 

Sung, Y. T., K. E. Chang, S. K. Chiou and H. T. Hou. 2005.* The design and application of a web-based 

self- and peer-assessment system. *Computers & Education* 45(2):* 187–202.  

Taras, M. 2010. Student self-assessment: Processes and consequences. *Teaching in Higher Education* 

15(2): 199–209. 

Tholin, J. 2008. Learner autonomy, self-directed learning and assessment: Lessons from Swedish 

experience. *Independence* 43: 9–12. 

Torrance, H. 2007. Assessment as learning? How the use of explicit learning objectives, assessment 

criteria and feedback in post‐secondary education and training can come to dominate learning. *Assessment in Education* 14(3): 281–294. 

Tremblay, N. A. and J. P. Theil. 1991. A conceptual model of autodidactism. In *Self-directed learning:* 

*Consensus and conflict*, ed. H. B. Long and Associates, 29–51. Norman: Oklahoma Research Center for Continuing Professional and Higher Education, University of Oklahoma.  

Vygotsky, L. S. 1978. *The collected works of L. S. Vygotsky*. New York: Plenum. 

Warnick, B. and G. Straquadine. n.d. *Andragogy application for higher education. Agricultural systems technology  and  education*.  Utah  State  University.  http://www.teach-usda.ahnrit.vt.edu/ 

pages/pdfs/Andragogy.pdf (Accessed 14 August 2018). 

Westraadt, G. 2017. A new take on the assessment of first-year art projects*. South African Journal of* 

*Higher Education* 31(6): 243–257. 

Wilcox,  S.  1996.  Fostering  self-directed  learning  in  the  university  setting.** *Studies  in  Higher* 

*Education* 21(2): 165–179. 

Wride, M. 2017. *Academic practice and elearning (CAPSL) resources assessment: Guide to self-*

*assessment*. Dublin: University of Dublin Trinity College. 
96 
